<doc id="2141" url="http://en.wikipedia.org/wiki?curid=2141" title="Atari ST">
Atari ST

The Atari ST is a home computer released by Atari Corporation in June 1985. Development machines were distributed around May 1985 and it was available commercially from that summer into the early 1990s. The "ST" officially stands for "Sixteen/Thirty-two", which referred to the Motorola 68000's 16-bit external bus and 32-bit internals. Due to its graphical user interface, it was jokingly referred to as the "Jackintosh", a reference to Jack Tramiel.
The Atari ST was part of the 16/32 bit generation of home computers, based on the Motorola 68000 CPU, typically with 512 kB of RAM or more, a graphical user interface, and 3½" microfloppy disks as storage. It was similar to the Apple Macintosh, and its simple design allowed the ST to precede the Commodore Amiga's commercial release by almost two months. The Atari ST was also the first personal computer to come with a bit-mapped color GUI, using a version of Digital Research's GEM released that February.
The ST was primarily a competitor to the Macintosh, Amiga, and in certain markets the Acorn Archimedes. Where the Amiga had a graphics accelerator and wavetable synthesis based sound, the ST had a simple frame buffer and a 3 voice synthesizer chip but with a slightly faster CPU, and had a high-resolution monochrome display mode, ideal for business and CAD. In some markets, particularly Germany, the machine gained a strong foothold as a small business machine for CAD and Desktop publishing work. The Atari ST also enjoyed some market popularity in Canada. 
The ST was also the first home computer with integrated MIDI support. Thanks to its built-in MIDI, it enjoyed success for running music-sequencer software and as a controller of musical instruments among amateurs and professionals alike, being used in concert by bands and performers such as Jean Michel Jarre, Madonna, Eurythmics, Tangerine Dream, Fatboy Slim, and 1990s UK dance acts Utah Saints & 808 State, as well as naming German digital hardcore band Atari Teenage Riot.
The ST was later superseded by the Atari STE, Atari TT, Atari MEGA STE and Falcon computers.
Origins.
The Atari ST was born from the rivalry between home-computer makers Atari, Inc. and Commodore International.
Amiga contract.
Jay Miner, one of the original designers for the custom chips found in the Atari 2600 and Atari 8-bit family, tried to convince Atari management to create a new chipset for a video game console and computer. When his idea was rejected, Miner left Atari to form a small think tank called Hi-Toro in 1982 and began designing the new "Lorraine" chipset. The company, which was later renamed Amiga Corporation, was pretending to sell video game controllers to deceive competition while it developed a Lorraine-based computer.
Amiga ran out of capital to complete Lorraine's development, and Atari, owned by Warner Communications, paid Amiga to continue development work. In return Atari received exclusive use of the Lorraine design for one year as a video game console. After one year Atari would have the right to add a keyboard and market the complete computer, designated the 1850XLD. As Atari was heavily involved with Disney at the time, it was later code-named "Mickey", and the 256K memory expansion board was codenamed "Minnie".
Tramel Technology.
After leaving Commodore International in January 1984 Jack Tramiel formed Tramel Technology with his sons and other ex-Commodore employees, and in April began planning a new computer. The company initially considered the National Semiconductor NS320xx microprocessor, but was disappointed with its performance. This started the move to the 68000.
Tramiel learned that Warner wanted to sell Atari, which in mid-1984 was losing about a million dollars per day. Interested in Atari's overseas manufacturing and world wide distribution network for his new computer, Tramiel negotiated with Warner in May and June 1984. He secured funding and bought Atari's Consumer Division (which included the console and home computer departments) in July. As executives and engineers left Commodore to join Tramiel's new Atari Corporation, Commodore responded by filing lawsuits against four former engineers for theft of trade secrets. This was intended to, in effect, bar Tramiel from releasing his new computer.
One of Tramiel's first acts after forming Atari Corp. was to fire most of Atari's remaining staff and cancel almost all ongoing projects in order to review their continued viability. It was during this time in late July/early August that his representatives discovered the original Amiga contract, which required Amiga Corporation to deliver the Lorraine chipset to Atari on June 30, 1984. Amiga Corp. had sought more monetary support from investors in spring 1984 (among them Tramel Technology, which wished to replace nearly everyone at Amiga).
Commodore and Amiga.
Having heard rumors that Tramiel was negotiating to buy Atari, Amiga Corp. entered into discussions with Commodore. The discussions led to Commodore wanting to purchase Amiga Corporation outright, which Commodore believed would cancel any outstanding contracts, including Atari's. Instead of Amiga Corp. delivering Lorraine to Atari, Commodore delivered a check of $500,000 to Atari on Amiga's behalf, in effect returning the funds Atari invested into Amiga for the chipset. Tramiel countersued Amiga Corp. on August 13, 1984. He sought damages and an injunction to bar Amiga (and effectively Commodore) from producing anything with its technology.
At Commodore, the Amiga team was in limbo during the summer of 1984 because of the lawsuit. No word on the status of the chipset, the Lorraine computer, or the team's fate was known. In the fall of 1984, Commodore informed the team that the Lorraine project was active again, the chipset was to be improved, the operating system developed, and the hardware design completed. While Commodore announced the Amiga 1000 with the Lorraine chipset in July 1985, the delay gave Atari, with its many former Commodore engineers, time to deliver the first Atari ST units in June 1985. In March 1987, the two companies settled the dispute out of court in a closed decision.
Operating system.
With the hardware design nearing completion, the Atari team started looking at solutions for the operating system. Soon after the Atari buyout, Microsoft approached Tramiel with the suggestion that they port Windows to the platform, but the delivery date was out by about two years, far too long for their needs. Another possibility was Digital Research, who were working on a new GUI-based system then known as Crystal, soon to become GEM. Another option was to write a new operating system in-house, but this was rejected as Atari management was unsure whether the company had the required expertise to do so.
Digital Research was fully committed to the Intel platform, so a team from Atari was sent to the Digital Research headquarters to work with the "Monterey Team" which comprised a mixture of Atari and Digital Research engineers. Atari's Leonard Tramiel was the Atari person overseeing "Project Jason" (aka — The Operating System) for the Atari ST line of computers. The name came from the original designer and developer, Jason Loveman. Tim Oren has an article describing the history of the project, from his series "Professional GEM".
CP/M-68K was essentially a direct port of CP/M's original, mature operating system. By 1985, it was becoming increasingly outdated in comparison to MS-DOS 2.0; for instance, CP/M did not support sub-directories. Digital Research was also in the process of building a new DOS-like operating system specifically for GEM, "GEMDOS", and there was some discussion of whether or not a port of GEMDOS could be completed in time for product delivery in June. The decision was eventually taken to port it, resulting in a GEMDOS file system which became part of TOS ("The Operating System") and colloquially known as the ("Tramiel Operating System"). This was beneficial as it gave the ST a fast, hierarchical file system, essential for hard drive storage disks, plus programmers had function calls similar to the IBM PC DOS.
Whitesmiths's OS called Idris was also available for Atari ST.
Debut.
After six months of intensive effort following Tramiel's takeover, Atari announced the "520ST" at the Winter Consumer Electronics Show in Las Vegas in January 1985. Due to its similarities to the original Apple Macintosh and Jack Tramiel's role in its development, it was quickly nicknamed the "Jackintosh". Atari's rapid development of the ST amazed many, but others were more skeptical, citing the ST's "cheap" appearance, Atari's uncertain financial health, and the poor relations Commodore under Tramiel had had with software developers. In 1984 "Ahoy!" had written, before he purchased Atari, that Tramiel "had never been able to establish very good relations with computer dealers ... Under his reign, computer retailers have accused Commodore of treating the as harshly as if they were suppliers or competitors". "Computer Gaming World" stated that his poor reputation likely made computer stores reluctant to deal with Atari, hurting the company's distribution of the ST. One retailer said, "If you can believe Lucy when she holds the football for Charlie Brown, you can believe Jack Tramiel", and in 1986 a columnist for Atari magazine "A.N.A.L.O.G." warned that Atari executives seemed to emulate Tramiel's "'penny-pinching' hard-nosed bargaining, sometimes at the risk of everything else". The majority of software companies were hesitant to support another platform beyond the IBM PC, Apple, and Commodore 64, and some were unsure of whether to choose the ST or the Amiga. The public saw both Commodore and Atari as selling, as John C. Dvorak wrote, "cheap disposable" game machines.
Atari ST advertisements stated "America, We Built It For You", and quoted Atari president Sam Tramiel: "We promised. We delivered. With pride, determination, and good old ATARI know how". Although Atari was out of cash and its employees feared that Jack Tramiel would shut the company down, the 520ST shipped during spring 1985 to the press and developers and then in early July 1985 for general retail sales, saving the company. The machine had gone from concept to store shelves in a little under a year. Atari had originally intended to release versions with 128 kB and 256 kB of RAM as the "130ST" and "260ST" respectively. However, with the OS loaded from floppy into RAM, there would be little or no room left over for applications to run. The 260ST did make its way into Europe on a limited basis.
Unlike the Amiga, Commodore 64, and Atari 8-bit computers, the ST did not have hardware-supported sprites. It supported a monochrome or color monitor. The former was less expensive, and had a higher resolution with its 640 × 400. Due to its noninterlaced operation at 70 Hz, the monochrome monitor was better suited to business applications. The hardware supported two different color resolutions, 320 × 200 with 16 out of 512 colors, or 640 × 200 with 4 out of 512 colors. The attached monitor determined available resolutions, so software either supported both types of monitors or only worked with one. Color was required by a majority of games.
The ST had no battery-backed clock so time needed to be set after turning on. Early models shipped with Atari Logo and "TOS" on disk; the operating system occupied 206K RAM, but were designed with four ROM sockets to make for easy upgrading to the future ROM-based "TOS". These became available only a few months later, and were included in all new machines, as well as being available to upgrade older machines. By late 1985 the machines were also upgraded with the addition of an RF modulator (for TV display), a version known as the 520STM.
Atari had originally intended to include GEM's GDOS (Graphical Device Operating System), which allowed programs to send GEM VDI (Virtual Device Interface) commands to drivers loaded by GDOS. This allowed developers to send VDI instructions to other devices simply by pointing to it. However, GDOS was not ready at the time the ST started shipping, and was included in software packages and later ST machines. Later versions of GDOS supported vector fonts.
A limited set of GEM fonts were also included within the ROMs. These fonts also featured an addition: The standard 8x8 pixel graphical character set for the ST (the main in-ROM "font" for GEM, and text-mode TOS operations in color modes) contains, following all the standard numbers, letters, symbols and accented characters, four unusual characters. These can be placed together in a square, forming a basic but recognisable facsimile of the face of J. R. "Bob" Dobbs, the figurehead of the Church of the Subgenius.
The ST was less expensive than most machines, including the Macintosh Plus, and tended to be faster than most. Largely as a result of the price/performance factor, the ST would go on to be a fairly popular machine, notably in European markets where the foreign-exchange rates amplified prices. Indeed, the company's English advertising strapline of the era was "power without the price". In fact, an Atari ST and terminal emulation software was much cheaper than a Digital VT220 terminal, which was commonly needed by offices with central computers.
Design.
Original housing.
The original 520ST case design was created by Ira Velinsky — Atari's chief Industrial Designer. The ST was basically wedge shaped, featuring bold angular lines and a series of grilles cut into the rear for airflow. The keyboard had soft tactile feedback and rhomboid-shaped function keys across the top. The 520ST was an all-in-one unit, similar to earlier home computers like the Commodore 64. By the time the 520ST reached the market, however, consumers demanded a keyboard with cursor keys and a numeric keypad. For this reason, the 520ST ended up significantly larger than previous popular all-in-one machines like the Commodore 64.
The 520ST used an external "brick" power supply, floppy disk, monitor and mouse. Even basic system setups thus suffered from cable spaghetti, a problem future versions would address to one degree or another. Early 520ST owners became accustomed to the "Atari Twist" and the "Atari Drop" service procedures. The "Atari Twist" seemed to help discharge built-up static electricity (Atari soldered-down the metal shielding to fix the problem) while the "Atari Drop" appeared to help re-seat chips which may have become partially unseated over time.
Port connections.
The 520ST featured a large number of ports mounted at the rear of the machine. The basic port layout would remain largely unchanged over the machine's history.
Because of its bi-directional design, the Centronics printer port could be used for joystick input, and several games made use of available adaptors that plugged into the printer socket, providing two additional 9-pin joystick ports.
Atari initially used single-sided disk drives that could store up to 360 kB. Later drives were double-sided versions that stored 720 kB. Due to the early sales of so many of the single-sided drives, some commercial software, particularly games, shipped by default on single-sided disks, even supplying two 360kB floppies instead of a single double-sided one, for fear of alienating early adopters. The problem was exacerbated by the early drive's single read/write head being on the "wrong" side of the disc - that is, reading/writing the same side of the disc as a more standard 720kB drive's "second" head ("head 1") instead of its "first" ("head 0"). The boot sector and FAT was typically written to "side 0" by double-sided drives (in both STs and other marques fitted with 3.5" drives), so owners of single-sided machines could not read any useful data from a standard double-sided disc at all, not even the root directory listing, and might well mistakenly end up reformatting just one side of a seemingly "faulty" disc as a result.
ST magazines wishing to cater to the entire audience while still supplying a large amount of material on a single cover disc had to adopt innovative custom formats to work around this problem, forcing the bootsector and FAT onto "side 1", along with the disc's main feature program, and tucking supplemental programs onto "side 0" (typically falsely renamed "side B", in allusion to classic 45rpm singles), "inside" a particular file folder which would only open successfully for owners of 720kB drives. Owners of single-sided drives were encouraged, if they wished to gain access to "side B", to send the original coverdisk(s) back to the publisher with a token fee for postage and duplication, for which they would be sent a set of single-sided discs containing the full software complement. This scheme was also operated by some producers of productivity software in later years, mirroring the PC situation where software would ship by default on a particular disc format (3.5" or 5.25", double or high density) and a customer who bought the wrong type could have it replaced by mail order.
Another early sticking point with the ST's floppy drives was that, whilst double-sided drive equipped STs could happily read discs formatted under MS-DOS on IBM PCs, PCs could not themselves read Atari disks, because the initial versions of TOS could recognise, read, and write to - but not themselves create - discs in the same particular specification used and indeed demanded by MS-DOS (single-sided Atari drives were completely incompatible in either direction, as MS-DOS never officially supported single-sided 3.5" hardware, and still placed its filesystem information on "side 0"). Achieving successful data interchange between the two platforms using floppies thus required pre-formatting dedicated file transfer discs under MS-DOS, and copying the necessary data onto them from any unsuitable Atari formatted discs. This formatting issue was soon resolved by the emergence of third-party formatting and file copier software, MS-DOS disc imaging software capable of reading the unusual formats used by the ST and various other machines (such as the Commodore Amiga) and, a few years later, Atari's own version 1.4 (and later) TOS upgrades.
STF and STFM models.
Atari later upgraded the basic design in 1986 with the "1040STF" (also written "STF"). The machine was generally similar to the earlier 520ST, but moved the power supply and a double-sided floppy drive into the rear of the housing of the computer, as opposed to being external. This added to the size of the machine, but reduced cable clutter in the back. However, the joystick/mouse ports, formerly on the right side of the machine where the disk now sat, had to be moved to an awkward location in a cramped niche underneath the keyboard.
The "1040ST" was the first personal computer shipped with a base RAM configuration of 1 MB. When the list price was reduced to $999 in the U.S. it appeared on the cover of "BYTE" in March 1986 as the first computer to break the $1000/megabyte price barrier; "Compute" noted that, in fact, the "1040ST" was the first computer to break the $2500/megabyte price barrier. However, the ST remained generally the same internally over the majority of its several-year lifespan. The choice of model numbers was inherited from the model numbers of the "XE series" of the Atari 8-bit family of computers. A limited number of 1040STFs shipped with a single-sided floppy drive.
The same basic design was also used for a cut-down version, the 512 kB "520STFM", which replaced the earlier 520ST models in the market. The early 'STF' machines lacked the 'M' modulator that allowed a TV to be used and would only work with a monitor.
Mega models.
Initial sales were strong, especially in Europe where Atari sold 75% of its computers. Germany became Atari's strongest market, with small business users using them for desktop publishing and CAD.
To address this growing market segment, Atari came up with the "ST1". Debuted at Comdex in 1986, it was received favorably. Renamed the "Mega", this new machine included a high-quality detached keyboard, a stronger case to support the weight of a monitor, and an internal bus expansion connector. The upcoming SLM804 laser printer would not come with a processor or memory, reducing costs. It would attach to the Mega through the ST DMA port and have the Mega computer render the pages. Initially equipped with 2 or 4 MB (a 1 MB version, the "Mega 1" would later follow), the Mega machines would complement the Atari laser printer for a low-cost desktop publishing package, which received acclaim and was featured on the cover of Computer Shopper magazine.
A custom blitter co-processor was to be included to speed the performance of some graphics operations on the screen, but due to delays it was eventually released on the "Mega 2" and "Mega 4" machines. Developers wanting to use it had to detect for it in their programs because it was not present on all machines. However, properly written programs using the screen VDI commands could use the blitter seamlessly, since GEM API was a higher-level interface to "TOS".
Later models.
For about the first four years, no major design changes in the ST platform took place, as Atari focused on manufacturing problems and distribution.
STE models.
In late 1989, Atari released the "520STE" and "1040STE" (also written "STE"), enhanced version of the ST with improvements to the multimedia hardware and operating system. It featured an increased color palette of 4096 colors from the ST's 512 (though the maximum displayable palette of these without programming tricks was still limited to 16 in the lowest 320x200 resolution, and even fewer in higher resolutions), Genlock support, and a graphics co-processor chip called Blitter, which could quickly move large blocks of data (most particularly, graphics sprites) around in RAM. It also included a new 2-channels digital sound chip that could play 8-bit stereo samples in hardware at up to 50 kHz. Two enhanced joystick ports (EJP) were added (two normal joysticks could be plugged into each port with an adaptor), with the new connectors placed in more easily accessed locations on the side of the case. The enhanced joystick ports were re-used in Atari's Jaguar console, and are compatible. RAM was now much more simply upgradable via SIMMs. Despite all of this, it still ran at 8 MHz.
The STE models initially had software and hardware conflicts resulting in some applications and video games written for the ST line being unstable or even completely unusable, primarily caused by programming direct hardware calls which bypassed the operating system. Sometimes incompatibility could be solved by expanding the RAM. Furthermore, even having a joystick plugged in would sometimes cause strange behavior with a few applications (such as the WYSIWYG word-processor application First Word Plus).
The STE was the first Atari with PCM audio, which was probably one of the most attractive features of the machine. It has the ability to play back 8-bit (signed) samples using the SDMA at the following frequencies: 6258 Hz, 12517 Hz, 25033 Hz and 50066 Hz—sampling frequencies above audio CDs, although, the resolution was still only 8 bit. The channels are arranged as either a mono track or a track of LRLRLRLR... bytes.
Very little use was made of the extra features of the STE: STE-enhanced and STE-only software were rare, generally being limited to serious art-, CAD-, or music applications, with very few games taking advantage of the hardware, since it was found on so few machines.
The last STE machine, the "Mega STE", was an STE in a grey Atari TT case that had a switchable 16 MHz, dual-bus design (16-bit external, 32-bit internal), optional Motorola 68881 FPU, built-in 3½" floppy disk drive, VME expansion slot, a network port (very similar to that used by Apple's LocalTalk) and an optional built-in 3½" hard drive. It also shipped with TOS 2.00 (better support for hard drives, enhanced desktop interface, memory test, 1.44 MB floppy support, bug fixes). It was marketed as more affordable than a TT but more powerful than an ordinary ST.
Atari TT.
In 1990, Atari released the high-end workstation-oriented "Atari TT030", based on a 32 MHz Motorola 68030 processor. The "TT" name ("Thirty-two/Thirty-two") continued the nomenclature system as the 68030 chip had full 32-bit wide buses both internally and externally. Originally planned with a 68020 CPU, the TT included improved graphics and more powerful support chips. The case was a new design with an integrated hard-drive enclosure.
Atari Falcon.
The final ST computer was the multimedia-capable "Atari Falcon030". Like the TT, this was also 68030-based, operating at 16 MHz, but with improved video modes and an on-board Motorola 56001 audio digital signal processor. The Falcon, like the Atari STE, supports sampling frequencies above 44.1 kHz; the sampling master clock is 98340 Hz, which can be divided by a number between 2 and 16 to get the actual sampling frequencies. Apart from these frequencies, it is also able to play the STE sample frequencies (up to 50066 Hz) in 8 or 16 bit, mono/stereo, all by using the same DMA interface as the STE, with a few additions. The Falcon can both play back and record samples; it has 8 mono channels / 4 stereo channels; thus this allowed musicians to use the computer for harddisk recording. Although the 68030 microprocessor was capable of using 32-bit memory, the Falcon used a 16-bit bus which affected performance, but also served to reduce its cost. In another cost-reduction measure, Atari shipped the Falcon in an inexpensive case much like that of the STF and STE. Aftermarket upgrade kits were available that allowed the Falcon to be put in a desktop or rack-mount case, with the keyboard separate.
Released in 1992, the Falcon was discontinued by Atari the following year. In Europe, C-Lab licenced the Falcon design from Atari, and released the C-Lab Falcon Mk I (the same as Atari's Falcon except for some slight modifications to the audio circuitry), Mk II (as Mk I but with an internal 500 MB SCSI hard disk) and Mk X (as Mk II but in a desktop case).
Aftermath.
In 1993, Atari ceased development on the ST computers to focus on the Jaguar.
Following the exit of Atari from the computer market, Medusa Computer Systems manufactured some powerful 3rd-party Atari Falcon/TT-compatible machines that used 68040 and 68060 processors, based on multimedia (particularly audio, but also video), CAD, and office uses.
Despite the lack of a hardware supplier, there is a small active community dedicated to keeping the ST platform alive. There have been advancements in the operating system, software emulators (for Windows, Mac & Linux), and some hardware developments. There are accelerator cards, such as the CT60 & CT63, which is a 68060 based accelerator card for the Falcon, and there is the Atari Coldfire Project, which aims at developing an Atari-clone based on the Coldfire processor. Milan Computer of Germany also made 68040 and 68060-based Atari clones that can run either Atari TOS 4.5 or Milan Computer's MultiOS operating system.
Software.
As with the Atari 8-bit computers, software publishers attributed their reluctance to produce Atari ST products in part to, as "Compute!" reported in 1988, the belief in the existence of a "higher-than-normal amount of software piracy". That year WordPerfect threatened to discontinue the Atari ST version of its word processor because the company discovered that pirate bulletin board systems (BBSs) were distributing it, causing "ST-Log" to warn that "we had better put a stop to piracy "now" ... it can have harmful effects on the longevity and health of your computer". In 1989 magazines published a letter by Gilman Louie, head of Spectrum Holobyte. He stated that he had been warned by competitors that releasing a game like "Falcon" on the ST would fail because BBSs would widely disseminate it. Within 30 days of releasing the non-copy protected ST version, the game was available on BBSs with maps and code wheels. Because the ST market was smaller than that for the IBM PC it was more vulnerable to piracy which, Louie said, seemed to be better organized and more widely accepted for the ST. He reported that the Amiga version sold in six weeks twice as much as the ST version in nine weeks, and that the Mac and PC versions had four times the sales. "Computer Gaming World" stated "This is certainly the clearest exposition ... we have seen to date" of why software companies produced less software for the ST than for other computers.
Music and sound.
The ST was the first home computer with built-in MIDI ports, and there was plenty of MIDI-related software for use professionally in music studios, or by amateur enthusiasts. The popular Windows/Macintosh applications "Cubase" and "Logic Pro" originated on the Atari ST (the latter as "Notator Logic", preceded by "Creator", "Notator" and "Notator-SL"). Another popular and powerful ST music sequencer application, Dr. T's "KCS", contained a "Multi-Program Environment" that allowed ST users to run other applications, such as the synthesizer patch editing software XoR (now known as Unisyn on the Macintosh), from within the sequencer application.
Music tracker software was popular on the ST, such as the "TCB Tracker", aiding the production of quality music from the Yamaha synthesizer ('chiptunes').
An innovative music composition program that combined the sample playing abilities of a tracker with conventional music notation (which was usually only found in MIDI software) was called "Quartet" (after its 4-note polyphonic tracker, which displayed one monophonic stave at a time on color screens).
Due to the ST having comparatively large amounts of memory for the time, sound sampling packages became a realistic proposition. The Microdeal Replay Professional product featured a sound sampler that cleverly used the ST cartridge port to read in parallel from the cartridge port from the ADC. For output of digital sound, it used the on-board frequency output, set it to 128 kHz (inaudible) and then modulated the amplitude of that.
Another program that had good success on the ST platform was "MasterTracks Pro" from Passport Designs, of Half Moon Bay, CA., that was first put out by Don Williams for the Macintosh. When the ST died, a PC version continued that one could port MIDI to using the generic .MID format. GVox bought out Passport, and continues the program for Windows and Mac OS along with the other Passport product, the notation program "Encore".
In addition to the sound-sampling functionalities, the availability of software packages with MIDI support for music composition and efficient sound analysis contributed to make the Atari ST a forerunner of later computer-based all-in-one studios.
The ST's low cost, built-in MIDI ports, and fast, low-latency response times made it a favorite with musicians:
Applications.
Also popular on the ST was professional desktop publishing software, such as "PageStream" and "Calamus"; office tools such as word processors ("WordPerfect", "Microsoft Write", "AtariWorks", "WordWriter ST", First Word with the machine and its Plus continuation, and others); spreadsheets ("3D-Calc", "LDW Power", "LDW Power 2", "LOGiSTiX Senior", "PowerLedger ST", "SwiftCalc ST", "VIP Professional", and others); turnkey programs ("Mail-Pro", "Sales-Pro 6", "Video-Pro", and others); database programs ("A-Calc Prime", "Data Manager", "Data Manager Professional", "DBMan V", "Base Two", "Informer II", "DB Master One", "SBT Database Accounting Library" ("dLedger", "dInvoice", "dOrder", "dPurchases", and "dPayables)", "Superbase Personal", "Superbase Professional", "Tracker ST", and others); and various CAD and CAM tools from amateur hobbyist to professional grade (Campus CAD, DynaCADD, Leonard ST, Technobox CAD/2...): all being largely targeted at, or even limited to owners of high-resolution monochrome monitors.
Graphics programs such as "NEOchrome", Degas & Degas Elite, "Canvas", "Deluxe Paint", and "Cyber Paint" (which author Jim Kent would later evolve into "Autodesk Animator") featured advanced features such as 3D design and animation. One paint program, "Spectrum 512", used the ST's rapid palette switching ability to expand the maximum number of colors to be displayed on-screen at once to 512 (up to 46 in each scan line — the STE never had a Spectrum4096, but other more minor applications filled this speciality niche, one even going so far as to program the shifter chip to palette shift at a rate enabling a display of 19200 colors).
3D computer graphics applications (like "Cyber Studio"s "CAD-3D", which author Tom Hudson would later develop into Autodesk "3D Studio"), brought 3D modelling, sculpting, scripting, and most important, computer animation (using delta-compression) to the desktop. Video-capture and -editing applications using special video-capture 'dongles' connected using the cartridge port — low frame rate, mainly silent and monochrome, but progressing to sound and basic color (in still frames) by the end of the machine's life. At the end, Spectrum 512 and CAD-3D teamed up to produce realistic 512-color textured 3D renderings, but processing was slow, and Atari's failure to deliver a machine with a math coprocessor had Hudson and Yost looking towards the PC as the future before a finished product could be delivered to the consumer.
The Atari ST was the computer upon which today's prevalent graphical touchscreen point of sale software for restaurants was originally developed. This software was created by Gene Mosher under the ViewTouch copyright and trademark. It did not feature the Atari ST's GEM graphical user interface but, instead, featured an application specific graphical user interface and widget framework which he developed using, in part, the Neochrome paint program.
Software development.
The Atari ST had a wide variety of languages and tools for development. 68000 assemblers (MadMac from Atari Corp, HiSoft Systems's Devpac, TurboAss, GFA-Assembler), Pascal (OSS Personal Pascal, Maxon Pascal, PurePascal), Modula-2, C compilers (like Turbo C (Borland), Alcyon C, Lattice C, Megamax C, Mark Williams C, GNU C, Aztec C, AHCC (A Home Cooked C)), LISP, Prolog, Logo, and many others.
The initial development kit from Atari included a computer and manuals. At $5,000, this discouraged many from developing software for the ST. Later, the Atari Developer's Kit consisted of software and manuals (no hardware) for $300. Included with the kit were a resource kit, C compiler (first Alcyon C, then Mark Williams C), debugger, and 68000 assembler (plus the non-disclosure agreement).
The ST came bundled with a system disk that contained "ST BASIC", the first BASIC for the ST. However, due to its poor performance, users favored other BASICs, such as "GFA BASIC", FaST BASIC (notable for being one of the few programs to actually be supplied as a ROM cartridge instead of on disc), and the relatively famous "STOS", which then inspired and led to the creation of AMOS on the Amiga, and powerful enough that it was used (with a compiler, opposed to its usual runtime interpreter) for the production of at least two commercial titles and an innumerable host of good quality shareware and public domain games. In the late years of the Atari ST Omikron Basic was bundled with it in Germany.
Even novelty tools such as "SEUCK" were available.
Games.
The ST enjoyed success in gaming due to low cost, fast performance and colorful graphics.
Notable individuals who developed games on the ST include Peter Molyneux, Doug Bell, Jeff Minter, Éric Chahi, Jez San, and David Braben. An early real-time 3D role-playing video game, "Dungeon Master", was first developed and released on the ST, and was the best-selling software ever produced for the platform. Simulation games like "Falcon" and "Flight Simulator II" made use of the enhanced graphics found in the ST machines, as did many arcade ports. One game, MIDI Maze, used the MIDI ports to connect up to 16 machines for interactive networked play, this is sometimes said to have inspired modern LAN games which became popular in the early 90s. Games simultaneously released on the Amiga that had identical graphics and sound were often accused by video game magazines of simply being ST ports. The reason for these accusations is because these games were not utilising the Amiga's ability to produce superior graphics and sound. The critically acclaimed game Another World was originally released for ST and Amiga in 1991 (but developed on Amiga though).
Garry Kasparov became the first player to register the commercial ChessBase, a popular commercial database program produced for storing and searching records of games of chess. The first version was built for Atari ST with his collaboration in January 1987. In his autobiography "Child of Change", he regards this facility as "the most important development in chess research since printing".
Utilities.
Utility software was available to drive hardware add-ons such as video digitisers. Office Productivity and graphics software was also bundled with the ST (HyperPaint II by Dimitri Koveos, HyperDraw by David Farmborough, 3D-Calc spreadsheet by Frank Schoonjans, and several others commissioned by Bob Katz, later of Electronic Arts).
There was a thriving output of public domain and shareware software which was distributed by, in the days long before public internet access, public domain software libraries that advertised in magazines and on popular dial-up bulletin board systems.
Remarkably, a modest core fanbase for the system, supporting a dwindling number of good quality print magazines, survived to the mid-'90s and the birth of the modern, publicly accessible Internet as we know it. Despite the limited graphics, memory, and temporary hard-storage capabilities of the system, several email, FTP, telnet, IRC, and even full-blown graphical World Wide Web browser applications are available and usable on the ST.
There were also DOS emulators released in the late 80s. "PC-Ditto" came in two versions, software-only-, and a hardware version that plugged into the cartridge slot or kludged internally. After running the PC-Ditto software, a DOS boot disk was required to load the system. Both allowed users to run DOS programs in CGA mode, though much more slowly than on an IBM PC. Other options were the "PC-Speed" (NEC V30), "AT-Speed" (Intel 80286) and "ATonce-386SX" (Intel 80386sx) hardware emulator boards.
Technical specifications.
All STs were made up of both custom and commercial chips:
ST/STF/STM/STFM.
As originally released in the "520ST":
Very early machines included the OS on a floppy disk due to it not being ready to be burned to ROM (like the Amiga 1000 had) This early version of TOS was bootstrapped from a very small core boot ROM, but this was quickly replaced with (expanded capacity) ROM versions of TOS 1.0 when it was ready. (This change was also greatly welcomed as older ST machines with memory below 512 kB suffered, as GEM loaded its entire 192 kB code into RAM when booting the desktop). Having the OS loaded from disk was due to Atari trying to rush the machines to market without ironing out all the bugs in the OS. Soon after this change, most production models became STFs, with an integrated single- (520STF/512 kB RAM) or double-sided (1040STF/1024 kB RAM) double density floppy disk drive built-in, but no other changes. The next later models used an upgraded version of TOS: 1.02 (also known as TOS 1.2). Another early addition (after about 6 months) was an RF Modulator that allowed the machine to be hooked to a color TV when run in its low or medium resolution (525/625 line 60/50 Hz interlace, even on RGB monitors) modes, greatly enhancing the machine's saleability and perceived value (no need to buy a prohibitively expensive, even if exceptionally crisp and clear, monitor). These models were known as the "520STM" (or "520STM"). Later "F" and "FM" models of the 520 had a built in double-sided disk drive instead of a single-sided one.
STE.
As originally released in the "520STE/1040STE":
Models.
The members of the ST family are listed below, in rough chronological order:
Related systems.
There were also some unreleased prototypes: Falcon 040 (based on a Motorola 68040, new case and slots), ST Pad/STylus (A4 (Letter paper) sized pen-operated portable ST computer, handheld and with an unlit monochrome LCD screen derived from the ST Book, forerunner of modern tablet PCs).

</doc>
<doc id="2142" url="http://en.wikipedia.org/wiki?curid=2142" title="List of artificial intelligence projects">
List of artificial intelligence projects

The following is a list of current and past, nonclassified notable artificial intelligence projects.

</doc>
<doc id="2144" url="http://en.wikipedia.org/wiki?curid=2144" title="Aaliyah">
Aaliyah

Aaliyah Dana Haughton (January 16, 1979 – August 25, 2001), who performed under the mononym Aaliyah (), was an American recording artist, dancer, actress, and model. She was born in Brooklyn, New York, and raised in Detroit, Michigan. At the age of 10, she appeared on the television show "Star Search" and performed in concert alongside Gladys Knight. At age 12, Aaliyah signed with Jive Records and her uncle Barry Hankerson's Blackground Records. Hankerson introduced her to R. Kelly, who became her mentor, as well as lead songwriter and producer of her debut album, "Age Ain't Nothing but a Number". The album sold three million copies in the United States and was certified double platinum by the Recording Industry Association of America (RIAA). After facing allegations of an illegal marriage with R. Kelly, Aaliyah ended her contract with Jive and signed with Atlantic Records.
Aaliyah worked with record producers Timbaland and Missy Elliott for her second album, "One in a Million"; it sold 3.7 million copies in the United States and over eight million copies worldwide. In 2000, Aaliyah appeared in her first major film, "Romeo Must Die". She contributed to the film's soundtrack, which spawned the single "Try Again". The song topped the "Billboard" Hot 100 solely on airplay, making Aaliyah the first artist in "Billboard" history to achieve this feat. "Try Again" earned Aaliyah a Grammy Award nomination for Best Female R&B Vocalist. After completing "Romeo Must Die", Aaliyah filmed her part in "Queen of the Damned". She released her third and final album, "Aaliyah", in July 2001.
On August 25, 2001, Aaliyah and eight others were killed in a plane crash in The Bahamas after filming the music video for the single "Rock the Boat". The pilot, Luis Morales III, was unlicensed at the time of the accident and had traces of cocaine and alcohol in his system. Aaliyah's family later filed a wrongful death lawsuit against Blackhawk International Airways, which was settled out of court. Aaliyah's music has continued to achieve commercial success with several posthumous releases. Aaliyah sold 52 million records worldwide. She has been credited for helping redefine contemporary R&B and hip hop, earning her the nicknames "Princess of R&B" and "Queen of Urban Pop". She is listed by "Billboard" as the tenth most successful female R&B artist of the past 25 years, and 27th most successful R&B artist in history.
Early life.
Aaliyah Dana Haughton was born on January 16, 1979, in Brooklyn, New York. Born of African American descent, with Oneida heritage from her grandmother, she was the second and youngest child of Diane and Michael Haughton. At a young age, Aaliyah was enrolled in voice lessons by her mother. She started performing at weddings, church choir and charity events. When she was five years old, her family moved to Detroit, Michigan, where she was raised along with her older brother, Rashad. She attended a Catholic school, Gesu Elementary, where in first grade, she received a part in the stage play "Annie". From then on, she was determined to become an entertainer.
Aaliyah's mother was a vocalist, and her uncle, Barry Hankerson, was an entertainment lawyer who had been married to Gladys Knight. As a child, Aaliyah traveled with Knight and worked with an agent in New York to audition for commercials and television programs, including "Family Matters"; she went on to appear on "Star Search" at the age of nine. She auditioned for several record labels and at age 11 appeared in concerts alongside Knight.
Career.
1991–95: "Age Ain't Nothing but a Number".
After Hankerson signed a distribution deal with Jive Records, he signed Aaliyah to his Blackground Records label at the age of 12. Hankerson later introduced her to recording artist and producer R. Kelly, who became Aaliyah's mentor, as well as lead songwriter and producer of the album, which was recorded when she was 14. Aaliyah's debut album, "Age Ain't Nothing but a Number", was released under Jive and Blackground Records; the album debut at number 24 on the "Billboard" 200 chart, selling 74,000 copies in its first week. It ultimately peaked at number 18 on the "Billboard" 200 and sold over three million copies in the United States, where it was certified two times Platinum by the RIAA. In Canada, the album sold over 50,000 copies and was certified gold by the CRIA. Aaliyah's debut single, "Back & Forth", topped the "Billboard" Hot R&B/Hip-Hop Songs chart for three weeks and was certified Gold by the RIAA. The second single, a cover of The Isley Brothers' "At Your Best (You Are Love)", peaked at number six on the "Billboard" Hot 100 and was also certified Gold by the RIAA. The title track, "Age Ain't Nothing but a Number", peaked at number 75 on the Hot 100. Additionally, she released "The Thing I Like" as part of the soundtrack to the 1994 film "A Low Down Dirty Shame".
"Age Ain't Nothing But a Number" received generally favorable reviews from music critics. Some writers noted that Aaliyah's "silky vocals" and "sultry voice" blended with Kelly's new jack swing helped define R&B in the 1990s. Her sound was also compared to that of female quartet En Vogue. Christopher John Farley of "Time" magazine described the album as a "beautifully restrained work", noting that Aaliyah's "girlish, breathy vocals rode calmly on R. Kelly's rough beats". Stephen Thomas Erlewine of AllMusic felt that the album had its "share of filler", but described the singles as "slyly seductive". He also claimed that the songs on the album were "frequently better" than that of Kelly's second studio album, "12 Play".
1996–99: "One in a Million".
In 1996, Aaliyah left Jive Records and signed with Atlantic Records. She worked with record producers Timbaland and Missy Elliott, who contributed to her second studio album, "One in a Million". The album yielded the single "If Your Girl Only Knew", which topped the "Billboard" Hot R&B/Hip-Hop Songs for two weeks. It also generated the singles "Hot Like Fire" and "4 Page Letter". The following year, Aaliyah was featured on Timbaland & Magoo's debut single, "Up Jumps da Boogie". "One in a Million" peaked at number 18 on the "Billboard" 200, selling over 3.7 million copies in the United States and over eight million copies worldwide.
The album was certified double platinum by the RIAA on June 16, 1997, denoting shipments of two million copies.
Aaliyah attended the Detroit High School for the Fine and Performing Arts, where she majored in drama and graduated in 1997. Aaliyah began her acting career that same year; she played herself in the police drama television series "New York Undercover". During this time, Aaliyah participated in the Children's Benefit Concert, a charity concert that took place at the Beacon Theatre in New York. Aaliyah also became the spokesperson for Tommy Hilfiger Corporation. She contributed on the soundtrack album for the Fox Animation Studios animated feature "Anastasia", performing a cover version of "Journey to the Past" which earned songwriters Lynn Ahrens and Stephen Flaherty a nomination for the Academy Award for Best Original Song. Aaliyah performed the song at the 1998 Academy Awards ceremony and became the youngest singer to perform at the event. The song "Are You That Somebody?" was featured on the "Dr. Dolittle" soundtrack, which earned Aaliyah her first Grammy Award nomination. The song peaked at number 21 on the Hot 100.
2000–01: Acting and eponymous album.
In 2000, Aaliyah landed her first major movie role in "Romeo Must Die". Aaliyah starred opposite martial artist Jet Li, playing a couple who fall in love amid their warring families. It grossed US$18.6 million in its first weekend, ranking number two at the box office. In addition to acting, Aaliyah served as an executive producer of the film soundtrack, where she contributed four songs. "Try Again" was released as a single from the soundtrack; the song topped the "Billboard" Hot 100, making Aaliyah the first artist to top the chart based solely on airplay; this led the song to be released in a 12" vinyl and 7" single. The music video won the Best Female Video and Best Video from a Film awards at the 2000 MTV Video Music Awards. It also earned her a Grammy Award nomination for Best Female R&B Vocalist. The soundtrack went on to sell 1.5 million copies in the United States. After completing "Romeo Must Die", Aaliyah began to work on her second film, "Queen of the Damned". She played the role of an ancient vampire, Queen Akasha, which she described as a "manipulative, crazy, sexual being". She was scheduled to film for the sequels of "The Matrix" as the character Zee.
Aaliyah released her eponymous album, "Aaliyah", in July 2001. It debuted at number two on the "Billboard" 200, selling 187,000 copies in its first week. The first single from the album, "We Need a Resolution", peaked at number 59 on the "Billboard" Hot 100. Aaliyah was engaged to co-founder of Roc-A-Fella Records Damon Dash at the time of her death and had plans to marry him after the premiere of "The Matrix Reloaded".
The week after Aaliyah's death, her third studio album, "Aaliyah", rose from number 19 to number one on the "Billboard" 200. "Rock the Boat" was released as a posthumous single. The music video premiered on BET's "Access Granted"; it became the most viewed and highest rated episode in the history of the show. The song peaked at number 14 on the "Billboard" Hot 100 and number two on the "Billboard" Hot R&B/Hip-Hop Songs chart. It was also included on the "Now That's What I Call Music! 8" compilation series; a portion of the album's profits was donated to the Aaliyah Memorial Fund. Promotional posters for "Aaliyah" that had been put up in major cities such as New York and Los Angeles became makeshift memorials for grieving fans. "More than a Woman" and "I Care 4 U" were released as posthumuous singles and peaked within the top 25 of the "Billboard" Hot 100. The album was certified double Platinum by the RIAA and sold 2.95 million copies in the United States. "More than a Woman" reached number one on the UK singles chart making Aaliyah the first deceased artist to reach number one on the UK singles chart. "More than a Woman" was replaced by George Harrison's "My Sweet Lord" which is the only time in the UK singles chart's history where a dead artist has replaced another dead artist at number one.
Aaliyah was signed to appear in several future films, including "Honey", a romantic film titled "Some Kind of Blue", and a Whitney Houston-produced remake of the 1976 film "Sparkle". Before her death, Aaliyah had filmed part of her role in "The Matrix Reloaded" and was scheduled to appear in "The Matrix Revolutions" as Zee. The role was subsequently recast to Nona Gaye. Aaliyah's scenes were included in the tribute section of the "Matrix Ultimate Collection" series.
Personal life.
With the release of "Age Ain't Nothing but a Number", rumors circulated of a relationship between Aaliyah and R. Kelly. Shortly after, there was speculation about a secret marriage with the release of "Age Ain't Nothing but a Number" and the adult content that Kelly had written for Aaliyah. "Vibe" magazine later revealed a marriage certificate that listed the couple married on August 31, 1994, in Sheraton Gateway Suites in Rosemont, Illinois. Aaliyah, who was 15 at the time, was listed as 18 on the certificate; the illegal marriage was annulled in February 1995 by her parents. The pair continued to deny marriage allegations, stating that neither was married.
Death.
On August 25, 2001, at 6:50 p.m. (EST), Aaliyah and various members of the record company boarded a twin-engine Cessna 402B (registration N8097W) at the Marsh Harbour Airport in Abaco Islands, The Bahamas, to travel to the Opa-locka Airport in Florida, after they completed filming the music video for the single "Rock the Boat". They had a flight scheduled the following day, but with filming finishing early, Aaliyah and her entourage were eager to return to the United States and made the decision to leave immediately. The designated airplane was smaller than the Cessna 404 on which they had originally arrived, but the whole party and all of the equipment were accommodated on board. The plane crashed shortly after takeoff, about from the runway. Aaliyah and the eight others on board, pilot Luis Morales III, hair stylist Eric Forman, Anthony Dodd, security guard Scott Gallin, video producer Douglas Kratz, stylist Christopher Maldonado, and Blackground Records employees Keith Wallace and Gina Smith, were all killed.
According to findings from an inquest conducted by the coroner's office in The Bahamas, Aaliyah suffered from "severe burns and a blow to the head", in addition to severe shock and a weak heart. The coroner theorized that she went into such a state of shock that even if she had survived the crash, her recovery would have been nearly impossible.
As the subsequent investigation determined, when the aircraft attempted to depart, it was over its maximum takeoff weight by and was carrying one excess passenger, according to its certification.
The National Transportation Safety Board (NTSB) report stated that "the airplane was seen lifting off the runway, and then nose down, impacting in a marsh on the south side of the departure end of runway 27 and then exploding in flames." It indicated that the pilot was not approved to fly the plane. Morales falsely obtained his Federal Aviation Administration (FAA) license by showing hundreds of hours never flown, and he may also have falsified how many hours he had flown in order to get a job with his employer, Blackhawk International Airways. Additionally, an autopsy performed on Morales revealed traces of cocaine and alcohol in his system. The NTSB reported that the maximum allowed gross weight of the plane was "substantially exceeded" and that the center of gravity was positioned beyond its rear limit. John Frank of the Cessna Pilots Association stated that the plane was "definitely overloaded".
Aaliyah's funeral was held on August 31, 2001, at the St. Ignatius Loyola Church in Manhattan. Her body was set in a silver casket, which was carried in a glass hearse and was drawn by horse. An estimated 800 mourners were in attendance at the procession. Among those in attendance at the private ceremony were Missy Elliott, Timbaland, Gladys Knight, Lil' Kim and Sean Combs. After the service, 22 white doves were released to symbolize each year of Aaliyah's life. Aaliyah was interred in a private room at the end of a corridor in the Rosewood Mausoleum at the Ferncliff Cemetery in Hartsdale, New York.
The day of the crash was Morales' first official day with Blackhawk International Airways, an FAA Part 135 single-pilot operation. Morales was not registered with the FAA to fly for Blackhawk. As a result of the accident, Aaliyah's parents filed a wrongful death lawsuit against the company, which was settled out of court for an undisclosed amount. Barry & Sons, Inc., a corporation formed in 1992 to develop, promote and capitalize Aaliyah and to oversee the production and distribution of her records and music videos, brought an unsuccessful lawsuit in the New York Supreme Court against Instinct Productions LLC, the company that was hired in August 2001 to produce the music video for "Rock the Boat". The case was dismissed because New York's wrongful death statute permits only certain people in relation to the deceased to recover damages for wrongful death.
Posthumous career.
She won two posthumous awards at the American Music Awards of 2002; Favorite Female R&B Artist and Favorite R&B/Soul Album for "Aaliyah". Her second and final film, "Queen of the Damned", was released in February 2002. Before its release, Aaliyah's brother, Rashad, re-dubbed some of her lines during post-production. It grossed US$15.2 million in its first weekend, ranking number one at the box office. On the first anniversary of Aaliyah's death, a candlelight vigil was held in Times Square; millions of fans observed a moment of silence; and throughout the United States, radio stations played her music in remembrance. In December 2002, a collection of previously unreleased material was released as Aaliyah's first posthumous album, "I Care 4 U". A portion of the proceeds was donated to the Aaliyah Memorial Fund, a program that benefits the Revlon UCLA Women's Cancer Research Program and Harlem's Sloan Kettering Cancer Center. It debuted at number three on the "Billboard" 200, selling 280,000 copies in its first week. The album's lead single, "Miss You", peaked at number three on the "Billboard" Hot 100 and topped the Hot R&B/Hip-Hop Songs chart. In August of the following year, clothing retailer Christian Dior donated profits from sales in honor of Aaliyah.
In 2005, Aaliyah's second compilation album, "Ultimate Aaliyah" was released in the UK by Blackground Records. "Ultimate Aaliyah" is a three disc set, which included a greatest hits audio CD and a DVD. Andy Kellman of AllMusic remarked ""Ultimate Aaliyah" adequately represents the shortened career of a tremendous talent who benefited from some of the best songwriting and production work by Timbaland, Missy Elliott, and R. Kelly." A documentary movie "Aaliyah Live in Amsterdam" was released in 2011., shortly before the tenth anniversary of Aaliyah's death. The documentary, by Pogus Caesar, contained previously unseen footage shot of her career beginnings in 1995 when she was appearing in the Netherlands.
In March 2012, music producer Jeffrey "J-Dub" Walker announced on his Twitter account that a song "Steady Ground", which he produced for Aaliyah's third album, would be included in the forthcoming posthumous Aaliyah album. This second proposed posthumous album would feature this song using demo vocals, as Walker claims the originals were somehow lost by his sound engineer. Aaliyah's brother Rashad later refuted Walker's claim, claiming that "no official album being released and supported by the Haughton family."
On August 5, 2012, a song entitled "Enough Said" was released online. The song was produced by Noah "40" Shebib and features Canadian rapper Drake. Four days later, Jomo Hankerson confirmed a posthumous album is being produced and that it is scheduled to be released by the end of 2012 by Blackground Records. The album was reported to include 16 unreleased songs and have contributions from Aaliyah's longtime collaborators Timbaland and Missy Elliott, among others. On August 13, Timbaland and Missy Elliott dismissed rumors about being contacted or participating for the project. Elliott's manager Mona Scott-Young said in a statement to "XXL", "Although Missy and Timbaland always strive to keep the memory of their close friend alive, we have not been contacted about the project nor are there any plans at this time to participate. We've seen the reports surfacing that they have been confirmed to participate but that is not the case. Both Missy and Timbaland are very sensitive to the loss still being felt by the family so we wanted to clear up any misinformation being circulated." Elliott herself said, "Tim and I carry Aaliyah with us everyday, like so many of the people who love her. She will always live in our hearts. We have nothing but love and respect for her memory and for her loved ones left behind still grieving her loss. They are always in our prayers."
In June 2013, Aaliyah was featured on a new track by Chris Brown, titled "Don't Think They Know"; with Aaliyah singing the song's hook. The video features dancing holographic versions of Aaliyah. The song is set to appear on Brown's upcoming sixth studio album, "X".
In January 2014, producer Noah "40" Shebib confirmed that the posthumous album was shelved due to the negative reception surrounding Drake's involvement. Shebib added, "Aaliyah's mother saying, 'I don't want this out' was enough for me [...] I walked away very quickly."
Artistry.
Voice and style.
Aaliyah had the vocal range of a soprano. With the release of her debut single "Back & Forth", Dimitri Ehrlich of "Entertainment Weekly" expressed that Aaliyah's "silky vocals are more agile than those of self-proclaimed queen of hip-hop soul Mary J. Blige." Aaliyah described her sound as "street but sweet", which featured her "gentle" vocals over a "hard" beat. Though Aaliyah did not write any of her own material, her lyrics were described as in-depth. She incorporated R&B, pop and hip hop into her music. Her songs were often uptempo and at the same time often dark, revolving around "matters of the heart". After her R. Kelly-produced debut album, Aaliyah worked with Timbaland and Missy Elliott, whose productions were more electronic. Sasha Frere-Jones of "The Wire" finds Aaliyah's "Are You That Somebody?" to be Timbaland's "masterpiece" and exemplary of his production's start-stop rhythms, with "big half-second pauses between beats and voices". Keith Harris of "Rolling Stone" cites "Are You That Somebody?" as "one of '90s R&B's most astounding moments".
Aaliyah's songs have been said to have "crisp production" and "staccato arrangements" that "extend genre boundaries" while containing "old-school" soul music. Kelefah Sanneh of "The New York Times" called Aaliyah "a digital diva who wove a spell with ones and zeroes", and writes that her songs comprised "simple vocal riffs, repeated and refracted to echo the manipulated loops that create digital rhythm", as Timbaland's "computer-programmed beats fitted perfectly with her cool, breathy voice to create a new kind of electronic music." When she experimented with other genres on "Aaliyah", such as Latin pop and heavy metal, "Entertainment Weekly"s Craig Seymour panned the attempt. As her albums progressed, writers felt that Aaliyah matured, calling her progress a "declaration of strength and independence". Stephen Thomas Erlewine of AllMusic described her eponymous album, "Aaliyah", as "a statement of maturity and a stunning artistic leap forward" and called it one of the strongest urban soul records of its time. She portrayed "unfamiliar sounds, styles and emotions", but managed to please critics with the contemporary sound it contained. Ernest Hardy of "Rolling Stone" felt that Aaliyah reflected a stronger technique, where she gave her best vocal performance. Prior to her death, Aaliyah expressed a desire to learn about the burgeoning UK garage scene she had heard about at the time.
Influences and image.
As an artist, Aaliyah often voiced that she was inspired by a number of performers. These include Michael Jackson, Stevie Wonder, Sade, En Vogue, Nine Inch Nails, Korn, Prince, Naughty by Nature, Johnny Mathis and Janet Jackson. Aaliyah expressed that Michael Jackson's "Thriller" was her "favorite album" and that "nothing will ever top "Thriller"." She stated that she admired Sade because "she stays true to her style no matter what... she's an amazing artist, an amazing performer... and I absolutely love her." Aaliyah expressed she had always desired to work with Janet Jackson, whom she had drawn frequent comparison to over the course of her career, stating "I admire her a great deal. She's a total performer... I'd love to do a duet with Janet Jackson." Jackson reciprocated Aaliyah's affections, commenting "I've loved her from the beginning because she always comes out and does something different, musically." Jackson also stated she would have enjoyed collaborating with Aaliyah.
Aaliyah focused on her public image throughout her career. She often wore baggy clothes and sunglasses, stating that she wanted to be herself. She described her image as being "important... to differentiate yourself from the rest of the pack". She often wore black clothing, starting a trend for similar fashion among women in United States and Japan. Aaliyah participated in fashion designer Tommy Hilfiger's All America Tour and was featured in Tommy Jean ads, which depicted her in boxer shorts, baggy jeans and a tube top. Hilfiger's brother, Andy, called it "a whole new look" that was "classy but sexy". When she changed her hairstyle, Aaliyah took her mother's advice to cover her left eye, much like Veronica Lake. In 1998, she hired a personal trainer to keep in shape, and exercised five days a week and ate diet foods. Aaliyah was praised for her "clean-cut image" and "moral values". Robert Christgau of "The Village Voice" wrote of Aaliyah's artistry and image, "she was lithe and dulcet in a way that signified neither jailbait nor hottie—an ingenue whose selling point was sincerity, not innocence and the obverse it implies."
Legacy.
Aaliyah has been credited for helping redefine R&B and hip hop in the 1990s, "leaving an indelible imprint on the music industry as a whole." Steve Huey of AllMusic wrote Aaliyah ranks among the "elite" artists of the R&B genre, as she "played a major role in popularizing the stuttering, futuristic production style that consumed hip-hop and urban soul in the late '90s." Described as one of "R&B's most important artists" during the 1990s, her second studio album, "One in a Million", became one of the most influential R&B albums of the decade. Music critic Simon Reynolds cited "Are You That Somebody?" as "the most radical pop single" of 1998. Kelefah Sanneh of "The New York Times" wrote that rather than being the song's focal point, Aaliyah "knew how to disappear into the music, how to match her voice to the bass line", and consequently "helped change the way popular music sounds; the twitchy, beat-driven songs of Destiny's Child owe a clear debt to 'Are You That Somebody'." Sanneh asserted that by the time of her death in 2001, Aaliyah "had recorded some of the most innovative and influential pop songs of the last five years." With sales of 8.1 million albums in the United States and an estimated 24 to 32 million albums worldwide, Aaliyah earned the nicknames "Princess of R&B" and "Queen of Urban Pop", as she "proved she was a muse in her own right". Ernest Hardy of "Rolling Stone" dubbed her as the "undisputed queen of the midtempo come-on". Japanese pop singer Hikaru Utada has said several times that "It was when I heard Aaliyah's "Age Ain't Nothing but a Number" that I got hooked on R&B.", after which Utada released her debut album "First Love" with heavy R&B influences.
Aaliyah was honored at the 2001 MTV Video Music Awards by Janet Jackson, Missy Elliott, Timbaland, Ginuwine and her brother, Rashad, who all paid tribute to her. In the same year, the United States Social Security Administration ranked the name Aaliyah one of the 100 most popular names for newborn girls. Aaliyah was ranked as one of "The Top 40 Women of the Video Era" in VH1's 2003 "The Greatest" series. She was also ranked at number 18 on BET's "Top 25 Dancers of All Time". Aaliyah appeared on both 2000 and 2001 list of "Maxim" Hot 100 in position 41 and the latter at 14. In memory of Aaliyah, the Entertainment Industry Foundation created the Aaliyah Memorial Fund to donate money raised to charities she supported. In December 2009, "Billboard" magazine ranked Aaliyah at number 70 on its Top Artists of the Decade, while her eponymous album was ranked at number 181 on the magazine's Top 200 Albums of the Decade. She is listed by "Billboard" as the tenth most successful female R&B artist of the past 25 years, and 27th most successful R&B artist overall. In 2012, VH1 ranked her number 48 in "VH1's Greatest Women in Music".
Aaliyah's work has influenced numerous artists including Adele, Ciara, Beyoncé Knowles, Monica, Chris Brown, Rihanna, Azealia Banks, Sevyn Streeter, Keyshia Cole, J. Cole, Kelly Rowland, Zendaya, Rita Ora, The xx, Omarion, Canadian R&B singer Keshia Chanté who is said to play as her in her pending biopic, complimented the singer's futuristic style of music. R&B singer and friend Brandy said about the late singer "She came out before Monica and I did, she was our inspiration. At the time, record companies did not believe in kid acts and it was just inspiring to see someone that was winning and winning being themselves. When I met her I embraced her, I was so happy to meet her." Rapper Drake said that the singer has had the biggest influence on his career. He also has a tattoo of the singer behind his back. 
In 2012, British singer-songwriter Katy B released the song "Aaliyah" as a tribute to Aaliyah's legacy and lasting impression on R&B music. The song first appeared on Katy B's "Danger" EP and featured Jessie Ware on guest vocals.

</doc>
<doc id="2147" url="http://en.wikipedia.org/wiki?curid=2147" title="Armour">
Armour

Armour or armor (see spelling differences) is a protective covering that is used to prevent damage from being inflicted to an object, individual, or vehicle by direct contact weapons or projectiles, usually during combat, or from damage caused by a potentially dangerous environment or action (e.g., cycling, construction sites, etc.). Personal armour is used to protect soldiers and war animals such as war horses (the application for the latter is called barding). Vehicle armour is used on warships and armoured fighting vehicles.
Etymology.
The word "armour" was introduced into use in the Middle Ages as a borrowing from the French. It is dated from 1297, as a "mail, defensive covering worn in combat" from Old French "armoire", itself derived from the Latin "armatura" "arms and/or equipment" with the root "arma" "arms or gear".
Personal.
Armour has been used throughout recorded history. It has been made from a variety of materials; from rudimentary leather protection, personal armour evolved to Mail and full plated suits of armour. For much of military history the manufacture of metal personal armour has dominated the technology and employment of armour. Armour drove the development of many important technologies of the Ancient World, including wood lamination, mining, metal refining, vehicle manufacture, leather processing, and later decorative metal working. Its production was influential in the industrial revolution, and influenced commercial development of metallurgy and engineering. Armour was the single most influential factor in the development of firearms, which in turn revolutionised warfare.
History.
Significant factors in the development of armour include the economic and technological necessities of its production. For instance, plate armour first appeared in Medieval Europe when water-powered trip hammers made the formation of plates faster and cheaper. Also, modern militaries usually do not equip their forces with the best armour available because it would be prohibitively expensive. At times the development of armour has paralleled the development of increasingly effective weaponry on the battlefield, with armourers seeking to create better protection without sacrificing mobility.
Well-known armour types in European history include the lorica hamata, lorica squamata, and the lorica segmentata of the Roman legions, the mail hauberk of the early medieval age, and the full steel plate harness worn by later medieval and renaissance knights, and breast and back plates worn by heavy cavalry in several European countries until the first year of World War I (1914–15). The samurai warriors of feudal Japan utilised many types of armour for hundreds of years up to the 19th century.
Early.
Cuirasses and helmets were manufactured in Japan as early as the 4th century."Tankō", worn by foot soldiers and "keikō", worn by horsemen were both pre-samurai types of early Japanese armour constructed from iron plates connected together by leather thongs. Japanese lamellar armour ("keiko") passed through Korea and reached Japan around the 5th century. These early Japanese lamellar armours took the form of a sleeveless jacket and a helmet.
Armour did not always cover all of the body; sometimes no more than a helmet and leg plates were worn. The rest of the body was generally protected by means of a large shield. Examples of armies equipping their troops in this fashion were the Aztecs (13th to 15th century CE).
In East Asia many types of armour were commonly used at different times by various cultures including, scale armour, lamellar armour, laminar armour, plated mail, mail, plate armour and brigandine. Around the dynastic Tang, Song, and early Ming Period, cuirasses and plates (mingguangjia) were also used, with more elaborate versions for officers in war. The Chinese, during that time used partial plates for "important" body parts instead of covering their whole body since too much plate armour hinders their martial arts movement. The other body parts were covered in cloth, leather, lamellar, and/or Mountain pattern. In pre-Qin dynasty times, leather armour was made out of various animals, with more exotic ones such as the rhinoceros.
Mail, sometimes called "chainmail", made of interlocking iron rings is believed to have first appeared some time after 300 BCE. Its invention is credited to the Celts, the Romans were thought to have adopted their design.
Gradually, small additional plates or discs of iron were added to the mail to protect vulnerable areas. Hardened leather and splinted construction were used for arm and leg pieces. The coat of plates was developed, an armour made of large plates sewn inside a textile or leather coat.
Early plate in Italy, and elsewhere in the 13th–15th century were made of iron. Iron armour could be carburised or case hardened to give a surface of harder steel. Plate armour became cheaper than mail by the 15th century as it required much less labour and labour had become much more expensive after the Black Death, though it did require larger furnaces to produce larger blooms. Mail continued to be used to protect those joints which could not be adequately protected by plate, such as the armpit, crook of the elbow and groin. Another advantage of plate was that a lance rest could be fitted to the breast plate.
The small skull cap evolved into a bigger true helmet, the bascinet, as it was lengthened downward to protect the back of the neck and the sides of the head. Additionally, several new forms of fully enclosed helmets were introduced in the late 14th century.
Probably the most recognised style of armour in the World became the plate armour associated with the knights of the European Late Middle Ages, but continuing to the early 17th century Age of Enlightenment in all European countries.
By about 1400 the full harness of plate armour had been developed in armouries of Lombardy. Heavy cavalry dominated the battlefield for centuries in part because of their armour.
In the early 15th century, advances in weaponry allowed infantry to defeat armoured knights on the battlefield. The quality of the metal used in armour deteriorated as armies became bigger and armour was made thicker, necessitating breeding of larger cavalry horses. If during the 14–15th centuries armour seldom weighed more than 15 kg, then by the late 16th century it weighed 25 kg. The increasing weight and thickness of late 16th century armour therefore gave substantial resistance.
In the early years of low velocity firearms, full suits of armour, or breast plates actually stopped bullets fired from a modest distance. Crossbow bolts, if still used, would seldom penetrate good plate, nor would any bullet unless fired from close range. In effect, rather than making plate armour obsolete, the use of firearms stimulated the development of plate armour into its later stages. For most of that period, it allowed horsemen to fight while being the targets of defending arquebuseers without being easily killed. Full suits of armour were actually worn by generals and princely commanders right up to the second decade of the 18th century. It was the only way they could be mounted and survey the overall battlefield with safety from distant musket fire.
The horse was afforded protection from lances and infantry weapons by steel plate barding. This gave the horse protection and enhanced the visual impression of a mounted knight. Late in the era, elaborate barding was used in parade armour.
Later.
Gradually starting in the mid-16th century, one plate element after another was discarded to save weight for foot soldiers.
Back and breast plates continued to be used throughout the entire period of the 18th century and through Napoleonic times, in many European (heavy) cavalry units, until the early 20th century. From their introduction, muskets could pierce plate armour, so cavalry had to be far more mindful of the fire. In Japan armour continued to be used until the end of the samurai era, with the last major fighting in which armour was used happening in 1868.Samurai armour had one last short lived use in 1877 during the Satsuma Rebellion.
Though the age of the knight was over, armour continued to be used in many capacities. Soldiers in the American Civil War bought iron and steel vests from peddlers (both sides had considered but rejected body armour for standard issue). The effectiveness of the vests varied widely—some successfully deflected bullets and saved lives, but others were poorly made and resulted in tragedy for the soldiers. In any case the vests were abandoned by many soldiers due to their weight on long marches as well as the stigma they got for being cowards from their fellow troops.
At the start of World War I, thousands of the French Cuirassiers rode out to engage the German Cavalry who likewise used helmets and armour. By that period, the shiny armour plate was covered in dark paint and a canvas wrap covered their elaborate Napoleonic style helmets. Their armour was meant to protect only against sabres and light lances. The cavalry had to beware of high velocity rifles and machine guns like the foot soldiers, who at least had a trench to protect them.
Present.
Today, ballistic vests, also known as flak jackets, made of ballistic cloth (e.g. kevlar, dyneema, twaron, spectra etc.) and ceramic or metal plates are common among police forces, security staff, corrections officers and some branches of the military.
The US Army has adopted Interceptor body armour, which uses Enhanced Small Arms Protective Inserts (E-S.A.P.I) in the chest, sides and back of the armour. Each plate is rated to stop a range of ammunition including 3 hits from a 7.62×51 NATO AP round at a range of , though accounts in Iraq and Afghanistan tell of soldiers shot as many as seven times in the chest without penetration. Dragon Skin body armour is another ballistic vest which is currently in testing with mixed results.
Despite advances in the protection offered by ballistic armour against projectiles, as the name implies, modern ballistic body armour is much less impervious to stabbing weapons unless they are augmented with anti-knife/anti-stab armour (usually a form of mail).
Other types.
The first modern production technology for armour plating was used by navies in the construction of the Ironclad warship, reaching its pinnacle of development with the battleship. It was also naval engineers that constructed the first tanks during World War I, giving rise to armoured fighting vehicles. Aerial armour has been used to protect pilots and aircraft systems since the Second World War.
In modern ground forces' usage, the meaning of armour has expanded to include the role of troops in combat. After the evolution of armoured warfare, mechanised infantry were mounted in armoured fighting vehicles and replaced light infantry in many situations. In modern armoured warfare, armoured units equipped with tanks and infantry fighting vehicles serve the historic role of both the battle cavalry, light cavalry and dragoons, and belong to the armoured branch.
History.
Ships.
The first ironclad battleship, with iron armour over a wooden hull, "La Gloire", was launched by the French Navy in 1859; she prompted the British Royal Navy to build a counter. The following year they launched "Warrior", which was twice the size and had iron armour over an iron hull. After the first battle between two ironclads took place in 1862 during the American Civil War, it became clear that the ironclad had replaced the unarmoured line-of-battle ship as the most powerful warship afloat.
Ironclads were designed for several roles, including as high seas battleships, coastal defence ships, and long-range cruisers. The rapid evolution of warship design in the late 19th century transformed the ironclad from a wooden-hulled vessel which carried sails to supplement its steam engines into the steel-built, turreted battleships and cruisers familiar in the 20th century. This change was pushed forward by the development of heavier naval guns (the ironclads of the 1880s carried some of the heaviest guns ever mounted at sea), more sophisticated steam engines, and advances in metallurgy which made steel shipbuilding possible.
The rapid pace of change in the ironclad period meant that many ships were obsolete as soon as they were complete, and that naval tactics were in a state of flux. Many ironclads were built to make use of the ram or the torpedo, which a number of naval designers considered the crucial weapons of naval combat. There is no clear end to the ironclad period, but towards the end of the 1890s the term "ironclad" dropped out of use. New ships were increasingly constructed to a standard pattern and designated battleships or armoured cruisers.
Trains.
Armoured trains saw use during the 19th century in the American Civil War (1861–1865), the Franco-Prussian War (1870–1871), the First and Second Boer Wars (1880–81 and 1899–1902),the Polish–Soviet War (1919–1921); the First (1914–1918) and Second World Wars (1939–1945) and the First Indochina War (1946–1954). The most intensive use of armoured trains was during the Russian Civil War (1918–1920).
During the Second Boer War on 15 November 1899, Winston Churchill, then a war-correspondent, was travelling on board an armoured train when it was ambushed by "Boer commandos". Churchill and many of the train's garrison were captured, though many others escaped, including wounded placed on the train's engine.
Armoured fighting vehicles.
Towards the end of World War I, armies on both sides were experimenting with plate armour as protection against shrapnel and ricocheting projectiles. The first proposal for a tank was by the Austrian "Oberleutenant" Günther Burstyn who, in 1911, proposed a design for "motor artillery" ("Motorengeschütz") with a turret, but his design never progressed beyond a German patent in 1912.
Armoured cars were put into use by the British on the Western Front. Initially an innovation to aid the recovery of downed pilots, they were sidelined when the front became static. They continued to be used in the more open Middle East battlefields.
Tank or "landship" development, originally conducted by the British Navy under the auspices of the Landships Committee was sponsored by the First Lord of the Admiralty, Winston Churchill and proceeded through a number of prototypes culminating in the Mark I tank prototype, named "Mother". The first tank to engage in battle was designated "D1", a British Mark I, during the Battle of Flers-Courcelette (part of the Somme Offensive) on 15 September 1916.
In contrast to World War II, Germany fielded very few tanks during WWI, with only 15 of the A7V type being produced in Germany during the war. Most German tanks were captured British ones. The first tank versus tank action took place on 24 April 1918 at Second Battle of Villers-Bretonneux, when three British Mark IVs met an advance of three German A7Vs, supported by infantry. Tanks were knocked out on both sides, but the German attack failed and they retreated.
Mechanical problems, poor mobility and piecemeal tactical deployment limited the military significance of the tank in World War I and the tank did not fulfil its promise of rendering trench warfare obsolete. Nonetheless, it was clear to military thinkers on both sides that tanks would play a significant role in future conflicts.
Aircraft.
With the development of effective anti-aircraft artillery in the period before the Second World War, military pilots, once the "knights of the air" during the First World War, became far more vulnerable to ground fire. As a response armour plating was added to aircraft to protect aircrew and vulnerable areas such as fuel tanks and engine.
Present.
Tank armour has progressed from the Second World War armour forms, now incorporating not only harder composites, but also reactive armour designed to defeat shaped charges. As a result of this, the main battle tank (MBT) conceived in the Cold War era can survive multiple RPG strikes with minimal effect on the crew or the operation of the vehicle. The light tanks that were the last descendants of the light cavalry during the Second World War have almost completely disappeared from the world's militaries due to increased lethality of the weapons available to the vehicle-mounted infantry.
The armoured personnel carrier (APC) is a relatively recent development, stemming from trials and experiences during the Second World War. The APC allows the safe and rapid movement of infantry in a combat zone, minimising casualties and maximising mobility. APCs are fundamentally different from the previously used armoured half-tracks in that they offer a higher level of protection from artillery burst fragments, and greater mobility in more terrain types. The basic APC design was substantially expanded to an Infantry fighting vehicle (IFV) when properties of an armoured personnel carrier and a light tank were combined in one vehicle.
Naval armour has fundamentally changed from the Second World War doctrine of thicker plating to defend against shells, bombs and torpedos. Passive defence naval armour is limited to kevlar or steel (either single layer or as spaced armour) protecting particularly vital areas from the effects of nearby impacts. Since ships cannot carry enough armour to completely prevent penetration by anti-ship missiles, they depend more on destroying an incoming missile before it hits, or causing it to miss its target.
Although the role of the ground attack aircraft significantly diminished after the Korean War, it re-emerged during the Vietnam War, and in the recognition of this, the US Air Force authorised the design and production of what was later to become the A-10 dedicated anti-armour and ground-attack aircraft of the Cold War.

</doc>
<doc id="2148" url="http://en.wikipedia.org/wiki?curid=2148" title="Armoured fighting vehicle">
Armoured fighting vehicle

An armoured fighting vehicle (or armored fighting vehicle - see spelling differences) AFV is a combat vehicle, protected by strong armour and armed with weapons, which combines operational mobility, tactical offensive, and defensive capabilities. AFVs can be wheeled or tracked. It is not uncommon for AFVs to be simply referred to as "armour".
Armoured fighting vehicles are classified according to their intended role on the battlefield and characteristics. This classification is not absolute; at different times different countries will classify the same vehicle in different roles. For example, armoured personnel carriers were generally replaced by infantry fighting vehicles in a similar role, but the latter has some capabilities lacking in the former. There may also be hybrid vehicles, such as the Stryker family of AFVs; the M1128 Mobile Gun System, an armoured car which mounts a large 105mm gun normally used in tank destroyers, but can theoretically be reconfigured to the M1126 Infantry Carrier Vehicle.
Successful general-purpose armoured fighting vehicles often also serve as the base of a whole family of specialized vehicles, for example, the M113 and MT-LB tracked carriers, and the MOWAG Piranha wheeled AFV.
Evolution of AFVs.
History.
Conception.
Prior to the invention of the internal combustion engine and the advent of armoured warfare in the 20th century, the AFV classification did not exist. However, war machines with rudimentary armour have been used in battle for millennia. These designs historically struggled between the paradox of exposed-mobility, effective-firepower and cumbersome-protection. Siege engines, such as battering rams, would often be armoured in order to protect the crews from the defenders. 
The idea of a vehicle with a tortoise like cover has been known since antiquity. Frequently cited is Leonardo da Vinci's 15th century sketch of a mobile, protected gun platform; the drawings show a conical, wooden shelter with apertures for cannons around the circumference. The machine was to be mounted on four wheels which would be turned by the crew through a system of hand cranks and cage (or "lantern") gears. Leonardo quoted ""I will build armored wagons which will be safe and invulnerable to enemy attacks. There will be no obstacle which it cannot overcome."" However, modern replicas have demonstrated that the human crew would have been able to move it over only short distances.
The chariot was used as a mobile archery platform and as a "battle taxi". The original chariot was a fast, light, open, two-wheeled conveyance drawn by two or more horses hitched side by side. It was used for ancient warfare during the bronze and the iron ages. The war wagon were medieval weapon-platforms development during the Hussite Wars around 1420 by Hussite forces rebelling in Bohemia. These heavy wagon were given protective sides with firing slits and heavy firepower from either a cannon or a force of hand-gunners and crossbowmen, supported by infantry using pikes and flails.
Modern AFVs.
Armoured car.
The first modern AFVs were armoured cars, dating back virtually to the invention of the motor car. The Motor Scout was designed and built by British inventor F.R. Simms in 1898. It was the first armed petrol engine powered vehicle ever built. The vehicle was a De Dion-Bouton quadricycle with a mounted Maxim machine gun on the front bar. An iron shield in front of the car protected the driver.
The first armoured car was the Simms' Motor War Car, designed by Simms and built by Vickers, Sons & Maxim in1899. The vehicle had Vickers armour 6 mm thick and was powered by a four-cylinder 3.3-litre 16 hp Cannstatt Daimler engine giving it a maximum speed of around . The armament, consisting of two Maxim guns, was carried in two turrets with 360° traverse.
Another early armoured car of the period was the French Charron, Girardot et Voigt 1902, presented at the "Salon de l'Automobile et du cycle" in Brussels, on 8 March 1902. The vehicle was equipped with a Hotchkiss machine gun, and with 7 mm armour for the gunner. Armoured cars were first used in large numbers on both sides during World War I as scouting vehicles which offered armoured protection to the crew.
Tank.
The development of the AFV took a great leap forward during World War I, when the tracked tank was developed by Britain and France to break the stalemate on the Western Front. The tank was envisioned as an armoured machine that could cross ground under fire from machine guns and respond with fire from mounted guns. It was to move on caterpillar tracks to enable it to cross ground broken up by shellfire and trenches.
In Great Britain, the Landships Committee was formed by the First Lord of the Admiralty, Winston Churchill on 20 February 1915. The Director of Naval Construction for the Royal Navy, Eustace Tennyson d'Eyncourt, was appointed to head the Committee in view of his experience with the engineering methods it was felt might be required. The first design, Little Willie, ran for the first time in September 1915 and served to develop the form of the track but an improved design, better able to cross trenches, swiftly followed and in January 1916 the prototype, nicknamed "Mother", was adopted as the design for future tanks. Production models of "Male" tanks (armed with naval cannon and machine guns) and "Females" (carrying only machine-guns) would go on to fight in history's first tank action at the Somme in September 1916. Great Britain produced about 2,600 tanks of various types during the war.
In 1916, the French pioneered the use of a full 360° rotation turret in a tank for the first time, with the creation of the Renault FT light tank, with the turret containing the tank's main armament. In addition to the traversible turret, another innovative feature of the FT was its engine located at the rear. This pattern, with the gun located in a mounted turret and the engine at the back, became the standard for most succeeding tanks across the world. The FT was the most numerous tank of the War; over 3,000 were made by late 1918.
Other AFVs.
The tank proved highly successful, and as technology improved the tank became a weapon that could cross large distances at much higher speeds than supporting infantry and artillery. The need to provide the units that would fight alongside the tank led to the development of a wide range of specialised AFVs, especially during the Second World War.
The Armoured personnel carrier, designed to transport infantry troops to the frontline, emerged towards the end of WWI. During the first actions with tanks it had become clear that often infantry could not keep up with the tanks; they could not be transported in the tank, due to the poor atmosphere quality. In 1917, Lieutenant G.R. Rackham was ordered to design an armoured vehicle specifically for troop transport. The Mark IX tank was built by Armstrong, Whitworth & Co., although just three vehicles were finished at the time of the Armistice and only 34 were built in total.
Different tank classifications emerged in the interwar period. The tankette was conceived as a mobile, two man model, mainly intended for reconnaissance. In 1925 Sir John Carden and Vivian Loyd produced the first such design - the Carden Loyd tankette. Tankettes saw use in the Italian Royal Army during the Italian invasion of Ethiopia, the Spanish Civil War, and almost every place Italian soldiers fought during World War II. The Imperial Japanese Army also used them for jungle warfare.
The British Gun Carrier Mark I was the first Self-propelled artillery and was fielded in 1917. It was based on the first tank, the British Mark I and carried a heavy field gun. The next major advance was the Birch gun developed for the motorised warfare experimental brigade (the Experimental Mechanized Force). This mounted a field gun, capable of the usual artillery trajectories, on a tank style chassis.
During WW2, most nations developed self-propelled artillery vehicles. These had mounted guns on a tracked chassis (often that of an obsolete or superseded tank) and provide an armoured superstructure to protect the gun and its crew. The first British design, "Bishop", carried the 25 pdr gun-howitzer, but in a mounting that severely limited the gun's performance. It was replaced by the more effective Sexton. The Germans created many examples of lightly armored self-propelled anti-tank guns using captured French equipment (example Marder I), their own obsolete light tank chassis (Marder II), or ex-Czech chassis (Marder III). These led to better protected tank destroyers, built on medium tank chassis such as the Jagdpanzer IV and Jagdpanther.
The Self-propelled anti-aircraft weapon debuted in WWI. The German 77 mm anti-aircraft gun, was truck-mounted and used to great effect against British tanks, and the British QF 3 inch 20 cwt was mounted on trucks for use on the Western Front. Although the Birch gun was a general purpose artillery piece on an armoured tracked chassis, it was capable of being elevated for anti-aircraft use. Vickers Armstrong developed one of the first SPAAGs based on the chassis of the Mk.E 6-ton light tank/Dragon Medium Mark IV tractor, mounting a Vickers QF-1 "Pom-Pom" gun of 40 mm. The Germans fielded the SdKfz 10/4 and 6/2, cargo halftracks mounting single 20 mm or 37 mm AA guns (respectively) by the start of the War.
By the end of World War II, most modern armies had vehicles to carry infantry, artillery and anti-aircraft weaponry . Most modern AFVs are superficially similar in design to their World War II counterparts, but with significantly better armour, weapons, engines and suspension. The increase in the capacity of transport aircraft has allowed AFVs to be practically transported by air. Many armies are replacing some or all of their traditional heavy vehicles with lighter airmobile versions, often with wheels instead of tracks.
Design.
Armour.
The level of armour protection between AFVs varies greatly - a main battle tank will normally be designed to take hits from other tank guns and anti-tank missiles, whilst light reconnaissance vehicles are often only armoured "just in case". Whilst heavier armour provides better protection, it makes vehicles less mobile (for a given engine power), limits its air-transportability, increases cost, uses more fuel and may limit the places it can go - for example, many bridges may be unable to support the weight of a main battle tank. A trend toward composite armour is taking place in place of steel - composites are stronger for a given weight, allowing the tank to be lighter for the same protection as steel armour, or better protected for the same weight. Armour is being supplemented with active protection systems on a number of vehicles, allowing the AFV to protect itself from incoming projectiles.
The level of protection also usually varies considerably throughout the individual vehicle too, depending on the role of the vehicle and the likely direction of attack. For example, a main battle tank will usually have the heaviest armour on the hull front and the turret, lighter armour on the sides of the hull and the thinnest armour on the top and bottom of the tank. Other vehicles - such as the MRAP family - may be primarily armoured against the threat from IEDs and so will have heavy, sloped armour on the bottom of the hull.
Weaponry.
Weaponry varies by a very wide degree between AFVs - lighter vehicles for infantry carrying, reconnaissance or specialist roles may have only a machine gun for self-defence (or no armament at all), whereas heavy self propelled artillery will carry large guns, mortars or rocket launchers. These weapons may be mounted on a pintle, affixed directly to the vehicle or placed in a turret or cupola.
The greater the recoil a weapon on an AFV is, the larger the turret ring needs to be. A larger turret ring necessitates a larger vehicle. To avoid listing to the side, turrets are usually located at the centre of the vehicle on vehicles that are capable of amphibious operations.
Grenade launchers provide a versatile launch platform for a plethora of munitions including, smoke, phosphorus, tear gas, illumination, anti-personnel, infrared and radar-jamming rounds.
Turret stabilization is an important capability because it enables firing on the move and prevents crew fatigue.
Engine.
Modern AFVs have primarily used either petrol (gasoline) or diesel piston engines. More recently gas turbines have been used. Most early AFVs used petrol engines, as they offer a good power-to-weight ratio. However, they fell out of favour during World War Two due to the flammability of the fuel.
Most current AFVs are powered by a diesel engine; modern technology including the use of turbo-charging help to overcome the lower power-to-weight ratio of diesel engines compared to petrol.
Gas turbine (turboshaft) engines offer a very high power-to-weight ratio and were starting to find favour in the late 20th century - however they offer very poor fuel consumption and as such some armies are switching from gas turbines back to diesel engines (i.e. the Russian T-80 used a gas turbine engine, whereas the later T-90 does not). The US M1 Abrams is a notable example of a gas turbine powered tank.
Modern classification by type and role.
Notable armoured fighting vehicles extending from post-World War I to today.
Tank.
The tank is an all terrain AFV designed primarily to engage enemy forces by the use of direct fire in the frontal assault role. Though several configurations have been tried, particularly in the early experimental days of tank development, a standard, mature design configuration has since emerged to a generally accepted pattern. This features a main artillery gun, mounted in a fully rotating turret atop a tracked automotive hull, with various additional machine guns throughout.
Philosophically, the tank is, by its very nature, an offensive weapon. Being a protective encasement with at least one gun position, it is essentially a pillbox or small fortress (though these are static fortifications of a purely defensive nature) that can move toward the enemy - hence its offensive utility.
Historically, tanks are divided into three categories: 
Cavalry tank, cruiser tank, infantry tank, and assault-breakthrough tank have been used by various countries to classify tanks by operational role. Tankette is used to describe particularly small one or two-man vehicles, typically armed with a machine gun and/or anti-air weapons.
In modern use, the heavy tank has fallen out of favour, being supplanted by more heavily-armed and armoured descendent of the medium tanks - the main battle tank. The light tank has in many militaries lost favour to cheaper, faster, lighter armoured cars and tank destroyers - however light tanks (or similar vehicles with other names) are still in service with a number of forces as reconnaissance vehicles, most notably the Russian Marines with the Pt76, British Army with the Scimitar and the Chinese Army with the Type 63.
Main battle tank.
Modern main battle tanks incorporates recent advances in automotive, artillery, and armour technology to combine the best characteristics of the historic medium and heavy tanks into a single, all around type. They are also the most expensive to mass-produce. It is distinguished by its high level of firepower, mobility and armour protection relative to other vehicles of its era. It can cross comparatively rough terrain at high speeds, but its heavy-dependency on fuel, maintenance, and ammunition makes it logistically demanding. It has the heaviest armour of any IFV on the battlefield, and carries a powerful precision-guided munition weapon systems that may be able to engage a wide variety of both ground targets and air targets. It is among the most versatile and fearsome land-based weapon-systems of the 21st-century, valued for its shock action against other troops and high survivability, although it is still vulnerable to anti-tank warfare.
Tankette.
A tankette is a tracked armed and armoured vehicle resembling a small "ultra-light tank" roughly the size of a car, mainly intended for light infantry support or scouting. They were one or two-man vehicles armed with a machine gun. Colloquially it may also simply mean a "small tank".
Tankettes were designed and built by several nations between the 1920s and 1940s. They were very popular with smaller countries. Some saw some combat (with limited success) in World War II. However, the vulnerability of their light armour eventually caused the concept to be abandoned.
"Super"-heavy tank.
The term "super-heavy tank" has been used to describe armoured fighting vehicles of extreme size, generally over 75 tonnes. Programs have been initiated on several occasions with the aim of creating an invincible siegeworks/breakthrough vehicle for penetrating enemy formations and fortifications without fear of being destroyed in combat. Examples were designed in World War I and World War II, along with a few in the Cold War. However, few working prototypes were ever been built and there are no clear evidence any of these vehicles saw combat, as their immense size would have made most designs impracticable.
Flame tank.
A flame tank is a tank equipped with a flamethrower, most commonly used to supplement combined arms attacks against fortifications, confined spaces, or other obstacles. The type only reached significant use in the Second World War, during which the United States, Soviet Union, Germany, Italy, Japan and the United Kingdom (including members of the British Commonwealth) all produced flamethrower-equipped tanks.
A number of production methods were used. The flamethrowers used were either modified versions of existing infantry flame weapons (Flammpanzer I and II) or specially designed (Flammpanzer III). They were mounted externally (Flammpanzer II), replaced existing machine gun mounts, or replaced the tank's main armament (Flammpanzer III). Fuel for the flame weapon was either carried inside the tank, in armoured external storage, or in some cases in a special trailer behind the tank (Churchill Crocodile).
Flame tanks have been superseded by thermobaric weapons such as the Russian TOS-1.
Infantry tank.
The idea for this tank was developed during World War I by the British and French. The infantry tank was designed to work in concert with infantry in the assault, moving mostly at a walking pace, which required it to carry heavy armour to survive defensive fire. Its main purpose would have been to clear the battlefield of obstacles, suppress or destroy defenders, and protect the infantry on their advance into and through enemy lines by giving mobile overwatch and cover.
The British came back to the concept in the pre-Second World War era. The infantry tank did not need to be fast so it could carry more armour. One of the best-known infantry tanks was the Matilda II of World War II.
Cruiser tank.
A cruiser tank, or cavalry tank, was designed to move fast and exploit penetrations of the enemy front. The idea originated in "Plan 1919", a British plan to break the trench deadlock of World War I in part via the use of high-speed tanks. This concept was later implemented in the "fast tanks" pioneered by Walter Christie.
They were used by the United Kingdom during World War II. Cruiser tanks were designed to complement infantry tanks, exploiting gains made by the latter to attack and disrupt the enemy rear areas. In order to give them the required speed, cruiser designs sacrificed armour compared to the infantry tanks.
The Soviet fast tank ("bistrokhodniy tank", or BT tank) classification also came out of the infantry/cavalry concept of armoured warfare and formed the basis for the British cruisers after 1936. The T-34 was a development of this line of tanks as well, though their armament, armour, and all-round capability places them firmly in the medium tank category.
Armoured car.
The military's armoured car is a wheeled armoured vehicle, generally lighter than other armoured fighting vehicles, primarily being armoured and/or armed for self-defence of the occupants. Other multi-axled wheeled military vehicles can be quite large, and actually be superior to some smaller tracked vehicles in terms of armour and armament. They usually do not have attached weaponry. Armoured cars are often used in military marches and processions, or for the escorting of important figures.
Aerosani.
An "aerosani" (, literally "aerosled") is a type of propeller-driven snowmobile, running on skis, used for communications, mail deliveries, medical aid, emergency recovery and border patrolling in northern Russia, as well as for recreation. Aerosanis were used by the Soviet Red Army during the Winter War and World War II.
The first aerosanis may have been built by young Igor Sikorsky in 1909–10, before he built multi-engine airplanes and helicopters. They were very light plywood vehicles on skis, propelled by old airplane engines and propellers.
Scout car.
A scout car is a of military armored reconnaissance vehicle, capable of off-road mobility and often carrying mounted weapons such as machine guns for offensive capabilities and crew protection. They often only carry an operational crew aboard, which differentiates them from wheeled armored personnel carriers (APCs) and Infantry Mobility Vehicles (IMVs), but early scout cars, such as the open-topped US M3 Scout Car could carry a crew of seven. The term is often used synonymously with the more general term armored car, which also includes armored civilian vehicles. They are also differentiated by being designed and built for purpose, as opposed to improved technicals which might serve in the same role.
Internal security vehicle.
An internal security vehicle (ISV), also known as an armoured security vehicle (ASV), is a combat vehicle used for supporting contingency operations. Security vehicles are typically armed with a turreted heavy machine gun and auxiliary medium machine gun. The vehicle is designed to minimize firepower dead space and the vehicles weapons can be depressed to a maximum of 12°. Non-lethal water cannons and tear gas cannons can provide suppressive fire in lieu of unnecessary deadly fire.
The vehicle must be protected against weapons typical of riots. Protection from incendiary devices is achieved though coverage of the air intake and exhaust ports as well as a strong locking mechanism on the fuel opening. Turret and door locks prevent access to the interior of the vehicle by rioters. Vision blocks, ballistic glass and window shutters and outside surveillance cameras allow protected observation from within the vehicle. Wheeled 4x4 and 6x6 configurations are typical of security vehicles. Tracked security vehicles are often cumbersome and leave negative political connotations for being perceived as an imperial invading force.
Improvised fighting vehicle.
An improvised fighting vehicle is a combat vehicle resulting from modifications to a civilian or military non-combat vehicle in order to give it a fighting capability. Such modifications usually consist of the grafting of armour plating and weapon systems. Various militaries have procured such vehicles, ever since the introduction of the first automobiles into military service.
During the early days, the absence of a doctrine for the military use of automobiles or of an industry dedicated to producing them, lead to much improvisation in the creation of early armoured cars, and other such vehicles. Later, despite the advent of arms industries in many countries, several armies still resorted to using ad hoc contraptions, often in response to unexpected military situations, or as a result of the development of new tactics for which no available vehicle was suitable. The construction of improvised fighting vehicles may also reflect a lack of means for the force that uses them. This is especially true in developing countries, where various armies and guerrilla forces have used them, as they are more affordable than military-grade combat vehicles.
Modern examples include military gun truck used by units of regular armies or other official government armed forces, based on a conventional cargo truck, that is able to carry a large weight of weapons and armour. They have mainly been used by regular armies to escort military convoys in regions subject to ambush by guerrilla forces. "Narco tanks", used by Mexican drug cartels in the Mexican Drug War, are built from such trucks, which combines operational mobility, tactical offensive, and defensive capabilities.
Troop Carriers.
Troop-carrying AFVs are divided into two main types - armoured personnel carriers (APCs) and infantry fighting vehicles (IFVs). The main difference between the two is down to their intended role - the APC is designed purely to transport troops and is armed for self-defence only - whereas the IFV is designed to provide fire support to the infantry it carries.
Infantry fighting vehicle.
An infantry fighting vehicle (IFV), also known as a mechanized infantry combat vehicle (MICV), is a type of armoured fighting vehicle used to carry infantry into battle and provide direct fire support. The first example of an IFV was the West German Schützenpanzer Lang HS.30 which served in the Bundeswehr from 1958 until the early 1980s..
IFVs are similar to armoured personnel carriers (APCs) and infantry carrier vehicles (ICVs), designed to transport a section or squad of infantry (generally between five and ten men) and their equipment. They are differentiated from APCs— which are purely "troop-transport" vehicles armed only for self-defense— because they are designed to give direct fire support to the dismounted infantry and so usually have significantly enhanced armament. IFVs also often have improved armour and some have firing ports (allowing the infantry to fire personal weapons while mounted).
They are typically armed with an autocannon of 20 to 40mm calibre, 7.62mm machine guns, anti-tank missiles (ATGMs) and/or surface-to-air missiles (SAGMs). IFVs are usually tracked, but some wheeled vehicles fall into this category. IFVs are generally less heavily armed and armoured than main battle tanks. They sometimes carry anti-tank missiles to protect and support infantry against armoured threats, such as the NATO TOW missile and Soviet Bastion, which offer a significant threat to tanks. Specially-equipped IFVs have taken on some of the roles of light tanks; they are used by reconnaissance organizations, and light IFVs are used by airborne units which must be able to fight without the heavy firepower of tanks.
Armoured personnel carrier.
Armoured personnel carriers are intended to carry infantry quickly and relatively safely to point where they are deployed. In 1918, the British Mk V* (Mark Five Star) tank carried a small number of troops as an experiment, but the men were debilitated by the conditions inside the vehicle. The first purpose-built APC was the British Mk IX (Mark Nine). In the US the term "Infantry Carrier Vehicle (ICV)" is used. In 1944, the Canadian general Guy Simonds ordered the conversion of redundant armoured vehicles to carry troops (generically named "Kangaroos"). This proved highly successful, even without training, and the concept was widely used in the 21st Army Group. Post-war, specialised designs were built, such as the Soviet BTR-60 and US M113.
Infantry mobility vehicle.
An infantry mobility vehicle (IMV) or protected patrol vehicle (PPV) is a wheeled armored personnel carrier (APC) serving as a military patrol, reconnaissance or security vehicle. Examples include the ATF Dingo, AMZ Dzik, AMZ Tur, Mungo ESK, and Bushmaster IMV. This term also applies to the vehicles currently being fielded as part of the MRAP program.
IMVs were developed in response to the threats of modern counter insurgency warfare, with an emphasis on Ambush Protection and Mine-Resistance. Similar vehicles existed long before the term IMV was coined, such as the French VAB and South African Buffel. The term is coming more into use to differentiate light 4x4 wheeled APCs from the traditional 8x8 wheeled APCs. It is a neologism for what might have been classified in the past as an armoured scout car, such as the BRDM, but the IMV is distinguished by having a requirement to carry dismountable infantry. The up-armoured M1114 Humvee variant can be seen as an adaptation of the unarmoured Humvee to serve in the IMV role.
Amphibious vehicles.
Many modern military vehicles, ranging from light wheeled command and reconnaissance, through armoured personnel carriers and tanks, are manufactured with amphibious capabilities. Contemporary wheeled armoured amphibians include the French Véhicule de l'Avant Blindé and Véhicule Blindé Léger. The latter is a small, lightly armoured 4x4 all-terrain vehicle that is fully amphibious and can swim at 5.4 km/h. The VAB ("Véhicule de l'Avant Blindé" - "Armoured Vanguard Vehicle") is a fully amphibious armoured personnel carrier powered in the water by two water jets, that entered service in 1976 and produced in numerous configurations, ranging from basic personnel carrier, anti-tank missile platform.
During the Cold War the Soviet bloc states developed a number of amphibious APCs, fighting vehicles and tanks, both wheeled and tracked. Most of the vehicles the Soviets designed were amphibious, or could ford deep water. Wheeled examples are the BRDM-1 and BRDM-2 4x4 armoured scout cars, as well as the BTR-60, BTR-70, BTR-80 and BTR-94 8x8 armoured personnel carriers and the BTR-90 infantry fighting vehicle.
The United States started developing a long line of Landing Vehicle Tracked (LVT) designs from ca. 1940. The US Marine Corps currently uses the AAV7-A1 Assault Amphibious Vehicle, which was to be succeeded by the Expeditionary Fighting Vehicle, which was capable of planing on water and can achieve water speeds of 37–46 km/h. The EFV project has been cancelled.
A significant amount of tracked armoured vehicles that are primarily intended for land-use, have some amphibious cability, tactically useful inland, reducing dependence on bridges. They use their tracks, sometimes with added propeller or water jets for propulsion. As long as the banks have a shallow enough slopes to enter or leave the water they can cross rivers and water obstacles.
Some heavy tanks can operate amphibiously with a fabric skirt to add buoyancy. The Sherman DD tank used in the Normandy landings had this setup. When in water the waterproof float screen was raised and propellers deployed. Some modern vehicles use a similar skirt.
Armoured engineering vehicle.
Typically based on the platform of a main battle tank, these vehicles go by different names depending upon the country of use or manufacture. In the US the term "combat engineer vehicle (CEV)" is used, in the UK the term "Armoured Vehicle Royal Engineers (AVRE)" is used, while in Canada and other commonwealth nations the term "armoured engineer vehicle (AEV)" is used. There is no set template for what such a vehicle will look like, yet likely features include a large dozer blade or mine ploughs, a large calibre demolition cannon, augers, winches, excavator arms and cranes, or lifting booms.
These vehicles are designed to directly conduct obstacle breaching operations and to conduct other earth-moving and engineering work on the battlefield. Good examples of this type of vehicle include the UK Trojan AVRE, the Russian IMR, and the US M728 Combat Engineer Vehicle.
It should be noted that while the term "armoured engineer vehicle" is used specifically to describe these multi-purpose tank-based engineering vehicles, that term is also used more generically in British and Commonwealth militaries to describe all heavy tank-based engineering vehicles used in the support of mechanized forces. Thus, "armoured engineer vehicle" used generically would refer to AEV, AVLB, Assault Breachers, and so on.
Assault breacher vehicle.
An assault breacher vehicle (ABV), also known as a explosive ordnance disposal vehicle (EODV), or simply Breacher, is especially designed to clear pathways for troops and other vehicles through minefields and along roadside bombs and Improvised Explosive Devices. These vehicles are based on a tank-chassis with 1,500+ horsepower engines, but fitted with a 50-caliber machine gun and a front-mounted 5-meter-wide plow, supported by metallic skis that glide on the dirt and typically equipped with at least of Mine Clearing Line Charges: rockets carrying C-4 explosives up to 100–150 meters forward, detonating hidden bombs at a safe distance, so that troops and vehicles can pass through safely. They were called ""the answer"" to the deadliest threat facing NATO troops in modern asymmetrical conflict. 
Armoured bulldozer.
The armored bulldozer is a basic tool of combat engineering. These combat engineering vehicles combine the earth moving capabilities of the bulldozer with armor which protects the vehicle and its operator in or near combat. Most are civilian bulldozers modified by addition of vehicle armor/military equipment, but some are tanks stripped of armament and fitted with a dozer blade. Some tanks have bulldozer blades while retaining their armament, but this does not make them armored bulldozers as such, because combat remains the primary role — earth moving is a secondary task.
Armoured recovery vehicle.
An armoured recovery vehicle (ARV) is a type of vehicle recovery armoured fighting vehicle used to repair battle- or mine-damaged as well as broken-down armoured vehicles during combat, or to tow them out of the danger zone for more extensive repairs. To this end the term ""Armoured Repair and Recovery Vehicle" (ARRV)" is also used.
ARVs are normally built on the chassis of a main battle tank (MBT), but some are also constructed on the basis of other armoured fighting vehicles, mostly armoured personnel carriers (APCs). ARVs are usually built on the basis of a vehicle in the same class as they are supposed to recover; a tank-based ARV is used to recover tanks, while an APC-based one recovers APCs, but does not have the power to tow a much heavier tank.
Armoured vehicle-launched bridge.
An armoured vehicle-launched bridge (AVLB) is a combat support vehicle, sometimes regarded as a subtype of combat engineering vehicle, designed to assist militaries in rapidly deploying tanks and other armoured fighting vehicles across rivers. The AVLB is usually a tracked vehicle converted from a tank chassis to carry a folding metal bridge instead of weapons. The AVLB's job is to allow armoured or infantry units to cross water, when a river too deep for vehicles to wade through is reached, and no bridge is conveniently located (or sufficiently sturdy, a substantial concern when moving 60-ton tanks).
The bridge layer unfolds and launches its cargo, providing a ready-made bridge across the obstacle in only minutes. Once the span has been put in place, the AVLB vehicle detaches from the bridge, and moves aside to allow traffic to pass. Once all of the vehicles have crossed, it crosses the bridge itself and reattaches to the bridge on the other side. It then retracts the span ready to move off again. A similar procedure can be employed to allow crossings of small chasms or similar obstructions. AVLBs can carry bridges of or greater in length. By using a tank chassis, the bridge layer is able to cover the same terrain as main battle tanks, and the provision of armour allows them to operate even in the face of enemy fire. However, this is not a universal attribute: some exceptionally sturdy 6x6 or 8x8 truck chassis have lent themselves to bridge-layer applications.
Combat engineer section carriers.
The combat engineer section carriers are used to transport sappers (combat engineers) and can be fitted with a bulldozer's blade and other mine-breaching devices. They are often used as APCs because of their carrying ability and heavy protection. They are usually armed with machine guns and grenade launchers and usually tracked to provide enough tractive force to push blades and rakes. Some examples are the U.S. M113 APC, IDF Puma, Nagmachon, Husky, and U.S. M1132 ESV (a Stryker variant).
Air defense vehicles.
An anti-aircraft vehicle, also known as a self-propelled anti-aircraft weapon (SPAA) or self-propelled air defense system (SPAD), is a mobile vehicle with a dedicated anti-aircraft capability. The Russian equivalent of SPAAG is ZSU (from "zenitnaya samokhodnaya ustanovka" - "anti-aircraft self-propelled mount"). Specific weapon systems used include machine guns, autocannons, larger guns, or missiles, and some mount both guns and longer-ranged missiles. Platforms used include both trucks and heavier combat vehicles such as APCs and tanks, which add protection from aircraft, artillery, and small arms fire for front line deployment. Anti-aircraft guns are usually mounted in a quickly-traversing turret with a high rate of elevation, for tracking fast-moving aircraft. They are often in dual or quadruple mounts, allowing a high rate of fire. Today, missiles (generally mounted on similar turrets) have largely supplanted anti-aircraft guns.
Self-propelled artillery.
Self-propelled artillery vehicles give mobility to artillery. Within the term are covered self-propelled guns (or howitzers) and rocket artillery. They are highly mobile, usually based on tracked chassis carrying either a large howitzer or other field gun or alternatively a mortar or some form of rocket or missile launcher. They are usually used for long-range indirect bombardment support on the battlefield.
In the past, self-propelled artillery has included direct-fire "Gun Motor Carriage" vehicles such as assault guns and tank destroyers (also known as self-propelled anti-tank guns). These have been heavily armoured vehicles, the former providing danger-close fire-support for infantry and the latter acting as specialized anti-tank vehicles.
Modern self-propelled artillery vehicles may superficially resemble tanks, but they are generally lightly armoured, too lightly to survive in direct-fire combat. However, they protect their crews against shrapnel and small arms and are therefore usually included as armoured fighting vehicles. Many are equipped with machine guns for defence against enemy infantry.
The key advantage of self-propelled over towed artillery is that it can be brought into action much faster. Before the towed artillery can be used, it has to stop, unlimber and set up the guns. To move position, the guns must be limbered up again and brought — usually towed — to the new location. By comparison self-propelled artillery in combination with modern communications can stop at a chosen location and begin firing almost immediately, then quickly move on to a new position. This ability is very useful in a mobile conflict and particularly on the advance.
Conversely, towed artillery was and remains cheaper to build and maintain. It is also lighter and can be taken to places that self-propelled guns cannot reach, so despite the advantages of the self-propelled artillery, towed guns remain in the arsenals of many modern armies.
Assault gun carriage.
An assault gun is a gun or howitzer mounted on a motor vehicle or armoured chassis, designed for use in the direct fire role in support of infantry when attacking other infantry or fortified positions.
Historically the custom-built fully armored assault guns usually mounted the gun or howitzer in a fully enclosed casemate on a tank chassis. The use of a casemate instead of a gun turret limited these weapons field of fire, but allowed a larger gun to be fitted relative to the chassis, more armour to be fitted for the same weight, and provided a cheaper construction. The increased space and reduced weight of the turretless design also allowed for the mounting of a larger weapon and heavier frontal armour on any given chassis. In most cases, these turretless vehicles also presented a lower profile as a target for the enemy.
Mortar carrier.
A mortar carrier is a self-propelled artillery vehicle carrying a mortar as its primary weapon. Mortar carriers cannot be fired while on the move and some must be dismounted to fire. In U.S. Army doctrine, mortar carriers provide close and immediate indirect fire support for maneuver units while allowing for rapid displacement and quick reaction to the tactical situation. The ability to relocate not only allows fire support to be provided where it is needed faster but also allows these units to avoid counter-battery fire. Mortar carriers have traditionally avoided direct contact with the enemy. Many units report never using secondary weapons in combat.
Prior to the Iraq War, American 120mm mortar platoons reorganized from six M1064 mortar carriers and two M577 fire direction centers (FDC) to four M1064 and one FDC. The urban environment of Iraq made it difficult to utilize mortars. New technologies such as mortar ballistic computers and communication equipment and are being integrated. Modern era combat is becoming more reliant on direct fire support from mortar carrier machine guns.
Multiple rocket launcher.
A multiple rocket launcher is a type of unguided rocket artillery system. Like other rocket artillery, multiple rocket launchers are less accurate and have a much lower (sustained) rate of fire than batteries of traditional artillery guns. However, they have the capability of simultaneously dropping many hundreds of kilograms of explosive, with devastating effect.
The Korean Hwacha is an example of an early weapon system with a resemblance to the modern-day multiple rocket launcher. The first modern multiple rocket launcher was the German "Nebelwerfer" of the 1930s, a small towed artillery piece. Only later in World War II did the Allies deploy similar weapons in the form of the Land Mattress.
The first self-propelled multiple rocket launchers — and arguably the most famous — were the Soviet BM-13 Katyushas, first used during World War II and exported to Soviet allies afterwards. They were simple systems in which a rack of launch rails was mounted on the back of a truck. This set the template for modern multiple rocket launchers. The Americans mounted tubular launchers atop M4 Sherman tanks to create the T34 Calliope rocket launching tank, only used in small numbers, as their closest equivalent to the Katyusha.
Tank destroyer.
Tank destroyers and tank hunters are armed with an anti-tank gun or missile launcher, and are designed specifically to engage enemy armoured vehicles. Many have been based on a tracked tank chassis, while others are wheeled. Since World War II, main battle tanks have largely replaced gun-armed tank destroyers; although lightly armoured anti tank guided missile (ATGM) carriers are commonly used for supplementary long-range anti-tank engagements.
In post-Cold War conflict, the resurgence of expeditionary warfare has seen the emergence of gun-armed wheeled vehicles, sometimes called "protected gun systems", which may bear a superficial resemblance to tank destroyers, but are employed as direct fire support units typically providing support in low intensity operations such as Iraq and Afghanistan. These have the advantage of easier deployment, as only the largest air transports can carry a main battle tank, and their smaller size makes them more effective in urban combat.
Many forces' IFVs carry anti-tank missiles in every infantry platoon, and attack helicopters have also added anti-tank capability to the modern battlefield. But there are still dedicated anti-tank vehicles with very heavy long-range missiles, or intended for airborne use. There have also been dedicated anti-tank vehicles built on ordinary armoured personnel carrier or armoured car chassis. Examples include the U.S. M901 ITV (Improved TOW Vehicle) and the Norwegian NM142, both on an M113 chassis, several Soviet ATGM launchers based on the BRDM reconnaissance car, the British FV438 Swingfire and FV102 Striker and the German Raketenjagdpanzer series built on the chassis of the HS 30 and Marder IFV.
Armoured train.
An armoured train is a railway train protected with armour. They are usually equipped with railroad cars armed with artillery and machine guns. They were mostly used during the late 19th and early 20th century, when they offered an innovative way to quickly move large amounts of firepower. Their use was discontinued in most countries when road vehicles became much more powerful and offered more flexibility, and because armoured trains were too vulnerable to track sabotage as well as attacks from the air. However, the Russian Federation used improvised armoured trains in the Second Chechen War in the late 1990s and 2000s.
The railroad cars on an armoured train were designed for many tasks such as carrying guns and machine guns, infantry units, anti-aircraft guns. During World War II, the Germans would sometimes put a "Fremdgerät" (such as a captured French Somua S-35 or Czech PzKpfw 38(t) light tank, or Panzer II light tank) on a flatbed car which could be quickly offloaded by means of a ramp and used away from the range of the main railway line to chase down enemy partisans
Different types of armour were used to protect from attack by tanks. In addition to various metal plates, concrete and sandbags were used in some cases for improvised armoured trains.
Armoured trains were sometimes escorted by a kind of rail-tank called a draisine. One such example was the 'Littorina' armoured trolley which had a cab in the front and rear, each with a control set so it could be driven down the tracks in either direction. Littorina mounted two dual 7.92mm MG13 machine gun turrets from Panzer I light tanks.

</doc>
<doc id="2151" url="http://en.wikipedia.org/wiki?curid=2151" title="Anton Drexler">
Anton Drexler

Anton Drexler (13 June 1884 – 24 February 1942) was a German far-right political leader of the 1920s who was instrumental in the formation of the pan-German and anti-Semitic German Workers' Party ("Deutsche Arbeiterpartei" - DAP), the antecedent of the Nazi Party ("Nationalsozialistische Deutsche Arbeiterpartei" - NSDAP). Drexler served as mentor to Adolf Hitler during his early days in politics.
Biography.
Born in Munich, Drexler was a machine-fitter before becoming a railway locksmith in Berlin. He joined the Fatherland Party during World War I. In March 1918 Drexler founded a branch of the "Freien Arbeiterausschuss für einen guten Frieden" (Free Workers' Committee for a good Peace) league. Thereafter in 1918, Karl Harrer (a journalist and member of the Thule Society), along with Drexler and several others formed the "Politischer Arbeiterzirkel" (Political Workers' Circle). The members met periodically for discussions with themes of nationalism and racism directed against the Jews. Drexler was a poet and a member of the völkisch agitators who, together with Harrer, founded the German Workers' Party (DAP), in Munich with Gottfried Feder and Dietrich Eckart on 5 January 1919.
At a meeting of the Party in Munich in September 1919, the main speaker was Gottfried Feder. When he had finished speaking, Adolf Hitler got involved in a heated political argument with a visitor, Professor Baumann, who questioned the soundness of Feder's arguments against capitalism and proposed that Bavaria should break away from Prussia and found a new South German nation with Austria. In vehemently attacking the man's arguments he made an impression on the other party members with his oratory skills and, according to Hitler, the "professor" left the hall acknowledging unequivocal defeat. Drexler approached Hitler and thrust a booklet into his hand. It was "My Political Awakening" and, according to Hitler, it reflected the ideals he already believed in. Impressed with Hitler, Drexler invited him to join the DAP. Hitler accepted on 12 September 1919, becoming the party's 55th member. In less than a week, Hitler received a postcard from Drexler stating he had officially been accepted as a DAP member and he should come to a "committee" meeting to discuss it. Hitler attended the "committee" meeting held at the run-down Alte Rosenbad beer-house.
Hitler began to make the party more public, and he organised their biggest meeting yet of 2,000 people, for 24 February 1920 in the "Staatliches Hofbräuhaus in München". Such was the significance of this particular move in publicity that Karl Harrer resigned from the party in disagreement. It was in this speech that Hitler, for the first time, enunciated the twenty-five points of the "German Worker's Party'"s manifesto that had been drawn up by Drexler, Feder, and Hitler. Through these points he gave the organisation a much bolder stratagem with a clear foreign policy (abrogation of The Treaty of Versailles, a Greater Germany, Eastern expansion, exclusion of Jews from citizenship). On the same day the party was renamed the "Nationalsozialistische Deutsche Arbeiterpartei" - NSDAP.
By 1921, Hitler was rapidly becoming the undisputed leader of the Party. In June 1921, while Hitler and Eckart were on a fundraising trip to Berlin, a mutiny broke out within the NSDAP in Munich. Members of its executive committee, some of whom considered Hitler to be too overbearing, wanted to merge with the rival German Socialist Party (DSP). Hitler returned to Munich on 11 July and angrily tendered his resignation. The committee members realised his resignation would mean the end of the party. Hitler announced he would rejoin on the condition that he would replace Drexler as party chairman, and that the party headquarters would remain in Munich. The committee agreed; he rejoined the party as member 3,680. Drexler was thereafter moved to the purely symbolic position of honorary president, and left the Party in 1923.
Drexler was also a member of a "völkisch" political club for affluent members of Munich society known as the Thule Society. His membership in the NSDAP ended when it was temporarily outlawed in 1923 following the Beer Hall Putsch, in which Drexler had not taken part. In 1924 he was elected to the Bavarian state parliament for another party, in which he served as vice-president until 1928. He had no part in the NSDAP's refounding in 1925, and rejoined only after Hitler had come to power in 1933. He received the party's Blood Order in 1934 and was still occasionally used as a propaganda tool until about 1937, but he was never again allowed any real power or played an active part in the movement. He died in Munich in February 1942.
In popular culture.
In the 2003 film "", British actor Robert Glenister plays Drexler, although Drexler is portrayed without his trademark spectacles and moustache.

</doc>
<doc id="2152" url="http://en.wikipedia.org/wiki?curid=2152" title="All Quiet on the Western Front">
All Quiet on the Western Front

All Quiet on the Western Front () is a novel by Erich Maria Remarque, a German veteran of World War I. The book describes the German soldiers' extreme physical and mental stress during the war, and the detachment from civilian life felt by many of these soldiers upon returning home from the front.
The novel was first published in November and December 1928 in the German newspaper "Vossische Zeitung" and in book form in late January 1929. The book and its sequel, "The Road Back", were among the books banned and burned in Nazi Germany. It sold 2.5 million copies in 22 languages in its first eighteen months in print.
In 1930, the book was adapted as an Oscar-winning film of the same name, directed by Lewis Milestone.
Title and translation.
The 1929 English translation by Arthur Wesley Wheen gives the title as " All Quiet on the Western Front". The literal translation of "Im Westen nichts Neues" is "In the West Nothing New," with "West" being the Western Front; the phrase refers to the content of an official communiqué at the end of the novel.
Brian Murdoch's 1993 translation would render the phrase as "there was nothing new to report on the Western Front" within the narrative. Explaining his retention of the original book-title, he says:
Although it does not match the German exactly, Wheen's title has justly become part of the English language and is retained here with gratitude.
The phrase "all quiet on the Western Front" has become a colloquial expression meaning stagnation, or lack of visible change, in any context.
Plot summary.
The book tells the story of Paul Bäumer, a German soldier who—urged on by his school teacher—joins the German army shortly after the start of World War I. His class was "scattered over the platoons amongst Frisian fishermen, peasants, and labourers." Bäumer arrives at the Western Front with his friends and schoolmates (Tjaden, Müller, Kropp and a number of other characters). There they meet Stanislaus Katczinsky, an older soldier, nicknamed Kat, who becomes Paul's mentor. While fighting at the front, Bäumer and his comrades have to engage in frequent battles and endure the dangerous and often dirty conditions of warfare.
At the very beginning of the book Erich Maria Remarque says "This book is to be neither an accusation nor a confession, and least of all an adventure, for death is not an adventure to those who stand face to face with it. It will try simply to tell of a generation of men who, even though they may have escaped (its) shells, were destroyed by the war." The book does not focus on heroic stories of bravery, but rather gives a view of the conditions in which the soldiers find themselves. The monotony between battles, the constant threat of artillery fire and bombardments, the struggle to find food, the lack of training of young recruits (meaning lower chances of survival), and the overarching role of random chance in the lives and deaths of the soldiers are described in detail.
The battles fought here have no names and seem to have little overall significance, except for the impending possibility of injury or death for Bäumer and his comrades. Only pitifully small pieces of land are gained, about the size of a football field, which are often lost again later. Remarque often refers to the living soldiers as old and dead, emotionally drained and shaken. "We are not youth any longer. We don't want to take the world by storm. We are fleeing from ourselves, from our life. We were eighteen and had begun to love life and the world; and we had to shoot it to pieces."
Paul's visit on leave to his home highlights the cost of the war on his psyche. The town has not changed since he went off to war; however, he finds that he does "not belong here anymore, it is a foreign world." He feels disconnected from most of the townspeople. His father asks him "stupid and distressing" questions about his war experiences, not understanding "that a man cannot talk of such things." An old schoolmaster lectures him about strategy and advancing to Paris, while insisting that Paul and his friends know only their "own little sector" of the war but nothing of the big picture.
Indeed, the only person he remains connected to is his dying mother, with whom he shares a tender, yet restrained relationship. The night before he is to return from leave, he stays up with her, exchanging small expressions of love and concern for each other. He thinks to himself, "Ah! Mother, Mother! How can it be that I must part from you? Here I sit and there you are lying; we have so much to say, and we shall never say it." In the end, he concludes that he "ought never to have come on leave."
Paul feels glad to be reunited with his comrades. Soon after, he volunteers to go on a patrol and kills a man for the first time in hand-to-hand combat. He watches the man die, in pain for hours. He feels remorse and asks forgiveness from the man's corpse. He is devastated and later confesses to Kat and Albert, who try to comfort him and reassure him that it is only part of the war.
They are then sent on what Paul calls a "good job." They must guard a village that is being shelled too heavily. The men enjoy themselves but while evacuating the villagers, Paul and Albert are wounded.
They recuperate in a Catholic hospital and Paul returns to active duty.
By now, the war is nearing its end and the German Army is retreating. In despair, Paul watches as his friends fall one by one. It is the death of Kat that eventually makes Paul careless about living. In the final chapter, he comments that peace is coming soon, but he does not see the future as bright and shining with hope. Paul feels that he has no aims left in life and that their generation will be different and misunderstood. When he dies at the end of the novel, the situation report from the frontline states, "All is Quiet on the Western Front," symbolizing the insignificance of one individual's death during the war.
Themes.
One of the major themes of the novel is the difficulty of soldiers to revert to civilian life after having experienced extreme combat situations. Remarque comments in the preface that "Quiet on the Western Front will try simply to tell of a generation of men who, even though they may have escaped its shells, were destroyed by the war." This internal destruction can be found as early as the first chapter as Paul comments that, although all the boys are young, their youth has left them.
When on leave from the front, Paul feels strongly isolated from his family and removed from daily life. Another topic concerns how soldiers' lives are put at risk by their commanding officers who seem unaware of the trauma of their charges.
Main characters.
Paul Bäumer.
Paul Bäumer is the main character and narrator. At 19 years of age, Paul enlists in the German Army and is deployed to the Western Front where he experiences the severe psychological and physical effects of the war. 
Before the war, Paul was a creative, sensitive and passionate person, writing poems and having a clear love for his family. But as the war changed his attitude and personality, poems and other aspects of his past life become something Paul could not remember having any link to, and he learns to disconnect himself from his feelings. He feels he can't tell anyone about his experiences, and feels like an outsider where his family is concerned.
By the end of the book, Paul realises that he no longer knows what to do with himself and decides that he has nothing more to lose. The war appears to have snuffed out his hopes and dreams, which he feels he can never regain. After years of fighting, Paul is finally killed in October 1918, on an extraordinarily quiet, peaceful day. The army report that day contains only one phrase: “All quiet on the Western Front.” As Paul dies, his face is calm, “as though almost glad the end had come."
Albert Kropp.
Kropp was in Paul's class at school and is described as the clearest thinker of the group. Kropp is wounded towards the end of the novel and undergoes an amputation. Both he and Bäumer end up spending time in a Roman Catholic hospital together, Bäumer suffering from shrapnel wounds to the leg and arm. Though Kropp initially plans to commit suicide if he requires an amputation, the book suggests he postponed suicide because of the strength of military camaraderie. Kropp and Bäumer part ways when Bäumer is recalled to his regiment after recovering. Paul comments that saying farewell was "very hard, but it is something a soldier learns to deal with."
Haie Westhus.
Haie is described as being tall and strong, and a peat-digger by profession. Overall, his size and behavior make him seem older than Paul, yet he is the same age as Paul and his school-friends (roughly 19 at the start of the book). Haie in addition has a good sense of humor. During combat, he is injured in his back, fatally (Chapter 6) — the resulting wound is large enough for Paul to see Haie's breathing lung when Himmelstoß carries him to safety.
Fredrich Müller.
Müller is about 18 and a half years of age, one of Bäumer's classmates, when he also joins the German army as a volunteer to go to the war. Carrying his old school books with him to the battlefield, he constantly reminds himself of the importance of learning and education. Even while under enemy fire, he "mutters propositions in physics". He became interested in Kemmerich's boots and inherits them when Kemmerich dies early in the novel. He is killed later in the book after being shot point-blank in the stomach with a flare gun. As he was dying "quite conscious and in terrible pain", he gave his boots which he inherited from Kemmerich to Paul.
Stanislaus "Kat" Katczinsky.
Kat has the most positive influence on Paul and his comrades on the battlefield. Katczinsky was a cobbler in civilian life; he is older than Paul Bäumer and his comrades, about 40 years old, and serves as their leadership figure. He also represents a literary model highlighting the differences between the younger and older soldiers. While the older men have already had a life of professional and personal experience before the war, Bäumer and the men of his age have had little life experience or time for personal growth.
Kat is also well known for his ability to scavenge nearly any item needed, especially food. At one point he secures four boxes of lobster. Bäumer describes Kat as possessing a sixth sense. One night, Bäumer along with a group of other soldiers are holed up in a factory with neither rations nor comfortable bedding. Katczinsky leaves for a short while, returning with straw to put over the bare wires of the beds. Later, to feed the hungry men, Kat brings bread, a bag of horse flesh, a lump of fat, a pinch of salt and a pan in which to cook the food.
Kat is hit by shrapnel at the end of the story, leaving him with a smashed shin. Paul carries him back to camp on his back, only to discover upon their arrival that a stray splinter had hit Kat in the back of the head and killed him on the way. He is thus the last of Paul's close friends to die in battle. It is Kat's death that eventually makes Bäumer careless whether he survives the war or not, but that he can face the rest of his life without fear. "Let the months and the years come, they can take nothing from me, they can take nothing more. I am so alone, and so without hope that I can confront them without fear."
Tjaden.
One of Bäumer's non-schoolmate friends. Before the war Tjaden was a locksmith. A big eater with a grudge against the former postman-turned corporal Himmelstoß (thanks to his strict 'disciplinary actions'), he manages to forgive Himmelstoß later in the book. Throughout the book, Paul frequently remarks on how much of an eater he is, yet somehow manages to stay as "thin as a rake." Tjaden appears in the sequel, "The Road Back".
Minor characters.
Kantorek.
Kantorek was the schoolmaster of Paul and his friends, including Kropp, Leer, Müller, and Behm. Behaving "in a way that cost nothing," Kantorek is a strong supporter of the war and encourages Bäumer and other students in his class to join the war effort. Among twenty enlistees was Joseph Behm, the first of the class to die in battle. In an example of tragic irony, Behm was the only one who did not want to enter the war.
Kantorek is a hypocrite, urging the young men he teaches to fight in the name of patriotism, while not voluntarily enlisting himself. In a twist of fate, Kantorek is later called up as a soldier as well. He very reluctantly joins the ranks of his former students, only to be drilled and taunted by Mittelstädt, one of the students he had earlier persuaded to enlist.
Peter Leer.
Leer is an intelligent soldier in Bäumer's company, and one of his classmates. He is very popular with women; when he and his comrades meet three French women, he is the first to seduce one of them. Bäumer describes Leer's ability to attract women by saying "Leer is an old hand at the game". In chapter 11, Leer is hit by a shell fragment, which also hits Bertinck. The shrapnel tears open Leer's hip, causing him to bleed to death quickly. His death causes Paul to ask himself, "What use is it to him now that he was such a good mathematician in school?"
Bertinck.
Lieutenant Bertinck is the leader of Bäumer's company. His men have a great respect for him, and Bertinck has great respect for his men. He permits them to eat the rations of the men that had been killed in action, standing up to the chef Ginger who would only allow them their allotted share. Bertinck is genuinely despondent when he learns that few of his men had survived an engagement.
When he and the other characters are trapped in a trench under heavy attack, Bertinck, who has been injured in the firefight, spots a flamethrower team advancing on them. He gets out of cover and takes aim on the flamethrower but misses, and gets hit by enemy fire. With his next shot he kills the flamethrower, and immediately afterwards an enemy shell explodes on his position blowing off his chin. The same explosion also fatally wounds Leer.
Himmelstoß.
Corporal Himmelstoß (spelled Himmelstoss in some editions) was a postman before enlisting in the war. He is a power-hungry corporal with special contempt for Paul and his friends, taking sadistic pleasure in punishing the minor infractions of his trainees during their basic training in preparation for their deployment. Paul later figures that the training taught by Himmelstoß made them "hard, suspicious, pitiless, and tough" but most importantly it taught them comradeship. However, Bäumer and his comrades have a chance to get back at Himmelstoß because of his punishments, mercilessly whipping him on the night before they board trains to go to the front.
Himmelstoß later joins them at the front, revealing himself as a coward who shirks his duties for fear of getting hurt or killed, and pretends to be wounded because of a scratch on his face. Paul Bäumer beats him because of it and when a lieutenant comes along looking for men for a trench charge, Himmelstoß joins and leads the charge. He carries Haie Westhus's body to Bäumer after he is fatally wounded. Matured and repentant through his experiences Himmelstoß later asks for forgiveness from his previous charges. As he becomes the new staff cook, to prove his friendship he secures two pounds of sugar for Bäumer and half a pound of butter for Tjaden.
Detering.
Detering is a farmer who constantly longs to return to his wife and farm. He is also fond of horses and is angered when he sees them used in combat. He says, "It is of the vilest baseness to use horses in the war," when the group hears several wounded horses writhe and scream for a long time before dying during a bombardment. He tries to shoot them to put them out of misery, but is stopped by Kat to keep their current position hidden. He is driven to desert when he sees a cherry tree in blossom, which reminds him of home too much and inspires him to leave. He is found by military police and court-martialed, and is never heard from again.
Josef Hamacher.
Hamacher is a patient at the Catholic hospital where Paul and Albert Kropp are temporarily stationed. He has an intimate knowledge of the workings of the hospital. He also has a "shooting license," certifying him as sporadically not responsible for his actions due to a head wound, though he is clearly quite sane and exploiting his license so he can stay in the hospital and away from the war as long as possible.
Franz Kemmerich.
A young boy of only 19 years. Franz Kemmerich had enlisted in the army for World War I along with his best friend and classmate, Bäumer. Kemmerich is shot in the leg early in the story; his injured leg has to be amputated, and he dies shortly after. In anticipation of Kemmerich's imminent death, Müller was eager to get his boots. While in the hospital, someone steals Kemmerich's watch from him, causing him great distress, prompting him to ask about his watch every time his friends came to visit him in the hospital.
Joseph Behm.
A student in Paul's class. Behm was the only student that was not quickly influenced by Kantorek's patriotism to join the war. Eventually, due to pressure from friends and Kantorek, he joins the war. He is the first of Paul's friends to die. He is blinded in no man's land and believed to be dead by his friends. The next day, when he is seen walking blindly around no-man's-land, it is discovered that he was only unconscious. However, he is killed before he can be rescued.
Publication and Reception.
From November 10 to December 9, 1928, "All Quiet on the Western Front" was published in serial form in Vossische Zeitung magazine. It was released in book form the following year to smashing success, selling one and a half million copies that same year. Although publishers had worried that interest in the Great War had waned more than 10 years after the armistice, Remarque's realistic depiction of trench warfare from the perspective of young soldiers struck a chord with the war's survivors—soldiers and civilians alike—and provoked strong reactions, both positive and negative, around the world.
With "All Quiet on the Western Front", Remarque emerged as an eloquent spokesperson for a generation that had been, in his own words, "destroyed by war, even though it might have escaped its shells." Remarque's harshest critics, in turn, were his countrymen, many of whom felt the book denigrated the German war effort, and that Remarque had exaggerated the horrors of war to further his pacifist agenda. The strongest voices against Remarque came from the emerging National Socialist (Nazi) Party, an ultranationalist group in Germany led by the future Führer, Adolf Hitler. In 1933, when the Nazis rose to power, "All Quiet on the Western Front" became one of the first "degenerate" books to be publicly burnt.
However, objections to Remarque’s portrayal of the German army personnel during World War I were not limited to the Nazis. Dr. Karl Kroner (de) objected to Remarque’s depiction of the medical personnel as being inattentive, uncaring, or absent from frontline action. Dr. Kroner was specifically worried that the book would perpetuate German stereotypes abroad that had subsided since the First World War. He offered the following clarification: “People abroad will draw the following conclusions: if German doctors deal with their own fellow countrymen in this manner, what acts of inhumanity will they not perpetuate against helpless prisoners delivered up into their hands or against the populations of occupied territory?” 
A fellow patient of Remarque’s in the military hospital in Duisburg objected to the negative depictions of the nuns and patients, and of the general portrayal of soldiers: “There were soldiers to whom the protection of homeland, protection of house and homestead, protection of family were the highest objective, and to whom this will to protect their homeland gave the strength to endure any extremities”.
These criticisms suggest that perhaps experiences of the war and the personal reactions of individual soldiers to their experiences may be more diverse than Remarque portrays them; however, it is beyond question that Remarque gives voice to a side of the war and its experience that was overlooked or suppressed at the time. This perspective is crucial to understanding the true effects of World War I. The evidence can be seen in the lingering depression that Remarque and many of his friends and acquaintances were suffering a decade later.
In contrast, "All Quiet on the Western Front" was trumpeted by pacifists as an anti-war book. Remarque makes a point in the opening statement that the novel does not advocate any political position, but is merely an attempt to describe the experiences of the soldier.
The main artistic criticism was that it was a mediocre attempt to cash in on public sentiment. The enormous popularity the work received was a point of contention for some literary critics, who scoffed at the fact that such a simple work could be so earth-shattering. Much of this literary criticism came from Salomo Friedlaender, who wrote a book "Hat Erich Maria Remarque wirklich gelebt?" Another author, Max Joseph Wolff, wrote a parody titled "Vor Troja nichts Neues" under the pseudonym "Emil Marius Requark". Friedlaender’s criticism's were mainly personal in nature—he attacked Remarque as being ego-centric and greedy. Remarque publicly stated that he wrote "All Quiet on the Western Front" for personal reasons, not for profit, as Friedlaender had claimed.
Adaptations.
Film.
In 1930, an American film of the novel was made, directed by Lewis Milestone. The screenplay was by Maxwell Anderson, George Abbott, Del Andrews, C. Gardner Sullivan, with uncredited work by Walter Anthony and Milestone. It stars Louis Wolheim, Lew Ayres, John Wray, Arnold Lucy and Ben Alexander.
The film won the Academy Award for Best Picture in 1930 for its producer Carl Laemmle Jr., and an Academy Award for Directing for Lewis Milestone. It was the first all-talking non-musical film to win the Best Picture Oscar. It also received two further nominations: Best Cinematography, for Arthur Edeson, and Best Writing Achievement for Abbott, Anderson and Andrews.
In June 2009, an announcement was made that "All Quiet on the Western Front" would be remade. Director Mimi Leder was linked with the film in 2011, but as of 2013, the film was still listed as being in pre-production.
TV film.
In 1979, the film was remade for CBS television by Delbert Mann, starring Richard Thomas of "The Waltons" as Paul Bäumer and Ernest Borgnine as Kat. The movie was filmed in Czechoslovakia.
Radio.
On November 9, 2008, a radio adaptation of the novel was broadcast on BBC Radio 3, starring Robert Lonsdale as Paul Bäumer and Shannon Graney as Katczinsky. Its screenplay was written by Dave Sheasby and the show was directed by David Hunter.
Music.
Elton John's 1982 album "Jump Up!" features the song, "All Quiet On The Western Front" (written by Elton and Bernie Taupin). The song is a sorrowful rendition of the novel's story (""It's gone all quiet on the Western Front / Male Angels sigh / ghosts in a flooded trench / As Germany dies"").
Theatre.
In 2009 prior to a UK Tour, Nottingham Playhouse commissioned a play of the book by Robin Kingsland.

</doc>
<doc id="2154" url="http://en.wikipedia.org/wiki?curid=2154" title="African American">
African American

African Americans, also referred to as Black Americans or Afro-Americans, are citizens of the United States who have total or partial antebellum ancestry from any of the native populations of Sub-Saharan Africa.
African Americans constitute the second largest racial and ethnic minority in the United States. Most African Americans are of West and Central African descent and are descendants of enslaved blacks within the boundaries of the present United States. However, some immigrants from African, Caribbean, Central American, and South American nations, and their descendants, may be identified or self-identify with the term.
African-American history starts in the 16th century, with Africans forcibly taken to Spanish and English colonies in North America as slaves. After the founding of the United States, black people continued to be enslaved and treated as inferiors. These circumstances were changed by Reconstruction, development of the black community, participation in the great military conflicts of the United States, the elimination of racial segregation, and the Civil Rights Movement. In 2008, Barack Obama became the first African American to be elected president of the United States.
History.
Slavery era.
The first African slaves arrived in the present-day United States as part of the San Miguel de Gualdape colony (most likely located in the Winyah Bay area of present-day South Carolina), founded by Spanish explorer Lucas Vázquez de Ayllón in 1526. The ill-fated colony was almost immediately disrupted by a fight over leadership, during which the slaves revolted and fled the colony to seek refuge among local Native Americans. De Ayllón and many of the colonists died shortly afterwards of an epidemic and the colony was abandoned, leaving the escaped slaves behind on North American soil.
In 1565, the colony of Saint Augustine in Florida, founded by Pedro Menendez de Aviles, became the first permanent European settlement in North America. It included an unknown number of free and enslaved Africans that were part of this colonial expedition.
The first recorded Africans in British North America (including most of the future United States) were "20 and odd negroes" who came to Jamestown, Virginia via Cape Comfort in August 1619 as indentured servants. As English settlers died from harsh conditions, more and more Africans were brought to work as laborers. Typically, young men or women would sign a contract of indenture in exchange for transportation to the New World. The landowner received 50 acres of land from the state (headrights) for each servant purchased (around £6 per person to 9 months income in the 17th century) from a ships captain. An indentured servant (who could be white or black) would work for several years (usually four to seven) without wages. The status of indentured servants in early Virginia and Maryland was similar to slavery. Servants could be bought, sold, or leased and they could be physically beaten for disobedience or running away. Unlike slaves, they were freed after their term of service expired or was bought out, their children did not inherit their status, and on their release from contract they received "a year's provision of corn, double apparel, tools necessary" and a small cash payment called "freedom dues".
Africans could legally raise crops and cattle to purchase their freedom. They raised families, marrying other Africans and sometimes intermarrying with Native Americans or English settlers. By the 1640s and 1650s, several African families owned farms around Jamestown and some became wealthy by colonial standards and purchased indentured servants of their own. In 1640, the Virginia General Court recorded the earliest documentation of lifetime slavery when they sentenced John Punch, a Negro, to lifetime servitude under his master Hugh Gwyn for running away. One of Dutch African arrivals, Anthony Johnson, would later own one of the first black "slaves," John Casor, resulting from the court ruling of a civil case.
The popular conception of a race-based slave system did not fully develop until the 18th century. The Dutch West India Company introduced slavery in 1625 with the importation of eleven black slaves into New Amsterdam (present-day New York City). All the colony's slaves, however, were freed upon its surrender to the British. Massachusetts was the first British colony to legally recognize slavery in 1641. In 1662 Virginia passed a law that children of enslaved women (who were of African descent and thus foreigners) took the status of the mother, rather than that of the father, as under English common law. This principle was called "partus sequitur ventrum". By an act of 1699, the colony ordered all free blacks deported, virtually defining as slaves all persons of African descent who remained in the colony. In 1670 the colonial assembly passed a law prohibiting free and baptized negroes (and Indians) from purchasing Christians (in this act meaning English or European whites) but allowing them to buy persons "of their owne nation."
The earliest African-American congregations and churches were organized before 1800 in both northern and southern cities following the Great Awakening. By 1775, Africans made up 20% of the population in the American colonies, which made them the second largest ethnic group after the English. During the 1770s, Africans, both enslaved and free, helped rebellious English colonists secure American Independence by defeating the British in the American Revolution. Africans and Englishmen fought side by side and were fully integrated.
James Armistead, an African American, played a large part in making possible the 1781 Yorktown victory, which established the United States as an independent nation. Baron Closen, a German officer in the French Royal Deux-Ponts Regiment, estimated the American army at Yorktown to be about one quarter black and it is estimated that more than a third of the Americans actually engaged were black. Other prominent African Americans were Prince Whipple and Oliver Cromwell, both of whom are possibly depicted in the front of the boat in the famous "Washington Crossing the Delaware" portrait.
By 1860, there were 3.5 million enslaved African Americans in the United States due to the Atlantic slave trade, and another 500,000 African Americans lived free across the country. In 1863, during the American Civil War, President Abraham Lincoln signed the Emancipation Proclamation. The proclamation declared that all slaves in states which had seceded from the Union were free. Advancing Union troops enforced the proclamation with Texas being the last state to be emancipated in 1865.
Reconstruction and Jim Crow.
[[File:Jesse Owens3.jpg|thumb|150px|Jesse Owens shook racial stereotypes both with Nazis and
segregationists in the USA at the 1936 Berlin Olympics.]]
African Americans quickly set up congregations for themselves, as well as schools and community/civic associations, to have space away from white control or oversight. While the post-war reconstruction era was initially a time of progress for African Americans, in the late 1890s, Southern states enacted Jim Crow laws to enforce racial segregation and disenfranchisement. Most African Americans followed the Jim Crow laws, using a mask of compliance to prevent becoming victims of racially motivated violence. To maintain self-esteem and dignity, African Americans such as Anthony Overton and Mary McLeod Bethune continued to build their own schools, churches, banks, social clubs, and other businesses.
In the last decade of the 19th century, racially discriminatory laws and racial violence aimed at African Americans began to mushroom in the United States. These discriminatory acts included racial segregation—upheld by the United States Supreme Court decision in Plessy v. Ferguson in 1896—which was legally mandated by southern states and nationwide at the local level of government, voter suppression or disenfranchisement in the southern states, denial of economic opportunity or resources nationwide, and private acts of violence and mass racial violence aimed at African Americans unhindered or encouraged by government authorities.
Great Migration and Civil Rights Movement.
The desperate conditions of African Americans in the South that sparked the Great Migration of the early 20th century, combined with a growing African-American community in the Northern United States, led to a movement to fight violence and discrimination against African Americans that, like abolitionism before it, crossed racial lines. The Civil Rights Movement from 1954 to 1968 was directed at abolishing racial discrimination against African Americans, particularly in the Southern United States. The March on Washington for Jobs and Freedom and the conditions which brought it into being are credited with putting pressure on President John F. Kennedy and Lyndon B. Johnson.
Johnson put his support behind passage of the Civil Rights Act of 1964 that banned discrimination in public accommodations, employment, and labor unions, and the Voting Rights Act of 1965, which expanded federal authority over states to ensure black political participation through protection of voter registration and elections. By 1966, the emergence of the Black Power movement, which lasted from 1966 to 1975, expanded upon the aims of the Civil Rights Movement to include economic and political self-sufficiency, and freedom from white authority.
During the postwar period, many African Americans continued to be economically disadvantaged relative to other Americans. Average black income stood at 54% of that of white workers in 1947, and 55% in 1962. In 1959, median family income for whites was $5,600, compared with $2,900 for nonwhite families. In 1965, 43% of all black families fell into the poverty bracket, earning under $3,000 a year. The Sixties saw improvements in the social and economic conditions of many black Americans.
From 1965 to 1969, black family income rose from 54% to 60% of white family income. In 1968, 23% of black families earned under $3,000 a year, compared with 41% in 1960. In 1965, 19% of black Americans had incomes equal to the national median, a proportion that rose to 27% by 1967. In 1960, the median level of education for blacks had been 10.8 years, and by the late Sixties the figure rose to 12.2 years, half a year behind the median for whites.
Post-Civil Rights era.
Politically and economically, African Americans have made substantial strides during the post-civil rights era. In 1989, Douglas Wilder became the first African American elected governor in U.S. history. Currently, Deval Patrick of Massachusetts, is the only African-American governor in office. Clarence Thomas became the second African-American Supreme Court Justice. In 1992 Carol Moseley-Braun of Illinois became the first African-American woman elected to the U.S. Senate. There were 8,936 black officeholders in the United States in 2000, showing a net increase of 7,467 since 1970. In 2001 there were 484 black mayors.
On November 4, 2008, Democratic Senator Barack Obama defeated Republican Senator John McCain to become the first African American to be elected President. At least 95 percent of African-American voters voted for Obama. He also received overwhelming support from young and educated whites, a majority of Asians, Hispanics, and Native Americans picking up a number of new states in the Democratic electoral column. Obama lost the overall white vote, although he won a larger proportion of white votes than any previous nonincumbent Democratic presidential candidate since Jimmy Carter. Four years later, Obama was reelected president by a similar margin on November 6, 2012.
Demographics.
In 1790, when the first U.S. Census was taken, Africans (including slaves and free people) numbered about 760,000—about 19.3% of the population. In 1860, at the start of the Civil War, the African-American population had increased to 4.4 million, but the percentage rate dropped to 14% of the overall population of the country. The vast majority were slaves, with only 488,000 counted as "freemen". By 1900, the black population had doubled and reached 8.8 million.
In 1910, about 90% of African Americans lived in the South. Large numbers began migrating north looking for better job opportunities and living conditions, and to escape Jim Crow laws and racial violence. The Great Migration, as it was called, spanned the 1890s to the 1970s. From 1916 through the 1960s, more than 6 million black people moved north. But in the 1970s and 1980s, that trend reversed, with more African Americans moving south to the Sun Belt than leaving it.
The following table of the African-American population in the United States over time shows that the African-American population, as a percentage of the total population, declined until 1930 and has been rising since then.
By 1990, the African-American population reached about 30 million and represented 12% of the U.S. population, roughly the same proportion as in 1900. In 2010, 38.9 million Americans identified as "Black or African-American," representing 12.6% of the population. Controversy has surrounded the "accurate" population count of African Americans for decades. The NAACP believed it was under counted intentionally to minimize the significance of the black population in order to reduce their political power base.
At the time of the 2000 Census, 54.8% of African Americans lived in the South. In that year, 17.6% of African Americans lived in the Northeast and 18.7% in the Midwest, while only 8.9% lived in the western states. The west does have a sizable black population in certain areas, however. California, the nation's most populous state, has the fifth largest African-American population, only behind New York, Texas, Georgia, and Florida. According to the 2000 Census, approximately 2.05% of African Americans identified as Hispanic or Latino in origin, many of whom may be of Brazilian, Puerto Rican, Dominican, Cuban, Haitian, or other Latin American descent. The only self-reported "ancestral" groups larger than African Americans are the Irish and Germans. Because many African Americans trace their ancestry to colonial American origins, some simply self-identify as "American".
U.S. cities.
Almost 58% of African Americans lived in metropolitan areas in 2000. With over 2 million black residents, New York City had the largest black urban population in the United States in 2000, overall the city has a 28% black population. Chicago has the second largest black population, with almost 1.6 million African Americans in its metropolitan area, representing about 18 percent of the total metropolitan population.
Among cities of 100,000 or more, Detroit, Michigan had the highest percentage of black residents of any U.S. city in 2010, with 82%. Other large cities with African-American majorities include New Orleans, Louisiana (60%), Baltimore, Maryland (63%) Atlanta, Georgia (54%, see African Americans in Atlanta), Memphis, Tennessee (61%), and Washington, D.C. (50.7%).
The nation's most affluent county with an African-American majority is Prince George's County, Maryland, with a median income of $62,467. Within that county, among the wealthiest communities are Glenn Dale, Maryland and Fort Washington, Maryland. Other affluent predominantly African-American counties include Dekalb County in Georgia, and Charles City County in Virginia. Queens County, New York is the only county with a population of 65,000 or more where African Americans have a higher median household income than White Americans.
The oldest black community in the United States: Seatack. It survives today with a vibrant and very active civic community.
Education.
By 2000, African Americans had advanced greatly. They still lagged overall in education attainment compared to white or Asian Americans, with 14 percent with four-year and 5 percent with advanced degrees, though it was higher than for other minorities. African Americans attend college at about half the rate of whites, but at a greater rate than Americans of Hispanic origin. More African-American women attend and complete college than men. Black schools for kindergarten through twelfth grade students were common throughout the U.S., and a pattern towards re-segregation is currently occurring across the country.
Historically black colleges and universities remain today which were originally set up when segregated colleges did not admit African Americans. As late as 1947, about one third of African Americans over 65 were considered to lack the literacy to read and write their own names. By 1969, illiteracy as it had been traditionally defined, had been largely eradicated among younger African Americans.
US Census surveys showed that by 1998, 89 percent of African Americans aged 25 to 29 had completed high school, less than whites or Asians, but more than Hispanics. On many college entrance, standardized tests and grades, African Americans have historically lagged behind whites, but some studies suggest that the achievement gap has been closing. Many policy makers have proposed that this gap can and will be eliminated through policies such as affirmative action, desegregation, and multiculturalism.
In Chicago, Marva Collins, an African-American educator, created a low cost private school specifically for the purpose of teaching low-income African-American children whom the public school system had labeled as being "learning disabled". One article about Marva Collins' school stated,
Working with students having the worst of backgrounds, those who were working far below grade level, and even those who had been labeled as 'unteachable,' Marva was able to overcome the obstacles. News of third grade students reading at ninth grade level, four-year-olds learning to read in only a few months, outstanding test scores, disappearance of behavioral problems, second-graders studying Shakespeare, and other incredible reports, astounded the public. During the 2006–2007 school year, Collins' school charged $5,500 for tuition, and parents said that the school did a much better job than the Chicago public school system. Meanwhile, during the 2007–2008 year, Chicago public school officials claimed that their budget of $11,300 per student was not enough.
Economic status.
[[File:US Homeownership by Race 2009.png|thumb|450px|US Homeownership by Race 2009|The US homeownership rate according to race.
Economically, African Americans have benefited from the advances made during the Civil Rights era, particularly among the educated, but not without the lingering effects of historical marginalization when considered as a whole. The racial disparity in poverty rates has narrowed. The black middle class has grown substantially. In 2010, 45% of African Americans owned their homes, compared to 67% of all Americans. The poverty rate among African Americans has decreased from 26.5% in 1998 to 24.7% in 2004, compared to 12.7% for all Americans.
African Americans have a combined buying power of over $892 billion currently and likely over $1.1 trillion by 2012. In 2002, African American-owned businesses accounted for 1.2 million of the US's 23 million businesses. As of 2011 African American-owned business account for approximately 2 million US businesses. Black-owned businesses experienced the largest growth in number of businesses among minorities from 2002 to 2011.
In 2004, African-American men had the third-highest earnings of American minority groups after Asian Americans and non-Hispanic whites.
Twenty-five percent of blacks had white-collar occupations (management, professional, and related fields) in 2000, compared with 33.6% of Americans overall. In 2001, over half of African-American households of married couples earned $50,000 or more. Although in the same year African Americans were over-represented among the nation's poor, this was directly related to the disproportionate percentage of African-American families headed by single women; such families are collectively poorer, regardless of ethnicity.
In 2006, the median earnings of African-American men was more than black and non-black American women overall, and in all educational levels. At the same time, among American men, income disparities were significant; the median income of African-American men was approximately 76 cents for every dollar of their European American counterparts, although the gap narrowed somewhat with a rise in educational level.
Overall, the median earnings of African-American men were 72 cents for every dollar earned of their Asian American counterparts, and $1.17 for every dollar earned by Hispanic men. On the other hand by 2006, among American women with post-secondary education, African-American women have made significant advances; the median income of African-American women was more than those of their Asian-, European- and Hispanic American counterparts with at least some college education.
The US public sector is the single most important source of employment for African Americans. During 2008–2010, 21.2% of all Black workers were public employees, compared with 16.3% of non-Black workers. Both before and after the onset of the Great Recession, African Americans were 30% more likely than other workers to be employed in the public sector.
The public sector is also a critical source of decent-paying jobs for Black Americans. For both men and women, the median wage earned by Black employees is significantly higher in the public sector than in other industries.
In 1999, the median income of African-American families was $33,255 compared to $53,356 of European Americans. In times of economic hardship for the nation, African Americans suffer disproportionately from job loss and underemployment, with the black underclass being hardest hit. The phrase "last hired and first fired" is reflected in the Bureau of Labor Statistics unemployment figures. Nationwide, the October 2008 unemployment rate for African Americans was 11.1%, while the nationwide rate was 6.5%.
The income gap between black and white families is also significant. In 2005, employed blacks earned 65% of the wages of whites, down from 82% in 1975. "The New York Times" reported in 2006 that in Queens, New York, the median income among African-American families exceeded that of white families, which the newspaper attributed to the growth in the number of two-parent black families. It noted that Queens was the only county with more than 65,000 residents where that was true.
In 2011, it was reported that 72% of black babies were born to unwed mothers. The poverty rate among single-parent black families was 39.5% in 2005, according to Williams, while it was 9.9% among married-couple black families. Among white families, the respective rates were 26.4% and 6% in poverty.
Health.
The life expectancy for Black men in 2008 was 70.8 years. Life expectancy for Black women was 77.5 years in 2008. In 1900, when information on Black life expectancy started being collated, a Black man could expect to live to 32.5 years and a Black woman 33.5 years. In 1900, White men lived an average of 46.3 years and White women lived an average of 48.3 years. African-American life expectancy at birth is persistently five to seven years lower than European Americans.
Black people have higher rates of obesity, diabetes and hypertension than the US average. For adult Black men, the rate of obesity was 31.6% in 2010. For adult Black women, the rate of obesity was 41.2% in 2010. African Americans have higher rates of mortality than does any other racial or ethnic group for 8 of the top 10 causes of death. The cancer incidence rate among African Americans is 10% higher than among European Americans.
Violence has an impact upon African-American life expectancy. A report from the U.S. Department of Justice states "In 2005, homicide victimization rates for blacks were 6 times higher than the rates for whites". The report also found that "94% of black victims were killed by blacks."
AIDS is one of the top three causes of death for African-American men aged 25–54 and for African-American women aged 35–44 years. In the United States, African Americans make up about 48% of the total HIV-positive population and make up more than half of new HIV cases. The main route of transmission for women is through unprotected heterosexual sex. African-American women are 19 times more likely to contract HIV than other women.
Washington, D.C. has the nation's highest rate of HIV/AIDS infection, at 3%. This rate is comparable to what is seen in West Africa, and is considered a severe epidemic. Dr. Ray Martins, Chief Medical Officer at the Whitman-Walker Clinic, the largest provider of HIV care in Washington D.C., estimated that the actual underlying percent with HIV/AIDS in the city is "closer to five percent".
Sexuality.
According to a Gallup survey conducted from June to September 2012, it found that 4.6 percent of Black or African Americans self identify as LGBT; this is greater than the estimated 3.4 percent of American adults that self identify as LGBT in the total population.
Religion.
The majority of African Americans are Protestant of whom many follow the historically black churches. Black church refers to churches which minister predominantly African-American congregations. Black congregations were first established by freed slaves at the end of the 17th century, and later when slavery was abolished more African Americans were allowed to create a unique form of Christianity that was culturally influenced by African spiritual traditions.
According to a 2007 survey, more than half of the African-American population are part of the historically black churches. The largest Protestant denomination among African Americans are the Baptists, distributed mainly in four denominations, the largest being the National Baptist Convention, USA and the National Baptist Convention of America. The second largest are the Methodists, the largest sects are the African Methodist Episcopal Church and the African Methodist Episcopal Zion Church.
Pentecostals are distributed among several different religious bodies with the Church of God in Christ as the largest among them by far. About 16% of African-American Christians are members of white Protestant communions, these denominations (which include the United Church of Christ) mostly have a 2 to 3% African-American membership. There are also large numbers of Roman Catholics, constituting 5% of the African-American population. Of the total number of Jehovah's Witnesses, 22% are black.
Some African Americans follow Islam. Historically, between 15 to 30% of enslaved Africans brought to the Americas were Muslims, but most of these Africans were converted to Christianity during the era of American slavery. However during the 20th century, some African Americans converted to Islam, mainly through the influence of black nationalist groups that preached with distinctive Islamic practices; these include the Moorish Science Temple of America, though the largest organization was the Nation of Islam, founded during the 1930s, which attracted at least 20,000 people as of 1963, prominent members included activist Malcolm X and boxer Muhammad Ali.
Malcolm X is considered the first person to start the movement among African Americans towards mainstream Islam, after he left the Nation and made the pilgrimage to Mecca. In 1975, Warith Deen Mohammed, the son of Elijah Muhammad who took control of the Nation after his death, guided majority of its members to orthodox Islam. However, few members rejected these changes, in particular Louis Farrakhan, who revived the Nation of Islam in 1978 based on its original teachings.
African-American Muslims constitute 20% of the total U.S. Muslim population, the majority are Sunni or orthodox Muslims, some of these identify under the community of W. Deen Mohammed. The Nation of Islam led by Louis Farrakhan has a membership from 20,000–50,000 members.
There are relatively few African-American Jews; estimates of their number range from 20,000 to 200,000. Most of these Jews are part of mainstream groups such as the Reform, Conservative, or Orthodox branches of Judaism; although there are significant numbers of people who are part of non-mainstream Jewish groups, largely the Black Hebrew Israelites, whose beliefs include the claim that African Americans are descended from the Biblical Israelites.
Contemporary issues.
African Americans have improved their social and economic standing significantly since the Civil Rights Movement and recent decades have witnessed the expansion of a robust, African American middle class across the United States. Unprecedented access to higher education and employment in addition to representation in the highest levels of American government has been gained by African Americans in the post-civil rights era.
Nevertheless, due in part to the legacy of slavery, racism and discrimination, African Americans as a group remain at a pronounced economic, educational and social disadvantage in many areas relative to European Americans. Persistent social, economic and political issues for many African Americans include inadequate health care access and delivery; institutional racism and discrimination in housing, education, policing, criminal justice and employment; crime, poverty and substance abuse.
One of the most serious and long standing issues within African-American communities is poverty. Poverty itself is a hardship as it is related to marital stress and dissolution, health problems, low educational attainment, deficits in psychological functioning, and crime. In 2004, 24.7% of African-American families lived below the poverty level. In 2007, the average African-American income was $33,916, compared with $54,920 for whites.
Politics and social issues.
Collectively, African Americans are more involved in the American political process than other minority groups in the United States, indicated by the highest level of voter registration and participation in elections among these groups in 2004. African Americans collectively attain higher levels of education than immigrants to the United States. African Americans also have the highest level of Congressional representation of any minority group in the U.S.
The large majority of African Americans support the Democratic Party. In the 2004 Presidential Election, Democrat John Kerry received 88% of the African-American vote compared to 11% for Republican George W. Bush. Although there is an African-American lobby in foreign policy, it has not had the impact that African-American organizations have had in domestic policy.
Until the New Deal, African Americans were supporters of the Republican Party because it was Republican President Abraham Lincoln who helped in granting freedom to American slaves; at the time, the Republicans and Democrats represented the sectional interests of the North and South, respectively, rather than any specific ideology, and both right and left were represented equally in both parties.
The African-American trend of voting for Democrats can be traced back to the 1930s during the Great Depression, when Franklin D. Roosevelt's New Deal program provided economic relief to African Americans; Roosevelt's New Deal coalition turned the Democratic Party into an organization of the working class and their liberal allies, regardless of region. The African-American vote became even more solidly Democratic when Democratic presidents John F. Kennedy and Lyndon B. Johnson pushed for civil rights legislation during the 1960s.
After over 50 years, marriage rates for "all" Americans began to decline while divorce rates and out-of-wedlock births have climbed. These changes have been greatest among African Americans. After more than 70 years of racial parity black marriage rates began to fall behind whites. Single-parent households have become common, and according to US census figures released in January 2010, only 38 percent of black children live with both their parents.
In 2008, Democrats overwhelmingly voted 70% against California Proposition 8, African Americans voted 58% in favor of it while 42% voted against Proposition 8. On May 9, 2012, Barack Obama, the first African-American president, became the first US president to support same sex marriage. After Obama's endorsement there is a rapid growth in support for same sex marriage among African Americans. Now 59% of African Americans support same sex marriage, which is higher than support among the national average (53%) and white Americans (50%).
Polls in North Carolina, Pennsylvania, Missouri, Maryland, Ohio, Florida, and Nevada have also shown an increase in support for same sex marriage among African Americans. On November 6, 2012, Maryland, Maine, and Washington all voted for approve of same-sex marriage, along with Minnesota rejecting a constitutional amendment banning same-sex marriage. Exit polls in Maryland show about 50% of African Americans voted for same-sex marriage, showing a vast evolution among African Americans on the issue and was crucial in helping pass same-sex marriage in Maryland.
Blacks hold far more conservative opinions on abortion, extramarital sex, and raising children out of wedlock than Democrats as a whole. On financial issues, however, African Americans are very much in line with Democrats, generally supporting a more progressive tax structure to provide more services and reduce injustice and as well as more government spending on social services.
News media and coverage.
Some activists and academics contend that news media coverage of African-American news concerns or dilemmas is inadequate
or the news media present distorted images of African Americans. To combat this, Robert L. Johnson founded Black Entertainment Television, a network that targets young African Americans and urban audiences in the United States. Most programming on the network consists of rap and R&B music videos and urban-oriented movies and series. The channel also shows syndicated television series, original programs, and some public affairs programs. On Sunday mornings, BET broadcasts a lineup of network-produced Christian programming; other, non-affiliated Christian programs are also shown during the early morning hours daily. BET is now a global network that reaches 90 million households in the United States, Caribbean, Canada, and the United Kingdom.
In addition to BET there is Centric, which is a spin-off cable television channel of BET, created originally as "BET on Jazz" to showcase jazz music-related programming, especially that of black jazz musicians. Programming has been expanded to include a block of urban programs as well as some R&B, soul, and world music.
TV One is another African-American-oriented network and a direct competitor to BET, targeting African American adults with a broad range of programming. The network airs original lifestyle and entertainment-oriented shows, movies, fashion and music programming, as well as classic series such as 227, Good Times, Martin, Boston Public and It's Showtime at the Apollo. The network primarily owned by Radio One. Founded and controlled by Catherine Hughes, it is one of the nation's largest radio broadcasting companies and the largest African-American-owned radio broadcasting company in the United States.
Other African-American networks scheduled to launch in 2009 are the Black Television News Channel founded by former Congressman J. C. Watts and Better Black Television founded by Percy Miller. In June 2009, NBC News launched a new website named The Grio in partnership with the production team that created the black documentary film, Meeting David Wilson. It is the first African-American video news site which focuses on underrepresented stories in existing national news. The Grio consists of a broad spectrum of original video packages, news articles, and contributor blogs on topics including breaking news, politics, health, business, entertainment and Black History.
Cultural influence in the United States.
From their earliest presence in North America, African Americans have contributed literature, art, agricultural skills, foods, clothing styles, music, language, social and technological innovation to American culture. The cultivation and use of many agricultural products in the United States, such as yams, peanuts, rice, okra, sorghum, grits, watermelon, indigo dyes, and cotton, can be traced to African and African-American influences. Notable examples include George Washington Carver, who created 300 products from peanuts, 118 products from sweet potatoes, and 75 from pecans; and George Crum, who invented the potato chip in 1853. Soul food is a variety of cuisine popular among African-Americans. It is closely related to the cuisine of the Southern United States. The descriptive terminology may have originated in the mid-1960s, when "soul" was a common definer used to describe African-American culture (for example, soul music).
African-American music is one of the most pervasive African-American cultural influences in the United States today and is among the most dominant in mainstream popular music. Hip hop, R&B, funk, rock and roll, soul, blues, and other contemporary American musical forms originated in black communities and evolved from other black forms of music, including blues, doo-wop, barbershop, ragtime, bluegrass, jazz, and gospel music.
African-American-derived musical forms have also influenced and been incorporated into virtually every other popular musical genre in the world, including country and techno. African-American genres are the most important ethnic vernacular tradition in America, as they have developed independent of African traditions from which they arise more so than any other immigrant groups, including Europeans; make up the broadest and longest lasting range of styles in America; and have, historically, been more influential, interculturally, geographically, and economically, than other American vernacular traditions.
African Americans have also had an important role in American dance. Bill T. Jones, a prominent modern choreographer and dancer, has included historical African-American themes in his work, particularly in the piece "Last Supper at Uncle Tom's Cabin/The Promised Land". Likewise, Alvin Ailey's artistic work, including his "Revelations" based on his experience growing up as an African American in the South during the 1930s, has had a significant influence on modern dance. Another form of dance, Stepping, is an African-American tradition whose performance and competition has been formalized through the traditionally black fraternities and sororities at universities.
Many African-American authors have written stories, poems, and essays influenced by their experiences as African Americans. African-American literature is a major genre in American literature. Famous examples include Langston Hughes, James Baldwin, Richard Wright, Zora Neale Hurston, Ralph Ellison, Nobel Prize winner Toni Morrison, and Maya Angelou.
African-American inventors have created many widely used devices in the world and have contributed to international innovation. Norbert Rillieux created the technique for converting sugar cane juice into white sugar crystals. Moreover, Rillieux left Louisiana in 1854 and went to France, where he spent ten years working with the Champollions deciphering Egyptian hieroglyphics from the Rosetta Stone. Most slave inventors were nameless, such as the slave owned by the Confederate President Jefferson Davis who designed the ship propeller used by the Confederate navy.
By 1913 over 1,000 inventions were patented by black Americans. Among the most notable inventors were Jan Matzeliger, who developed the first machine to mass-produce shoes, and Elijah McCoy, who invented automatic lubrication devices for steam engines. Granville Woods had 35 patents to improve electric railway systems, including the first system to allow moving trains to communicate. Garrett A. Morgan developed the first automatic traffic signal and gas mask.
Lewis Howard Latimer invented an improvement for the incandescent light bulb. More recent inventors include Frederick McKinley Jones, who invented the movable refrigeration unit for food transport in trucks and trains. Lloyd Quarterman worked with six other black scientists on the creation of the atomic bomb (code named the Manhattan Project.) Quarterman also helped develop the first nuclear reactor, which was used in the atomically powered submarine called the Nautilus.
A few other notable examples include the first successful open heart surgery, performed by Dr. Daniel Hale Williams, and the air conditioner, patented by Frederick McKinley Jones. Dr. Mark Dean holds three of the original nine patents on the computer on which all PCs are based. More current contributors include Otis Boykin, whose inventions included several novel methods for manufacturing electrical components that found use in applications such as guided missile systems and computers, and Colonel Frederick Gregory, who was not only the first black astronaut pilot but the person who redesigned the cockpits for the last three space shuttles. Gregory was also on the team that pioneered the microwave instrumentation landing system.
Political legacy.
African Americans have fought in every war in the history of the United States.
The gains made by African Americans in the Civil Rights and Black Power movements not only obtained certain rights for African Americans, but changed American society in far-reaching and fundamentally important ways. Prior to the 1950s, Black Americans in the South were subject to de jure discrimination, or Jim Crow. They would often be the victims of extreme cruelty and violence, sometimes resulting in deaths: by the post WWII era, African Americans became increasingly discontented with their long-standing inequality. In the words of Martin Luther King, Jr., African Americans and their supporters challenged the nation to "rise up and live out the true meaning of its creed that all men are created equal ..."
The Civil Rights Movement marked a sea-change in American social, political, economic and civic life. It brought with it boycotts, sit-ins, demonstrations, court battles, bombings and other violence; prompted worldwide media coverage and intense public debate; forged enduring civic, economic and religious alliances; and disrupted and realigned the nation's two major political parties.
Over time, it has changed in fundamental ways the manner in which blacks and whites interact with and relate to one another. The movement resulted in the removal of codified, "de jure" racial segregation and discrimination from American life and law, and heavily influenced other groups and movements in struggles for civil rights and social equality within American society, including the Free Speech Movement, the disabled, women, Native Americans, and migrant workers.
Terminology.
Political overtones.
The term "African American" carries important political overtones. Earlier terms used to describe Americans of African ancestry referred more to skin color than ancestry, and were conferred upon the group by colonists and Americans of European ancestry; people with dark skins were considered inferior in fact and in law. The terms (such as "colored", "person of color", or "negro") were included in the wording of various laws and legal decisions which some thought were being used as tools of white supremacy and oppression. There developed among blacks in America a growing desire for a term of self-identification of their own choosing.
With the political consciousness that emerged from the political and social ferment of the late 1960s and early 1970s, blacks no longer approved of the term Negro. They believed it had suggestions of a moderate, accommodationist, even "Uncle Tom" connotation. In this period, a growing number of blacks in the United States, particularly African-American youth, celebrated their blackness and their historical and cultural ties with the African continent. The Black Power movement defiantly embraced "Black" as a group identifier. It was a term social leaders themselves had repudiated only two decades earlier, but they proclaimed, "Black is beautiful".
In this same period, a smaller number of people favored "Afro-American", a common shortening (as is 'Anglo-American'). However, after the decline in popularity of the 'Afro' hairstyle in the late 1970s, the term fell out of use.
In the 1980s the term "African American" was advanced on the model of, for example, German-American or Irish-American to give descendants of American slaves and other American blacks who lived through the slavery era a heritage and a cultural base. The term was popularized in black communities around the country via word of mouth and ultimately received mainstream use after Jesse Jackson publicly used the term in front of a national audience. Subsequently, major media outlets adopted its use.
Some such as Maulana Karenga and Owen Alik Shahadah argue African-American is more appropriate, because it accurately articulates geography and historical origin. Thus linking a people to a continent as opposed to an abstract color. Others believe the term black is inaccurate because African Americans have a variety of skin tones. Surveys show that the majority of Black Americans have no preference for "African American" versus "Black," although they have a slight preference for "Black" in personal settings and "African American" in more formal settings.
Many African Americans expressed a preference for the term, as it was formed in the same way as names for others of the many ethnic groups in the nation. Some argued further that, because of the historical circumstances surrounding the capture, enslavement and systematic attempts to de-Africanize blacks in the United States under chattel slavery, most African Americans are unable to trace their ancestry to a specific African nation; hence, the entire continent serves as a geographic marker.
For many, "African American" is more than a name expressive of cultural and historical roots. The term expresses pride in Africa and a sense of kinship and solidarity with others of the African diaspora—an embrace of pan-Africanism as earlier enunciated by prominent African thinkers such as Marcus Garvey, W. E. B. Du Bois and George Padmore. Rarely used terms include Afro-Usonian and African-Usanian,
Identity.
Since 1977, in an attempt to keep up with changing social opinion, the United States government has officially classified black people (revised to "black" or "African American" in 1997) as "having origins in any of the black racial groups of Africa." Other federal offices, such as the United States Census Bureau, adhere to the Office of Management and Budget standards on race in its data collection and tabulations efforts. In preparation for the United States 2010 Census, a marketing and outreach plan, called "2010 Census Integrated Communications Campaign Plan" (ICC) recognized and defined African Americans as black people born in the United States. From the ICC perspective, African Americans are one of three groups of black people in the United States
The ICC plan was to reach the three groups by acknowledging that each group has its own sense of community that is based on geography and ethnicity. The best way to market the census process toward any of the three groups is to reach them through their own unique communication channels and not treat the entire black population of the U.S. as though they are all African Americans with a single ethnic and geographical background. The U.S. Department of Justice Federal Bureau of Investigation categorizes black or African-American people as "A person having origins in any of the black racial groups of Africa" through racial categories used in the UCR Program adopted from the Statistical Policy Handbook (1978) and published by the Office of Federal Statistical Policy and Standards, U.S. Department of Commerce, derived from the 1977 Office of Management and Budget classification.
Admixture.
Historically, "race mixing" between black and white people was taboo in the United States. So-called anti-miscegenation laws, barring blacks and whites from marrying or having sex, were established in colonial America as early as 1691. The taboo among American whites surrounding white-black relations can be seen as a historical consequence of the oppression and racial segregation of African Americans. Historian David Brion Davis notes the racial mixing that occurred during slavery was frequently attributed by the planter class to the "lower-class white males" but Davis concludes that "there is abundant evidence that many slaveowners, sons of slaveowners, and overseers took black mistresses or in effect raped the wives and daughters of slave families." A famous example was Thomas Jefferson's mistress, Sally Hemings.
Harvard University historian Henry Louis Gates, Jr. wrote in 2009, "African Americans ... are a racially mixed or mulatto people—deeply and overwhelmingly so." For example, after the Emancipation Proclamation Chinese American men married African-American women in high proportions to their total marriage numbers due to few Chinese American women being in the United States. African slaves and their descendants have also had a history of cultural exchange and intermarriage with Native Americans although they did not necessarily retain social, cultural or linguistic ties to Native peoples. There are also increasing intermarriages and offspring between non-Hispanic blacks and Hispanics of any race, especially between Puerto Ricans and African Americans (American-born blacks).
Racially mixed marriages have become increasingly accepted in the United States since the Civil Rights movement and up to the present day. Approval in national opinion polls have risen from 36% in 1978, to 48% in 1991, 65% in 2002, 77% in 2007. Scientific analysis indicates that current African Americans inherit about 14–17.7% of their ancestry from Europeans.
The African-American experience.
In her book "The End of Blackness", as well as in an essay on the liberal website "Salon", author Debra Dickerson has argued that the term "black" should refer strictly to the descendants of Africans brought to America as slaves, and not the sons and daughters of black immigrants who lack that ancestry. In her opinion, President Barack Obama, who is the son of a Kenyan immigrant, although technically African-American, is not black. She makes the argument that grouping all people of African descent together regardless of their unique ancestral circumstances would inevitably deny the lingering effects of slavery within the American community of slave descendants, in addition to denying black immigrants recognition of their own unique ancestral backgrounds. "Lumping us all together", Dickerson wrote, "erases the significance of slavery and continuing racism while giving the appearance of progress".
Similar viewpoints have been expressed by Stanley Crouch in a "New York Daily News" piece, Charles Steele, Jr. of the Southern Christian Leadership Conference and African-American columnist David Ehrenstein of the "LA Times" who accused white liberals of flocking to blacks who were "Magic Negros", a term that refers to a black person with no past who simply appears to assist the mainstream white (as cultural protagonists/drivers) agenda. Ehrenstein went on to say "He's there to assuage white 'guilt' they feel over the role of slavery and racial segregation in American history."
Former Secretary of State Condoleezza Rice (who was famously mistaken for a "recent American immigrant" by French President Nicolas Sarkozy), said "descendants of slaves did not get much of a head start, and I think you continue to see some of the effects of that." She has also rejected an immigrant designation for African Americans and instead prefers the term "black" or "white" to denote the African and European U.S. founding populations.
Terms no longer in common use.
The terms mulatto and colored were widely used until the second quarter of the 20th century, when they were considered outmoded and generally gave way to the use of "negro". By the 1940s, the term commonly was capitalized, Negro, but by the mid-1960s it was considered disparaging. By the end of the 20th century "Negro" had come to be considered inappropriate and was rarely used and perceived as a pejorative. The term is rarely used by younger black people, but remained in use by many older black Americans who had grown up with the term, particularly in the southern U.S.
The word "negro" is the Spanish and Portuguese word for the color "black". In regions such as Latin America where these languages are spoken, "negro" (pronounced slightly differently from "Negro" in English), is a normal word used without disparaging intent in relation to black people.
There are many other deliberately insulting terms. Many were in common use ("e.g.", "nigger"), but had become unacceptable in normal discourse before the end of the 20th century.
See also.
Diaspora:
Lists:

</doc>
<doc id="2161" url="http://en.wikipedia.org/wiki?curid=2161" title="Artistic License">
Artistic License

The Artistic License refers most commonly to the original Artistic License (version 1.0), a software license used for certain free and open source software packages, most notably the standard implementation of the Perl programming language and most CPAN modules, which are dual-licensed under the Artistic License and the GNU General Public License (GPL). The original Artistic License was written by Larry Wall. The name of the license is a reference to the concept of artistic license.
The terms of the Artistic License 1.0 were at issue in a 2007 federal district court decision in the US, which suggested that FOSS-like licenses could only be enforced through contract law rather than through copyright law, in contexts where contract damages would be difficult to establish. On appeal, a federal appellate court "determined that the terms of the Artistic License are enforceable copyright conditions".
The case was remanded to the District Court which did not apply the superior court's criteria (on the grounds that in the interim, the Supreme Court had changed the applicable law). However, this left undisturbed the finding that a free and open source license nonetheless has economic value.
Artistic License 1.0.
Whether or not the original Artistic License is a free software license is largely unsettled. It was criticized by the Free Software Foundation
as being "too vague; some passages are too clever for their own good, and their meaning is not clear." The Free Software Foundation has also explicitly called the original Artistic License a non-free license. The FSF recommended that the license not be used on its own, but approved the common AL/GPL dual-licensing approach for Perl projects.
In response to this, Bradley Kuhn, who later worked for the Free Software Foundation, made a minimal redraft to clarify the ambiguous passages. This was released as the Clarified Artistic License, and was approved by the FSF. It is used by the SNEeSe emulator, the Paros Proxy, the JavaFBP toolkit and NcFTP.
Artistic License 2.0.
In response to the Request for comments process for improving the licensing position for Perl 6, Kuhn's draft was extensively rewritten by Roberta Cairney and Allison Randal for readability and legal clarity, with input from the Perl community. This resulted in the Artistic License 2.0 which has been approved as both a free software and open source license.
It has been adopted by some of the Perl 6 implementations, and has been used by the Parrot virtual machine since version 0.4.13.
The OSI recommends that all developers and projects licensing their products with the Artistic License adopt Artistic License 2.0.

</doc>
<doc id="2162" url="http://en.wikipedia.org/wiki?curid=2162" title="Afrikaans">
Afrikaans

Afrikaans is a West Germanic language, spoken in South Africa and Namibia, and to a lesser extent in Botswana and Zimbabwe. It is an offshoot of several Dutch dialects spoken by the mainly Dutch settlers of what is now South Africa, where it gradually began to develop independently in the course of the 18th century. Hence, historically, it is a daughter language of Dutch, and was previously referred to as "Cape Dutch" (a term also used to refer collectively to the early Cape settlers) or "kitchen Dutch" (a derogatory term used to refer to Afrikaans in its earlier days).
Although Afrikaans adopted words from languages such as Portuguese, the Bantu languages, Malay, and the Khoisan languages, an estimated 90 to 95% of Afrikaans vocabulary is of Dutch origin.
Therefore, differences with Dutch often lie in the more analytic morphology and grammar of Afrikaans, and a spelling that expresses Afrikaans pronunciation rather than standard Dutch. There is a large degree of mutual intelligibility between the two languages—especially in written form.
With about 7 million native speakers in South Africa, or 13.5% of the population, it is the third-most-spoken mother tongue in the country. It has the widest geographical and racial distribution of all the official languages of South Africa, and is widely spoken and understood as a second or third language. It is the majority language of the western half of South Africa — the provinces of the Northern Cape and Western Cape — and the first language of over 70% of Coloured South Africans (3.4 million people) and about 60% of White South Africans (2.7 million). About 600,000 black South Africans speak it as their first language. Large numbers of Bantu-speaking and English-speaking South Africans also speak it as their second language.
In neighbouring Namibia, Afrikaans is widely spoken as a second language and used as "lingua franca", while as a native language it is spoken in 11% of households, mainly concentrated in the capital Windhoek and the southern regions of Hardap and Karas.
Estimates of the total number of Afrikaans-speakers range between 15 and 23 million.
History.
The Afrikaans language arose in the Dutch Cape Colony, through a gradual divergence from European Dutch dialects, during the course of the 18th century. As early as the mid-18th century and as recently as the mid-20th century, Afrikaans was known in standard Dutch as a "kitchen language" (Afr. "kombuistaal"), lacking the prestige accorded, for example even by the educational system in Africa, to languages spoken outside Africa; other early epithets setting apart "Kaaps Hollands" ("Cape Dutch", i.e. Afrikaans) as putatively beneath official Dutch standards included "geradbraakt/gebroken/onbeschaafd Hollands" ("mutilated/broken/uncivilised Dutch"), as well as "verkeerd Nederlands" ("incorrect Dutch"). An estimated 90 to 95% of Afrikaans vocabulary is ultimately of Dutch origin, and there are few lexical differences between the two languages; however, Afrikaans has a considerably more regular morphology, grammar, and spelling. There is a degree of mutual intelligibility between the two languages, particularly in written form.
Afrikaans acquired some lexical and syntactical borrowings from other languages such as Malay, Khoisan languages, Portuguese, and of the Bantu languages, and to a lesser extent, French. Afrikaans has also been significantly influenced by South African English. Nevertheless, Dutch speakers are confronted with fewer noncognates when listening to Afrikaans than the other way round. Mutual intelligibility thus tends to be asymmetrical, as it is easier for Dutch speakers to understand Afrikaans than for Afrikaans speakers to understand Dutch. In general, mutual intelligibility between Dutch and Afrikaans is better than between Dutch and Frisian or between Danish and Swedish. The South African poet writer Breyten Breytenbach, attempting to visualize the language distance to anglophones once remarked that the differences between (Standard) Dutch and Afrikaans are comparable to those between the Received Pronunciation and Southern American English.
Afrikaans was considered a Dutch dialect in South Africa until the early 20th century, when it became recognised as a distinct language under South African law, alongside Standard Dutch, which it eventually replaced as an official language. A relative majority of the first settlers whose descendants today are the Afrikaners were from the United Provinces (now Netherlands and Belgium), though there were also many from Germany, a considerable number from France, and some from Madeira, Norway, Portugal, Scotland, and various other countries.
The workers and slaves who contributed to the development of Afrikaans were Asians (especially Malays) and Malagasys, as well as the Khoi, San, and Bantu peoples who also lived in the area. African creole people in the early 18th century — documented on the cases of Hendrik Bibault and patriarch Oude Ram — were the first to call themselves "Afrikaner" (Africans). Only much later in the second half of the 19th century did the Boers adopt this attribution, too. The Khoi and mixed-race groups became collectively referred to as 'Coloureds'.
Dialects.
Following early dialectical studies of Afrikaans, it was theorised that three main historical dialects probably existed after the Great Trek in the 1830s. These dialects are the "Northern Cape", "Western Cape", and "Eastern Cape" dialects. Northern Cape dialect may have resulted from contact between Dutch settlers and the Khoi-Khoi people between the Great Karoo and the Kunene, and Eastern Cape dialect between the Dutch and the Xhosa. Remnants of these dialects still remain in present-day Afrikaans, although the standardising effect of Standard Afrikaans has contributed to a great levelling of differences in modern times.
There is also a prison cant, known as soebela or sombela, which is based on Afrikaans, yet heavily influenced by Zulu. This language is used as a secret language in prison and is taught to initiates.
Kaapse Afrikaans.
The term "Kaapse Afrikaans" ("Cape Afrikaans") is sometimes erroneously used to refer to the entire Western Cape dialect; it is more commonly used for a particular sociolect spoken in the Cape Peninsula of South Africa. Kaapse Afrikaans was once spoken by all population groups. However, it became increasingly restricted to the Cape Coloured ethnic group in Cape Town and environs.
Kaapse Afrikaans preserves some features more similar to Dutch than to Afrikaans.
Kaapse Afrikaans has some other features not typically found in Afrikaans.
Kaapse Afrikaans is also characterised by much code-switching between English and Afrikaans, especially in the inner-city and lower socio-economic status areas of Cape Town.
An example of characteristic Kaapse Afrikaans
Oranjerivierafrikaans.
The term "Oranjeriverafrikaans" ("Afrikaans of the Orange River") is sometimes erroneously used to refer to the Northern Cape dialect; it is more commonly used for the regional peculiarities of standard Afrikaans spoken in the Upington/Orange River wine district of South Africa.
Some of the characteristics of Oranjerivierafrikaans are the plural form -goed (Ma-goed, meneergoed), variant pronunciation such as in "kjerk" ("Church") and "gjeld" ("money") and the ending "-se", which indicates possession.
Expatriate geolect.
Although Afrikaans is mainly spoken in South Africa and Namibia, smaller Afrikaans-speaking populations live in Argentina, Australia, Botswana, Brazil, Canada, Lesotho, Malawi, the Netherlands, New Zealand, Swaziland, the United Kingdom, the United States, Zambia, and Zimbabwe. Most, if not all, Afrikaans-speaking people living outside Africa are emigrants and their descendants. Because of emigration and migrant labour, more than 100,000 Afrikaans speakers may live in the United Kingdom.
Standardisation.
The linguist Paul Roberge suggested the earliest 'truly Afrikaans' texts are doggerel verse from 1795 and a dialogue transcribed by a Dutch traveller in 1825. Printed material among the Afrikaners at first used only standard European Dutch. By the mid-19th century, more and more were appearing in Afrikaans, which was very much still regarded as a set of regional dialects.
In 1861, L.H. Meurant published his ' ("Conversation between Claus Truthsayer and John Doubter"), which is considered by some to be the first authoritative Afrikaans text. Abu Bakr Effendi also compiled his Arabic Afrikaans Islamic instruction book between 1862 and 1869, although this was only published and printed in 1877. The first Afrikaans grammars and dictionaries were published in 1875 by the ' ('Society for Real Afrikaners') in Cape Town.
The First and Second Boer Wars further strengthened the position of Afrikaans. The official languages of the Union of South Africa were English and Dutch until Afrikaans was subsumed under Dutch on 5 May 1925.
The main Afrikaans dictionary is the Woordeboek van die Afrikaanse Taal (WAT) (Dictionary of the Afrikaans Language), which is as yet incomplete owing to the scale of the project, but the one-volume dictionary in household use is the Verklarende Handwoordeboek van die Afrikaanse Taal (HAT). The official orthography of Afrikaans is the "Afrikaanse Woordelys en Spelreëls", compiled by Die Taalkommissie.
The Afrikaans Bible.
A major landmark in the development of the language was the translation of the whole Bible into Afrikaans. Before this, most Cape Dutch-Afrikaans speakers had to rely on the Dutch Statenbijbel. This Statenvertaling had its origins with the Synod of Dordrecht of 1618 and was thus in an archaic form of Dutch. This was hard for Dutch and Cape Dutch speakers to understand, and increasingly unintelligible for Afrikaans speakers.
C. P. Hoogehout, Arnoldus Pannevis, and Stephanus Jacobus du Toit were the first Afrikaans Bible translators. Important landmarks in the translation of the Scriptures were in 1878 with C. P. Hoogehout's translation of the "Evangelie volgens Markus" (Gospel of Mark, lit. Gospel according to Mark), however this translation was never published. The manuscript is to be found in the South African National Library, Cape Town.
The first official translation of the entire Bible into Afrikaans was in 1933 by J. D. du Toit, E. E. van Rooyen, J. D. Kestell, H. C. M. Fourie, and BB Keet. This monumental work established Afrikaans as "", that is "a pure and proper language" for religious purposes, especially amongst the deeply Calvinist Afrikaans religious community that previously had been rather sceptical of a Bible translation that varied from the Dutch version that they were used to.
In 1983 a fresh translation marked the 50th anniversary of the 1933 version and provided a much needed revision. The final editing of this edition was done by E. P. Groenewald, A. H. van Zyl, P. A. Verhoef, J. L. Helberg and W. Kempen.
Grammar.
In Afrikaans grammar, there is no distinction between the infinitive and present forms of verbs, with the exception of the verbs 'to be' and 'to have':
In addition, verbs do not conjugate differently depending on the subject. For example,
Only a handful of Afrikaans verbs have a preterite, namely the auxiliary "wees" ("to be"), the modal verbs, and the verb "dink" ("to think"). The preterite of "mag" ("may") is rare in contemporary Afrikaans.
All other verbs use the perfect tense ("hê" + past participle) for the past. Therefore there is no distinction in Afrikaans between "I drank" and "I have drunk". (Note that in colloquial Dutch and particularly in colloquial German, the past tense is also widely replaced with the perfect.)
When telling a longer story, Afrikaans speakers usually avoid the perfect and simply use the present tense instead (as is possible, but less common, in English as well).
A particular feature of Afrikaans is its use of the double negative; it is classified in Afrikaans as "ontkennende vorm" and is something that is absent from the other West Germanic standard languages. For example,
Both French and San origins have been suggested for double negation in Afrikaans. While double negation is still found in Low Franconian dialects in West-Flanders and in some "isolated" villages in the center of the Netherlands (i.e. Garderen), it takes a different form, which is not found in Afrikaans. The following is an example:
The "-ne" was the Middle Dutch way to negate but it has been suggested that since "-ne" became highly non-voiced, nie or niet was needed to complement the "-ne". With time the "-ne" disappeared in most Dutch dialects.
The double negative construction has been fully grammaticalized in standard Afrikaans and its proper use follows a set of fairly complex rules as the examples below show:
The Dutch word "het" ("it" in English) does not correspond to "het" in Afrikaans; the Dutch word "heb" corresponds to "het" in Afrikaans.
A notable exception to this is the use of the negating grammar form that coincides with negating the English present participle. In this case there is only a single negation.
Certain words in Afrikaans arise due to grammar. For example, "moet nie", which literally means "must not", usually becomes "moenie"; although one does not have to write or say it like this, virtually all Afrikaans speakers will change the two words to "moenie" in the same way as "do not" shifts to "don't" in English.
Sounds.
Afrikaans' sound system is similar to that of other West Germanic languages like Dutch or Frisian.
Orthography.
There are many parallels to the Dutch orthography conventions and those used for Afrikaans. There are 26 letters.
In Afrikaans, many consonants are dropped from the earlier Dutch spelling. For example, "slechts" ('only') in Dutch becomes "slegs" in Afrikaans. For example, Afrikaans and some Dutch dialects make no distinction between and , having merged the latter into the former; while the word for "south" is written "" in Dutch, it is spelled "" in Afrikaans to represent this merger. Similarly, the Dutch digraph "ĳ", normally pronounced as , is written as "y", except where it replaces the Dutch suffix "–lijk" which is pronounced as or , as in " > ".
Another difference is the indefinite article, ' in Afrikaans and in Dutch. 'A book' is ' in Afrikaans, whereas it is either ' or ' in Dutch. This "" is usually pronounced as just a weak vowel, .
The diminutive suffix in Afrikaans is "-tjie", whereas in Dutch it is "-tje", hence a "bit" is in Afrikaans and in Dutch.
The letters "c", "q", "x", and "z" occur almost exclusively in borrowings from French, English, Greek and Latin. This is usually because words that had "c" and "ch" in the original Dutch are spelled with "k" and "g", respectively, in Afrikaans. Similarly original "qu" and "x" are spelt "kw" and "ks" respectively. For example "" instead of "equatoriaal", and "" instead of "excuus".
The vowels with diacritics in non-loanword Afrikaans are: "á, é, è, ê, ë, í, î, ï, ó, ô, ú, û, ý". Diacritics are ignored when alphabetising, though they are still important, even when typing the diacritic forms may be difficult. For example "" instead of the 3 e's alongside each other: geeet which can never occur in Afrikaans or "" which translates to say, whereas "" is a possessive form.
Initial apostrophes.
A few short words in Afrikaans take initial apostrophes. In modern Afrikaans, these words are always written in lower case (except if the entire line is uppercase), and if they occur at the beginning of a sentence, the next word is capitalised. Three examples of such apostrophed words are '. The last (the indefinite article) is the only apostrophed word that is common in modern written Afrikaans, since the other examples are shortened versions of other words (' and "" respectively) and are rarely found outside of a poetic context.
Here are a few examples:
The apostrophe and the following letter are regarded as two separate characters, and are never written using a single glyph, although a single character variant of the indefinite article appears in Unicode, .
Table of characters.
For more on the pronunciation of the letters below, see "".
Afrikaans phrases.
Afrikaans is a very centralised language, meaning that most of the vowels are pronounced in a very centralised (or schwa-like) way. Although there are many different dialects and accents, the transcription would be fairly standard.
It should be noted that in the Dutch language the word "Afrikaans" means African, in the general sense. Consequently Afrikaans is commonly but incorrectly denoted as "Zuid-Afrikaans". This ambiguity also exists in Afrikaans itself and is either resolved in the context of its usage, or by using "Afrikaan" for an African person, and "Afrika-" in the adjective sense.
The following Afrikaans sentences, which have the same meaning in English, are also written identically though their pronunciation differs:
Sample text.
Psalm 23 1983 translation:
"Die Here is my Herder, ek kom niks kort nie."<br>
"Hy laat my in groen weivelde rus. Hy bring my by waters waar daar vrede is."<br>
"Hy gee my nuwe krag. Hy lei my op die regte paaie tot eer van Sy naam."<br>
"Selfs al gaan ek deur donker dieptes, sal ek nie bang wees nie, want U is by my. In U hande is ek veilig."
Psalm 23 alternative translation:
"Die Here is my Herder, niks sal my ontbreek nie."<br>
"Hy laat my neerlê in groen weivelde; na waters waar rus is, lei Hy my heen."<br>
"Hy verkwik my siel; Hy lei my in die spore van geregtigheid, om sy Naam ontwil."<br>
"Al gaan ek ook in 'n dal van doodskaduwee, ek sal geen onheil vrees nie; want U is met my: u stok en u staf die vertroos my."
Lord's Prayer (Afrikaans New Living translation)
"Ons Vader in die hemel, laat U Naam geheilig word."<br>
"Laat U koningsheerskappy spoedig kom."<br>
"Laat U wil hier op aarde uitgevoer word soos in die hemel."<br>
"Gee ons die porsie brood wat ons vir vandag nodig het."<br>
"En vergeef ons ons sondeskuld soos ons ook óns skuldenaars vergewe het."<br>
"Bewaar ons sodat ons nie aan verleiding sal toegee nie; en bevry ons van die greep van die Bose."<br>
"Want van U is die koninkryk,"<br>
"en die krag,"<br>
"en die heerlikheid,"<br>
"tot in ewigheid. Amen"
Lord's Prayer (Original translation):
"Onse Vader wat in die hemel is,"<br>
"laat U Naam geheilig word;"<br>
"laat U koninkryk kom;"<br>
"laat U wil geskied op die aarde,"<br>
"net soos in die hemel."<br>
"Gee ons vandag ons daaglikse brood;"<br>
"en vergeef ons ons skulde"<br>
"soos ons ons skuldenaars vergewe"<br>
"en laat ons nie in die versoeking nie"<br>
"maar verlos ons van die Bose"<br>
"Want aan U behoort die koninkryk"<br>
"en die krag"<br>
"en die heerlikheid"<br>
"tot in ewigheid. Amen"
Sociolinguistics.
Some state that instead of "Afrikaners" which refers to an ethnic group, the terms "Afrikaanses" or "Afrikaanssprekendes" (lit. Afrikaans speakers) should be used for people of any ethnic origin who speak Afrikaans. Linguistic identity has not yet established which terms shall prevail, and all three are used in common parlance.
Afrikaans is also widely spoken in Namibia. Before independence, Afrikaans had equal status with German as an official language. Since independence in 1990, Afrikaans has had constitutional recognition as a national, but not official, language. There is a much smaller number of Afrikaans speakers among Zimbabwe's white minority, as most have left the country since 1980. Afrikaans was also a medium of instruction for schools in Bophuthatswana Bantustan.
Many South Africans living and working in Belgium, the Netherlands, the United Kingdom, Australia, New Zealand, Canada, the United States and Kuwait are also Afrikaans-speaking. They have access to Afrikaans websites, news sites such as Nuus24.com and Sake24, and radio broadcasts over the web, such as those from Radio Sonder Grense and Radio Pretoria.
Afrikaans has been influential in the development of South African English. Many Afrikaans loanwords have found their way into South African English, such as 'bakkie' ("pickup truck"), 'braai' ("barbecue"), 'naartjie' ("tangerine"), 'tekkies' (AE "sneakers"/BE "trainers"/CE "runners"). A few words in standard English are derived from Afrikaans, such as 'aardvark' (lit. "earth pig"), 'trek' ("pioneering journey", in Afrikaans lit. "pull" but used also for "migrate"), "spoor" ("animal track"), "veld" ("Southern African grassland" in Afrikaans lit. "field"), "commando" from Afrikaans "kommando" meaning small fighting unit, "boomslang" ("tree snake") and apartheid ("segregation"; more accurately "apartness" or "the state or condition of being apart").
In 1976, secondary school pupils in Soweto began a rebellion in response to the government's decision that Afrikaans be used as the language of instruction for half the subjects taught in non-White schools (with English continuing for the other half). Although English is the mother tongue of only 8.2% of the population, it is the language most widely understood, and the second language of a majority of South Africans. Afrikaans is more widely spoken than English in the Northern and Western Cape provinces, several hundred kilometers from Soweto. The Black community's opposition to Afrikaans and preference for continuing English instruction was underscored when the government rescinded the policy one month after the uprising: 96% of Black schools chose English (over Afrikaans or native languages) as the language of instruction.
Under South Africa's Constitution of 1996, Afrikaans remains an official language, and has equal status to English and nine other languages. The new policy means that the use of Afrikaans is now often reduced in favour of English, or to accommodate the other official languages. In 1996, for example, the South African Broadcasting Corporation reduced the amount of television airtime in Afrikaans, while South African Airways dropped its Afrikaans name "" from its livery. Similarly, South Africa's diplomatic missions overseas now only display the name of the country in English and their host country's language, and not in Afrikaans.
In spite of these moves, the language has remained strong, and Afrikaans newspapers and magazines continue to have large circulation figures. Indeed, the Afrikaans-language general-interest family magazine "Huisgenoot" has the largest readership of any magazine in the country. In addition, a pay-TV channel in Afrikaans called KykNet was launched in 1999, and an Afrikaans music channel, MK (Musiek kanaal) (lit. 'Music Channel'), in 2005. A large number of Afrikaans books are still published every year, mainly by the publishers Human & Rousseau, Tafelberg Uitgewers, Struik, and Protea Boekhuis.
Afrikaans has two monuments erected in its honour. The first was erected in Burgersdorp, South Africa, in 1893, and the second, better-known Afrikaans Language Monument ("") was built in Paarl, South Africa, in 1975.
When the British design magazine "Wallpaper" described Afrikaans as "one of the world's ugliest languages" in its September 2005 article about the monument, South African billionaire Johann Rupert (chairman of the Richemont Group), responded by withdrawing advertising for brands such as Cartier, Van Cleef & Arpels, Montblanc and Alfred Dunhill from the magazine. The author of the article, Bronwyn Davies, was an English-speaking South African.
Modern Dutch and Afrikaans share over 90 per cent of their vocabulary. Afrikaans speakers are able to learn Dutch within a comparatively short time. Native Dutch speakers pick up written Afrikaans even more quickly, due to its simplified grammar, whereas understanding spoken Afrikaans might need more effort. Afrikaans speakers can learn Dutch pronunciation with little training. This has enabled Dutch and Belgian companies to outsource their call centre operations to South Africa.
Future of Afrikaans.
Post-apartheid South Africa has seen a loss of preferential treatment by the government for Afrikaans, in terms of education, social events, media (TV and radio), and general status throughout the country, given that it now shares its place as official language with ten other languages. Nevertheless, Afrikaans remains more prevalent in the media – radio, newspapers and television – than any of the other official languages, except English. More than 300 book titles in Afrikaans are published annually. South African census figures suggest a growing number of speakers in all 9 provinces, a total of 6.85 million in 2011 compared to 5.98 million a decade earlier. The South African Institute of Race Relations (SAIRR) project that a growing majority will be Coloured Afrikaans speakers. Afrikaans speakers enjoy higher employment rates than other South African language groups, though half a million remain unemployed.
Despite the challenges of demotion and emigration that it faces in South Africa, the Afrikaans vernacular remains competitive, being popular in DSTV pay channels and several internet sites, while generating high newspaper and music CD sales. A resurgence in Afrikaans popular music since the late 1990s has invigorated the language, especially among a younger generation of South Africans. A recent trend is the increased availability of pre-school educational CDs and DVDs. Such media also prove popular with the extensive Afrikaans-speaking expatriate communities who seek to retain language proficiency in a household context.
After years of slumber, Afrikaans language cinema is showing signs of new vigour. The 2007 film "Ouma se slim kind", the first full-length Afrikaans movie since Paljas of 1998, is seen as the dawn of a new era in Afrikaans cinema. Several short films have been created and more feature-length movies, such as "Poena is Koning" and "Bakgat" (both in 2008) have been produced, besides the 2011 Afrikaans-language film "Skoonheid", which was the first Afrikaans film to screen at the Cannes Film Festival. The film "Platteland" was also released in 2011.
Afrikaans seems to be returning to the SABC. SABC3 announced early in 2009 that it would increase Afrikaans programming due to the "growing Afrikaans-language market and need for working capital as Afrikaans advertising is the only advertising that sells in the current South African television market". In April 2009, SABC3 started screening several Afrikaans-language programmes. Further latent support for the language derives from its de-politicised image in the eyes of younger-generation South Africans, who less and less often view it as "the language of the oppressor". Indeed, there is a groundswell movement within Afrikaans to be inclusive, and to promote itself along with the other indigenous official languages.
In Namibia, the percentage of Afrikaans speakers declined from 11.4% (2001 Census) to 10.4% (2011 Census). The major concentrations are in Hardap (41.0%), Karas (36.1%), Erongo (20.5%), Khomas (18.5%), Omaheke (10.0%), Otjozondjupa (9.4%), Kunene (4.2%), and Oshikoto (2.3%).

</doc>
<doc id="2163" url="http://en.wikipedia.org/wiki?curid=2163" title="Aeolus">
Aeolus

Aeolus (; , "Aiolos" , Modern Greek: ), a name shared by three mythical characters, was the ruler of the winds in Greek mythology. These three personages are often difficult to tell apart, and even the ancient mythographers appear to have been perplexed about which Aeolus was which. Diodorus Siculus made an attempt to define each of these three (although it is clear he also became muddled), and his opinion is followed here. Briefly, the first Aeolus was a son of Hellen and eponymous founder of the Aeolian race; the second was a son of Poseidon, who led a colony to islands in the Tyrrhenian Sea; and the third Aeolus was a son of Hippotes who is mentioned in "Odyssey" book 10 as Keeper of the Winds who gives Odysseus a tightly closed bag full of the captured winds so he could sail easily home to Ithaca on the gentle West Wind. But instead his men thought it was filled with riches, so they opened it which is why the journey was extended. All three men named Aeolus appear to be connected genealogically, although the precise relationship, especially regarding the second and third Aeolus, is often ambiguous.
Son of Hellen.
This Aeolus was son of Hellen and the nymph Orseis, and a brother of Dorus, Xuthus and, in some sources, of Amphictyon (who is otherwise a brother of Hellen). Described as the ruler of Aeolia (later called Thessaly) and held to be the founder of the Aeolic branch of the Greek nation, this Aeolus married Enarete, daughter of Deimachus (otherwise unknown). Aeolus and Enarete had many children, although the precise number and identities of these children vary from author to author in the ancient sources. The great extent of country which this race occupied, and the desire of each part of it to trace its origin to some descendant of Aeolus, probably gave rise to the varying accounts about the number of his children. Some scholars contend that the most ancient and genuine story told of only four sons of Aeolus: Sisyphus, Athamas, Cretheus, and Salmoneus, as the representatives of the four main branches of the Aeolic race. Other sons included Deioneus, Perieres, Cercaphas and perhaps Magnes (usually regarded as a brother of Macedon) and Aethlius. Another son is named Mimas, who provides a link to the third Aeolus in a genealogy that seems very contrived. Calyce, Peisidice, Perimede and Alcyone were counted among the daughters of Aeolus and Enarete. This Aeolus also had an illegitimate daughter named Arne, begotten on Melanippe, daughter of the Centaur Chiron. This Arne became the mother of the second Aeolus, by the god Poseidon.
Son of Poseidon.
This Aeolus was a son of Poseidon by Arne, daughter of Aeolus. He had a twin brother named Boeotus. Arne confessed to her father that she was with child by the god Poseidon; her father, however, did not believe her, and handed her over to a man named Metapontus, King of Icaria. When Bœotus and Aeolus were born, they were raised by Metapontus; but their stepmother (Autolyte, wife of Metapontus) quarrelled with their mother Arne, prompting Bœotus and Aeolus to kill Autolyte and flee from Icaria. Bœotus (accompanied by Arne) went to southern Thessaly, and founded Boeotia; but Aeolus went to a group of islands in the Tyrrhenian Sea, which received from him the name of the Aeolian Islands; according to some accounts this Aeolus founded the town of Lipara. Although his home has been traditionally identified as one of the Aeolian Islands (there is little consensus as to which), near Sicily, an alternative location has been suggested at Gramvousa off the northwest coast of Crete. Aeolus had six sons and six daughters, whom in Homer he wed to one another and the family lived happily together. Later writers were shocked by the incest: in Hyginus, the day Aeolus learned that one of his sons, Macareus, had committed incest with his sister Canace he expelled Macareus and threw the child born of this incestuous union to the dogs, and sent his daughter a sword by which she was to kill herself. Other late accounts claim that Macareus had a daughter named Amphissa, beloved by Apollo.
Son of Hippotes.
This Aeolus is most frequently conflated with Aeolus, the son of Poseidon, god of the sea. It is difficult to differentiate this Aeolus from the second Aeolus, as their identities seem to have been merged by many ancient writers. The father of this third Aeolus is given as Hippotes, son of Mimas, a son of the first Aeolus (son of Hellen). According to some accounts, Hippotes married the same Melanippe who was the mother of Arne. This Aeolus lived on the floating island of Aeolia and was visited by Odysseus and his crew in the "Odyssey." He gave hospitality for a month and provided for a west wind to carry them home. He also provided a gift of a bag containing all winds but the west, which Odysseus's crew members unwittingly opened just before they were to reach Ithaca. Unfortunately, they were blown back to Aeolia, where Aeolus refused to provide any further help, because he believed that their short and unsuccessful voyage meant that the gods did not favour them. This Aeolus was perceived by post-Homeric authors as a god, rather than as a mortal and simple Keeper of the Winds (as in the "Odyssey"). 
Like the previous, this Aeolus was said to have had twelve children - six sons and six daughters. According to Diodorus, he was father of six sons by Cyane, daughter of Liparus (the eponym of the island Lipara, whom Aeolus assisted in conquering lands above Surrentum, Italy). The sons' names were Agathyrnus, Astyochus, Androcles, Iocastus, Pheraemon, Xuthus, whereas the daughters are not mentioned at all. The sons were said to have become kings: Iocastus of the region in southern Italy as far as Rhegium; Pheraemon and Androcles of the part of Sicily between the Strait of Messina and Lilybaeum; Xuthus of Leontini; Agathyrnus of what was known as Agathyrnitis, having founded Agathyrnum; and Astyochus of Lipara. All were said to have been remembered as just and pious rulers. Another list of Aeolus' children is found in scholia on the "Odyssey". The latter source gives the sons' names as Androcles, Chrysippus, Iocastus, Phalacrus, Pheraemon, Xuthus, and the daughters' as Aeole, Astycrateia, Dia, Hephaestia, Iphthe, Periboea; their mother in this account is Telepora or Telepatra, daughter of Laestrygon.
Parthenius of Nicaea recorded a love affair between Odysseus and Aeolus' daughter Polymele; the latter was said to have ended up betrothed to her own brother Diores. 
In the "Aeneid" by Virgil, Juno offers Aeolus the nymph Deiopea as a wife if he will release his winds upon the fleet of Aeneas.

</doc>
<doc id="2166" url="http://en.wikipedia.org/wiki?curid=2166" title="ABC">
ABC

ABC are the first three letters of the Latin script.
ABC may refer to:

</doc>
<doc id="2167" url="http://en.wikipedia.org/wiki?curid=2167" title="Alford plea">
Alford plea

An "Alford" plea (also called a Kennedy plea in West Virginia, an
"Alford" guilty plea, and the "Alford" doctrine) in United States law is a guilty plea in criminal court, whereby a defendant in a criminal case does not admit the criminal act and asserts innocence. In entering an Alford plea, the defendant admits that the evidence the prosecution has would be likely to persuade a judge or jury to find the defendant guilty beyond a reasonable doubt.
Origin.
The "Alford" guilty plea originated in the United States Supreme Court case of "North Carolina v. Alford" (1970). Henry Alford had been indicted on a charge of first-degree murder in 1963. Evidence in the case included testimony from witnesses that Alford had said after the death of the victim that he had killed the individual. Court testimony showed Alford and the victim argued at the victim's house. Alford left the house, and afterwards the victim received a fatal gunshot wound when he opened the door responding to a knock.
Alford was faced with the possibility of capital punishment if convicted by a jury trial. The death penalty was the automatic sentence by North Carolina law at the time, if two requisites in the case were satisfied: the defendant had to have pleaded not guilty, and the jury did not instead recommend a life sentence. Had he pled guilty to first-degree murder, Alford would have had the possibility of a life sentence, but would have avoided the death penalty. The defendant did not want to admit guilt. Alford pled guilty to second-degree murder, and said he was doing so to avoid a death sentence if he had been convicted of first-degree murder after attempting to contest that charge. Alford was sentenced to thirty years in prison, after the trial judge in the case accepted the plea bargain and ruled that the defendant had been adequately informed by his lawyer.
Alford appealed and requested a new trial, arguing he was forced into a guilty plea because he was afraid of receiving a death sentence. The Supreme Court of North Carolina ruled that the defendant had voluntarily entered the guilty plea, with knowledge of what that meant. Following this ruling, Alford petitioned for a writ of habeas corpus in the United States District Court for the Middle District of North Carolina, which upheld the initial ruling, and subsequently to the United States Court of Appeals for the Fourth Circuit which ruled that Alford's plea was not voluntary, because it was made under fear of the death penalty. "I just pleaded guilty because they said if I didn't, they would gas me for it," wrote Alford in one of his appeals.
The case was then appealed to the Supreme Court. Supreme Court Justice Byron White wrote the decision for the majority. The Supreme Court held that for the plea to be accepted, the defendant must have been advised by a competent lawyer who was able to inform the individual that his best decision in the case would be to enter a guilty plea. The Court ruled that the defendant can enter such a plea "when he concludes that his interests require a guilty plea and the record strongly indicates guilt." The Court allowed the guilty plea only with a simultaneous protestation of innocence as there was enough evidence to show that the prosecution had a strong case for a conviction, and the defendant was entering such a plea to avoid this possible sentencing. The Court went on to note that even if the defendant could have shown that he would not have entered a guilty plea "but for" the rationale of receiving a lesser sentence, the plea itself would not have been ruled invalid. As evidence existed that could have supported Alford's conviction, the Supreme Court held that his guilty plea was allowable while the defendant himself still maintained that he was not guilty.
Definition.
The "Dictionary of Politics: Selected American and Foreign Political and Legal Terms" defines the term Alford plea as: "A plea under which a defendant may choose to plead guilty, not because of an admission to the crime, but because the prosecutor has sufficient evidence to place a charge and to obtain conviction in court. The plea is commonly used in local and state courts in the United States." According to "University of Richmond Law Review", "When offering an Alford plea, a defendant asserts his innocence but admits that sufficient evidence exists to convict him of the offense." "A Guide to Military Criminal Law" notes that under the Alford plea, "the defendant concedes that the prosecution has enough evidence to convict, but the defendant still refuses to admit guilt." The book "Plea Bargaining's Triumph: A History of Plea Bargaining in America" published by Stanford University Press defines the plea as one in "which the defendant adheres to his/her claim of innocence even while allowing that the government has enough evidence to prove his/her guilt beyond a reasonable doubt". According to the book "Gender, Crime, and Punishment" published by Yale University Press, "Under the Alford doctrine, a defendant does not admit guilt but admits that the state has sufficient evidence to find him or her guilty, should the case go to trial." "Webster's New World Law Dictionary" defines Alford plea as: "A guilty plea entered as part of a plea bargain by a criminal defendant who denies committing the crime or who does not actually admit his guilt. In federal courts, such plea may be accepted as long as there is evidence that the defendant is actually guilty."
The Alford guilty plea is "a plea of guilty containing a protestation of innocence". The defendant pleads guilty, but does not have to specifically admit to the guilt itself. The defendant maintains a claim of innocence, but agrees to the entry of a conviction in the charged crime. Upon receiving an Alford guilty plea from a defendant, the court may immediately pronounce the defendant guilty and impose sentence as if the defendant had otherwise been convicted of the crime. Sources disagree, as may differing states' laws, as to what category of plea the "Alford" plea falls under: Some sources state that the Alford guilty plea is a form of "nolo contendere", where the defendant in the case states "no contest" to the factual matter of the case as given in the charges outlined by the prosecution. Others hold that an "Alford" plea is simply one form of a guilty plea, and, as with other guilty pleas, the judge must see there is some factual basis for the plea.
Defendants can take advantage of the ability to use the Alford guilty plea, by admitting there is enough evidence to convict them of a higher crime, while at the same time pleading guilty to a lesser charge. Defendants usually enter an Alford guilty plea if they want to avoid a possible worse sentence were they to lose the case against them at trial. It affords defendants the ability to accept a plea bargain, while maintaining innocence.
Court and government usage.
This form of guilty plea has been frequently used in local and state courts in the United States, though it consists of a small percentage of all plea bargains in the U.S. This form of plea is not allowed in courts of the United States military. In 2000 the United States Department of Justice noted, "In an Alford plea the defendant agrees to plead guilty because he or she
realizes that there is little chance to win acquittal because of the strong evidence of guilt. About 17% of State inmates and 5% of Federal inmates submitted either an Alford plea or a no contest plea, regardless of the type of attorney. This difference reflects the relative readiness of State courts, compared to Federal courts, to accept an alternative plea."
In the 1995 case "State of Idaho v. Howry" before the Idaho Court of Appeals, the Court commented on the impact of the Alford guilty plea on later sentencing. The Court ruled, "Although an Alford plea allows a defendant to plead guilty amid assertions of innocence, it does not require a court to accept those assertions. The sentencing court may, of necessity, consider a broad range of information, including the evidence of the crime, the defendant's criminal history and the demeanor of the defendant, including the presence or absence of remorse." In the 1999 South Carolina Supreme Court case "State v. Gaines", the Court held that Alford guilty pleas were to be held valid in the absence of a specific on-the-record ruling that the pleas were voluntary – provided that the sentencing judge acted appropriately in accordance with the rules for acceptance of a plea made voluntarily by the defendant. The Court held that a ruling that the plea was entered into voluntarily is implied by the act of sentencing.
In the 2006 case before the United States Court of Appeals for the Fifth Circuit, "Ballard v. Burton", Judge Carl E. Stewart writing for the Court held that an Alford guilty plea is a "variation of an ordinary guilty plea". In October 2008, the United States Department of Justice defined an Alford plea as: "the defendant maintains his or her innocence with respect to the charge to which he or she offers to plead guilty".
In March 2009, the Minnesota House of Representatives characterized the Alford plea as: "a form of a guilty plea in which the defendant asserts innocence but acknowledges on the record that the prosecutor could present enough evidence to prove guilt." The Minnesota Judicial Branch similarly states: "Alford Plea: A plea of guilty that may be accepted by a court even where the defendant does not admit guilt. In an Alford plea, defendant has to admit that he has reviewed the state's evidence, a reasonable jury could find him guilty, and he wants to take advantage of a plea offer that has been made. Court has discretion as to whether to accept this type of plea."
The U.S. Attorneys' Manual states that in the federal system, Alford pleas "should be avoided except in the most unusual circumstances, even if no plea agreement is involved and the plea would cover all pending charges." U.S. Attorneys are required to obtain the approval of the Assistant Attorney General with supervisory responsibility over the subject matter before accepting such a plea.
Commentary.
In his 1972 book "American Criminal Justice", Jonathan D. Caplan comments on the Supreme Court decision, noting, "The "Alford" decision recognizes the plea-bargaining system, acknowledging that a man may maintain his innocence but still plead guilty in order to minimize his potential loss." Caplan comments on the impact of the Supreme Court's decision making it necessary for there to be evidence of guilt in such a plea, "By requiring that there be some evidence of guilt in such a situation, the decision attempts to protect the 'really' innocent from the temptations to which plea-bargaining and defense attorneys may subject them."
Major Steven E. Walburn argues in a 1998 article in "The Air Force Law Review" that this form of guilty plea should be adopted for usage by the United States military. "In fairness to an accused, if, after consultation with his defense counsel, he knowingly and intelligently determines that his best interest is served by an Alford-type guilty plea, he should be free to choose this path. The system should not force him to lie under oath, nor to go to trial with no promise of the ultimate outcome concerning guilt or punishment. We must trust the accused to make such an important decision for himself. The military provides an accused facing court-martial with a qualified defense attorney. Together, they are in the best position to properly weigh the impact his decision, and the resulting conviction, will have upon himself and his family," writes Walburn. He emphasizes that when allowing these pleas, "trial counsel should establish as strong a factual basis as possible", in order to minimize the possible negative outcomes to "the public's perception of the administration of justice within the military".
Stephanos Bibas writes in a 2003 analysis for "Cornell Law Review" that Judge Frank H. Easterbrook and a majority of scholars "praise these pleas as efficient, constitutional means of resolving cases." Bibas notes that prominent plea bargain critic Albert Alschuler supports the use of this form of plea, writing, "He views them as a lesser evil, a way to empower defendants within a flawed system. As long as we have plea bargaining, he maintains, innocent defendants should be free to use these pleas to enter advantageous plea bargains without lying. And guilty defendants who are in denial should be empowered to use these pleas instead of being forced to stand trial." Bibas instead asserts that this form of plea is "unwise and should be abolished". Bibas argues, "These procedures may be constitutional and efficient, but they undermine key values served by admissions of guilt in open court. They undermine the procedural values of accuracy and public confidence in accuracy and fairness, by convicting innocent defendants and creating the perception that innocent defendants are being pressured into pleading guilty. More basically, they allow guilty defendants to avoid accepting responsibility for their wrongs."
Legal scholar Jim Drennan, an expert on the court system at the Institute of Government at the University of North Carolina at Chapel Hill, told the "Winston-Salem Journal" in a 2007 interview that the ability to use this form of guilty plea as an option in courts had a far-reaching effect throughout the United States. Drennan commented, "We have lots of laws, but human interaction creates unique circumstances and the law has to adapt." He said of the Supreme Court case, "They had to make a decision about what to do. One of the things the court has to do is figure out how to answer new questions, and that is what happened in this case."

</doc>
<doc id="2170" url="http://en.wikipedia.org/wiki?curid=2170" title="ABCD">
ABCD

ABCD is a list of the first four letters in the English alphabet. It may also refer to:

</doc>
<doc id="2171" url="http://en.wikipedia.org/wiki?curid=2171" title="Anti-realism">
Anti-realism

In analytic philosophy, the term anti-realism is used to describe any position involving either the denial of an objective reality or the denial that verification-transcendent statements are either true or false. This latter construal is sometimes expressed by saying "there is no fact of the matter as to whether or not P." Thus, we may speak of anti-realism with respect to other minds, the past, the future, universals, mathematical entities (such as natural numbers), moral categories, the material world, or even thought. The two construals are clearly distinct but often confused. For example, an "anti-realist" who denies that other minds exist (i. e., a solipsist) is quite different from an "anti-realist" who claims that there is no fact of the matter as to whether or not there are unobservable other minds (i. e., a logical behaviorist).
Anti-realism in philosophy.
Michael Dummett.
The term was coined by Michael Dummett, who introduced it in his paper "Realism" to re-examine a number of classical philosophical disputes involving such doctrines as nominalism, conceptual realism, idealism and phenomenalism. The novelty of Dummett's approach consisted in seeing these disputes as analogous to the dispute between intuitionism and Platonism in the philosophy of mathematics.
According to intuitionists (anti-realists with respect to mathematical objects), the truth of a mathematical statement consists in our ability to prove it. According to platonists (realists), the truth of a statement consists in its correspondence to objective reality. Thus, intuitionists are ready to accept a statement of the form "P or Q" as true only if we can prove P or if we can prove Q:
this is called the disjunction property. In particular, we cannot in general claim that "P or not P" is true (the law of Excluded Middle), since in some cases we may not be able to prove the statement "P" nor prove the statement "not P". Similarly, intuitionists object to the existence property for classical logic, where one can prove formula_1, without being able to produce any term formula_2 of which formula_3 holds.
Dummett argues that the intuitionistic notion of truth lies at the bottom of various classical forms of anti-realism. He uses this notion to re-interpret phenomenalism, claiming that it need not take the form of a reductionism (often considered untenable).
Dummett's writings on anti-realism also draw heavily on the later writings of Wittgenstein concerning meaning and rule following. In fact, Dummett's writings on anti-realism can be seen as an attempt to integrate central ideas from the "Philosophical Investigations" into analytical philosophy.
Anti-realism in the sense that Dummett uses the term is also often called semantic anti-realism.
Hilary Putnam's "internal realism".
Despite being at one time a defender of metaphysical realism, Hilary Putnam later abandoned this view in favor of a position he termed "internal realism".
Precursors.
Doubts about the possibility of definite truth have been expressed since ancient times, for instance in the skepticism of Pyrrho. Anti-realism about matter or physical entities also has a long history. It can be found in the idealism of
Berkeley, as well as Hegel and other post-Kantians.
Metaphysical Realism vis-à-vis Internal Realism.
Anti-realist arguments.
Idealists are skeptics about the physical world, maintaining either: 1) that nothing exists outside the mind, or 2) that we would have no access to a mind-independent reality even if it may exist; the latter case often takes the form of a denial of the idea that we can have unconceptualised experiences (see Myth of the Given). Conversely, most realists (specifically, indirect realists) hold that perceptions or sense data are caused by mind-independent objects. But
this introduces the possibility of another kind of skepticism: since our understanding of causality is that the same effect can be produced by multiple causes, there is a lack of determinacy about what one is really perceiving. A concrete example of a situation where an individual's sensory input might be caused by something other than what he thinks is causing it is the brain in a vat scenario.
On a more abstract level, model theoretic arguments hold that a given set of symbols in a theory can be mapped onto any number of sets of real-world objects — each set being a "model" of the theory — providing the interrelationships between the objects are the same. (Compare with symbol grounding).
Anti-realism in science.
In philosophy of science, anti-realism applies chiefly to claims about the non-reality of "unobservable" entities such as electrons or genes, which are not detectable with human senses. For a brief discussion comparing such anti-realism to its opposite, realism, see (Okasha 2002, ch. 4). Ian Hacking (1999, p. 84) also uses the same definition. One prominent position in the philosophy of science is instrumentalism, which is a non-realist position. Non-realism takes a purely agnostic view towards the existence of unobservable entities: unobservable entity X serves simply as an instrument to aid in the success of theory Y. We need not determine the existence or non-existence of X. Some scientific anti-realists argue further, however, and deny that unobservables exist even as non-truth conditioned instruments.
Anti-realism in mathematics.
Realism in the philosophy of mathematics is the claim that mathematical entities such as number have a mind-independent existence. The main forms are empiricism, which associates numbers with concrete physical objects; and Platonism, according to which numbers are abstract, non-physical entities. 
The "epistemic argument" against Platonism has been made by Paul Benacerraf and Hartry Field. Platonism posits that mathematical objects are "abstract" entities. By general agreement, abstract entities cannot
interact causally with concrete, physical entities. ("the truth-values of our mathematical assertions depend on facts involving platonic entities that reside in a realm outside of space-time") Whilst our knowledge of concrete, physical objects is based on our ability to perceive them, and therefore to causally interact with them, there is no parallel account of how mathematicians come to have knowledge of abstract objects. ("An account of mathematical truth ..must be consistent with the possibility of mathematical knowledge"). Another way of making the point is that if the Platonic world were to disappear, it would make no difference to the ability of mathematicians to generate proofs, etc., which is already fully accountable in terms of physical processes in their brains.
Field developed his views into fictionalism. Benacerraf also developed the philosophy of mathematical structuralism, according to which there are no mathematical objects. Nonetheless, some versions of structuralism are compatible with some versions of realism.
The argument hinges on the idea that a satisfactory naturalistic account of thought processes in terms of brain processes can be given for mathematical reasoning along with everything else. One line of defense is to maintain that this is false, so that mathematical reasoning uses some special intuition that involves contact with the Platonic realm. A modern form of this argument is given by Sir Roger Penrose.
Another line of defense is to maintain that abstract objects are relevant to mathematical reasoning in a way that is non causal, and not analogous to perception. This argument is developed by Jerrold Katz in his book "Realistic Rationalism".
A more radical defense is to deny the separation of physical world and the platonic world, i.e. the mathematical universe hypothesis. In that case, a mathematician's knowledge of mathematics is one mathematical object making contact with another.

</doc>
<doc id="2174" url="http://en.wikipedia.org/wiki?curid=2174" title="Arsenal F.C.">
Arsenal F.C.

Arsenal Football Club are an English Premier League football club based in Holloway, London. One of the most successful clubs in English football, they have won 13 First Division and Premier League titles and a joint record 11 FA Cups. Arsenal's success has been particularly consistent: the club has accumulated the second most points in English top flight football, holds the ongoing record for the longest uninterrupted period in the top flight, and would be placed first in an aggregated league of the entire 20th century. Arsenal are the second side to complete an English top flight season unbeaten (in the 2003–04 season), doing so under almost twice the matches of the previous team.
Arsenal were founded in 1886 in Woolwich and in 1893 became the first club from the south of England to join the Football League. In 1913, they moved north across the city to Arsenal Stadium in Highbury. In the 1930s, they won five League Championship titles and two FA Cups. After a lean period in the post-war years they won the League and FA Cup Double, in the 1970–71 season, and in the 1990s and first decade of the 21st century, won two more Doubles and reached the 2006 UEFA Champions League Final. Since neighbouring Tottenham Hotspur, the two clubs have had a fierce rivalry, the North London derby.
Arsenal has one of the highest incomes and largest fanbases in the world. Forbes's 2014 estimate put Arsenal as the fifth most valuable association football club in the world, valued at more than $1.3 billion.
History.
Arsenal Football Club were formed as Dial Square in 1886 by workers at the Royal Arsenal in Woolwich, south-east London, and were renamed Royal Arsenal shortly afterwards. The club was renamed again to Woolwich Arsenal after becoming a limited company in 1893. The club became the first southern member of the Football League in 1893, starting out in the Second Division, and won promotion to the First Division in 1904. The club's relative geographic isolation resulted in lower attendances than those of other clubs, which led to the club becoming mired in financial problems and effectively bankrupt by 1910, when they were taken over by businessmen Henry Norris and William Hall. Norris sought to move the club elsewhere, and in 1913, soon after relegation back to the Second Division, Arsenal moved to the new Arsenal Stadium in Highbury, North London; they dropped "Woolwich" from their name the following year. Arsenal only finished in fifth place in the second division during the last pre-war competitive season of 1914–15, but were nevertheless elected to rejoin the First Division when competitive football resumed in 1919–20, at the expense of local rivals Tottenham Hotspur. Some books have reported that this election to division 1 was achieved by dubious means.
Arsenal appointed Herbert Chapman as manager in 1925. Having already won the league twice with Huddersfield Town in 1923–24 and 1924–25 (see Seasons in English football), Chapman brought Arsenal their first period of major success. His revolutionary tactics and training, along with the signings of star players such as Alex James and Cliff Bastin, laid the foundations of the club's domination of English football in the 1930s. Under his guidance Arsenal won their first major trophies – victory in the 1930 FA Cup Final preceded two League Championships, in 1930–31 and 1932–33. In addition, Chapman was behind the 1932 renaming of the local London Underground station from "Gillespie Road" to "Arsenal", making it the only Tube station to be named specifically after a football club.
Chapman died suddenly of pneumonia in early 1934, leaving Joe Shaw and George Allison to carry on his successful work. Under their guidance, Arsenal won three more titles, in 1933–34, 1934–35 and 1937–38, and the 1936 FA Cup while also becoming known as the "Bank of England club." As key players retired, Arsenal had started to fade by the decade's end, and then the intervention of the Second World War meant competitive professional football in England was suspended.
After the war, Arsenal enjoyed a second period of success under Allison's successor Tom Whittaker, winning the league in 1947–48 and 1952–53, and the FA Cup in 1950. Their fortunes waned thereafter; unable to attract players of the same calibre as they had in the 1930s, the club spent most of the 1950s and 1960s in trophyless mediocrity. Even former England captain Billy Wright could not bring the club any success as manager, in a stint between 1962 and 1966.
Arsenal began winning silverware again with the surprise appointment of club physiotherapist Bertie Mee as manager in 1966. After losing two League Cup finals, they won their first European trophy, the 1969–70 Inter-Cities Fairs Cup. This was followed by an even greater triumph: their first League and FA Cup double in 1970–71. This marked a premature high point of the decade; the Double-winning side was soon broken up and the following decade was characterised by a series of near misses, starting with Arsenal finishing as FA Cup runners up in 1972, and First Division runners-up in 1972–73.
Terry Neill was recruited by the Arsenal board to replace Bertie Mee on 9 July 1976 and at the age of 34 he became the youngest Arsenal manager to date. With new signings like Malcolm Macdonald and Pat Jennings, and a crop of talent in the side such as Liam Brady and Frank Stapleton, the club enjoyed their best form since the 1971 double, reaching a trio of FA Cup finals (1978, 1979 and 1980), and losing the 1980 European Cup Winners' Cup Final on penalties. The club's only success during this time was a last-minute 3–2 victory over Manchester United in the 1979 FA Cup Final, widely regarded as a classic.
The return of former player George Graham as manager in 1986 brought a third period of glory. Arsenal won the League Cup in 1987, Graham's first season in charge. This was followed by a League title win in 1988–89, won with a last-minute goal in the final game of the season against fellow title challengers Liverpool. Graham's Arsenal won another title in 1990–91, losing only one match, won the FA Cup and League Cup double in 1993, and a second European trophy, the European Cup Winners' Cup, in 1994. Graham's reputation was tarnished when he was found to have taken kickbacks from agent Rune Hauge for signing certain players, and he was dismissed in 1995. His replacement, Bruce Rioch, lasted for only one season, leaving the club after a dispute with the board of directors.
The club's success in the late 1990s and first decade of the 21st century owed a great deal to the 1996 appointment of Arsène Wenger as manager. Wenger brought new tactics, a new training regime and several foreign players who complemented the existing English talent. Arsenal won a second League and Cup double in 1997–98 and a third in 2001–02. In addition, the club reached the final of the 1999–2000 UEFA Cup (losing on penalties to Galatasaray), were victorious in the 2003 and 2005 FA Cups, and won the Premier League in 2003–04 without losing a single match, an achievement which earned the side the nickname "The Invincibles". The feat came within a run of 49 league matches unbeaten from 7 May 2003 to 24 October 2004, a national record.
Arsenal finished in either first or second place in the league in eight of Wenger's first eleven seasons at the club, although on no occasion were they able to retain the title. As of July 2013, they were one of only five teams, the others being Manchester United, Blackburn Rovers, Chelsea, and Manchester City, to have won the Premier League since its formation in 1992. Arsenal had never progressed beyond the quarter-finals of the Champions League until 2005–06; in that season they became the first club from London in the competition's fifty-year history to reach the final, in which they were beaten 2–1 by Barcelona. In July 2006, they moved into the Emirates Stadium, after 93 years at Highbury.
Arsenal reached the final of the 2007 and 2011 League Cups, losing 2–1 to Chelsea and Birmingham City respectively. The club had not gained a major trophy since the 2005 FA Cup until 17 May 2014, when Arsenal beat Hull City in the 2014 FA Cup Final, coming back from a 2–0 deficit to win the match 3–2.
Crest.
Unveiled in 1888, Royal Arsenal's first crest featured three cannon viewed from above, pointing northwards, similar to the coat of arms of the Metropolitan Borough of Woolwich. These can sometimes be mistaken for chimneys, but the presence of a carved lion's head and a cascabel on each are clear indicators that they are cannon. This was dropped after the move to Highbury in 1913, only to be reinstated in 1922, when the club adopted a crest featuring a single cannon, pointing eastwards, with the club's nickname, "The Gunners", inscribed alongside it; this crest only lasted until 1925, when the cannon was reversed to point westward and its barrel slimmed down.
In 1949, the club unveiled a modernised crest featuring the same style of cannon below the club's name, set in blackletter, and above the coat of arms of the Metropolitan Borough of Islington and a scroll inscribed with the club's newly adopted Latin motto, "Victoria Concordia Crescit" "victory comes from harmony", coined by the club's programme editor Harry Homer. For the first time, the crest was rendered in colour, which varied slightly over the crest's lifespan, finally becoming red, gold and green. Because of the numerous revisions of the crest, Arsenal were unable to copyright it. Although the club had managed to register the crest as a trademark, and had fought (and eventually won) a long legal battle with a local street trader who sold "unofficial" Arsenal merchandise, Arsenal eventually sought a more comprehensive legal protection. Therefore, in 2002 they introduced a new crest featuring more modern curved lines and a simplified style, which was copyrightable. The cannon once again faces east and the club's name is written in a sans-serif typeface above the cannon. Green was replaced by dark blue. The new crest was criticised by some supporters; the Arsenal Independent Supporters' Association claimed that the club had ignored much of Arsenal's history and tradition with such a radical modern design, and that fans had not been properly consulted on the issue.
Until the 1960s, a badge was worn on the playing shirt only for high-profile matches such as FA Cup finals, usually in the form of a monogram of the club's initials in red on a white background.
The monogram theme was developed into an Art Deco-style badge on which the letters A and C framed a football rather than the letter F, the whole set within a hexagonal border. This early example of a corporate logo, introduced as part of Herbert Chapman's rebranding of the club in the 1930s, was used not only on Cup Final shirts but as a design feature throughout Highbury Stadium, including above the main entrance and inlaid in the floors. From 1967, a white cannon was regularly worn on the shirts, until replaced by the club crest, sometimes with the addition of the nickname "The Gunners", in the 1990s.
In the 2011–2012 season, Arsenal celebrated their 125th year anniversary. The celebrations included a modified version of the current crest worn on their jerseys for the season. The crest was all white, surrounded by 15 oak leaves to the right and 15 laurel leaves to the left. The oak leaves represent the 15 founding members of the club who met at the Royal Oak pub. The 15 laurel leaves represent the design detail on the six pence pieces paid by the founding fathers to establish the club. The laurel leaves also represent strength. To complete the crest, 1886 and 2011 are shown on either sides of the motto "Forward" at the bottom of the crest.
Colours.
For much of Arsenal's history, their home colours have been bright red shirts with white sleeves and white shorts, though this has not always been the case. The choice of red is in recognition of a charitable donation from Nottingham Forest, soon after Arsenal's foundation in 1886. Two of Dial Square's founding members, Fred Beardsley and Morris Bates, were former Forest players who had moved to Woolwich for work. As they put together the first team in the area, no kit could be found, so Beardsley and Bates wrote home for help and received a set of kit and a ball. The shirt was redcurrant, a dark shade of red, and was worn with white shorts and socks with blue and white hoops.
In 1933, Herbert Chapman, wanting his players to be more distinctly dressed, updated the kit, adding white sleeves and changing the shade to a brighter pillar box red. Two possibilities have been suggested for the origin of the white sleeves. One story reports that Chapman noticed a supporter in the stands wearing a red sleeveless sweater over a white shirt; another was that he was inspired by a similar outfit worn by the cartoonist Tom Webster, with whom Chapman played golf.
Regardless of which story is true, the red and white shirts have come to define Arsenal and the team have worn the combination ever since, aside from two seasons. The first was 1966–67, when Arsenal wore all-red shirts; this proved unpopular and the white sleeves returned the following season. The second was 2005–06, the last season that Arsenal played at Highbury, when the team wore commemorative redcurrant shirts similar to those worn in 1913, their first season in the stadium; the club reverted to their normal colours at the start of the next season. In the 2008–09 season, Arsenal replaced the traditional all-white sleeves with red sleeves with a broad white stripe.
Arsenal's home colours have been the inspiration for at least three other clubs. In 1909, Sparta Prague adopted a dark red kit like the one Arsenal wore at the time; in 1938, Hibernian adopted the design of the Arsenal shirt sleeves in their own green and white strip. In 1920, Sporting Clube de Braga's manager returned from a game at Highbury and changed his team's green kit to a duplicate of Arsenal's red with white sleeves and shorts, giving rise to the team's nickname of "Os Arsenalistas". These teams still wear these designs to this day.
For many years Arsenal's away colours were white shirts and either black or white shorts. In the 1969–70 season, Arsenal introduced an away kit of yellow shirts with blue shorts. This kit was worn in the 1971 FA Cup Final as Arsenal beat Liverpool to secure the double for the first time in its history. Arsenal reached the FA Cup final again the following year and wearing the red and white home strip and were beaten by Leeds United. Arsenal then competed in three consecutive FA Cup finals between 1978 and 1980 wearing their "lucky" yellow and blue strip, which remained the club's away strip until the release of a green and navy away kit in 1982–83. The following season, Arsenal returned to the yellow and blue scheme, albeit with a darker shade of blue than before.
When Nike took over from Adidas as Arsenal's kit provider in 1994, Arsenal's away colours were again changed to two-tone blue shirts and shorts. Since the advent of the lucrative replica kit market, the away kits have been changed regularly, with Arsenal usually releasing both away and third choice kits. During this period the designs have been either all blue designs, or variations on the traditional yellow and blue, such as the metallic gold and navy strip used in the 2001–02 season, the yellow and dark grey used from 2005 to 2007, and the yellow and maroon of 2010 to 2013.
As of 2009, the away kit is changed every season, and the outgoing away kit becomes the third-choice kit if a new home kit is being introduced in the same year.
Kit manufacturers and shirt sponsors.
Arsenal's shirts have been made by manufacturers including Bukta (from the 1930s until the early 1970s), Umbro (from the 1970s until 1986), Adidas (1986–1994), Nike (1994–2014), and Puma (from 2014). Like those of most other major football clubs, Arsenal's shirts have featured sponsors' logos since the 1980s; sponsors include JVC (1982–1999), Sega (1999–2002), O2 (2002–2006), and Emirates (from 2006).
Stadiums.
For most of their time in south-east London, Arsenal played at the Manor Ground in Plumstead, apart from a three-year period at the nearby Invicta Ground between 1890 and 1893. The Manor Ground was initially just a field, until the club installed stands and terracing for their first Football League match in September 1893. They played their home games there for the next twenty years (with two exceptions in the 1894–95 season), until the move to north London in 1913.
Widely referred to as Highbury, Arsenal Stadium was the club's home from September 1913 until May 2006. The original stadium was designed by the renowned football architect Archibald Leitch, and had a design common to many football grounds in the UK at the time, with a single covered stand and three open-air banks of terracing. The entire stadium was given a massive overhaul in the 1930s: new Art Deco West and East stands were constructed, opening in 1932 and 1936 respectively, and a roof was added to the North Bank terrace, which was bombed during the Second World War and not restored until 1954.
Highbury could hold more than 60,000 spectators at its peak, and had a capacity of 57,000 until the early 1990s. The Taylor Report and Premier League regulations obliged Arsenal to convert Highbury to an all-seater stadium in time for the 1993–94 season, thus reducing the capacity to 38,419 seated spectators. This capacity had to be reduced further during Champions League matches to accommodate additional advertising boards, so much so that for two seasons, from 1998 to 2000, Arsenal played Champions League home matches at Wembley, which could house more than 70,000 spectators.
Expansion of Highbury was restricted because the East Stand had been designated as a Grade II listed building and the other three stands were close to residential properties. These limitations prevented the club from maximising matchday revenue during the 1990s and first decade of the 21st century, putting them in danger of being left behind in the football boom of that time.
After considering various options, in 2000 Arsenal proposed building a new 60,361-capacity stadium at Ashburton Grove, since named the Emirates Stadium, about 500 metres south-west of Highbury.
The project was initially delayed by red tape and rising costs,
and construction was completed in July 2006, in time for the start of the 2006–07 season.
The stadium was named after its sponsors, the airline company Emirates, with whom the club signed the largest sponsorship deal in English football history, worth around £100 million;
some fans referred to the ground as Ashburton Grove, or the Grove, as they did not agree with corporate sponsorship of stadium names.
The stadium will be officially known as Emirates Stadium until at least 2028, and the airline will be the club's shirt sponsor until the end of the 2018–19 season. From the start of the 2010–11 season on, the stands of the stadium have been officially known as North Bank, East Stand, West Stand and Clock end.
Arsenal's players train at the Shenley Training Centre in Hertfordshire, a purpose-built facility which opened in 1999. Before that the club used facilities on a nearby site owned by the University College of London Students' Union. Until 1961 they had trained at Highbury. Arsenal's Academy under-18 teams play their home matches at Shenley, while the reserves play their games at Meadow Park, which is also the home of Boreham Wood F.C..
Supporters.
Arsenal fans often refer to themselves as "Gooners", the name derived from the team's nickname, "The Gunners". The fanbase is large and generally loyal, and virtually all home matches sell out; in 2007–08 Arsenal had the second-highest average League attendance for an English club (60,070, which was 99.5% of available capacity), and as of 2006, the fourth-highest all-time average attendance. Arsenal has the seventh highest average attendance of European football clubs only behind Borussia Dortmund, FC Barcelona, Manchester United, Real Madrid, Bayern Munich, and Schalke. The club's location, adjoining wealthy areas such as Canonbury and Barnsbury, mixed areas such as Islington, Holloway, Highbury, and the adjacent London Borough of Camden, and largely working-class areas such as Finsbury Park and Stoke Newington, has meant that Arsenal's supporters have come from across the usual class divides.
Like all major English football clubs, Arsenal has a number of domestic supporters' clubs, including the Arsenal Football Supporters Club, which works closely with the club, and the Arsenal Independent Supporters' Association, which maintains a more independent line. The Arsenal Supporters' Trust promotes greater participation in ownership of the club by fans. The club's supporters also publish fanzines such as "The Gooner", "Gunflash" and the satirical "Up The Arse!". In addition to the usual English football chants, supporters sing "One-Nil to the Arsenal" (to the tune of "Go West") and "Boring, Boring Arsenal", which used to be a common taunt from opposition fans but is now sung ironically by Arsenal supporters when the team is playing well.
There have always been Arsenal supporters outside London, and since the advent of satellite television, a supporter's attachment to a football club has become less dependent on geography. Consequently, Arsenal have a significant number of fans from beyond London and all over the world; in 2007, 24 UK, 37 Irish and 49 other overseas supporters clubs were affiliated with the club. A 2005 report by Granada Ventures, which at the time owned a 9.9% stake in the club, estimated Arsenal's global fanbase at 27 million.
Arsenal's longest-running and deepest rivalry is with their nearest major neighbours, Tottenham Hotspur; matches between the two are referred to as North London derbies. Other rivalries within London include those with Chelsea, Fulham and West Ham United. In addition, Arsenal and Manchester United developed a strong on-pitch rivalry in the late 1980s, which intensified in recent years when both clubs were competing for the Premier League title – so much so that a 2003 online poll by the Football Fans Census listed Manchester United as Arsenal's biggest rivals, followed by Tottenham and Chelsea. A 2008 poll listed the Tottenham rivalry as more important.
Ownership and finances.
Arsenal's parent company, Arsenal Holdings plc, operates as a non-quoted public limited company, whose ownership is considerably different from that of other football clubs. Only 62,217 shares in Arsenal have been issued, and they are not traded on a public exchange such as the FTSE or AIM; instead, they are traded relatively infrequently on PLUS (AFC), a specialist market. At 31 August 2010, a single share in Arsenal had a mid price of £10,250, which set the club's market capitalisation value at approximately £637.74m. The club made a pre-tax operating profit (excluding player transfers) of £62.7m in the year ending 31 May 2009, from a turnover of £313.3m.
The largest shareholder on the Arsenal board is American sports tycoon Stan Kroenke, who launched a bid for the club in 2007, and in November 2009 increased his holding to 18,594 shares (29.9%).
A rival bid to Kroenke's came from Red & White Securities, which is co-owned by Russian billionaire Alisher Usmanov and London-based financier Farhad Moshiri. Red & White launched its bid in August 2007, buying the stake held by former Arsenal vice-chairman David Dein, and as at February 2009 owned 15,555 shares (25.0%) in the club. This led to press speculation of a bidding war between Kroenke and Usmanov. However, Kroenke agreed not to purchase more than 29.9% of the club until at least September 2009, while the rest of the board have first option on each other's shares until October 2012.
As of October 2011, Kroenke owns 41,574 shares (66.82%) and Red & White Securities own 18,261 shares (29.35%). Under company law Kroenke, as majority shareholder, is obliged to make an offer for the remaining shares in the club.
Ivan Gazidis has been the club's Chief Executive since 2009.
In popular culture.
Arsenal have appeared in a number of media "firsts". On 22 January 1927, their match at Highbury against Sheffield United was the first English League match to be broadcast live on radio. A decade later, on 16 September 1937, an exhibition match between Arsenal's first team and the reserves was the first football match in the world to be televised live. Arsenal also featured in the first edition of the BBC's "Match of the Day", which screened highlights of their match against Liverpool at Anfield on 22 August 1964. BSkyB's coverage of Arsenal's January 2010 match against Manchester United was the first live public broadcast of a sports event on 3D television.
As one of the most successful teams in the country, Arsenal has often featured when football is depicted in the arts in Britain. They formed the backdrop to one of the earliest football-related films, "The Arsenal Stadium Mystery" (1939). The film centres on a friendly match between Arsenal and an amateur side, one of whose players is poisoned while playing. Many Arsenal players appeared as themselves and manager George Allison was given a speaking part. More recently, the book "Fever Pitch" by Nick Hornby was an autobiographical account of Hornby's life and relationship with football and Arsenal in particular. Published in 1992, it formed part of the revival and rehabilitation of football in British society during the 1990s. The book was twice adapted for the cinema – the 1997 British film focuses on Arsenal's 1988–89 title win, and a 2005 American version features a fan of baseball's Boston Red Sox.
Arsenal has often been stereotyped as a defensive and "boring" side, especially during the 1970s and 1980s; many comedians, such as Eric Morecambe, made jokes about this at the team's expense. The theme was repeated in the 1997 film "The Full Monty", in a scene where the lead actors move in a line and raise their hands, deliberately mimicking the Arsenal defence's offside trap, in an attempt to co-ordinate their striptease routine. Another film reference to the club's defence comes in the film "Plunkett & Macleane", in which two characters are named Dixon and Winterburn after Arsenal's long-serving full backs – the right-sided Lee Dixon and the left-sided Nigel Winterburn.
The 1991 television comedy sketch show "Harry Enfield & Chums" featured a sketch from the characters Mr Cholmondly-Warner and Grayson where the Arsenal team of 1933, featuring exaggerated parodies of fictitious amateur players take on the Liverpool team of 1991.
In the community.
In 1985, Arsenal founded a community scheme, "Arsenal in the Community", which offered sporting, social inclusion, educational and charitable projects. The club support a number of charitable causes directly and in 1992 established The Arsenal Charitable Trust, which by 2006 had raised more than £2 million for local causes. An ex-professional and celebrity football team associated with the club also raised money by playing charity matches.
In the 2009–10 season Arsenal announced that there had raised a record breaking £818,897 for the Great Ormond Street Hospital Children's Charity. The original target was £500,000 but thanks to the overwhelming support from fans, players, directors and staff. They were able to smash the target.
Statistics and records.
Arsenal's tally of 13 League Championships is the third highest in English football, after Manchester United (20) and Liverpool (18), while the total of 11 FA Cups is the joint-highest with Manchester United. Arsenal have achieved three League and FA Cup "Doubles" (in 1971, 1998 and 2002), a feat only previously achieved by Manchester United (in 1994, 1996 and 1999), and in 1993 were the first side in English football to complete the FA Cup and League Cup double. Arsenal were also the first London club to reach the final of the UEFA Champions League, in 2006, losing the final 2–1 to Barcelona.
Arsenal have one of the best top-flight records in history, having finished below fourteenth only seven times. Arsenal also have the highest average league finishing position for the 20th century, with an average league placing of 8.5. In addition, they are one of only six clubs to have won the FA Cup twice in succession, in 2002 and 2003. Arsenal also hold the record for the longest unbeaten run in the Premier League at 49 games, and are the only team to have gone an entire Premier League season unbeaten in 2003–04.
David O'Leary holds the record for Arsenal appearances, having played 722 first-team matches between 1975 and 1993. Fellow centre half and former captain Tony Adams comes second, having played 669 times. The record for a goalkeeper is held by David Seaman, with 564 appearances.
Thierry Henry is the club's top goalscorer with 228 goals in all competitions between 1999 and 2012, having surpassed Ian Wright's total of 185 in October 2005. Wright's record had stood since September 1997, when he overtook the longstanding total of 178 goals set by winger Cliff Bastin in 1939. Henry also holds the club record for goals scored in the League, with 175, a record that had been held by Bastin until February 2006.
Arsenal's record home attendance is 73,707, for a UEFA Champions League match against RC Lens on 25 November 1998 at Wembley Stadium, where the club formerly played home European matches because of the limits on Highbury's capacity. The record attendance for an Arsenal match at Highbury is 73,295, for a 0–0 draw against Sunderland on 9 March 1935, while that at Emirates Stadium is 60,161, for a 2–2 draw with Manchester United on 3 November 2007.
Arsenal have also set records in English football, including the most consecutive seasons spent in the top flight (87 as of 2013–14) and the longest run of unbeaten League matches (49 between May 2003 and October 2004). This included all 38 matches of their title-winning 2003–04 season, when Arsenal became only the second club to finish a top-flight campaign unbeaten, after Preston North End (who played only 22 matches) in 1888–89.
Arsenal also set a Champions League record during the 2005–06 season by going ten matches without conceding a goal, beating the previous best of seven set by A.C. Milan. They went a record total stretch of 995 minutes without letting an opponent score; the streak ended in the final, when Samuel Eto'o scored a 76th-minute equaliser for Barcelona.
Managers.
There have been eighteen permanent and five caretaker managers of Arsenal since the appointment of the club's first professional manager, Thomas Mitchell in 1897. The club's longest-serving manager, in terms of both length of tenure and number of games overseen, is Arsène Wenger, who was appointed in 1996. Wenger is also Arsenal's only manager from outside the United Kingdom. Two Arsenal managers have died in the job – Herbert Chapman and Tom Whittaker.
Arsenal Ladies.
Arsenal Ladies are the women's football club affiliated to Arsenal. Founded in 1987, they turned semi-professional in 2002 and are managed by Laura Harvey. Arsenal Ladies are the most successful team in English women's football. In the 2008–09 season, they won all three major English trophies – the FA Women's Premier League, FA Women's Cup and FA Women's Premier League Cup, and, as of 2009, were the only English side to have won the UEFA Women's Cup, having done so in the 2006–07 season as part of a unique quadruple. The men's and women's clubs are formally separate entities but have quite close ties; Arsenal Ladies are entitled to play once a season at the Emirates Stadium, though they usually play their home matches at Boreham Wood.
The ladies team won the 2013 FA Women's Cup 3–0 against Bristol Academy W.F.C..

</doc>
<doc id="2175" url="http://en.wikipedia.org/wiki?curid=2175" title="Cuisine of the United States">
Cuisine of the United States

The cuisine of the United States refers to food preparation originating from the United States of America. European colonization of the Americas yielded the introduction of a number of ingredients and cooking styles to the latter. The various styles continued expanding well into the 19th and 20th centuries, proportional to the influx of immigrants from many foreign nations; such influx developed a rich diversity in food preparation throughout the country.
History.
Pre-Colonial cuisine.
Seafood.
Seafood in the United States originated with the Native Americans, who often ate cod, lemon sole, flounder, herring, halibut, sturgeon, smelt, drum on the East Coast, and olachen and salmon on the West Coast. Whale was hunted by Native Americans off the Northwest coast, especially by the Makah, and used for their meat and oil. Seal and walrus were also eaten, in addition to eel from New York's Finger Lakes region. Catfish was also popular amongst native peoples, including the Modocs. Crustacean included shrimp, lobster, crayfish, and dungeness crabs in the Northwest and blue crabs in the East. Other shellfish include abalone and geoduck on the West Coast, while on the East Coast the surf clam, quahog, and the soft-shell clam. Oysters were eaten on both shores, as were mussels and periwinkles.
Cooking methods.
Early Native Americans utilized a number of cooking methods in early American Cuisine that have been blended with early European cooking methods to form the basis of American Cuisine. Grilling meats was common. Spit roasting over a pit fire was common as well. Vegetables, especially root vegetables were often cooked directly in the ashes of the fire. As early Native Americans lacked pottery that could be used directly over a fire, they developed a technique which has caused many anthropologists to call them "Stone Boilers". They would heat rocks directly in a fire and then add the bricks to a pot filled with water until it came to a boil so that it would cook the meat or vegetables in the boiling water. In what is now the Southwestern United States, they also created adobe ovens called hornos to bake items such as cornmeal breads, and in other parts of America, made ovens of dug pits. These pits were also used to steam foods by adding heated rocks or embers and then seaweed or corn husks placed on top to steam fish and shellfish as well as vegetables; potatoes would be added while still in-skin and corn while in-husk, this would later be referred to as a clambake by the colonists.
Colonial period.
When the colonists came to Virginia, Massachusetts, or any of the other English colonies on the eastern seaboard of North America, their initial attempts at survival included planting crops familiar to them from back home in England. In the same way, they farmed animals for clothing and meat in a similar fashion. Through hardships and eventual establishment of trade with Britain, the West Indies and other regions, the colonists were able to establish themselves in the American colonies with a cuisine similar to their previous British cuisine. There were some exceptions to the diet, such as local vegetation and animals, but the colonists attempted to use these items in the same fashion as they had their equivalents or ignore them entirely if they could. The manner of cooking for the American colonists followed along the line of British cookery up until the Revolution. The British sentiment followed in the cookbooks brought to the New World as well.
There was a general disdain for French cookery, even with the French Huguenots in South Carolina and French-Canadians. One of the cookbooks that proliferated in the colonies was The Art of Cookery Made Plain and Easy written by Hannah Glasse, wrote of disdain for the French style of cookery, stating “the blind folly of this age that would rather be imposed on by a French booby, than give encouragement to a good English cook!” Of the French recipes, she does add to the text she speaks out flagrantly against the dishes as she “… think it an odd jumble of trash.” Reinforcing the anti-French sentiment was the French and Indian War from 1754–1764. This created a large anxiety against the French, which influenced the English to either deport many of the French, or as in the case of many Acadians from Nova Scotia, they forcibly relocated to Louisiana. The Acadian French did create a large French influence in the diet of those settled in Louisiana, but had little or no influence outside of Louisiana - except among the Acadian Francophones who settled eastern Maine at the same time they colonised New Brunswick.
Common ingredients.
The American colonial diet varied depending on the settled region in which someone lived. Local cuisine patterns had established by the mid-18th century. The New England colonies were extremely similar in their dietary habits to those that many of them had brought from England. A striking difference for the colonists in New England compared to other regions was seasonality. While in the southern colonies, they could farm almost year round, in the northern colonies, the growing seasons were very restricted. In addition, colonists’ close proximity to the ocean gave them a bounty of fresh fish to add to their diet, especially in the northern colonies. Wheat, however, the grain used to bake bread back in England was almost impossible to grow, and imports of wheat were far from cost productive. Substitutes in cases such as this included cornmeal. The Johnnycake was a poor substitute to some for wheaten bread, but acceptance by both the northern and southern colonies seems evident.
As many of the New Englanders were originally from England game hunting was often a pastime from back home that paid off when they immigrated to the New World. Much of the northern colonists depended upon the ability either of themselves to hunt, or for others from which they could purchase game. This was the preferred method for protein consumption over animal husbandry, as it required much more work to defend the kept animals against Native Americans or the French.
Livestock and game.
Commonly hunted game included deer, bear, buffalo and wild turkey. The larger muscles of the animals were roasted and served with currant sauce, while the other smaller portions went into soups, stews, sausages, pies, and pasties. In addition to game, colonists' protein intake was supplemented by mutton. The Spanish in Florida originally introduced sheep to the New World, but this development never quite reached the North, and there they were introduced by the Dutch and English. The keeping of sheep was a result of the English non-practice of animal husbandry. The animals provided wool when young and mutton upon maturity after wool production was no longer desirable. The forage-based diet for sheep that prevailed in the Colonies produced a characteristically strong, gamy flavor and a tougher consistency, which required aging and slow cooking to tenderize.
Fats and oils.
A number of fats and oils made from animals served to cook much of the colonial foods. Many homes had a sack made of deerskin filled with bear oil for cooking, while solidified bear fat resembled shortening. Rendered pork fat made the most popular cooking medium, especially from the cooking of bacon. Pork fat was used more often in the southern colonies than the northern colonies as the Spanish introduced pigs earlier to the South. The colonists enjoyed butter in cooking as well, but it was rare prior to the American Revolution, as cattle were not yet plentiful.
Alcoholic drinks.
Prior to the Revolution, New Englanders consumed large quantities of rum and beer, as maritime trade provided them relatively easy access to the goods needed to produce these items: Rum was the distilled spirit of choice, as the main ingredient, molasses, was readily available from trade with the West Indies. Further into the interior, however, one would often find colonists consuming whiskey, as they did not have similar access to sugar cane. They did have ready access to corn and rye, which they used to produce their whiskey. However, until the Revolution, many considered whiskey to be a coarse alcohol unfit for human consumption, as many believed that it caused the poor to become raucous and unkempt drunkards. In addition to these alcohol-based products produced in America, imports were seen on merchant shelves, including wine and brandy.
Southern variations.
In comparison to the northern colonies, the southern colonies were quite diverse in their agricultural diet and did not have a central region of culture. The uplands and the lowlands made up the two main parts of the southern colonies. The slaves and poor of the south often ate a similar diet, which consisted of many of the indigenous New World crops. Salted or smoked pork often supplement the vegetable diet. Rural poor often ate squirrel, possum, rabbit and other woodland animals. Those on the “rice coast” often ate ample amounts of rice, while the grain for the rest of the southern poor and slaves was cornmeal used in breads and porridges. Wheat was not an option for most of those that lived in the southern colonies.
The diet of the uplands often included cabbage, string beans, white potatoes, while most avoided sweet potatoes and peanuts. Well-off whites in the uplands avoided crops imported from Africa because of the perceived inferiority of crops of the African slaves. Those who could grow or afford wheat often had biscuits as part of their breakfast, along with healthy portions of pork. Salted pork was a staple of any meal, as it was used in the preparations of vegetables for flavor, in addition to being eaten directly as a protein.
The lowlands, which included much of the Acadian French regions of Louisiana and the surrounding area, included a varied diet heavily influenced by Africans and Caribbeans, rather than just the French. As such, rice played a large part of the diet as it played a large part of the diets of the Africans and Caribbean. In addition, unlike the uplands, the lowlands subsistence of protein came mostly from coastal seafood and game meats. Much of the diet involved the use of peppers, as it still does today. Interestingly, although the English had an inherent disdain for French foodways, as well as many of the native foodstuff of the colonies, the French had no such disdain for the indigenous foodstuffs. In fact, they had a vast appreciation for the native ingredients and dishes.
Post-colonial cuisine.
During the 18th and 19th centuries, Americans developed many new foods. Some, such as Rocky Mountain oysters, stayed regional; some spread throughout the nation but with little international appeal, such as peanut butter (a core ingredient of the famous peanut butter and jelly sandwich); and some spread throughout the world, such as popcorn, Coca-Cola and its competitors, fried chicken, cornbread, unleavened muffins such as the poppyseed muffin, and brownies.
Modern cuisine.
During the Progressive Era (1890s–1920s) food production and presentation became more industrialized. Major railroads featured upscale cuisine in their dining cars. Restaurant chains emerged with standardized decor and menus, most famously the Fred Harvey restaurants along the route of the Sante Fe Railroad in the Southwest.
At the universities, nutritionists and home economists taught a new scientific approach to food. During World War I the Progressives' moral advice about food conservation was emphasized in large-scale state and federal programs designed to educate housewives. Large-scale foreign aid during and after the war brought American standards to Europe.
Newspapers and magazines ran recipe columns, aided by research by corporate kitchens (for example, General Mills, Campbell's, Kraft Foods). One characteristic of American cooking is the fusion of multiple ethnic or regional approaches into completely new cooking styles. Hamburgers and hot dogs from German cuisine, spaghetti and pizza from Italian cuisine became popular. Since the 1960s Asian cooking has played a particularly large role in American fusion cuisine.
Similarly, some dishes that are typically considered American have their origins in other countries. American cooks and chefs have substantially altered these dishes over the years, to the degree that the dishes now enjoyed around the world are considered to be American. Hot dogs and hamburgers are both based on traditional German dishes, but in their modern popular form they can be reasonably considered American dishes.
Pizza is based on the traditional Italian dish, brought by Italian immigrants to the United States, but varies highly in style based on the region of development since its arrival (a "Chicago" style has focus on a thicker, more bread-like crust, whereas a "New York Slice" is known to have a much thinner crust, for example) and these types can be advertised throughout the country and are generally recognizable/well-known (with some restaurants going so far as to import New York City tap water from a thousand or more miles away to recreate the signature style in other regions).
Many companies in the American food industry develop new products requiring minimal preparation, such as frozen entrees. Many of these recipes have become very popular. For example, the General Mills "Betty Crocker's Cookbook", first published in 1950 and currently in its 10th edition, is commonly found in American homes.
A wave of celebrity chefs began with Julia Child and Graham Kerr in the 1970s, with many more following after the rise of cable channels like Food Network. Trendy food items in the 2000s and 2010s (albeit with long traditions) include doughnuts, cupcakes, macaroons, and meatballs.
New American.
During the 1980s, upscale restaurants introduced a mixing of cuisines that contain Americanized styles of cooking with foreign elements commonly referred as New American cuisine.
Regional cuisines.
Given the United States's large size, numerous regions each have their own distinctive cuisines, all quite diverse.
New England.
New England is a Northeastern region of the United States, including the six states of Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont. The Native American cuisine became part of the cookery style that the early colonists brought with them. The style of New England cookery originated from its colonial roots, that is to say practical, frugal and willing to eat anything other than what they were used to from their British roots. Much of the cuisine started with one-pot cookery, which resulted in such dishes as succotash, chowder, baked beans, and others.
Lobster is an integral ingredient to the cuisine, indigenous to the coastal waters of the region. Other shellfish of the coastal regions include little neck clams, sea scallops, blue mussels, oysters, soft shell clams and razor shell clams. Much of this shellfish contributes to New England tradition, the clambake. The clambake as known today is a colonial interpretation of an American Indian tradition.
The fruits of the region include the "Vitis labrusca" grapes used in grape juice made by companies such as Welch's, along with jelly, Kosher wine by companies like Mogen David and Manischewitz along with other wineries that make higher quality wines. Apples from New England include the original varieties Baldwin, Lady, Mother, Pomme Grise, Porter, Roxbury Russet, Wright, Sops of Wine, Peck's Pleasant, Titus Pippin, Westfield-Seek-No-Further, and Duchess of Oldenburg. Cranberries are another fruit indigenous to the region.
Pacific and Hawaiian cuisine.
Hawaii is often considered to be one of the most culturally diverse U.S. states, as well as being the only state with an Asian majority population. As a result, Hawaiian cuisine borrows elements of a variety of cuisines, particularly those of Asian and Pacific-rim cultures, as well as traditional native Hawaiian. Some notable Hawaiian fare includes seared ahi tuna, opakapaka (snapper) with passionfruit, Hawaiian island-raised lamb, beef and meat products, Hawaiian plate lunch, and Molokai shrimp and seafood caught fresh in Hawaiian waters. Some cuisine also incorporates a broad variety of produce and locally grown agricultural products, including tomatoes, strawberries, mushrooms, sweet maui onions, and tropical fruits including papayas, mangoes, lilikoi (passionfruit) and lychee.
Midwest.
Midwestern cuisine covers everything from barbecue to the Chicago-style hot dog.
The American South.
The cuisine of the American South has been influenced by the many diverse inhabitants of the region, including Americans of European descent, Native Americans and African Americans. The cuisine of the American South, along with the rest of its culture, is one of the most distinct in all of the country.
Cuisine in the West.
Cooking in the American West gets its influence from Native American and Mexican cultures, and other European settlers into the part of the country. Common dishes vary depending on the area. For instance, the Northwest relies on local seafood, while in the Southwest, Mexican flavors are extremely common.
Ethnic and immigrant influence.
The demand for ethnic foods in the United States reflects the nation's changing diversity as well as its development over time. According to the National Restaurant Association, 
Restaurant industry sales are expected to reach a record high of $476 billion in 2005, an increase of 4.9 percent over 2004... Driven by consumer demand, the ethnic food market reached record sales in 2002, and has emerged as the fastest growing category in the food and beverage product sector, according to USBX Advisory Services. Minorities in the U.S. spend a combined $142 billion on food and by 2010, America's ethnic population is expected to grow by 40 percent.
A movement began during the 1980s among popular leading chefs to reclaim America's ethnic foods within its regional traditions, where these trends originated. One of the earliest was Paul Prudhomme, who in 1984 began the introduction of his influential cookbook, "Paul Prodhomme's Louisiana Kitchen", by describing the over 200 year history of Creole and Cajun cooking; he aims to "preserve and expand the Louisiana tradition." Prodhomme's success quickly inspired other chefs. Norman Van Aken embraced a Floridian type cuisine fused with many ethnic and globalized elements in his "Feast of Sunlight" cookbook in 1988. The movement finally gained fame around the world when California became swept up in the movement, then seemingly started to lead the trend itself, in, for example, the popular restaurant Chez Panisse in Berkeley. Examples of the Chez Panisse phenomenon, chefs who embraced a new globalized cuisine, were celebrity chefs like Jeremiah Tower and Wolfgang Puck, both former colleagues at the restaurant. Puck went on to describe his belief in contemporary, new style American cuisine in the introduction to "The Wolfgang Puck Cookbook":
Another major breakthrough, whose originators were once thought to be crazy, is the mixing of ethnic cuisines. It is not at all uncommon to find raw fish listed next to tortillas on the same menu. Ethnic crossovers also occur when distinct elements meet in a single recipe. This country is, after all, a huge melting pot. Why should its cooking not illustrate the American transformation of diversity into unity?
Puck's former colleague, Jeremiah Tower became synonymous with California Cuisine and the overall American culinary revolution. Meanwhile, the restaurant that inspired both Puck and Tower became a distinguished establishment, popularizing its so called "mantra" in its book by Paul Bertolli and owner Alice Waters, "Chez Panisse Cooking", in 1988. Published well after the restaurants' founding in 1971, this new cookbook from the restaurant seemed to perfect the idea and philosophy that had developed over the years. The book embraced America's natural bounty, specifically that of California, while containing recipes that reflected Bertoli and Waters' appreciation of both northern Italian and French style foods.
Early ethnic influences.
While the earliest cuisine of the United States was influenced by indigenous Native Americans, the cuisine of the thirteen colonies or the culture of the antebellum American South; the overall culture of the nation, its gastronomy and the growing culinary arts became ever more influenced by its changing ethnic mix and immigrant patterns from the 18th and 19th centuries unto the present. Some of the ethnic groups that continued to influence the cuisine were here in prior years; while others arrived more numerously during “The Great Transatlantic Migration (of 1870—1914) or other mass migrations.
Some of the ethnic influences could be found in the nation from after the American Civil War and into the History of United States continental expansion during most of the 19th century. Ethnic influences already in the nation at that time would include the following groups and their respective cuisines:
Later ethnic and immigrant influence.
Mass migrations of immigrants to the United States came in several waves. Historians identify several waves of migration to the United States: one from 1815–1860, in which some five million English, Irish, Germanic, Scandinavian, and others from northwestern Europe came to the United States; one from 1865–1890, in which some 10 million immigrants, also mainly from northwestern Europe, settled, and a third from 1890–1914, in which 15 million immigrants, mainly from central, eastern, and southern Europe (many Austrian, Hungarian, Turkish, Lithuanian, Russian, Jewish, Greek, Italian, and Romanian) settled in the United States.
Together with earlier arrivals to the United States (including the indigenous Native Americans, Hispanic and Latino Americans, particularly in the West, Southwest, and Texas; African Americans who came to the United States in the Atlantic slave trade; and early colonial migrants from Britain, France, Germany, Spain, and elsewhere), these new waves of immigrants had a profound impact on national or regional cuisine. Some of these more prominent groups include the following:
"Italian, Mexican and Chinese (Cantonese) cuisines have indeed joined the mainstream. These three cuisines have become so ingrained in the American culture that they are no longer foreign to the American palate. According to the study, more than nine out of 10 consumers are familiar with and have tried these foods, and about half report eating them frequently. The research also indicates that Italian, Mexican and Chinese (Cantonese) have become so adapted to such an extent that "authenticity" is no longer a concern to customers."
Contributions from these ethnic foods have become as common as traditional "American" fares such as hot dogs, hamburgers, beef steak, which are derived from German cuisine, (chicken-fried steak, for example, is a variation on German schnitzel), cherry pie, Coca-Cola, milkshakes, fried chicken (Fried chicken is of Scottish and African influence) and so on. Nowadays, Americans also have a ubiquitous consumption of foods like pizza and pasta, tacos and burritos to "General Tso's chicken" and fortune cookies. Fascination with these and other ethnic foods may also vary with region.
Notable American chefs.
American chefs have been influential both in the food industry and in popular culture. An important 19th Century American chef was Charles Ranhofer of Delmonico's Restaurant in New York City. American cooking has been exported around the world, both through the global expansion of restaurant chains such as T.G.I. Friday's and McDonald's and the efforts of individual restaurateurs such as Bob Payton, credited with bringing American-style pizza to the UK.
The first generation of television chefs such as Robert Carrier and Julia Child tended to concentrate on cooking based primarily on European, especially French and Italian, cuisines. Only during the 1970s and 1980s did television chefs such as James Beard and Jeff Smith shift the focus towards home-grown cooking styles, particularly those of the different ethnic groups within the nation. Notable American restaurant chefs include Thomas Keller, Charlie Trotter, Grant Achatz, Alfred Portale, Paul Prudhomme, Paul Bertolli, Frank Stitt, Alice Waters, Patrick O’Connell and celebrity chefs like Mario Batali, David Chang, Alton Brown, Emeril Lagasse, Cat Cora, Michael Symon, Bobby Flay, Ina Garten, Todd English, Sandra Lee, Anthony Bourdain, and Paula Deen.
Regional chefs are emerging as localized celebrity chefs with growing broader appeal, such as Peter Merriman (Hawaii Regional Cuisine), Jerry Traunfeld, Alan Wong (Pacific Rim cuisine), Norman Van Aken (New World Cuisine – fusion Latin, Caribbean, Asian, African and American), and Mark Miller (American Southwest cuisine).

</doc>
<doc id="2176" url="http://en.wikipedia.org/wiki?curid=2176" title="Ahmad Shah Massoud">
Ahmad Shah Massoud

Ahmad Shah Massoud (Dari: احمد شاه مسعود; September 2, 1953September 9, 2001) was an Afghan political and military leader, who was a central figure in the resistance against the Soviet occupation between 1979 and 1989 and in the following years of civil war. He was assassinated on September 9, 2001.
Massoud came from an ethnic Tajik, Sunni Muslim background from the Panjshir valley in northern Afghanistan. He studied engineering at Kabul University in the 1970s, where he became involved with Muslim anti-communist movements around Burhanuddin Rabbani. After the Soviet occupation of 1979, his role as an insurgence leader earned him the nickname of "Lion of Panjshir" (). In 1992, he was appointed as the minister of defense through the Peshawar Accord, a peace and power-sharing agreement, in the post-communist Islamic State of Afghanistan—a position he held until 2001. He fought against an alliance of militias led by Gulbuddin Hekmatyar and eventually the Taliban, who started to lay siege to the capital in January 1995.
Following the rise of the Taliban in 1996, Massoud, who rejected the Taliban's fundamentalist interpretation of Islam, returned to the armed opposition. He served as the military and political leader of the United Islamic Front (also known in the West as "Northern Alliance"). He was assassinated, probably at the instigation of al-Qaeda, in a suicide bombing on September 9, 2001, just two days before the September 11 attacks in the
United States, which led to the U.S. and NATO to intervene in Afghanistan, allying with Massoud's forces.
Massoud was posthumously named "National Hero" by the order of Afghan President Hamid Karzai. The date of his death, September 9, is observed as a national holiday known as "Massoud Day" in Afghanistan. His followers call him "Āmir Sāhib-e Shahīd" (, "Our Beloved Martyred Commander").
Early life.
Ahmad Shah Massoud was born in the year 1953 in Bazarak, Panjshir, to a well-to-do family native to the Panjshir valley. His name at birth was "Ahmed Shah"; he took the name "Massoud" as a "nom de guerre" when he went into the resistance movement in 1974. His father, Dost Mohammad Khan, was a colonel in the Royal Afghan army. From his native Panjshir, his family moved briefly to Herat and then to Kabul, where Massoud spent most of his childhood.
Massoud attended the renowned Franco-Afghan Lycée Esteqlal. Regarded as a gifted student, he studied engineering at Kabul University after his graduation from the Lycée. Massoud spoke Dari, Pashto, Urdu and French and had good English reading skills.
In 1973, Mohammed Daoud Khan was brought to power in a coup d'état backed by the Afghan communist party, and the Republic of Afghanistan was established. These developments gave rise to the Islamist and Islamic movement opposed to the increasing communist and Soviet influence over Afghanistan. During that time, while studying at Kabul University, Massoud became involved with the Sazman-i Jawanan-i Musulman ("Organization of Muslim Youth"), the student branch of the Jamiat-e Islami ("Islamic Society"), whose chairman then was the professor Burhanuddin Rabbani. Kabul University was a centre for political debate and activism during that time.
By 1975, after a failed uprising by the Muslim Youth, a "profound and long-lasting schism" within the Islamist and Islamic movement began to emerge. The "Islamic Society" split between supporters of the more moderate forces around Massoud and Rabbani, who led the Jamiat-i Islami, and more radical Islamist elements surrounding Gulbuddin Hekmatyar, who founded the Hezb-i Islami. The conflict reached such a point that Hekmatyar reportedly tried to kill Massoud, then 22 years old.
The Soviet invasion and PDPA communism.
Communist revolution in Afghanistan (1978).
The government of Mohammed Daoud Khan tried to scale back the communist People's Democratic Party of Afghanistan's influence, dismissing PDPA members from their government posts, appointing conservatives to replace them, and finally announcing the dissolution of the PDPA, with the arrests of senior party members.
On April 27, 1978, the PDPA and military units loyal to it killed Daoud Khan, his immediate family, and bodyguards in a violent coup, and seized control of the capital Kabul. The new PDPA government, led by a revolutionary council, did not enjoy the support of the masses. It announced and implemented a doctrine hostile to political dissent, whether inside or outside the party.
The PDPA started reforms along Marxist–Leninist and Soviet lines. The reforms and the PDPA's affinity to the Soviet Union were met with strong resistance by the population, especially as the government attempted to enforce its Marxist policies by arresting or executing those who resisted. Between 50,000 and 100,000 people were estimated to have been arrested and killed by communist troops in the countryside alone. Due to the repression, large parts of the country, especially the rural areas, organized into open revolt against the PDPA government. By spring 1979 unrest had reached 24 out of 28 Afghan provinces, including major urban areas. Over half of the Afghan army either deserted or joined the insurrection.
Believing that an uprising against the Soviet-backed communists would be supported by the people, Massoud, on July 6, 1979, started an insurrection in the Panjshir, which initially failed. Massoud decided to avoid conventional confrontation with the larger government forces and to wage a guerrilla war. He subsequently took full control of Panjshir, pushing out Afghan communist troops. Oliver Roy writes that in the following period, Massoud's "personal prestige and the efficiency of his military organisation persuaded many local commanders to come and learn from him."
Resistance against the Soviet Union (1979–1989).
Following the 1979 Soviet invasion and occupation of Afghanistan, Massoud devised a strategic plan for expelling the invaders and overthrowing the communist regime. The first task was to establish a popularly based resistance force that had the loyalty of the people. The second phase was "active defense" of the Panjshir stronghold, while carrying out asymmetric warfare. In the third phase, the "strategic offensive", Massoud's forces would gain control of large parts of Northern Afghanistan. The fourth phase was the "general application" of Massoud's principles to the whole country, and the defeat of the Afghan communist government.
From the start of the war, Massoud's mujahideen attacked the occupying Soviet forces, ambushing Soviet and Afghan communist convoys travelling through the Salang Pass, and causing fuel shortages in Kabul.
The Soviets mounted a series of offensives against the Panjshir. Between 1980 and 1985, these offensives were conducted twice a year. Despite engaging more men and hardware on each occasion, the Soviets were unable to defeat Massoud's forces. In 1982, the Soviets began deploying major combat units in the Panjshir, numbering up to 30,000 men. Massoud pulled his troops back into subsidiary valleys, where they occupied fortified positions. When the Soviet columns advanced onto these positions, they fell into ambushes. When the Soviets withdrew, Afghan army garrisons took over their positions. Massoud and his mujahideen forces attacked and recaptured them one by one.
In 1983, the Soviets offered Massoud a temporary truce, which he accepted in order to rebuild his own forces and give the civilian population a break from Soviet attacks. He put the respite to good use. In this time he created the Shura-e Nazar (Supervisory Council), which subsequently united 130 commanders from 12 Afghan provinces in their fight against the Soviet army. This council existed outside the Peshawar parties, which were prone to internecine rivalry and bickering, and served to smooth out differences between resistance groups, due to political and ethnic divisions. It was the predecessor of what could have become a unified Islamic Afghan army.
Relations with the party headquarters in Peshawar were often strained, as Rabbani insisted on giving Massoud no more weapons and supplies than to other Jamiat commanders, even those who did little fighting. To compensate for this deficiency, Massoud relied on revenues drawn from exports of emeralds and lapis lazuli, that are traditionally exploited in Northern Afghanistan.
To organize support for the mujahideen, Massoud established an administrative system that enforced law and order ("nazm") in areas under his control. The Panjshir was divided into 22 bases ("qarargah") governed by a military commander and a civilian administrator, and each had a judge, a prosecutor and a public defender. Massoud's policies were implemented by different committees: an economic committee was charged with funding the war effort. The health committee provided health services, assisted by volunteers from foreign humanitarian non-governmental organizations, such as Aide médicale internationale. An education committee was charged with the training of the military and administrative cadre. A culture committee and a judiciary committee were also created.
This expansion prompted Babrak Karmal to demand that the Red Army resume their offensives, in order to crush the Panjshir groups. However, Massoud had received warning of the attack through his intelligence agents in the government and he evacuated all 130,000 inhabitants from the valley into the Hindukush mountains, leaving the Soviet bombings to fall on empty ground and the Soviet battalions to face the mountains.
With the defeat of the Soviet-Afghan attacks, Massoud carried out the next phase of his strategic plan, expanding the resistance movement and liberating the northern provinces of Afghanistan. In August 1986, he captured Farkhar in Takhar Province. In November 1986, his forces overran the headquarters of the government's 20th division at Nahrin in Baghlan Province, scoring an important victory for the resistance. This expansion was also carried out through diplomatic means, as more mujahideen commanders were persuaded to adopt the Panjshir military system.
Despite almost constant attacks by the Red Army and the Afghan army, Massoud increased his military strength. Starting in 1980 with a force of less than 1,000 ill-equipped guerrillas, the Panjshir valley mujahideen grew to a 5,000-strong force by 1984. After expanding his influence outside the valley, Massoud increased his resistance forces to 13,000 fighters by 1989. These forces were divided into different types of units: the locals (mahalli) were tasked with static defense of villages and fortified positions. The best of the mahalli were formed into units called grup-i zarbati (shock troops), semi-mobile groups that acted as reserve forces for the defense of several strongholds. A different type of unit was the mobile group (grup-i-mutaharek), a lightly equipped commando-like formation numbering 33 men, whose mission was to carry out hit-and-run attacks outside the Panjshir, sometimes as far as 100 km from their base. These men were professional soldiers, well-paid and trained, and, from 1983 on, they provided an effective strike force against government outposts. Uniquely among the mujahideen, these groups wore uniforms, and their use of the "pakul" made this headwear emblematic of the Afghan resistance.
Massoud's military organization was an effective compromise between the traditional Afghan method of warfare and the modern principles of guerrilla warfare which he had learned from the works of Mao Zedong and Che Guevara. His forces were considered the most effective of all the various Afghan resistance movements.
The United States provided Massoud with close to no support. Part of the reason was that it permitted its funding and arms distribution to be administered by Pakistan, which favored the rival mujahideen leader Gulbuddin Hekmatyar. In an interview, Massoud said, "We thought the CIA knew everything. But they didn't. They supported some bad people Hekmatyar." Primary advocates for supporting Massoud were the US State Department's Edmund McWilliams and Peter Tomsen, who were on the ground in Afghanistan and Pakistan. Others included two Heritage Foundation foreign policy analysts, Michael Johns and James A. Phillips, both of whom championed Massoud as the Afghan resistance leader most worthy of U.S. support under the Reagan Doctrine. Thousands of foreign Islamic volunteers entered Afghanistan to fight with the mujahideen against the Soviet troops.
The Soviet army and the Afghan communist army were mainly defeated by Massoud and his mujahideen in numerous small engagements between 1984 and 1988. In 1989, after describing the Soviet Union's military engagement in Afghanistan "a bleeding wound", Soviet General Secretary Mikhail Gorbachev began a withdrawal of Soviet troops from the nation. On February 15, 1989, in what was depicted as an improbable victory for the mujahideen, the last Soviet soldier left the nation.
Fall of the Afghan communist regime (1992).
After the departure of Soviet troops in 1989, the People's Democratic Party of Afghanistan regime, then headed by Mohammad Najibullah, held its own against the mujahideen. Backed by a massive influx of weapons from the Soviet Union, the Afghan armed forces reached a level of performance they had never reached under direct Soviet tutelage. They maintained control over all of Afghanistan's major cities. By 1992, however, after the collapse of the Soviet Union, the regime began to crumble. Food and fuel shortages undermined the capacities of the government's army, and a resurgence of factionalism split the regime between Khalq and Parcham supporters.
A few days after Najibullah had lost control of the nation, his army commanders and governors arranged to turn over authority to resistance commanders and local warlords throughout the country. Joint councils ("shuras") were immediately established for local government, in which civil and military officials of the former government were usually included. In many cases, prior arrangements for transferring regional and local authority had been made between foes.
Collusions between military leaders quickly brought down the Kabul government. In mid-January 1992, within three weeks of the demise of the Soviet Union, Massoud was aware of conflict within the government's northern command. General Abdul Momim, in charge of the Hairatan border crossing at the northern end of Kabul's supply highway, and other non-Pashtun generals based in Mazari Sharif, feared removal by Najibullah and replacement by Pashtun officers. When the generals rebelled, Abdul Rashid Dostum, who held general rank as head of the Jowzjani militia, also based in Mazari Sharif, took over.
He and Massoud reached a political agreement, together with another major militia leader, Sayyed Mansour, of the Ismaili community based in Baghlan Province. These northern allies consolidated their position in Mazar-i-Sharif on March 21. Their coalition covered nine provinces in the north and northeast. As turmoil developed within the government in Kabul, no government force stood between the northern allies and the major air force base at Bagram, some seventy kilometers north of Kabul. By mid-April 1992, the Afghan air force command at Bagram had capitulated to Massoud. On March 18, 1992, Najibullah announced he would resign. On April 17, as his government fell, he tried to escape but was stopped at Kabul Airport by Dostum's forces. He took refuge at the United Nations mission, where he remained unharmed until 1996, while Massoud controlled the area surrounding the mission.
Senior communist generals and officials of the Najibullah administration acted as a transitional authority to transfer power to Ahmad Shah Massoud's alliance. The Kabul interim authority invited Massoud to enter Kabul as the new Head of State, but he held back. Massoud ordered his forces, positioned to the north of Kabul, not to enter the capital until a political solution was in place. He called on all the senior Afghan party leaders, many then based in exile in Peshawar, to work out a political settlement acceptable to all sides and parties.
Pakistani interference and war in Afghanistan (1992–today).
War in Kabul and other parts of the country (1992–1996).
Peace and power-sharing agreement (1992).
With United Nations support, most Afghan political parties decided to appoint a legitimate national government to succeed communist rule, through an elite settlement. While the external Afghan party leaders were residing in Peshawar, the military situation around Kabul involving the internal commanders was tense. A 1991 UN peace process brought about some negotiations, but the attempted elite settlement did not develop. In April 1992, resistance leaders in Peshawar tried to negotiate a settlement. Massoud supported the Peshawar process of establishing a broad coalition government inclusive of all resistance parties, but Hekmatyar sought to become the sole ruler of Afghanistan, stating, "In our country coalition government is impossible because, this way or another, it is going to be weak and incapable of stabilizing the situation in Afghanistan."
Massoud wrote:
"All the parties had participated in the war, in jihad in Afghanistan, so they had to have their share in the government, and in the formation of the government. Afghanistan is made up of different nationalities. We were worried about a national conflict between different tribes and different nationalities. In order to give everybody their own rights and also to avoid bloodshed in Kabul, we left the word to the parties so they should decide about the country as a whole. We talked about it for a temporary stage and then after that the ground should be prepared for a general election."
A recorded radio communication between the two leaders showed the divide as Massoud asked Hekmatyar: "The Kabul regime is ready to surrender, so instead of the fighting we should gather. ... The leaders are meeting in Peshawar. ... The troops should not enter Kabul, they should enter later on as part of the government." Hekmatyar's response: "We will march into Kabul with our naked sword. No one can stop us. ... Why should we meet the leaders?" Massoud answered: "It seems to me that you don't want to join the leaders in Peshawar nor stop your threat, and you are planning to enter Kabul ... in that case I must defend the people."
At that point Osama bin Laden, trying to mediate, urged Hekmatyar to "go back with your brothers" and to accept a compromise. Bin Laden reportedly "hated Ahmad Shah Massoud". Bin Laden was involved in ideological and personal disputes with Massoud and had sided with Gulbuddin Hekmatyar against Massoud in the inner-Afghan conflict since the late 1980s. But Hekmatyar refused to accept a compromise, confident that he would be able to gain sole power in Afghanistan.
On April 24, 1992, the leaders in Peshawar agreed on and signed the Peshawar Accord, establishing the post-communist Islamic State of Afghanistan. The creation of the Islamic State was welcomed by the General Assembly of the United Nations and the Islamic State of Afghanistan was recognized as the legitimate entity representing Afghanistan until June 2002, when its successor, the Islamic Republic of Afghanistan, was established under the interim government of Hamid Karzai. Under the 1992 Peshawar Accord, the Defense Ministry was given to Massoud while the Prime Ministership was given to Hekmatyar. Hekmatyar refused to sign. With the exception of Hekmatyar's Hezb-e Islami, all of the other Peshawar resistance parties were unified under this peace and power-sharing accord in April 1992.
War against Hekmatyar (1992–1995).
Although repeatedly offered the position of prime minister, Gulbuddin Hekmatyar refused to recognize the peace and power-sharing agreement. His Hezb-e Islami militia initiated a massive bombardment campaign against the Islamic State and the capital city Kabul. Gulbuddin Hekmatyar received operational, financial and military support from neighboring Pakistan. The Director of the Centre for Arab and Islamic Studies at the Australian National University, Amin Saikal, writes in "Modern Afghanistan: A History of Struggle and Survival" that without Pakistan's support, Hekmatyar "would not have been able to target and destroy half of Kabul." Saikal states that Pakistan wanted to install a favorable regime under Hekmatyar in Kabul so that it could use Afghan territory for access to Central Asia.
Hekmatyar's rocket bombardments and the parallel escalation of violent conflict between two militias, Ittihad and Wahdat, which had entered some suburbs of Kabul, led to a breakdown in law and order. Shia Iran and Sunni Wahabbi Saudi Arabia, as competitors for regional hegemony, encouraged conflict between the Ittihad and Wahdat factions. On the one side was the Shia Hazara Hezb-i Wahdat of Abdul Ali Mazari and on the other side, the Sunni Pashtun Ittihad-i Islami of Abdul Rasul Sayyaf.
According to Human Rights Watch, Iran was strongly supporting the Hezb-i Wahdat forces, with Iranian intelligence officials providing direct orders, while Saudi Arabia supported Sayyaf and his Ittihad-i Islami faction to maximize Wahhabi influence. Kabul descended into lawlessness and chaos, as described in reports by Human Rights Watch and the Afghanistan Justice Project. Massoud's Jamiat commanders, the interim government, and the International Committee of the Red Cross (ICRC) repeatedly tried to negotiate ceasefires, which broke down in only a few days. Another militia, the Junbish-i Milli of former communist general Abdul Rashid Dostum, was backed by Uzbekistan. Uzbek president Karimov was keen to see Dostum controlling as much of Afghanistan as possible, especially in the north. Dostum repeatedly changed allegiances.
The Afghanistan Justice Project (AJP) says, that "while anti-government Hizb-i Islami is frequently named as foremost among the factions responsible for the deaths and destruction in the bombardment of Kabul, it was not the only perpetrator of these violations." According to the AJP, "the scale of the bombardment and kinds of weapons used represented disproportionate use of force" in a capital city with primarily residential areas by all the factions involved—including the government forces. Crimes were committed by individuals within the different armed factions. Gulbuddin Hekmatyar released 10,000 dangerous criminals from the main prisons into the streets of Kabul to destabilize the city and cut off Kabul from water, food and energy supplies. The Iran-controlled Wahdat of Abdul Ali Mazari, as well as the Ittihad of Abdul Rasul Sayyaf supported by Saudi Arabia, targeted civilians of the 'opposite side' in systematic atrocities. Abdul Rashid Dostum allowed crimes as a perceived payment for his troops. The Taliban, placing Kabul under a two-year siege and bombardment campaign from early 1995 onwards, in later years committed massacres against civilians, compared by United Nations observers to those that happened during the War in Bosnia.
"The major criticism of Massoud's human rights record" is the escalation of the Afshar military operation in 1993. A report by the Afghanistan Justice Project describes Massoud as failing to prevent atrocities carried out by his forces and those of their factional ally, Ittihad-i Islami, against civilians on taking the suburb of Afshar during a military operation against an anti-state militia allied to Gulbuddin Hekmatyar. They shelled residential areas in the capital city in February 1993. Critics said that Massoud should have foreseen these problems. A meeting convened by Massoud on the next day ordered a halt to killing and looting, but it failed to stop abuses. Human Rights Watch, in a report based largely on the material collected by the Afghanistan Justice Project, concurs that Massoud's Jamiat forces bear a share of the responsibility for human rights abuses throughout the war, including the indiscriminate targeting of civilians in Afshar, and that Massoud was personally implicated in some of these abuses. Roy Gutman has argued that the witness reports about Afshar cited in the AJP report implicated only the Ittihad forces, and that these had not been under Massoud's direct command.
Anthony Davis, who studied and observed Massoud's forces from 1981 to 2001, reported that during the observed period, there was "no pattern of repeated killings of enemy civilians or military prisoners" by Massoud's forces. Edward Girardet, who covered Afghanistan for over three decades, was also in Kabul during the war. He states that while Massoud was able to control most of his commanders well during the anti-Soviet and anti-Taliban resistance, he was not able to control every commander in Kabul. According to this and similar testimonies, this was due to a breakdown of law and order in Kabul and a war on multiple fronts, which they say, Massoud personally had done all in his power to prevent.
In 1993, Massoud created the Cooperative Mohammad Ghazali Culture Foundation ("Bonyad-e Farhangi wa Ta'wani Mohammad-e Ghazali") to further humanitarian assistance and politically independent Afghan culture. The Ghazali Foundation provided free medical services during some days of the week to residents of Kabul who were unable to pay for medical treatment. The Ghazali Foundation's department for distribution of auxiliary goods was the first partner of the Red Cross. The Ghazali Foundation's department of family consultation was a free advisory board, which was accessible seven days a week for the indigent. Although Massoud was responsible for the financing of the foundation, he did not interfere with its cultural work. A council led the foundation and a jury, consisting of impartial university lecturers, decided on the works of artists. The Ghazali foundation enabled Afghan artists to exhibit their works at different places in Kabul, and numerous artists and authors were honoured for their works; some of them neither proponents of Massoud nor the Islamic State government.
In March 1993, Massoud resigned his government position in exchange for peace, as requested by Hekmatyar, who considered him as a personal rival. According to the Islamabad Accord, Burhanuddin Rabbani, belonging to the same party as Massoud, remained president, while Gulbuddin Hekmatyar took the long-offered position of prime minister. Two days after the Islamabad Accord was put into effect, however, Hekmatyar's allies of Hezb-e Wahdat renewed rocket attacks in Kabul.
Both the Wahhabi Pashtun Ittehad-i Islami of Abdul Rasul Sayyaf backed by Saudi Arabia and the Shia Hazara Hezb-e Wahdat supported by Iran remained involved in heavy fighting against each other. Hekmatyar was afraid to enter Kabul proper, and chaired only one cabinet meeting. The author Roy Gutman of the United States Institute of Peace wrote in "How We Missed the Story: Osama bin Laden, the Taliban, and the Hijacking of Afghanistan":
"Hekmatyar had become prime minister ... But after chairing one cabinet meeting, Hekmatyar never returned to the capital, fearing, perhaps, a lynching by Kabulis infuriated over his role in destroying their city. Even his close aides were embarrassed. Hekmatyar spokesman Qutbuddin Helal was still setting up shop in the prime minister's palace when the city came under Hezb[-i Islami] rocket fire late that month. "We are here in Kabul and he is rocketing us. Now we have to leave. We can't do anything," he told Massoud aides."
Hekmatyar, who was generally opposed to coalition government and struggled for undisputed power, had conflicts with other parties over the selection of cabinet members. His forces started major attacks against Kabul for one month. The President, Burhanuddin Rabbani, was attacked when he attempted to meet Hekmatyar. Massoud resumed his responsibilities as minister of defense.
In May 1993, a new effort was made to reinstate the Islamabad Accord. In August, Massoud reached out to Hekmatyar in an attempt to broaden the government. By the end of 1993, however, Hekmatyar and the former communist general and militia leader, Abdul Rashid Dostum, were involved in secret negotiations encouraged by Pakistan's secret Inter-Services Intelligence, Iran's intelligence service, and Uzbekistan's Karimov administration. They planned a coup to oust the Rabbani administration and to attack Massoud in his northern areas.
In January 1994, Hekmatyar and Dostum mounted a bombardment campaign against the capital and attacked Massoud's core areas in the northeast. Amin Saikal writes, Hekmatyar had the following objectives in all his operations:
"The first was to make sure that Rabbani and Massoud were not allowed to consolidate power, build a credible administration, or expand their territorial control, so that the country would remain divided into small fiefdoms, run by various Muajhideen leaders and local warlords or a council of such elements, with only some of them allied to Kabul. The second was to ensure the Rabbani government acquired no capacity to dispense patronage, and to dissuade the Kabul population from giving more than limited support to the government. The third was to make Kabul an unsafe city for representatives of the international community and to prevent the Rabbani government from attracting the international support needed to begin the post-war reconstruction of Afghanistan and generate a level of economic activity which would enhance its credibility and popularity."
By mid-1994, Hekmatyar and Dostum were on the defensive in Kabul against Islamic State forces led by Massoud. By early 1995, the Islamic State had been able to secure the capital. Bombardment of the capital came to a halt. The government began to restore some law and order, and to start basic public services. Massoud initiated a nationwide political process with the goal of national consolidation and democratic elections. But the Taliban, which had emerged over the course of 1994 in southern Afghanistan, were already at the doors of the capital city.
Southern Afghanistan had been neither under the control of foreign-backed militias nor the government in Kabul, but was ruled by local Pashtun leaders, such as Gul Agha Sherzai, and their militias. In 1994, the Taliban (a movement originating from Jamiat Ulema-e-Islam-run religious schools for Afghan refugees in Pakistan) also developed in Afghanistan as a politico-religious force, reportedly in opposition to the tyranny of the local governor. When the Taliban took control of Kandahar in 1994, they forced the surrender of dozens of local Pashtun leaders who had presided over a situation of complete lawlessness and atrocities. In 1994, the Taliban took power in several provinces in southern and central Afghanistan.
Taliban siege of Kabul (1995–1996).
As the Islamic State had been able to consolidate control over the capital, the government took steps to restore law and order. Courts started to work again also convicting individuals inside government troops who had committed crimes. Massoud initiated a nationwide political process with the goal of national consolidation and democratic elections. He arranged a conference in three parts uniting political and cultural personalities, governors, commanders, clergymen and representatives, in order to reach a lasting agreement. Massoud, like most people in Afghanistan, saw this conference as a small hope for democracy and for free elections. His favourite for candidacy to the presidency was Dr. Mohammad Yusuf, the first democratic prime minister under Zahir Shah, the former king. In the first meeting representatives from 15 different Afghan provinces met, in the second meeting there were already 25 provinces participating.
Massoud also invited the Taliban to join the peace process wanting them to be a partner in providing stability to Afghanistan during such a process. Against the advice of his security personnel, he went to talk to some Taliban leaders in Maidan Shar, Taliban territory. The Taliban declined to join the peace process leading towards general elections. When Massoud returned to Kabul unharmed, the Taliban leader who had received him as his guest paid with his life: he was killed by other senior Taliban for failing to assassinate Massoud while the possibility had presented itself.
Neighboring Pakistan exerted strong influence over the Taliban. A publication with the George Washington University describes: ""Initially, the Pakistanis supported ... Gulbuddin Hekmatyar ... When Hekmatyar failed to deliver for Pakistan, the administration began to support a new movement of religious students known as the Taliban."" Many analysts like Amin Saikal describe the Taliban as developing into a proxy force for Pakistan's regional interests which the Taliban decline. The Taliban started shelling Kabul in early 1995 but were defeated by forces of the Islamic State government under Ahmad Shah Massoud. () Amnesty International, referring to the Taliban offensive, wrote in a 1995 report:
The Taliban's early victories in 1994 were followed by a series of defeats that resulted in heavy losses. The Taliban's first major offensive against the important western city of Herat, under the rule of Islamic state ally Ismail Khan, in February 1995 was defeated when Massoud airlifted 2,000 of his own core forces from Kabul to help defend Herat. Ahmed Rashid writes: ""The Taliban had now been decisively pushed back on two fronts by the government and their political and military leadership was in disarray. Their image as potential peacemakers was badly dented, for in the eyes of many Afghans they had become nothing more than just another warlord party."" International observers already speculated that the Taliban as a country-wide organization might have "run its course".
Mullah Omar, however, consolidated his control inside the Taliban and with foreign help rebuild and equipped his forces. Pakistan increased its support to the Taliban. Its military advisers oversaw the restructuring of Taliban forces. The country provided armored pick-up trucks and other military equipment. Saudi Arabia provided the funding. Furthermore, there was a massive influx of 25,000 new Taliban fighters, many of them recruited in Pakistan. This enabled the Taliban to capture Herat to the west of Kabul in a surprise attack against the forces of Ismail Khan in September 1995. A nearly one-year siege and bombardment campaign against Kabul, however, was again defeated by Massoud's forces.
Massoud and Rabbani meanwhile kept working on an internal Afghan peace process—successfully. By February 1996, all of Afghanistan's armed factions—except for the Taliban—had agreed to take part in the peace process and to set up a peace council to elect a new interim president. Many Pashtun areas under Taliban control had representatives also advocating for a peace agreement with the Islamic State government. But Taliban leader Mullah Omar and the Kandaharis surrounding him wanted to expand the war. At that point the Taliban leadership and their foreign supporters decided they needed to act quickly before the government could consolidate the new understanding between the parties. The Taliban moved against Jalalabad, under the control of the Pashtun Jalalabad Shura, to the east of Kabul. Part of the Jalalabad Shura was bribed with millions of dollars by the Taliban's foreign sponsors, especially Saudi Arabia, to vacate their positions. The Taliban's battle for Jalalabad was directed by Pakistani military advisers. Hundreds of Taliban crossed the Afghan-Pakistani border moving on Jalalabad from Pakistan and thereby suddenly placed to the east of Kabul. This left the capital city Kabul "wide open" to many sides as Ismail Khan had been defeated to the west, Gulbuddin Hekmatyar had vacated his positions to the south and the fall and surrender of Jalalabad had suddenly opened a new front to the east. At that point Massoud decided to conduct a strategic retreat through a northern corridor, according to Ahmed Rashid, ""knowing he could not defend from attacks coming from all four points of the compass. Nor did he want to lose the support of Kabul's population by fighting for the city and causing more bloodshed."" On September 26, 1996, as the Taliban with military support by Pakistan and financial support by Saudi Arabia prepared for another major offensive, Massoud ordered a full retreat from Kabul. The Taliban marched into Kabul on September 27, 1996, and established the Islamic Emirate of Afghanistan. Massoud and his troops retreated to the northeast of Afghanistan which became the base for the still internationally recognized Islamic State of Afghanistan.
Resistance against the Taliban (1996–2001).
United Front against the Taliban.
Ahmad Shah Massoud created the United Front (Northern Alliance) against the Taliban advance. The United Front included forces and leaders from different political backgrounds as well as from all ethnicities of Afghanistan. From the Taliban conquest in 1996 until November 2001, the United Front controlled territory in which roughly 30% of Afghanistan's population was living, in provinces such as Badakhshan, Kapisa, Takhar and parts of Parwan, Kunar, Nuristan, Laghman, Samangan, Kunduz, Ghōr and Bamyan.
Meanwhile, the Taliban imposed their repressive regime in the parts of Afghanistan under their control. Hundreds of thousands of people fled to Northern Alliance territory, Pakistan and Iran. Massoud's soldiers held some 1,200 Taliban prisoners in the Panjshir Valley, 122 of them foreign Muslims who had come to Afghanistan to fight a jihad.
In 1998, after the defeat of Abdul Rashid Dostum's faction in Mazar-i-Sharif, Ahmad Shah Massoud remained the only main leader of the United Front in Afghanistan and the only leader who was able to defend vast parts of his area against the Taliban. Most major leaders including the Islamic State's President Burhanuddin Rabbani, Abdul Rashid Dostum, and others, were living in exile. During this time, commentators remarked that "The only thing standing in the way of future Taliban massacres is Ahmad Shah Massoud."
Massoud stated that the Taliban repeatedly offered him a position of power to make him stop his resistance. He declined, declaring the differences between their ideology and his own pro-democratic outlook on society to be insurmountable.
Massoud wanted to convince the Taliban to join a political process leading towards democratic elections in a foreseeable future. He also predicted that without assistance from Pakistan and external extremist groups, the Taliban would lose their hold on power.
In early 2001, the United Front employed a new strategy of local military pressure and global political appeals. Resentment was increasingly gathering against Taliban rule from the bottom of Afghan society including the Pashtun areas. At the same time, Massoud was very wary not to revive the failed Kabul government of the early 1990s. Already in 1999 the United Front leadership ordered the training of police forces specifically to keep order and protect the civilian population in case the United Front would be successful.
Cross-factional negotiations.
From 1999 onwards, a renewed process was set into motion by the Tajik Ahmad Shah Massoud and the Pashtun Abdul Haq to unite all the ethnicities of Afghanistan. Massoud united the Tajiks, Hazara and Uzbeks as well as several Pashtun commanders under his United Front. Besides meeting with Pashtun tribal leaders and acting as a point of reference, Abdul Haq received increasing numbers of Pashtun Taliban themselves who were secretly approaching him. Some commanders who had worked for the Taliban military apparatus agreed to the plan to topple the Taliban regime as the Taliban lost support even among the Pashtuns. Senior diplomat and Afghanistan expert Peter Tomsen wrote that ""‘Lion of Kabul’ [Abdul Haq and the ‘Lion of Panjshir’ Shah Massoud would make a formidable anti-Taliban team if they combined forces. Haq, Massoud, and Karzai, Afghanistan’s three leading moderates, could transcend the Pashtun—non-Pashtun, north-south divide."" Steve Coll referred to this plan as a "grand Pashtun-Tajik alliance". The senior Hazara and Uzbek leaders took part in the process just like later Afghan president Hamid Karzai. They agreed to work under the banner of the exiled Afghan king Zahir Shah in Rome.
In November 2000, leaders from all ethnic groups were brought together in Massoud's headquarters in northern Afghanistan, travelling from other parts of Afghanistan, Europe, the United States, Pakistan and India to discuss a Loya Jirga for a settlement of Afghanistan's problems and to discuss the establishment of a post-Taliban government. In September 2001, an international official who met with representatives of the alliance remarked, ""It's crazy that you have this today ... Pashtuns, Tajiks, Uzbeks, Hazara ... They were all ready to buy in to the process"."
In early 2001, Ahmad Shah Massoud with leaders from all ethnicities of Afghanistan addressed the European Parliament in Brussels, asking the international community to provide humanitarian aid to the people of Afghanistan. He stated that the Taliban and Al Qaeda had introduced "a very wrong perception of Islam" and that without the support of Pakistan and Bin Laden the Taliban would not be able to sustain their military campaign for up to a year. On that visit to Europe, he also warned the US about Bin Laden.
The areas of Massoud.
Life in the areas under direct control of Massoud was different from the life in the areas under Taliban or Dostum's control. In contrast to the time of chaos in which all structures had collapsed in Kabul, Massoud was able to control most of the troops under his direct command well during the period starting in late 1996. Massoud always controlled the Panjshir, Takhar, parts of Parwan and Badakhshan during the war. Some other provinces (notably Kunduz, Baghlan, Nuristan and the north of Kabul) were captured by his forces from the Taliban and lost again from time to time as the frontlines varied.
Massoud created democratic institutions which were structured into several committees: political, health, education and economic. Still, many people came to him personally when they had a dispute or problem and asked him to solve their problems.
In September 2000, Massoud signed the Declaration of the Essential Rights of Afghan Women drafted by Afghan women. The declaration established gender equality in front of the law and the right of women to political participation, education, work, freedom of movement and speech. In the areas of Massoud, women and girls did not have to wear the Afghan burqa by law. They were allowed to work and to go to school. Although it was a time of war, girls' schools were operating in some districts. In at least two known instances, Massoud personally intervened against cases of forced marriage in favour of the women to make their own choice.
While it was Massoud's stated personal conviction that men and women are equal and should enjoy the same rights, he also had to deal with Afghan traditions which he said would need a generation or more to overcome. In his opinion, that could only be achieved through education. Author Pepe Escobar wrote in "Massoud: From Warrior to Statesman":
Humayun Tandar, who took part as an Afghan diplomat in the 2001 International Conference on Afghanistan in Bonn, said that "strictures of language, ethnicity, region were stifling for Massoud. That is why ... he wanted to create a unity which could surpass the situation in which we found ourselves and still find ourselves to this day." This applied also to strictures of religion. Jean-José Puig describes how Massoud often led prayers before a meal or at times asked his fellow Muslims to lead the prayer but also did not hesitate to ask the Jewish Princeton Professor Michael Barry or his Christian friend Jean-José Puig: "Jean-José, we believe in the same God. Please, tell us the prayer before lunch or dinner in your own language."
International relations.
U.S. policy regarding Massoud, the Taliban and Afghanistan remains ambiguous and differed between the various U.S. government agencies.
In 1997, U.S. State Department's Robin Raphel suggested to Massoud he should surrender to the Taliban. He soundly rejected the proposal.
At one point in the war, in 1997, two top foreign policy officials in the Clinton administration flew to northern Afghanistan in an attempt to convince Massoud not to take advantage of a strategic opportunity to make crucial gains against the Taliban.
In 1998, a U.S. Defense Intelligence Agency analyst, Julie Sirrs, visited Massoud's territories privately, having previously been denied official permission to do so by her agency. She reported that Massoud had conveyed warnings about strengthened ties between the Taliban and foreign Islamist terrorists. Returning home, she was sacked from her agency for insubordination, because at that time the U.S. administration had no trust in Massoud.
In the meantime, the only collaboration between Massoud and another U.S. intelligence service, the Central Intelligence Agency (CIA), consisted of an effort to trace Osama bin Laden following the 1998 embassy bombings. The U.S. and the European Union provided no support to Massoud for the fight against the Taliban.
A change of policy, lobbied for by CIA officers on the ground who had visited the area of Massoud, regarding support to Massoud, was underway in the course of 2001. According to Steve Coll's book "Ghost Wars" (who won the 2005 Pulitzer Prize for General Non-Fiction):
U.S. Congressman Dana Rohrabacher also recalled: "etween Bush's inauguration and 9/11, I met with the new national security staff on 3 occasions, including one meeting with Condoleezza Rice to discuss Afghanistan. There were, in fact, signs noted in an overview story in The Washington Post about a month ago that some steps were being made to break away from the previous administration's Afghan policy." CIA lawyers, working with officers in the Near East Division and Counterterrorist Center, began to draft a formal, legal presidential finding for Bush's signature authorizing a new covert action program in Afghanistan, the first in a decade that sought to influence the course of the Afghan war in favour of Massoud. This change in policy was finalized in August 2001 when it was too late.
After Pakistan had funded, directed and supported the Taliban's rise to power in Afghanistan, Massoud and the United Front received some assistance from India. India was particularly concerned about Pakistan's Taliban strategy and the Islamic militancy in its neighborhood; it provided U.S.$70 million in aid including two Mi-17 helicopters, three additional helicopters in 2000 and US$8 million worth of high-altitude equipment in 2001. Furthermore, the alliance supposedly also received minor aid from Tajikistan, Russia and Iran because of their opposition to the Taliban and the Pakistani control over the Taliban's Emirate. Their support, however, remained limited to the most needed things. Meanwhile, Pakistan engaged up to 28,000 Pakistani nationals and regular Pakistani army troops to fight alongside the Taliban and Al Qaeda forces against Massoud.
In April 2001, the president of the European Parliament, Nicole Fontaine (who called Massoud the "pole of liberty in Afghanistan"), invited Massoud with the support of French and Belgian politicians to address the European Parliament in Brussels, Belgium. In his speech, he asked for humanitarian aid for the people of Afghanistan. Massoud further went on to warn that his intelligence agents had gained limited knowledge about a large-scale terrorist attack on U.S. soil being imminent.
Assassination.
Massoud, then aged 48, was the target of a suicide attack at Khwaja Bahauddin, in Takhar Province in northeastern Afghanistan on September 9, 2001. The attackers' names were alternately given as Dahmane Abd al-Sattar, husband of Malika El Aroud, and Bouraoui el-Ouaer; or 34-year-old Karim Touzani and 26-year-old Kacem Bakkali.
The attackers claimed to be Belgians originally from Morocco. Their passports turned out to be stolen and their nationality was later determined to be Tunisian. Waiting for almost three weeks (during which they also interviewed Burhanuddin Rabbani and Abdul Rasul Sayyaf) for an interview opportunity, on September 8, 2001, an aide to Massoud recalls the would-be suicide attackers "were so worried" and threatened to leave if the interview did not happen in the next 24 hours (until September 10, 2001). They were finally granted an interview. During the interview, they set off a bomb composed of explosives hidden in the camera and in a battery-pack belt. Commander Massoud died in a helicopter that was taking him to a military field hospital in nearby Tajikistan. The explosion also killed Mohammed Asim Suhail, a United Front official, while Mohammad Fahim Dashty and Massoud Khalili were injured. One of the suicide attackers, Bouraoui, was killed by the explosion, while Dahmane Abd al-Sattar was captured and shot while trying to escape.
Despite initial denials by the United Front, news of Massoud's death was reported almost immediately, appearing on the BBC, and in European and North American newspapers on September 10, 2001. On September 16, the United Front officially announced that Massoud had died of injuries in the suicide attack. Massoud was buried in his home village of Bazarak in the Panjshir Valley. The funeral, although in a remote rural area, was attended by hundreds of thousands of people. ().
Massoud had survived assassination attempts over a period of 26 years, including attempts made by al-Qaeda, the Taliban, the Pakistani ISI and before them the Soviet KGB, the Afghan communist KHAD and Hekmatyar. The first attempt on Massoud's life was carried out by Hekmatyar and two Pakistani ISI agents in 1975 when Massoud was 22 years old. In early 2001, al-Qaeda would-be assassins were captured by Massoud's forces while trying to enter his territory.
The assassination of Massoud is considered to have a strong connection to the September 11 attacks in 2001 on U.S. soil, which killed nearly 3,000 people. It appeared to have been the major terrorist attack which Massoud had warned against in his speech to the European Parliament several months earlier.
Analysts believe Osama bin Laden ordered Massoud's assassination to help his Taliban protectors and ensure he would have their co-operation in Afghanistan. Following the assassination, bin Laden had an emissary deliver Dahmane Abd al-Sattar's widow a cassette of him speaking of his love for his wife and his decision to blow himself up, as well as $500 in an envelope to settle a debt. The Pakistani Inter-Services Intelligence (ISI) and Abdul Rasul Sayyaf, an Afghan Wahhabi Islamist, have also been mentioned as possible organizers or collaborators of the Massoud assassins. The assassins are said to have entered United Front (Northern Alliance) territory under the auspices of the Abdul Rasul Sayyaf and had his assistance in bypassing "normal security procedures."
Investigative commission
In April 2003, the Karzai administration announced the creation of a commission to investigate the assassination of Massoud. In 2003, French investigators announced that they and the FBI had been able to trace the provenance of the camera used in the assassination, which had been stolen in France some time earlier.
Legacy.
National Hero of Afghanistan.
Massoud was the only chief Afghan leader who never left Afghanistan in the fight against the Soviet Union and later in the fight against the Taliban Emirate. In the areas under his direct control, such as Panjshir, some parts of Parwan and Takhar, Massoud established democratic institutions. One refugee who cramped his family of 27 into an old jeep to flee from the Taliban to the area of Massoud described Massoud's territory in 1997 as "the last tolerant corner of Afghanistan".
"One man holds a greater political punch than all 18 living presidential candidates combined. Though already dead for three years... Since his death on September 9, 2001 at the hands of two al Qaeda-linked Islamic radicals, Massoud has been transformed from mujahedin to national hero—if not saint. Pictures of Massoud, the Afghan mujahedin who battled the Soviets, other warlords, and the Taliban for more than 20 years, vastly outnumber those of any other Afghan including those of Karzai."
Today Panjshir, the home of Massoud,
"is arguably the most peaceful place in the entire country. A small US military reconstruction team is based here, but there are none of the signs of foreign occupation that exist elsewhere. Even Afghan soldiers are few and far between. Instead, the people like to boast about how they keep their own security," observes the United Arab Emirates newspaper, "The National."
The road near the Afghanistan Embassy is a "symbol of ties" that binds the two nations that have always "enjoyed excellent relations"
Lion of Panjshir.
Massoud's byname, "Lion of Panjshir" (, "Shir-e-Panjshir"), earned for his role during the Soviet occupation, is a rhyming play on words in Persian, as the name of the valley means "five lions".
The "Wall Street Journal" referred to Massoud as "The Afghan Who Won the Cold War", referring to the global significance of the Soviet defeat in Afghanistan for the subsequent collapse of the Eastern Bloc.
Warning the world about September 11.
In the spring 2001, Ahmad Shah Massoud had addressed the European Parliament in Brussels, saying that Pakistan was behind the situation in Afghanistan. He also said that he believed that, without the support of Pakistan, Osama bin Laden, and Saudi Arabia, the Taliban would not be able to sustain their military campaign for up to a year. He said the Afghan population was ready to rise against them. Addressing the United States specifically, he warned that should the U.S. not work for peace in Afghanistan and put pressure on Pakistan to cease their support to the Taliban, the problems of Afghanistan would soon become the problems of the U.S. and the world.
Declassified Defense Intelligence Agency (DIA) documents from November 2001 show that Massoud had gained "limited knowledge... regarding the intentions of Al-Qaeda to perform a terrorist act against the U.S. on a scale larger than the 1998 bombing of the U.S. Embassies in Kenya and Tanzania." They noted that he warned about such attacks.
Personal life.
Massoud was married to Sediqa Massoud. They have one son (Ahmad born in 1989) and five daughters (Fatima born in 1992, Mariam born in 1993, Ayesha born in 1995, Zohra born in 1996 and Nasrine born in 1998). In 2005 Sediqa Massoud published a personal account on her life with Massoud (co-authored by two women's rights activists and friends of Sediqa Massoud, Chékéba Hachemi and Marie-Francoise Colombani) called ""Pour l'amour de Massoud"" (For the love of Massoud), in which she describes a decent and loving husband.
The family has a great deal of prestige in the politics of Afghanistan. One of his six brothers, Ahmad Zia Massoud, was the Vice President of Afghanistan from 2004 until 2009 under the first democratically elected government of Afghanistan. Unsuccessful attempts have been made on the life of Ahmad Zia Massoud in 2004 and late 2009. The Associated Press reported that 8 Afghans died in the attempt on Ahmad Zia Massoud's life. Ahmad Zia Massoud leads the National Front of Afghanistan (a United Front group).
Another brother, Ahmad Wali Massoud, was Afghanistan's Ambassador to the United Kingdom from 2002 to 2006. He is a member of Abdullah Abdullah's National Coalition of Afghanistan (another United Front group).

</doc>
<doc id="2178" url="http://en.wikipedia.org/wiki?curid=2178" title="Atlantis">
Atlantis

Atlantis (, "island of Atlas") is the name of a fictional island mentioned within an allegory on the hubris of nations in Plato's works "Timaeus" and "Critias", where it represents the antagonist naval power that besieges "Ancient Athens", the pseudo-historic embodiment of Plato's ideal state (see "The Republic"). In the story, Athens was able to repel the Atlantean attack, unlike any other nation of the (western) known world, supposedly giving testament to the superiority of Plato's concept of a state. At the end of the story, Atlantis eventually falls out of favor with the gods and famously submerges into the Atlantic Ocean.
Despite its minor importance in Plato's work, the Atlantis story has had a considerable impact on literature. The allegorical aspect of Atlantis was taken up in utopian works of several Renaissance writers, such as Bacon's "New Atlantis" and More's "Utopia". On the other hand, 19th-century amateur scholars misinterpreted Plato's account as historical tradition, most notably in Donnelly's "". Plato's vague indications of the time of the events—more than 9,000 years before his day—and the alleged location of Atlantis—"beyond the Pillars of Hercules"—has led to much pseudoscientific speculation. As a consequence, Atlantis has become a byword for any and all supposed advanced prehistoric lost civilizations and continues to inspire today's fiction, from comic books to films.
While present-day philologists and historians unanimously accept the story's fictional character, there is still debate on what served as its inspiration. The fact that Plato borrowed some of his allegories and metaphors from older traditions—most notably the story of Gyges—has caused a number of scholars to investigate possible inspiration of Atlantis from Egyptian records of the Thera eruption, the Sea Peoples invasion, or the Trojan War. Others have rejected this chain of tradition as implausible and insist that Plato designed the story from scratch, drawing loose inspiration from contemporary events like the failed Athenian invasion of Sicily in 415–413 BC or the destruction of Helike in 373 BC.
Plato's account.
Plato's dialogues "Timaeus" and "Critias", written in 360 BC, contain the earliest references to Atlantis. For unknown reasons, Plato never completed "Critias". Plato introduced Atlantis in "Timaeus":
The four people appearing in those two dialogues are the politicians Critias and Hermocrates as well as the philosophers Socrates and Timaeus of Locri, although only Critias speaks of Atlantis. In his works Plato makes extensive use of the Socratic method in order to discuss contrary positions within the context of a supposition.
The "Timaeus" begins with an introduction, followed by an account of the creations and structure of the universe and ancient civilizations. In the introduction, Socrates muses about the perfect society, described in Plato's "Republic" (c. 380 BC), and wonders if he and his guests might recollect a story which exemplifies such a society. Critias mentions an allegedly historical tale that would make the perfect example, and follows by describing Atlantis as is recorded in the "Critias". In his account, ancient Athens seems to represent the "perfect society" and Atlantis its opponent, representing the very antithesis of the "perfect" traits described in the "Republic".
"Critias".
According to Critias, the Hellenic gods of old divided the land so that each god might have their own lot; Poseidon was appropriately, and to his liking, bequeathed the island of Atlantis. The island was larger than Ancient Libya and Asia Minor combined, but it afterwards was sunk by an earthquake and became an impassable mud shoal, inhibiting travel to any part of the ocean. The Egyptians, Plato asserted, described Atlantis as an island comprising mostly mountains in the northern portions and along the shore, and encompassing a great plain of an oblong shape in the south "extending in one direction three thousand "stadia" 555 km; 345 mi, but across the center inland it was two thousand stadia 370 km; 230 mi." Fifty stadia 6 mi from the coast was a mountain that was low on all sides ... broke it off all round about ... the central island itself was five stades in diameter 0.92 km; 0.57 mi.
In Plato's myth, Poseidon fell in love with Cleito, the daughter of Evenor and Leucippe, who bore him five pairs of male twins. The eldest of these, Atlas, was made rightful king of the entire island and the ocean (called the Atlantic Ocean in his honor), and was given the mountain of his birth and the surrounding area as his fiefdom. Atlas's twin Gadeirus, or Eumelus in Greek, was given the extremity of the island towards the pillars of Hercules. The other four pairs of twins—Ampheres and Evaemon, Mneseus and Autochthon, Elasippus and Mestor, and Azaes and Diaprepes—were also given "rule over many men, and a large territory."
Poseidon carved the mountain where his love dwelt into a palace and enclosed it with three circular moats of increasing width, varying from one to three stadia and separated by rings of land proportional in size. The Atlanteans then built bridges northward from the mountain, making a route to the rest of the island. They dug a great canal to the sea, and alongside the bridges carved tunnels into the rings of rock so that ships could pass into the city around the mountain; they carved docks from the rock walls of the moats. Every passage to the city was guarded by gates and towers, and a wall surrounded each of the city's rings. The walls were constructed of red, white and black rock quarried from the moats, and were covered with brass, tin and the precious metal orichalcum, respectively.
According to Critias, 9,000 years before his lifetime a war took place between those outside the Pillars of Hercules at the Strait of Gibraltar and those who dwelt within them. The Atlanteans had conquered the parts of Libya within the Pillars of Hercules as far as Egypt and the European continent as far as Tyrrhenia, and subjected its people to slavery. The Athenians led an alliance of resistors against the Atlantean empire, and as the alliance disintegrated, prevailed alone against the empire, liberating the occupied lands.
The logographer Hellanicus of Lesbos wrote an earlier work titled "Atlantis", of which only a few fragments survive. Hellanicus' work appears to have been a genealogical one concerning the daughters of Atlas (Ἀτλαντὶς in Greek means "of Atlas"), but some authors have suggested a possible connection with Plato's island. John V. Luce notes that when he writes about the genealogy of Atlantis's kings, Plato writes in the same style as Hellanicus and suggests a similarity between a fragment of Hellanicus's work and an account in the "Critias". Rodney Castleden suggests Plato may have borrowed his title from Hellanicus, and that Hellanicus may have based his work on an earlier work on Atlantis.
Castleden has pointed out that Plato wrote of Atlantis in 359 BCE, when he returned to Athens from Sicily. He notes a number of parallels between the physical organisation and fortifications of Syracuse and Plato's description of Atlantis. Gunnar Rudberg was the first who elaborated the idea that Plato's attempt to realize his political ideas in the city of Syracuse could have heavily inspired the Atlantis account.
Interpretations.
Ancient.
Some ancient writers viewed Atlantis as fiction while others believed it was real. The philosopher Crantor, a student of Plato's student Xenocrates, is often cited as an example of a writer who thought the story to be historical fact. His work, a commentary on Plato's "Timaeus", is lost, but Proclus, a Neoplatonist of the 5th century AD, reports on it. The passage in question has been represented in the modern literature either as claiming that Crantor actually visited Egypt, had conversations with priests, and saw hieroglyphs confirming the story or as claiming that he learned about them from other visitors to Egypt. Proclus wrote:
The next sentence is often translated "Crantor adds, that this is testified by the prophets of the Egyptians, who assert that these particulars are narrated by Plato are written on pillars which are still preserved." But in the original, the sentence starts not with the name Crantor but with the ambiguous "He", and whether this referred to Crantor or to Plato is the subject of considerable debate. Proponents of both Atlantis as a myth and Atlantis as history have argued that the word refers to Crantor.
Alan Cameron argues that it should be interpreted as referring to Plato, and that when Proclus writes that "we must bear in mind concerning this whole feat of the Athenians, that it is neither a mere myth nor unadorned history, although some take it as history and others as myth", he is treating "Crantor's view as mere personal opinion, nothing more; in fact he first quotes and then dismisses it as representing one of the two unacceptable extremes".
Cameron also points out that whether "he" refers to Plato or to Crantor, the statement does not support conclusions such as Otto Muck's "Crantor came to Sais and saw there in the temple of Neith the column, completely covered with hieroglyphs, on which the history of Atlantis was recorded. Scholars translated it for him, and he testified that their account fully agreed with Plato's account of Atlantis" or J. V. Luce's suggestion that Crantor sent "a special enquiry to Egypt" and that he may simply be referring to Plato's own claims.
Another passage from Proclus' commentary on the "Timaeus" gives a description of the geography of Atlantis: That an island of such nature and size once existed is evident from what is said by certain authors who investigated the things around the outer sea. For according to them, there were seven islands in that sea in their time, sacred to Persephone, and also three others of enormous size, one of which was sacred to Hades, another to Ammon, and another one between them to Poseidon, the extent of which was a thousand stadia [200 km]; and the inhabitants of it—they add—preserved the remembrance from their ancestors of the immeasurably large island of Atlantis which had really existed there and which for many ages had reigned over all islands in the Atlantic sea and which itself had like-wise been sacred to Poseidon. Now these things Marcellus has written in his "Aethiopica"". Marcellus remains unidentified.
Other ancient historians and philosophers believing in the existence of Atlantis were Strabo and Posidonius.
Plato's account of Atlantis may have also inspired parodic imitation: writing only a few decades after the "Timaeus" and "Critias", the historian Theopompus of Chios wrote of a land beyond the ocean known as Meropis. This description was included in Book 8 of his voluminous "Philippica", which contains a dialogue between King Midas and Silenus, a companion of Dionysus. Silenus describes the Meropids, a race of men who grow to twice normal size, and inhabit two cities on the island of Meropis (Cos?): "Eusebes" (, "Pious-town") and "Machimos" (, "Fighting-town"). He also reports that an army of ten million soldiers crossed the ocean to conquer Hyperborea, but abandoned this proposal when they realized that the Hyperboreans were the luckiest people on earth. Heinz-Günther Nesselrath has argued that these and other details of Silenus' story are meant as imitation and exaggeration of the Atlantis story, for the purpose of exposing Plato's ideas to ridicule.
Zoticus, a Neoplatonist philosopher of the 3rd century AD, wrote an epic poem based on Plato's account of Atlantis.
The 4th-century historian Ammianus Marcellinus, relying on a lost work by Timagenes, a historian writing in the 1st century BC, writes that the Druids of Gaul said that part of the inhabitants of Gaul had migrated there from distant islands. Some have understood Ammianus's testimony as a claim that at the time of Atlantis's actual sinking into the sea, its inhabitants fled to western Europe; but Ammianus in fact says that "the Drasidae (Druids) recall that a part of the population is indigenous but others also migrated in from islands and lands beyond the Rhine" ("Res Gestae" 15.9), an indication that the immigrants came to Gaul from the north (Britain, the Netherlands or Germany), not from a theorized location in the Atlantic Ocean to the south-west. Instead, the Celts that dwelled along the ocean were reported to venerate twin gods (Dioscori) that appeared to them coming from that ocean.
Jewish and Christian.
The Hellenistic Jewish philosopher Philo in the early 1st century AD wrote about the destruction of Atlantis in his "On the Eternity of the World", xxvi. 141, in a longer passage allegedly citing Aristotle's successor Theophrastus:
Some scholars believe Clement of Rome cryptically referred to Atlantis in his First Epistle of Clement, 20: 8:
On this passage the theologian Joseph Barber Lightfoot ("Apostolic Fathers", 1885, II, p. 84) noted: "Clement may possibly be referring to some known, but hardly accessible land, lying without the pillars of Hercules. But more probably he contemplated some unknown land in the far west beyond the ocean, like the fabled Atlantis of Plato ..."
Other early Christian writers wrote about Atlantis, though they had mixed views on whether it once existed or was an untrustworthy myth of pagan origin. Tertullian believed Atlantis was once real and wrote that in the Atlantic Ocean once existed "isle that was equal in size to Libya or Asia" referring to Plato's geographical description of Atlantis. The early Christian apologist writer Arnobius also believed Atlantis once existed but blamed its destruction on pagans.
Cosmas Indicopleustes in the 6th century wrote of Atlantis in his "Christian Topography" in an attempt to prove his theory that the world was flat and surrounded by water:
A Hebrew treatise on computational astronomy dated to AD 1378/79, alludes to the Atlantis myth in a discussion concerning the determination of zero points for the calculation of longitude:
Modern.
Aside from Plato's original account, modern interpretations regarding Atlantis are an amalgamation of diverse, speculative movements that began in the 16th century. Contemporary perceptions of Atlantis share roots with Mayanism, which can be traced to the beginning of the Modern Age, when European imaginations were fueled by their initial encounters with the indigenous peoples of the New World. From this era sprang apocalyptic and utopian visions that would inspire many subsequent generations of theorists.
Most of these interpretations are considered pseudohistory, pseudoscience, or pseudoarchaeology, as they have presented their works as academic or scientific, but lack the standards or criteria.
Atlantis pseudohistory.
Early influential literature.
The term "utopia" (from "no place") was coined by Sir Thomas More in "Utopia", his 16th Century work of fiction. Inspired by Plato's Atlantis and travelers' accounts of the Americas, More described an imaginary land set in the New World. His idealistic vision established a connection between the Americas and utopian societies, a theme which was further solidified by Sir Francis Bacon in "The New Atlantis" (c. 1623). Bacon describes a utopian society that he called "Bensalem," located off the western coast of America. A character in the narrative gives a history of Atlantis that is similar to Plato's and places Atlantis in America. People had begun believing that the Mayan and Aztec ruins could possibly be the remnants of Atlantis.
Impact of Mayanism.
Much speculation began as to the origins of the Maya, which led to a variety of narratives and publications which tried to rationalize the discoveries within the context of the Bible and which had undertones of racism in their connections between the Old and New World. The Europeans believed the indigenous people to be inferior and incapable of building that which was now in ruins and by sharing a common history they insinuate that another race must have been responsible.
In the middle and late 19th century, several renowned Mesoamerican scholars, starting with Charles Etienne Brasseur de Bourbourg, and including Edward Herbert Thompson and Augustus Le Plongeon, formally proposed that Atlantis was somehow related to Mayan and Aztec culture.
French scholar Brasseur de Bourbourg traveled extensively through Mesoamerica in the mid-1800s, and was renowned for his translations of Mayan texts, most notably the sacred book Popol Vuh, as well as a comprehensive history of the region. However, soon after these publications, Brasseur de Bourbourg lost his academic credibility, due to his claim that the Maya peoples had descended from the Toltecs, who he believed were the surviving population of the racially superior civilization of Atlantis. His work combined with the skillful, romantic illustrations of Jean Frederic Waldeck, which visually alluded to Egypt and other aspects of the Old World, creating an authoritative fantasy and exciting much interest in the connections between worlds.
Inspired by Brasseur de Bourbourg's diffusion theories, pseudoarchaeologist Augustus Le Plongeon traveled to Mesoamerica and performed some of the first excavations of many famous Mayan ruins. Le Plongeon invented narratives, such as the kingdom of Moo saga, which romantically drew connections between himself, his wife Alice, and Egyptian deities Osiris and Isis, as well as with Heinrich Schliemann, who had just discovered the ancient city of Troy from Homer's epics. He also believed that he had found connections between the Greek and Mayan languages, which produced a narrative of the destruction of Atlantis.
Ignatius Donnelly.
The 1882 publication of "" by Ignatius L. Donnelly stimulated much popular interest in Atlantis. He was greatly inspired by early works in Mayanism, and like them attempted to establish that all known ancient civilizations were descended from Atlantis, which he saw as a technologically sophisticated, more advanced culture. Donnelly drew parallels between creation stories in the Old and New Worlds, attributing the connections to Atlantis, where he believed existed the Biblical Garden of Eden. As implied by the title of his book, he also believed that Atlantis was destroyed by the Great Flood mentioned in the Bible.
Donnelly is credited as the "father of the 19th century Atlantis revival" and is the reason the myth endures today. He unintentionally promoted an alternative method of inquiry to history and science, and the idea that myths contain hidden information that opens them to "ingenious" interpretation by people who believe they have new or special insight.
Madame Blavatsky and the Theosophists.
The Russian mystic Helena Petrovna Blavatsky and her partner Henry Steel Olcott founded their Theosophical Society in the 1870s with a philosophy that combined western romanticism and eastern religious concepts. Blavatsky and her followers in this group are often cited as the founders of New Age and other spiritual movements.
Blavatsky took up Donnelly's interpretations when she wrote "The Secret Doctrine" (1888), which she claimed was originally dictated in Atlantis itself. She maintained that the Atlanteans were cultural heroes (contrary to Plato, who describes them mainly as a military threat). She believed in a form of racial evolution (as opposed to primate evolution), in which the Atlanteans were the fourth "Root Race", succeeded by the fifth and most superior "Aryan race" (her own race). The Theosophists believed that the civilization of Atlantis reached its peak between 1,000,000 and 900,000 years ago but destroyed itself through internal warfare brought about by the inhabitants' dangerous use of psychic and supernatural powers.
Rudolf Steiner, the founder of Anthroposophy and Waldorf Schools, along with other well known Theosophists, such as Annie Besant, also wrote of cultural evolution in much the same vein.
Nazism and occultism.
Blavatsky had also been inspired by the work of the 18th-century astronomer Jean-Sylvain Bailly, who had "Orientalized" the Atlantis myth in his mythical continent of Hyperborea, a reference to Greek myths featuring a Northern European region of the same name, home to a giant, godlike race. Her retooling of this theory in "The Secret Doctrine" provided the Nazis with a mythological precedent and pretense for their ideological platform and subsequent genocide.
Julius Evola's writing in 1934 also suggested that the Atlanteans were Hyperborean, Nordic supermen who originated at the North Pole (see Thule). Similarly, Alfred Rosenberg (in "The Myth of the Twentieth Century", 1930) spoke of a "Nordic-Atlantean" or "Aryan-Nordic" master race.
Edgar Cayce.
Edgar Cayce was a man from humble upbringings in Kentucky who allegedly possessed psychic abilities, which were performed from a trance-like state. In addition to allegedly healing the sick from this state, he also spoke frequently on the topic of Atlantis. In his "life readings," he purportedly revealed that many of his subjects were reincarnations of people that had lived on Atlantis, and by tapping into their collective consciousness, the "Akashic Records" (a term borrowed from Theosophy), he was able to give detailed descriptions of the lost continent. He also asserted that Atlantis would "rise" again in the 1960s (sparking much popularity of the myth in that decade), as well as that there is a "Hall of Records" beneath the Egyptian Sphinx that holds the historical texts of Atlantis.
Recent times.
As continental drift became more widely accepted during the 1960s, and the increased understanding of plate tectonics demonstrated the impossibility of a lost continent in the geologically recent past, most "Lost Continent" theories of Atlantis began to wane in popularity.
Plato scholar Julia Annas, Regents Professor of Philosophy at the University of Arizona, had this to say on the matter:
One of the proposed explanations for the historical context of the Atlantis story is a warning of Plato to his contemporary fourth-century fellow-citizens against their striving for naval power.
Kenneth Feder points out that Critias's story in the "Timaeus" provides a major clue. In the dialogue, Critias says, referring to Socrates' hypothetical society:
Feder quotes A. E. Taylor, who wrote, "We could not be told much more plainly that the whole narrative of Solon's conversation with the priests and his intention of writing the poem about Atlantis are an invention of Plato's fancy."
Location hypotheses.
Since Donnelly's day, there have been dozens of locations proposed for Atlantis, to the point where the name has become a generic concept, divorced from the specifics of Plato's account. This is reflected in the fact that many proposed sites are not within the Atlantic at all. Few today are scholarly or archaeological hypotheses, while others have been made by psychic (e.g., Edgar Cayce) or other pseudoscientific means. (The Atlantis researchers Jacques Collina-Girard and Georgeos Díaz-Montexano, for instance, each claim the other's hypothesis is pseudoscience.) Many of the proposed sites share some of the characteristics of the Atlantis story (water, catastrophic end, relevant time period), but none has been demonstrated to be a true historical Atlantis.
In or near the Mediterranean Sea.
Most of the historically proposed locations are in or near the Mediterranean Sea: islands such as Sardinia, Crete, Santorini, Sicily, Cyprus, and Malta; land-based cities or states such as Troy, Tartessos, and Tantalus (in the province of Manisa, Turkey); Israel-Sinai or Canaan; and northwestern Africa. The Thera eruption, dated to the 17th or 16th century BC, caused a large tsunami that some experts hypothesize devastated the Minoan civilization on the nearby island of Crete, further leading some to believe that this may have been the catastrophe that inspired the story.
A. G. Galanopoulos argued that Plato's dating of 9,000 years before Solon's time was the result of an error in translation, probably from Egyptian into Greek, which produced "thousands" instead of "hundreds". Such an error would also rescale Plato's Atlantis to the size of Crete, while leaving the city the size of the crater on Thera; 900 years before Solon would be the 15th century BC. In the area of the Black Sea the following locations have been proposed: Bosporus and Ancomah (a legendary place near Trabzon).
In the Atlantic Ocean and Europe.
In 2011, a team, working on a documentary for the National Geographic Channel, led by Professor Richard Freund from the University of Hartford, claimed to have found evidence of Atlantis in southwestern Andalusia. The team identified its possible location within the marshlands of the Doñana National Park, in the area that once was the Lacus Ligustinus, between the Huelva, Cádiz and Seville provinces, and speculated that Atlantis had been destroyed by a tsunami, extrapolating results from a previous study by Spanish researchers, published four years earlier.
Spanish scientists have dismissed Freund's speculations, claiming that he sensationalised their work. The anthropologist Juan Villarías-Robles, who works with the Spanish National Research Council, said, "Richard Freund was a newcomer to our project and appeared to be involved in his own very controversial issue concerning King Solomon's search for ivory and gold in Tartessos, the well documented settlement in the Doñana area established in the first millennium BC", and described Freund's claims as "fanciful".
A similar theory had previously been put forward by a German researcher, Rainer W. Kühne, but based only on satellite imagery and placing Atlantis in the Marismas de Hinojos, north of the city of Cádiz. Before that, the historian Adolf Schulten had stated in the 1920s that Plato had used Tartessos as the basis for his Atlantis myth.
The location of Atlantis in the Atlantic Ocean has a certain appeal given the closely related names. Popular culture often places Atlantis there, perpetuating the original Platonic setting. Several hypotheses place the sunken island in northern Europe, including Doggerland in the North Sea, and Sweden (by Olof Rudbeck in "Atland", 1672–1702). Doggerland, as well as Viking Bergen Island, is thought to have been flooded by a megatsunami following the Storegga slide c. 6100 BCE. Some have proposed the Celtic Shelf as a possible location, and that there is a link to Ireland.
The Canary Islands and Madeira Islands have also been identified as a possible location, west of the Straits of Gibraltar but in relative proximity to the Mediterranean Sea. Various islands or island groups in the Atlantic were also identified as possible locations, notably the Azores. However detailed geological studies of the Canary Islands, the Azores, Madeira, and the ocean bottom surrounding them found a complete lack of any evidence for the catastrophic subsidence of these islands at any time during their existence and a complete lack of any evidence that the ocean bottom surrounding them was ever dry land at any time in the recent past, with the exception of what appeared to be beaches. The submerged island of Spartel near the Strait of Gibraltar has also been suggested.
Other locations.
Several writers have speculated that Antarctica is the site of Atlantis, while others have proposed Caribbean locations such the alleged Cuban sunken city off the Guanahacabibes peninsula in Cuba, the Bahamas, and the Bermuda Triangle. Areas in the Pacific and Indian Oceans have also been proposed including Indonesia (i.e. Sundaland). Likewise some have speculated that the continent of South America bears striking similarities to the description of Atlantis by Plato, particularly the Altiplano region of the Andes. The stories of a lost continent off the coast of India, named "Kumari Kandam," have inspired some to draw parallels to Atlantis.
See also.
Underwater geography:
Ancient sites:
General:

</doc>
<doc id="2179" url="http://en.wikipedia.org/wiki?curid=2179" title="Autobiography">
Autobiography

An autobiography (from the Greek, αὐτός-"autos" self + βίος-"bios" life + γράφειν-"graphein" to write) is a written account of the life of a person written by that person.
Origin of the term.
The word 'autobiography' was first used deprecatingly by William Taylor in 1797 in the English periodical the "Monthly Review", when he suggested the word as a hybrid but condemned it as 'pedantic'; but its next recorded use was in its present sense by Robert Southey in 1809. The form of autobiography however goes back to antiquity. Biographers generally rely on a wide variety of documents and viewpoints; an autobiography, however, may be based entirely on the writer's memory. Closely associated with autobiography (and sometimes difficult to precisely distinguish from it) is the form of memoir.
"See also: List of autobiographies and :Category:Autobiographies for examples." -
Autobiography through the ages.
The classical period: Apologia, oration, confession.
In antiquity such works were typically entitled "apologia," purporting to be self-justification rather than self-documentation. John Henry Newman's autobiography (first published in 1864) is entitled "Apologia Pro Vita Sua" in reference to this tradition.
The pagan rhetor Libanius (c. 314–394) framed his life memoir ("Oration I" begun in 374) as one of his orations, not of a public kind, but of a literary kind that could not be aloud in privacy.
Augustine (354–430) applied the title "Confessions" to his autobiographical work, and Jean-Jacques Rousseau used the same title in the 18th century, initiating the chain of confessional and sometimes racy and highly self-critical, autobiographies of the Romantic era and beyond.
In the spirit of Augustine's "Confessions" is the 12th-century "Historia Calamitatum" of Peter Abelard, outstanding as an autobiographical document of its period.
Early autobiographies.
The first autobiographical work in Islamic society was written in the late 11th century, by Abdallah ibn Buluggin, last Zirid king of Granada.
In the 15th century, Leonor López de Córdoba, a Spanish noblewoman, wrote her "Memorias", which may be the first autobiography in Castillian.
Zāhir ud-Dīn Mohammad Bābur,who founded the Mughal dynasty of South Asia kept a journal "Bāburnāma" (Chagatai/; literally: ""Book of Babur"" or ""Letters of Babur"") which was written between 1493 and 1529.
One of the first great autobiographies of the Renaissance is that of the sculptor and goldsmith Benvenuto Cellini (1500–1571), written between 1556 and 1558, and entitled by him simply "Vita" (Italian: "Life"). He declares at the start: "No matter what sort he is, everyone who has to his credit what are or really seem great achievements, if he cares for truth and goodness, ought to write the story of his own life in his own hand; but no one should venture on such a splendid undertaking before he is over forty." These criteria for autobiography generally persisted until recent times, and most serious autobiographies of the next three hundred years conformed to them.
Another autobiography of the period is "De vita propria", by the Italian mathematician, physician and astrologer Gerolamo Cardano (1574).
The earliest known autobiography in English is the early 15th-century "Book of Margery Kempe", describing among other things Kempe's pilgrimage to the Holy Land and visit to Rome. The book remained in manuscript and was not published until 1936.
Notable English autobiographies of the 17th century include those of Lord Herbert of Cherbury (1643, published 1764) and John Bunyan ("Grace Abounding to the Chief of Sinners", 1666).
Memoirs.
A memoir is slightly different in character from an autobiography. While an autobiography typically focuses on the "life and times" of the writer, a memoir has a narrower, more intimate focus on his or her own memories, feelings and emotions. Memoirs have often been written by politicians or military leaders as a way to record and publish an account of their public exploits. 
One early example is that of Julius Caesar's "Commentarii de Bello Gallico", also known as "Commentaries on the Gallic Wars". In the work, Caesar describes the battles that took place during the nine years that he spent fighting local armies in the Gallic Wars. His second memoir, "Commentarii de Bello Civili" (or "Commentary on the Civil War") is an account of the events that took place between 49 and 48 BC in the civil war against Gnaeus Pompeius and the Senate.
Leonor López de Córdoba (1362–1420) wrote what is supposed to be the first autobiography in Spanish. The English Civil War (1642–1651) provoked a number of examples of this genre, including works by Sir Edmund Ludlow and Sir John Reresby. French examples from the same period include the memoirs of Cardinal de Retz (1614–1679) and the Duc de Saint-Simon.
18th and 19th centuries.
Notable 18th-century autobiographies in English include those of Edward Gibbon and Benjamin Franklin. Following the trend of Romanticism, which greatly emphasised the role and the nature of the individual, and in the footsteps of Jean-Jacques Rousseau's "Confessions", a more intimate form of autobiography, exploring the subject's emotions, came into fashion. An English example is William Hazlitt's "Liber Amoris" (1823), a painful examination of the writer's love-life.
With the rise of education, cheap newspapers and cheap printing, modern concepts of fame and celebrity began to develop, and the beneficiaries of this were not slow to cash in on this by producing autobiographies. It became the expectation—rather than the exception—that those in the public eye should write about themselves—not only writers such as Charles Dickens (who also incorporated autobiographical elements in his novels) and Anthony Trollope, but also politicians (e.g. Henry Brooks Adams), philosophers (e.g. John Stuart Mill), churchmen such as Cardinal Newman, and entertainers such as P. T. Barnum. Increasingly, in accordance with romantic taste, these accounts also began to deal, amongst other topics, with aspects of childhood and upbringing—far removed from the principles of "Cellinian" autobiography.
20th and 21st centuries.
From the 17th century onwards, "scandalous memoirs" by supposed libertines, serving a public taste for titillation, have been frequently published. Typically pseudonymous, they were (and are) largely works of fiction written by ghostwriters. So-called "autobiographies" of modern professional athletes and media celebrities—and to a lesser extent about politicians, generally written by a ghostwriter, are routinely published. Some celebrities, such as Naomi Campbell, admit to not having read their "autobiographies".. Some sensationalist autobiographies such as James Frey's "A Million Little Pieces" have been publicly exposed as having embellished or fictionalized significant details of the authors' lives.
Autobiography has become an increasingly popular and widely accessible form. With the critical and commercial success in the United States of such memoirs as "Angela’s Ashes" and "The Color of Water", more and more people have been encouraged to try their hand at this genre.
Victims and opponents of totalitarian and other governmental regimes have been able to present striking critiques of these regimes through autobiographical accounts of their experience. Among such works are the writings of Primo Levi, one of many personal accounts of the Shoah. Similarly, there are many works detailing atrocities and malevolence of Communist regimes (e.g., Nadezhda Mandelstam's "Hope against Hope").
Nature of autobiography.
Autobiographical works are by nature subjective. The inability—or unwillingness—of the author to accurately recall memories has in certain cases resulted in misleading or incorrect information. Some sociologists and psychologists have noted that autobiography offers the author the ability to recreate history.
Fictional autobiography.
The term "fictional autobiography" signifies novels about a fictional character written as though the character were writing their own autobiography, meaning that the character is the first-person narrator and that the novel addresses both internal and external experiences of the character. Daniel Defoe's "Moll Flanders" is an early example. Charles Dickens' "David Copperfield" is another such classic, and J.D. Salinger's "The Catcher in the Rye" is a well-known modern example of fictional autobiography. Charlotte Brontë's "Jane Eyre" is yet another example of fictional autobiography, as noted on the front page of the original version. The term may also apply to works of fiction purporting to be autobiographies of real characters, e.g., Robert Nye's "Memoirs of Lord Byron".

</doc>
<doc id="2180" url="http://en.wikipedia.org/wiki?curid=2180" title="Arcadius">
Arcadius

Arcadius (; ; 377/378 – 1 May 408) was Eastern Roman Emperor from 395 to 408. He was the eldest son of Theodosius I and his first wife Aelia Flaccilla, and brother of the Western Emperor Honorius. A weak ruler, his reign was dominated by a series of powerful ministers and by his wife, Aelia Eudoxia.
History.
Arcadius was born in Hispania, the elder son of Theodosius I and Aelia Flaccilla, and brother of Honorius, who would become a Western Roman Emperor. His father declared him an Augustus and co-ruler for the Eastern half of the Empire in January 383. His younger brother was also declared Augustus in 393, for the Western half.
As emperors, Honorius was under the control of the Romanized Vandal "magister militum" Flavius Stilicho while Arcadius was dominated by one of his ministers, Rufinus. Stilicho is alleged by some to have wanted control of both Emperors, and is supposed to have had Rufinus assassinated by Gothic mercenaries in 395; though definite proof of Stilicho's involvement in the assassination is lacking, the intense competition and political jealousies engendered by the two figures compose the main thread of the first part of Arcadius' reign. Arcadius' new advisor, the eunuch Eutropius, simply took Rufinus' place as the power behind the Eastern imperial throne.
Arcadius was also dominated by his wife Aelia Eudoxia, who convinced her husband to dismiss Eutropius, who was holding the consulate, at the height of his power, in 399. That same year, on 13 July, Arcadius issued an edict ordering that all remaining non-Christian temples should be immediately demolished.
Eudoxia's influence was strongly opposed by John Chrysostom, the Patriarch of Constantinople, who felt that she had used her family's wealth to gain control over the Emperor. Eudoxia used her influence to have Chrysostom deposed in 404, but she died later that year. Eudoxia gave to Arcadius four children: three daughters, Pulcheria, Arcadia and Marina, and one son, Theodosius, the future Emperor Theodosius II.
Arcadius was dominated for the rest of his rule by Anthemius, the Praetorian Prefect, who made peace with Stilicho in the West. Arcadius himself was more concerned with appearing to be a pious Christian than he was with political or military matters, and he died, only nominally in control of his Empire, in 408.
Character and works.
In this reign of a weak Emperor dominated by court politics, a major theme was the ambivalence felt by prominent individuals and the court parties that formed and regrouped round them towards barbarians, which in Constantinople at this period meant Goths. In the well-documented episode that revolved around Gainas, a number of Gothic "foederati" stationed in the capital were massacred, the survivors fleeing under the command of Gainas to Thrace, where they were tracked down by imperial troops and slaughtered and Gainas dispatched. The episode has been traditionally interpreted as a paroxysm of anti-barbarian reaction that served to stabilize the East. The main source for the affair is a mythology "à clef" by Synesius of Cyrene, "Aegyptus sive de providentia", (400) an Egyptianising allegory that embodies a covert account of the events, the exact interpretation of which continues to baffle scholars. Synesius' "De regno", which claims to be addressed to Arcadius himself, contains a tirade against Goths.
A new forum was built in the name of Arcadius, on the seventh hill of Constantinople, the "Xērolophos", in which a column was begun to commemorate his 'victory' over Gainas (although the column was only completed after Arcadius' death by Theodosius II).
The Pentelic marble portrait head of Arcadius ("illustration") was discovered in Istanbul close to the Forum Tauri, in June 1949, in excavating foundations for new buildings of the University at Beyazit. The neck was designed to be inserted in a torso, but no statue, base or inscription was found. The diadem is a fillet with rows of pearls along its edges and a rectangular stone set about with pearls over the young Emperor's forehead.

</doc>
<doc id="2185" url="http://en.wikipedia.org/wiki?curid=2185" title="Arabs">
Arabs

Arabs (, "ʿarab"), also known as Arab people or Arabic-speaking people, are a major panethnic group. They primarily inhabit Western Asia, North Africa, parts of the Horn of Africa, and other areas in the Arab world.
Arabic-speaking populations in general are a highly heterogeneous collection of peoples, with different ancestral origins and identities. The ties that bind the Arab peoples are a veneer of shared heritage by virtue of common linguistic, cultural, and political traditions. As such, Arab identity is based on one or more of genealogical, linguistic or cultural grounds, although with competing identities often taking a more prominent role, based on considerations including regional, national, clan, kin, sect, and tribe affiliations and relationships. If the Arab panethnicity is regarded as a single population, then it constitutes one of the world's largest groups after Han Chinese.
The Arabian Peninsula itself was not entirely originally Arab, Arabization occurred in some parts of the Arabian Peninsula. For example, the language shift to Arabic displaced the indigenous South Semitic Old South Arabian languages of modern-day Yemen and southern Oman. These were the languages spoken in the civilisations of Sheba, Ubar, Magan, Dilmun, and Meluhha—which were spread via migrants from the Arabian peninsula, together with written script, in the 8th and 7th centuries BC to the Horn of Africa (Ethiopia, Eritrea, Somalia, and Djibouti).
Name.
Originally, "Arabs" were synonymous with Arabians (inhabitants of the Arabian Peninsula), until the Arabisation of people with no Arabian ancestry, mostly during the Abbasid Caliphate. Therefore all uses of the word "Arab" prior to the 7th century, and most those prior to the 13th century AD refer specifically to Arabians. Later uses of the word "Arab" could refer to anyone whose part of the wider linguistic and panethnic definitions of Arabs.
The earliest documented use of the word "Arab" to refer to a people appears in the Monolith Inscription, an Akkadian language record of the 9th century BC Assyrian Conquest of Syria, which referred to Bedouins under King Gindibu who fought as part of a coalition opposed to the Assyrians. Listed among the booty captured by the army of king Shalmaneser III of Assyria in the Battle of Qarqar are 1000 camels of "Gi-in-di-bu'u the ar-ba-a-a" or "man Gindibu belonging to the "ʕarab"" ("ar-ba-a-a" being an adjectival nisba of the noun "ʕarab"). "ʕarab", with the Arabic letter "alif" in the second syllable, is still used today to describe Bedouins today, distinguishing them from "ʕrab", used to describe non-Bedouin Arabic speakers.
The most popular Arab account holds that the word 'Arab' came from an eponymous father called Yarab, who was supposedly the first to speak Arabic. Al-Hamdani had another view; he states that Arabs were called Gharab (West in Semitic) by Mesopotamians because Bedouins originally resided to the west of Mesopotamia; the term was then corrupted into Arab. Yet another view is held by Al-Masudi that the word Arabs was initially applied to the Ishmaelites of the "Arabah" valley.
In Biblical etymology, "Arab" (in Hebrew "Arvi" ) comes both from the desert origin of the Bedouins it originally described ("Arava" means wilderness) and/or from the concept of mixed people. ("Arev-rav" - a large group of mixed people.) The root "a-r-b" has several additional meanings in Semitic languages—including "west/sunset," "desert," "mingle," "merchant," and "raven"—and are "comprehensible" with all of these having varying degrees of relevance to the emergence of the name. It is also possible that some forms were metathetical from "moving around" (Arabic "traverse"), and hence, it is alleged, "nomadic."
Identity.
Arab identity is defined independently of religious identity, and pre-dates the spread of Islam, with historically attested Arab Christian kingdoms and Arab Jewish tribes. Today, however, most Arabs are Muslim.), with a minority adhering to other faiths, largely Christianity, but also Druze and Baha'i.
Arabs are generally Sunni, Shia or Sufi Muslims, but currently, 7.1 percent to 10 percent of Arabs are Arab Christians. This figure includes only Christians whose primary community language is today a variety of Arabic, and who identify as Arab.
Arab ethnic identity does not include Christian and other ethnic groups that retain non-Arabic languages and identities within the expanded Arab World. These include the Assyrians of Iraq and north east Syria, Armenians around the entire Near East, and Mandeans in Iraq—though many of these peoples speak Arabic as a first or second language. In addition, many Egyptian Copts and Lebanese Maronites espouse an Ancient Egyptian and Phoenician-Canaanite identity respectively, rather than an Arab one. A number of other peoples living in the Arab World are non-Arab, such as; Berbers, Kurds, Turks, Iranians, Azeris, Circassians, Shabaks, Turcomans, Romani, Chechens, Mhallami, Africans, South Asians, Samaritans, and Jews.
Today, the main unifying characteristic among Arabs is the Arabic language, a South Semitic language from the Afroasiatic language family. Modern Standard Arabic serves as the standardized and literary variety of Arabic used in writing, as well as in the most formal speech, although it is not spoken natively by the overwhelming majority of Arabs. Most Arabs who are functional in Modern Standard Arabic acquire it as a second language through education, while various varieties of Arabic are spoken as vernaculars by each distinct Arab group. Due to sociolinguistic reasons stemming from pan-Arab political and social considerations, however, these varieties are often regarded dialects rather than independent languages, despite the fact that most varieties of Arabic are not mutually intelligible, whether with each other or to Modern Standard Arabic. By contrast, neither the Maltese language is referred to as a variety of Arabic, nor are the Maltese people Arabs, despite the fact that the Maltese language is philologically a variety of Arabic in no greater or lesser extent than any of the other thus-defined Arabic varieties (sharing intelligibility with Tunisian Arabic), in addition to Malta itself lying on the African tectonic plate along with the other Arab-defined countries of North Africa. This anomaly owes to modern-day Malta being politically aligned and within the cultural sphere of influence of Europe rather than the Arab world, as was the case in Malta's earlier history.
During the Bronze Age, Iron Age and Classical Era there was no Arab presence in the areas encompassed by modern Iraq, Syria, Egypt, Jordan, Lebanon, Palestine, Iran, North Africa, Asia Minor or Kuwait.
The Arabs are first mentioned in the mid 9th century BC as a tribal people dwelling in the mid Arabian Peninsula subjugated by the north Mesopotamian based Assyrians. The Arabs appear to have remained largely under the vassalage of the Neo-Assyrian Empire (911-605 BC), and then the succeeding Neo-Babylonian Empire (605-539 BC), Persian Achaemenid Empire (539-332 BC), Greek Macedonian/Seleucid Empire and Iranian Parthian Empires.
Arab tribes, most notably the Ghassanids and Lakhmids begin to appear in the south Syrian deserts and southern Jordan from the mid 3rd century AD onwards, during the mid to later stages of the Roman Empire and Sassanid Empire. The Nabateans of Jordan appear to have been an Aramaic speaking ethnic mix of Canaanites, Arameans and Arabs. Thus, although a more limited difussion of Arabic culture and language was felt in some areas by these migrant minority Arabs in "pre-Islamic" times through Arab Christian kingdoms and Arab Jewish tribes, it was only after the rise of Islam in the mid-7th century that Arab culture, people and language began their wholesale spread from the central Arabian Peninsula (including the Syrian desert) through conquest and trade.
At the time of the Arab Muslim conquests of the 7th and 8th centuries AD, the population of Aramea and Phoenicia (modern Syria and Lebanon) was largely Aramean and Phoenician, with minorities of Greeks, Assyrians, Armenians and Romans also extant, as well as pre-Islamic Arabs in the south Syrian deserts. Israel-Palestine (ancient Israel, Judah and Samarra) and Jordan (ancient Moab, Edom and Ammon) were largely inhabited by native Jews, Samaritans, and other Canaanites, together with Arameans, Greeks and Nabateans. Egypt was largely populated by natives of Ancient Egyptian heritage together with a Greek minority, what had been Phoenician Carthage (modern Tunisia) by its mixed Phoenician-Berber population. A number of Germanic peoples such as the Vandals and Visigoths were also extant as rulers throughout North Africa (modern Libya, Algeria, Tunisia and Morocco) at this time.
Arab cultures went through a mixing process. Therefore, every Arab country has cultural specificities that form a cultural mix that incorporates local novelties acquired after arabization. However, all Arab countries do also share a common culture in arts (music, literature, poetry, calligraphy...), cultural products (handicrafts, carpets, henne, bronze carving...), social behaviour, and relations (hospitality, codes of conduct among friends and family...), customs and superstitions, some dishes (Shorba, mloukhia), traditional clothing, and architecture.
Non-Arab Muslims, who are about 80 percent of the world's Muslim population, do not form part of the Arab world, but instead comprise what is the geographically larger, and more diverse, Muslim World.
In the USA, Arabs are classified as white by the U.S. Census, and have been since 1997.
Arabic, the main unifying feature among Arabs, is a Semitic language originating in Arabia. From there it spread to a variety of distinct peoples across most of West Asia and North Africa, resulting in their acculturation and eventual denomination as Arabs. Arabization, a culturo-linguistic shift, was often, though not always, in conjunction with Islamization, a religious shift.
With the rise of Islam in the 7th century, and as the language of the Qur'an, Arabic became the lingua franca of the Islamic world. It was in this period that Arabic language and culture was widely disseminated with the early Islamic expansion, both through conquest and cultural contact.
Arabic culture and language, however, began a more limited diffusion before the Islamic age, first spreading in West Asia beginning in the 2nd century, as Arab Christians such as the Ghassanids, Lakhmids and Banu Judham began migrating north from Arabia into the Syrian Desert, south western Iraq and the Levant.
In the modern era, defining who is an Arab is done on the grounds of one or more of the following two criteria:
The relative importance of these factors is estimated differently by different groups and frequently disputed. Some combine aspects of each definition, as done by Palestinian Habib Hassan Touma, who defines an "Arab" "in the modern sense of the word", as "one who is a national of an Arab state, has command of the Arabic language, and possesses a fundamental knowledge of Arab tradition, that is, of the manners, customs, and political and social systems of the culture." Most people who consider themselves Arab do so based on the overlap of the political and linguistic definitions.
The Arab League, a regional organization of countries intended to encompass the Arab world, defines an Arab as:
According to Sadek Jawad Sulaimanis the former Ambassador of Oman to the United States:
The relation of ' and ' is complicated further by the notion of "lost Arabs" "" mentioned in the Qur'an as punished for their disbelief. All contemporary Arabs were considered as descended from two ancestors, Qahtan and Adnan.
Versteegh (1997) is uncertain whether to ascribe this distinction to the memory of a real difference of origin of the two groups, but it is certain that the difference was strongly felt in early Islamic times. Even in Islamic Spain there was enmity between the Qays of the northern and the Kalb of the southern group. The so-called Sabaean or Himyarite language described by Abū Muhammad al-Hasan al-Hamdānī (died 946) appears to be a special case of language contact between the two groups, an originally north Arabic dialect spoken in the south, and influenced by Old South Arabian.
During the Muslim conquests of the 7th and 8th centuries, the Arabs forged an Arab Empire (under the Rashidun and Umayyads, and later the Abbasids) whose borders touched southern France in the west, China in the east, Asia Minor in the north, and the Sudan in the south. This was one of the largest land empires in history. In much of this area, the Arabs spread Islam and the Arabic culture, science, and language (the language of the Qur'an) through conversion and cultural assimilation.
Two references valuable for understanding the political significance of Arab identity: Michael C. Hudson, Arab Politics: The Search for Legitimacy (Yale University Press, 1977), especially Chs. 2 and 3; and Michael N. Barnett, Dialogues in Arab Politics: Negotiations in Regional Order (Columbia University Press, 1998).
Subgroups.
While Pan-Arabism and Arab nationalism subsume all Arabic-speaking populations under the notion of "Arabs", there are numerous sub-divisions, not all of which necessarily identify as ethnically Arab.
The Arabians form a strict subset of the ethnolinguistic group of "Arabs" discussed here. The name of "Arab" historically was synonymous with Bedouin. Although, most Arabians were sedentary (not nomadic) in pre-Islamic times.
In some parts of the Arab World, the term "Arab" may still carry connotations of being Arabian, conflicting with the Pan-Arabist concept of ethnicity.
Arabians are most prevalent in the Arabian Peninsula, but are also found in large numbers in Mesopotamia (Arab tribes in Iraq), the Levant and Sinai (Negev Bedouin, Tarabin bedouin), as well as North Africa and the Sudan region.
Arabs in the narrow sense are the indigenous Arabians (who trace their roots back to the tribes of Arabia) and their immediate descendant groups in the Levant and North Africa. Within the people of the Arabian Peninsula, distinction is made between:
This traditional division of the Arabs of Arabia may have arisen at the time of early Muslim factional infighting during the Umayyad Caliphate.
Contrary to popular belief, most Arabians were sedentary (not nomadic) in pre-Islamic times.
Of the Arabian tribes that interacted with Muhammad, the most prominent was Banu Quraish. The Qur'aish sub-clan of Banu Hashim was the clan of Muhammad.
During the period of Muslim conquests and the Golden Age of Islam, the political rulers of Islam were exclusively members of the Banu Quraish tribe.
The 150 Arab tribes in Iraq are grouped into federations ("qabila"), and divided into clans ("fukhdh"). The so-called Marsh Arabs of southern Iraq consist of numerous tribes, partly within the large Al-Muntafiq tribal alliance.
Iranian Arabs form a 2% minority in Iran. The largest group are the Ahwazi Arabs, including Banu Kaab, Bani Turuf and the Musha'sha'iyyah sect
. Smaller groups are the Khamseh nomads in Fars Province and the Arabs in Khorasan.
The Arabs of the Levant are traditionally divided into Qays and Yaman tribes. This tribal division is likewise taken ot date to the Umayyad period.
The Yaman trace their origin to South Arabia or Yemen; they include Banu Kalb, Kindah, Ghassanids, and Lakhmids.
Since the 1834 Arab revolt in Palestine, the Arabic-speaking population of Palestine has shed its formerly tribal structure and emerged as the Palestinian people.
The Bedouin of western Egypt and eastern Libya are traditionally divided into Sa`ada and Murabtin, the Sa`ada group having higher social status. This may derive from a historical feudal system in which the Murabtin were vassals to the Sa`ada.
With the Muslim conquest of North Africa and the Sudan region, amalgamated populations emerged, now sometimes summarized under the terms Arab-Berber, Arabized Berber and Afro-Arab.
Egyptians are Arabic-speaking, but the question of their idenfitication as ethnically Arab has a long and complicated history of controversy.
The Arabic-speaking population of the Maghreb (Libyans, Algerians, Moroccans, Tunisians) is loosely divided into Arab-Berber for people of mixed Arab-Berber descent who embrace an Arab identity, and Arabized Berber for people of predominantly North African ancestry who retain a regional identity.
In Sudan, there are numerous Arab tribes, including the Shaigya, Ja'alin, Shukria, Rashaida, etc. in addition, there are Arabized or partially Arabized ethnic groups such as the Nubians, Copts, or Beja; they are sometimes united under the umbrella term of Sudanese Arabs.
Arab slave trade in the Sudan region and West Africa created a clean division between Arabs and indigenous populations, and slavery in contemporary Africa substantially persists along these lines, contributing to ethnic conflict in the region, such as the internal conflicts in Sudan, Northern Mali conflict, or the Islamist insurgency in Northern Nigeria.
Demographics.
The total number of Arabic speakers living in the Arab nations is
estimated at 366 million by the CIA Factbook (as of 2014).
The estimated number of Arabs in countries outside the Arab League is estimated at 17.5 million, yielding a total of close to 384 million.
According to the International Organization for Migration, there are 13 million first-generation Arab migrants in the world, of which 5.8 reside in Arab countries, yielding a total of about 7 million people in the Arab diaspora.
Arab world.
The table below shows the number of Arabic speaking people, including expatriates and some groups that may not be identified as ethnically Arab.
Migration and diaspora.
According to the International Organization for Migration, there are 13 million first-generation Arab migrants in the world, of which 5.8 reside in Arab countries. Arab expatriates contribute to the circulation of financial and human capital in the region and thus significantly promote regional development. In 2009 Arab countries received a total of 35.1 billion USD in remittance in-flows and remittances sent to Jordan, Egypt and Lebanon from other Arab countries are 40 to 190 per cent higher than trade revenues between these and other Arab countries.
The 250,000 strong Lebanese community in West Africa is the largest non-African group in the region.
Arab traders have long operated in Southeast Asia and along the East Africa's Swahili coast. Zanzibar was once ruled by Omani Arabs. Most of the prominent Indonesians, Malaysians, and Singaporeans of Arab descent are Hadhrami people with origins in southern Yemen in the Hadramawt coastal region.
Central Asia and Caucasus
In 1728, a Russian officer described a group of Sunni Arab nomads who populated the Caspian shores of Mughan (in present-day Azerbaijan) and spoke a mixed Turkic-Arabic language. It is believed that these groups migrated to the Caucasus in the 16th century. The 1888 edition of Encyclopædia Britannica also mentioned a certain number of Arabs populating the Baku Governorate of the Russian Empire. They retained an Arabic dialect at least into the mid-19th century, but since then have fully assimilated with the neighbouring Azeris and Tats. Today in Azerbaijan alone, there are nearly 30 settlements still holding the name "Arab" (for example, Arabgadim, Arabojaghy, Arab-Yengija, etc.).
From the time of the Arab conquest of the Caucasus, continuous small-scale Arab migration from various parts of the Arab world occurred in Dagestan, which influenced local culture. Until the mid-20th century, some individuals in Dagestan still claimed Arabic as their native language. The majority of these lived in the village of Darvag, to the north-west of Derbent. The latest of these accounts dates to the 1930s. Most Arab communities in southern Dagestan underwent linguistic Turkicisation, thus nowadays Darvag is a majority-Azeri village.
According to the "History of Ibn Khaldun", the Arabs that were once in Central Asia have been either killed or have fled the Tatar invasion of the region, leaving only the locals. However, today many people in Central Asia identify as Arabs. Most Arabs of Central Asia are fully integrated into local populations, and sometimes call themselves the same as locals (for example, Tajiks, Uzbeks) but they use special titles to show their Arabic origin such as Sayyid, Khoja or Siddiqui.
Iranian Arab communities are also found in Khuzestan Province.
South Asia
There are only two communities with the self-identity Arab in India, the Chaush of the Deccan region and the Chavuse of Gujerat, who are by and large descended of Hadhrami migrants who settled in these two regions in the 18th Centuries. However, both these communities no longer speak Arabic, although with the Chaush, there has been re-immigration to the Gulf States, and re-adoption of Arabic by these immigrants. In South Asia, claiming Arab ancestry is considered prestigious, and many communities have origin myths with claim to an Arab ancestry. Examples include the Mappilla of Kerala, Labbai of Tamil Nadu and Kokan of Maharashtra. These communities all allege an Arab ancestry, but none speak Arabic and follow the customs and traditions of the Hindu majority. Among Muslims of North India and Pakistan there are groups who claim the status of Sayyid, have origin myths that allege descent from the Prophet Mohammmad. None of these Sayyid families speak Arabic or follow Arab customs or traditions.
Ceylon Moors are “the descendants of Arab traders (mainly from Hadhramawt in Yemen and Morocco) who espoused local women. They are a mixed race with Arab dominance and a considerable infusion of Sinhalese and Dravidian blood.” The later generation Arab traders married the descendants of the Arab settlers. Some families trace their ancestry to prominent Arab tribes like Banu Quraysh and Arab personalities like Caliph Abu Bakr As Siddiq, Prince Jamaldeen of Konya etc.
“The epithet (Moor), was borrowed (from the Spaniards) by the Portuguese, (the earliest colonizers of ‘Ceylon’ – as Sri Lanka was then known) who, after their discovery of the passage by the Cape of Good Hope, bestowed it indiscriminately upon the Arabs and their descendants, whom in the sixteenth century, found established as traders in every port on the Asian and African coast, and who had good reason to regard them as their most formidable competitors for the commerce of the East."
Alexander Johnston has recorded that:
"...the first Muslims who settled in the country, were, according to the tradition which prevails among their descendants, a portion of those Arabs of the House of Hashim who were driven from Arabia in the early part of the eighth century by the Umayyad Caliph Abd-al Malik bin Marwan, and who proceeding from the Euphrates southward, established settlements in the Concan, the southern parts of the Indian peninsula, Sri Lanka and Malacca. He adds that the division of them that came to Sri Lanka formed eight considerable settlements.”
Hussein says:
"Although it is likely that it was Arabic that was the spoken language of the early Arab settlers of the country, and perhaps of the early Moors whom they sired, it is today largely Arab Tamil getting replaced by Sinhala, as the ‘home language’, so to say, of the present-day Moor community. Arabic is today employed by them only as their liturgical language in their prayers and other religious observances. Arab Tamil is by far the predominant speech of the Moors.
"The Tamil spoken by the Moors is however not quite the same as the Tamil spoken by the Tamils of Jaffna and South India. Indeed, this peculiar dialect or rather patois of the Moors is derogatorily referred to as ‘Sona Tamil’ by conservative Tamil folk. This Sona Tamil speech seems to have largely derived from a South Indian Tamil patois...
"It has also been considerably influenced by other languages such as Arabic, Hindustani, and Sinhala, all of which goes on to show that it approaches a sort of Creole, albeit considerably influenced by a Tamil dialect ...”
History.
Pre-Islamic.
Pre-Islamic Arabia refers to Arabic civilization in the Arabian Peninsula before the rise of Islam in the 630s. The study of Pre-Islamic Arabia is important to Islamic studies as it provides the context for the development of Islam.
Semitic origin.
There is a consensus that the Semitic peoples originated on the Arabian Peninsula. It should be pointed out that these settlers were not Arabs or Arabic speakers. Early non-Arab Semitic peoples from the Ancient Near East, such as the Arameans, Akkadians (Assyrians and Babylonians), Amorites, Israelites, Eblaites, Ugarites and Canaanites, built civilizations in Mesopotamia, Eastern Arabia and the Levant; genetically, they often interlapped and mixed. Slowly, however, they lost their political domination of the Near East due to internal turmoil and attacks by non-Semitic peoples. Although the Semites eventually lost political control of Western Asia to the Persian Empire, the Aramaic language remained the lingua franca of Assyria, Mesopotamia and the Levant. Aramaic itself was replaced by Greek as Western Asia's prestige language following the conquest of Alexander the Great, though it survives to this day among Assyrian Christians (aka Chaldo-Assyrians) and Mandeans in Iraq, northeast Syria, southeast Turkey and northwest Iran.
Early history.
The first written attestation of the ethnonym "Arab" occurs in an Assyrian inscription of 853 BCE, where Shalmaneser III lists a King Gindibu of "mâtu arbâi" (Arab land) as among the people he defeated at the Battle of Karkar. Some of the names given in these texts are Aramaic, while others are the first attestations of Ancient North Arabian dialects. In fact several different ethnonyms are found in Assyrian texts that are conventionally translated "Arab": "Arabi, Arubu, Aribi" and "Urbi". Many of the Qedarite queens were also described as queens of the "aribi". The Hebrew Bible occasionally refers to "Aravi" peoples (or variants thereof), translated as "Arab" or "Arabian." The scope of the term at that early stage is unclear, but it seems to have referred to various desert-dwelling Semitic tribes in the Syrian Desert and Arabia. Arab tribes came into conflict with the Assyrians during the reign of the Assyrian king Ashurbanipal, and he records military victories against the powerful Qedar tribe among others.
Medieval Arab genealogists divided Arabs into three groups:
Ibn Khaldun's "Muqaddima" distinguishes between sedentary Arabian Muslims who used to be nomadic, and Bedouin nomadic Arabs of the desert. He used the term "formerly nomadic" Arabs and refers to sedentary Muslims by the region or city they lived in, as in Yemenis. The Christians of Italy and the Crusaders preferred the term Saracens for all the Arabs and Muslims of that time. The Christians of Iberia used the term Moor to describe all the Arabs and Muslims of that time.
Before Islam, most Arabs of the Arabian Peninsula were sedentary (not nomadic). Muslims of Medina referred to the nomadic tribes of the deserts as the A'raab, and considered themselves sedentary, but were aware of their close racial bonds. The term "A'raab' mirrors the term Assyrians used to describe the closely related nomads they defeated in Syria.
The Qur'an does not use the word ', only the nisba adjective '. The Qur'an calls itself ', "Arabic", and ', "clear". The two qualities are connected for example in ayat 43.2–3, "By the "clear" Book: We have made it an "Arabic" recitation in order that you may understand". The Qur'an became regarded as the prime example of the ', the language of the Arabs. The term "I`rab" has the same root and refers to a particularly clear and correct mode of speech. The plural noun ' refers to the Bedouin tribes of the desert who resisted Muhammad, for example in ayat 9.97, "" "the Bedouin are the worst in disbelief and hypocrisy".
Based on this, in early Islamic terminology, ' referred to the language, and ' to the Arab Bedouins, carrying a negative connotation due to the Qur'anic verdict just cited. But after the Islamic conquest of the 8th century, the language of the nomadic Arabs became regarded as the most pure by the grammarians following Abi Ishaq, and the term , "language of the Arabs", denoted the uncontaminated language of the Bedouins.
Classical kingdoms.
Proto-Arabic, or Ancient North Arabian, texts give a clearer picture of the Arabs' emergence. The earliest are written in variants of epigraphic south Arabian "musnad" script, including the 8th century BCE Hasaean inscriptions of eastern Saudi Arabia, the 6th century BCE Lihyanite texts of southeastern Saudi Arabia and the Thamudic texts found throughout Arabia and the Sinai (not in reality connected with Thamud).
The Nabataeans were nomadic newcomers who moved into territory vacated by the Edomites – Semites who settled the region centuries before them. Their early inscriptions were in Aramaic, but gradually switched to Arabic, and since they had writing, it was they who made the first inscriptions in Arabic. The Nabataean Alphabet was adopted by Arabs to the south, and evolved into modern Arabic script around the 4th century. This is attested by Safaitic inscriptions (beginning in the 1st century BCE) and the many Arabic personal names in Nabataean inscriptions. From about the 2nd century BCE, a few inscriptions from Qaryat al-Faw (near Sulayyil) reveal a dialect no longer considered "proto-Arabic", but "pre-classical Arabic". Five Syriac inscriptions mentioning Arabs have been found at Sumatar Harabesi, one of which dates to the 2nd century CE.
Late kingdoms.
The Ghassanids, Lakhmids and Kindites were the last major migration of non-Muslims out of Yemen to the north.
Greeks and Romans referred to all the nomadic population of the desert in the Near East as Arabi. The Romans called Yemen "Arabia Felix". The Romans called the vassal nomadic states within the Roman Empire "Arabia Petraea" after the city of Petra, and called unconquered deserts bordering the empire to the south and east Arabia Magna.
Islamic.
Arab Caliphate.
Rashidun Era (632-661)
After the death of Muhammad in 632, Rashidun armies launched campaigns of conquest, establishing the Caliphate, or Islamic Empire, one of the largest empires in history. It was larger and lasted longer than the previous Arab empires of Queen Mawia or the Palmyrene Empire, which was predominantly Syriac rather than Arab. The Rashidun state was a completely new state and not a mere imitation of the earlier Arab kingdoms such as the Himyarite, Lakhmids or Ghassanids, although it benefited greatly from their art, administration and architecture.
Umayyad Era (661-750)
In 661 the Caliphate fell into the hands of the Umayyad dynasty and Damascus was established as the Muslim capital. They were proud of their Arab ancestry and sponsored the poetry and culture of pre-Islamic Arabia. They established garrison towns at Ramla, ar-Raqqah, Basra, Kufa, Mosul and Samarra, all of which developed into major cities.
Caliph Abd al-Malik established Arabic as the Caliphate's official language in 686. This reform greatly influenced the conquered non-Arab peoples and fueled the Arabization of the region. However, the Arabs' higher status among non-Arab Muslim converts and the latter's obligation to pay heavy taxes caused resentment. Caliph Umar II strove to resolve the conflict when he came to power in 717. He rectified the disparity, demanding that all Muslims be treated as equals, but his intended reforms did not take effect, as he died after only three years of rule. By now, discontent with the Umayyads swept the region and an uprising occurred in which the Abbasids came to power and moved the capital to Baghdad.
Umayyads expanded their Empire westwards capturing North Africa from the Byzantines. Prior to the Arab conquest, North Africa was inhibited by various people including Punics, Vandals and Greeks. It was not until the 11th century that the Maghreb saw a large influx of ethnic Arabs. Starting with the 11th century, the Arab bedouin Banu Hilal tribes migrated to the West. Having been sent by the Fatimids to punish the Berber Zirids for abandoning Shias, they travelled westwards. The Banu Hilal quickly defeated the Zirids and deeply weakened the neighboring Hammadids. Their influx was a major factor in the Arabization of the Maghreb. Although Berbers ruled the region until the 16th century (under such powerful dynasties as the Almoravids, the Almohads, Hafsids, etc.), the arrival of these tribes eventually helped Arabize much of it ethnically, in addition to the linguistic and political impact local non-Arabs. With the collapse of the Umayyad state in 1031 AD, Islamic Spain was divided into small kingdoms.
Abbassid Era (750-1513)
The Abbasids let a revolt against the Umayyads and defeated them in the Battle of the Zab effectively ending their rule in all part of the Empire except Al-Andalus. The Abbasids were descendants of Muhammad's uncle Abbas, but unlike the Umayyads they had the support of non-Arab subjects of the Umayyads. The Abbasids ruled for 200 years before they lost their central control when Wilayas began to fracture; afterwards, in the 1190s, there was a revival of their power, which was ended by the Mongols, who conquered Baghdad and killed the Caliph. Members of the Abbasid royal family escaped the massacre and resorted to Cairo, which had broken from the Abbasid rule two years earlier; the Mamluk generals taking the political side of the kingdom while Abbasid Caliphs were engaged in civil activities and continued patronizing science, arts and literature.
Golden Age of Islam.
The Islamic Golden Age was inaugurated by the middle of the 8th century by the ascension of the Abbasid Caliphate and the transfer of the capital from Damascus to the newly founded city Baghdad. The Abbassids were influenced by the Qur'anic injunctions and hadith such as "The ink of the scholar is more holy than the blood of martyrs" stressing the value of knowledge. During this period the Muslim world became an intellectual centre for science, philosophy, medicine and education as the Abbasids championed the cause of knowledge and established the "House of Wisdom" (Arabic: بيت الحكمة) in Baghdad. Rival Muslim dynasties such as the Fatimids of Egypt and the Umayyads of al-Andalus were also major intellectual centres with cities such as Cairo and Córdoba rivaling Baghdad.
Ottoman Caliphate.
Arabs were ruled by Ottoman sultans from 1513 to 1918. Ottomans defeated the Mamluk Sultanate in Cairo, and ended the Abbasid Caliphate when they assumed the title of Caliph. Arabs did not feel the change of administration because the Ottomans modeled their rule after the previous Arab administration systems. After World War I when the Ottoman Empire was overthrown by the British Empire, former Ottoman colonies were divided up between the British and French as League of Nations mandates.
Modern.
Arabs in modern times live in the Arab world, which comprises 22 countries in the Middle East, North Africa, and parts of the Horn of Africa. They are all modern states and became significant as distinct political entities after the fall and dissolution of the Ottoman Empire (1908–1918).
Religion.
Arab Muslims are mostly Sunni with a minority of Shia, one exception being the Ibadis, who predominate in Oman and can be found as small minorities in Algeria and Libya (mostly Berbers). There are also a minority of Ahmadi Muslims. Arab Christians generally follow Eastern Churches such as the Greek Orthodox and Greek Catholic churches, though a minority of Protestant Church followers also exists; The Copts and the Maronites, who are often associated with Arab people as well, follow the Coptic Church and Maronite Church accordingly. In Iraq most Christians are Assyrians rather than Arabs, and follow the Assyrian Church of the East, Syriac Orthodox and Chaldean Church. The Greek Catholic church and Maronite church are under the Pope of Rome, and a part of the larger worldwide Catholic Church. There are also Arab communities consisting of Druze and Baha'is.
Christianity was the most common religion throughout all these regions at this time, although Judaism, Mandeanism, Sabianism, Manicheanism, Mithraism, Zoroastrianism, and remnants of Mesopotamian religion, Canaanite religion, Greco-Roman religion and Egyptian religion could still also be found. Linguistically, the major Semitic language prior to the Arab conquest was Aramaic, spoken in various forms.
Ancient times.
Before the coming of Islam, most Arabs followed a pagan religion with a number of deities, including Hubal, Wadd, Allāt, Manat, and Uzza. A few individuals, the "hanifs", had apparently rejected polytheism in favor of monotheism unaffiliated with any particular religion. Some tribes had converted to Christianity or Judaism. The most prominent Arab Christian kingdoms were the Ghassanid and Lakhmid kingdoms. When the Himyarite king converted to Judaism in the late 4th century, the elites of the other prominent Arab kingdom, the Kindites, being Himyirite vassals, apparently also converted (at least partly). With the expansion of Islam, polytheistic Arabs were rapidly Islamized, and polytheistic traditions gradually disappeared.
Islam.
Today, Sunni Islam dominates in most areas, overwhelmingly so in North Africa and the Horn of Africa. Shia Islam is dominant among the Arab population in Bahrain and Iraq. Substantial Shia populations exist in Lebanon, Yemen, Kuwait, Saudi Arabia, northern Syria and the al-Batinah region in Oman. There are small numbers of Ibadi, Ahmadi and non-denominational Muslims too.
Druze faith.
The Druze community is concentrated in Lebanon, Syria, Israel, and Jordan. Many Druze claim independence from other major religions in the area and consider their religion more of a philosophy. Their books of worship are called Kitab Al Hikma (Epistles of Wisdom). They believe in reincarnation and pray to five messengers from God. In Israel, the Druze have a "status aparte" from the general Arab population, treated as a separate ethno-religious community.
Christianity.
In pre-Islamic Arabia, Christianity had a prominent presence among several Arab communities, including the Bahrani people of Eastern Arabia, the Christian community of Najran, in parts of Yemen, and among certain northern Arabian tribes such as the Ghassanids, Lakhmids, Taghlib and Tayy.
Christians make up 5.5% of the population of the Middle East. A sizeable share of those are Arab Christians proper, and affiliated populations of Copts and Maronites. In Lebanon, Christians number about 39% of the population. In Syria, Christians make up 10% of the population. In West Bank and in Gaza Strip, Christians make up 8% and 0.7% of the populations, respectively. In Egypt, Coptic Christians number about 10% of the population. In Iraq, Christians constitute 0.1% of the population. In Israel, Arab Christians constitute 2.1% (roughly 9% of the Arab population). Arab Christians make up 8% of the population of Jordan. Most North and South American Arabs are Christian, as are about half of Arabs in Australia who come particularly from Lebanon, Syria and Israel. One well known member of this religious and ethnic community is Saint Abo, martyr and the patron saint of Tbilisi, Georgia. Arab Christians are living also in a holy Christian cities such as Nazareth, Bethlehem and the Christian Quarter of the Old City of Jerusalem and yes, in many other villages with holy Christian sites.
Judaism.
The Jewish tribes of Arabia were Arabian tribes professing the Jewish faith that inhabited the Arabian Peninsula before and during the advent of Islam. It is not always clear whether they were originally Israelite in ancestry, genealogically Arab tribes that converted to Judaism, or a mixture of both. In Islamic tradition the Jewish tribes of the Hejaz were seen as the offspring of the ancient Israelites. According to Muslim sources, they spoke a language other than Arabic, which Al-Tabari claims was Persian. This implies they were connected to the major Jewish center in Babylon. Certain Jewish traditions records the existence of nomadic tribes such as the Rechabites that converted to Judaism in antiquity. The tribes collapsed with the rise of Islam, with many either converting or fleeing the Arab peninsula. Some of those tribes are thought to have merged into Yemenite Jewish community, while others, like the residents of Yatta consider themselves Islamized descendants of Khaybar, a Jewish tribe of Arabia.
Prior to the massive Sephardic emigrations to the Middle East in the 16th and 17th centuries, the Jewish communities of what are today Syria, Iraq, Israel, Lebanon, Egypt and Yemen were known by other Jewish communities as Musta'arabi Jews or "like Arabs". Also, prior to the emergence of the term "Mizrahi", the term "Arab Jews" was sometimes used to describe Jews living in the Arab world. From the late 1940s to the early 1960s, following the creation of the state of Israel, most of descendants of these Jews fled or were expelled from their countries of birth and now live in Israel, France or elsewhere. The few remaining Jews in the Arab countries reside mostly in Morocco and Tunisia.
Modern Jews from Arab countries – mainly Mizrahi Jews, Yemenite Jews and Maghrebi Jews – are today usually not categorized as Arab, though there is still some debate on whether or not the term "Arabs" can be applied to them. Sociologist Sammy Smooha stated "This ("Arab Jews") term does not hold water. It is absolutely not a parallel to 'Arab Christian'". Those who dispute the historicity of the term make the claim that Middle Eastern Jews are similar to Kurds, Assyrians, Berbers and other ancient Middle Eastern groups, who lived among the Arab societies as distinct minority groups with distinct identity and therefore are not categorized as Arabs. On the other hand, others gives examples of periods where the term "Arab-Jews" was applied in one form or another. Sociologist Philip Mendes asserts that before the anti-Jewish actions of the 1930s and 1940s, overall Iraqi Jews "viewed themselves as Arabs of the Jewish faith, rather than as a separate race or nationality".
Culture.
Arab culture is a term that draws together the common themes and overtones found in the Arab countries, especially those of the Middle-Eastern countries. This region's distinct religion, art, and food are some of the fundamental features that define Arab culture.
Art.
Arabic Art includes a wide range or artistic components, it can be Arabic miniature, calligraphy or Arabesque.
Architecture.
Arab Architecture has a deep diverse history, it dates to the dawn of the history in pre-Islamic Arabia. Each of it phases largely an extension of the earlier phase, it left also heavy impact on the architecture of other nations.
Music.
Arabic music is the music of Arab people or countries, especially those centered on the Arabian Peninsula. The world of Arab music has long been dominated by Cairo, a cultural center, though musical innovation and regional styles abound from Morocco to Saudi Arabia. Beirut has, in recent years, also become a major center of Arabic music. Classical Arab music is extremely popular across the population, especially a small number of superstars known throughout the Arab world. Regional styles of popular music include Algerian raï, Moroccan gnawa, Kuwaiti sawt, Egyptian el gil and Arabesque-pop music in Turkey.
Most historians agree that distinct forms of music existed in the Arabian peninsula in the pre-Islamic period between the 5th and 7th century AD. Arab poets of that time—called shu`ara' al-Jahiliyah (شعراء الجاهلية) or "Jahili poets", meaning "the poets of the period of ignorance"—recited poems with a high note.
Tradition believes that Jinns revealed poems to poets, and music to musicians. The choir of the time was a pedagogic facility where educated poets recited poems. Singing was thought not the work of intellectuals, and was instead entrusted to women who learned to play instruments of the time, such as the drum, oud, or rebab, and perform the songs while respecting the poetic metre.
Literature.
There is a small remnant of pre-Islamic poetry, but Arabic literature predominantly emerges in the Middle Ages, during the Golden Age of Islam.
Literary Arabic is derived from Classical Arabic, based on the language of the Qu'ran as it was analyzed by Arabic grammarians beginning in the 8th century.
A large portion of Arabic literature prior to the 20th century is in the form of poetry, and even prose from this period is either filled with snippets of poetry or is in the form of "saj" or rhymed prose. 
The "ghazal" or love poem had a long history being at times tender and chaste and at other times rather explicit. In the Sufi tradition the love poem would take on a wider, mystical and religious importance. 
Arabic epic literature was much less common than poetry, and presumably originates in oral tradition, written down from the 14th century or so.
Maqama or rhymed prose is intermediate between poetry and prose, and also between fiction and non-fiction. Maqama was an incredibly popular form of Arabic literature, being one of the few forms which continued to be written during the decline of Arabic in the 17th and 18th centuries.
Arabic literature and culture declined significantly after the 13th century, to the benefit of Turkish and Persian.
A modern revival took place beginning in the 19th century, alongside 
resistance against Ottoman rule
The literary revival is known as "al-Nahda" in Arabic, and was centered in Egypt and Lebanon.
Two distinct trends can be found in the "nahda" period of revival. The first was a neo-classical movement which sought to rediscover the literary traditions of the past, and was influenced by traditional literary genres—such as the "maqama"—and works like "One Thousand and One Nights". In contrast, a modernist movement began by translating Western modernist works—primarily novels—into Arabic.
A tradition of modern Arabic poetry was established by writers such as Francis Marrash, Ahmad Shawqi and Hafiz Ibrahim.
Iraqi poet Badr Shakir al-Sayyab is considered to be the originator of free verse in Arabic poetry.
Genetics.
Y-Chromosome.
Haplogroup E1b1b is the most frequent haplogroup in Western Arabs (Maghrebis) while haplogroup J is the most frequent haplogroup in Eastern Arabs (Mashriq).
The paternal ancestry found across all Arabic countries is Haplogroup J1, especially its major subclade J-P58, the haplogroup that spread with Arabic conquest in the 7th century. It was found that Haplogroup J1 occur at high frequencies among the Arabic-speaking populations of the Middle East and is the prevalent Y-chromosome lineage within the Near East. Haplogroup J1e (J-P58) is also associated with a Semitic linguistic common denominator, with the YCAII 22-22 allele state is closely associated with J1e.
J-P58 subclade of J1 is the single paternal lineage originating in the Near East of high frequency in Bedouins 70%, Yemenis 68%, Jordanians 55%, 55% of Palestinian Arabs, 48% of Omani People 34% of Tunisians, 35% of Algerians
, and its precipitations drop in frequency as one moves away from Saudi Arabia and the Near East. J-P58 include all the J1-CMH haplotypes and is YCAII=22-22 motif, both are found in Arabs and J1-Cohanim (Y-chromosomal Aaron). The motif YCAII=22-22 characterize a monophyletic clad found in Arabs but less frequent in Ethiopian J1 and rare in Europe and Caucasus.
It has now been resolved that the Arabic clade J1-P58, L147.1 (the major clad of P58 and still the major clade of J1) include all CMH haplotypes and is YCAII=22-22 (both specific to Arabs and J1-Cohanim) was the J1 clade that spread far and wide by the Islamic conquest. Both Qahtanite and Adnanite Arabs are J1-P58 haplogroup since the Arabs of North Africa like Algeria (known to have Qahtanite lineage from the Arab conquest and Adnanite lineage from Bani Hilal and bani Sulaim migration to North Africa in the 10th century by the Fatimides, yet only E of the Berber and J1 are found in Arabs of North Africa and this J1 is marked by CMH and the motif YCAII=22-22. The J2 in Algerian Arabs is minor 3% and is of the rare J2-M67 of Chechnya, rarely found in other Arabic countries and non existent in Arabian Peninsula and Yemen.
The Arab conquest appears to have had a dramatic influence on the East and South Mediterranean coasts. The presence of Arab Y chromosome lineages in the Middle East suggests that most have experienced substantial gene flow from the Arabian peninsula.
Maternal Chromosome.
The Maternal ancestral lineages of Arabic countries are very diverse. The original Historical Maternal ancestral Haplogroups of the Near East were Mt (Maternal) L3 Haplogroup and Mt HV1 haplogroup that are still high in Yemen, while in Greater Syria there is a European Maternal gene flow. In the Arabic West the dominant Maternal lineage is the rare Scandinavian European U8 haplogroup probably came with the Vandals when escaped from Spain from the Visigoths.
Other Chromosomes.
Many of the pronounced genetic deficiencies in Arabs (causing genetic disorders specific to Arabs) are located on HLA segment on chromosome 6. This same segment mutations are also markers of Arabs in Genealogical and forensic profiling tests and studies. Such studies as:
Arab population data on the PCR-based loci: HLA 
HLA polymorphism in Saudi.
Other mixed DNA studies on Arabic populations
Further reading.
Price-Jones, David. "The Closed Circle: an Interpretation of the Arabs". Pbk. ed., with a new preface by the author. Chicago: I. R. Dee, 2002. xiv, 464 p. ISBN 1-56663-440-7 pbk
Ankerl, Guy. "Coexisting Contemporary Civilizations: Arabo-Muslim, Bharati, Chinese, and Western." INU PRESS, Geneva, 2000. ISBN 2-88155-004-5.

</doc>
<doc id="2186" url="http://en.wikipedia.org/wiki?curid=2186" title="Armadillo">
Armadillo

Armadillos are New World placental mammals with a leathery armor shell. The Dasypodidae are the only surviving family in the order Cingulata, part of the superorder Xenarthra, along with the anteaters and sloths. The word "armadillo" means "little armored one" in Spanish. The Aztecs called them "āyōtōchtli" , Nahuatl for “turtle-rabbit”: "āyōtl" (turtle) and "tōchtli" (rabbit). 
About 10 extant genera and 20 extant species of armadillo have been described, some of which are distinguished by the number of bands on their armor. Their average length is about , including tail. The giant armadillo grows up to and weighs up to , while the pink fairy armadillo is a diminutive species, with an overall length of . All species are native to the Americas, where they inhabit a variety of environments.
Like all other xenarthran lineages, armadillos originated in South America. Due to the continent's former isolation, they were confined there for most of the Cenozoic. The recent formation of the Isthmus of Panama allowed a few members of the family to migrate northward into southern North America by the early Pleistocene, as part of the Great American Interchange. (Some of their much larger cingulate relatives, the pampatheres and glyptodonts, made the same journey.)
Today, all extant armadillos species are still present in South America. They are particularly diverse in Paraguay (where eleven species exist) and surrounding areas. Many species are endangered. Some, including four species of "Dasypus", are widely distributed over the Americas, whereas others, such as Yepes's mulita, are restricted to small ranges. Two species, the northern naked-tailed armadillo and nine-banded armadillo, are found in Central America; the latter has also reached the United States, primarily in the south-central states (notably Texas), but with a range that extends as far east as South Carolina and Florida, and as far north as Nebraska and central Indiana. Their range has consistently expanded in North America over the last century due to a lack of natural predators.
Habitat and anatomy.
Armadillos are small to medium-sized mammals. The smallest species, the pink fairy armadillo, is roughly chipmunk-sized at and in total length. The largest species, the giant armadillo, can be the size of a small pig, weigh up to and be over long. They are prolific diggers. Many species use their sharp claws to dig for food, such as grubs, and to dig dens. The nine-banded armadillo prefers to build burrows in moist soil near the creeks, streams, and arroyos around which it lives and feeds. The diets of different armadillo species vary, but consist mainly of insects, grubs, and other invertebrates. Some species, however, feed almost entirely on ants and termites.
In common with other xenarthrans, armadillos in general, have low body temperatures (33–36°C) and basal metabolic rates (from 40–60% of that expected in placental mammals of their mass). This is particularly true of types that specialize in using termites as their primary food source (for example, "Priodontes" and "Tolypeutes").
The armor is formed by plates of dermal bone covered in relatively small, overlapping epidermal scales called "scutes", composed of bone with a covering of horn. Most species have rigid shields over the shoulders and hips, with a number of bands separated by flexible skin covering the back and flanks. Additional armor covers the top of the head, the upper parts of the limbs, and the tail. The underside of the animal is never armored, and is simply covered with soft skin and fur.
This armor-like skin appears to be the main defense of many armadillos, although most escape predators by fleeing (often into thorny patches, from which their armor protects them) or digging to safety. Only the South American three-banded armadillos ("Tolypeutes") rely heavily on their armor for protection. When threatened by a predator, "Tolypeutes" species frequently roll up into a ball. Other armadillo species cannot roll up because they have too many plates. The North American nine-banded armadillo tends to jump straight in the air when surprised, and consequently often collides with the undercarriage or fenders of passing vehicles.
Armadillos have short legs, but can move quite quickly, and have the ability to remain under water for as long as six minutes. Because of the density of its armor, an armadillo will sink in water unless it swallows air, inflating its stomach to twice normal size and raising its buoyancy above that of water, allowing it to swim across narrow streams and ditches.
Armadillos have very poor eyesight, and use their keen sense of smell to hunt for food.
They use their claws for digging and finding food, as well as for making their homes in burrows. They dig their burrows with their claws, making only a single corridor the width of the animal's body. They have five clawed toes on their hindfeet, and three to five toes with heavy digging claws on their forefeet. Armadillos have a large number of cheek teeth, which are not divided into premolars and molars, but usually have incisors or canines. The dentition of the nine-banded armadillo is P 7/7, M 1/1 = 32.
Gestation lasts from 60 to 120 days, depending on species, although the nine-banded armadillo also exhibits delayed implantation, so the young are not typically born for eight months after mating. Most members of the genus "Dasypus" give birth to four monozygotic young (that is, identical quadruplets), but other species may have typical litter sizes that range from one to eight. The young are born with soft, leathery skin, which hardens within a few weeks. They reach sexual maturity in three to 12 months, depending on the species. Armadillos are solitary animals that do not share their burrows with other adults.
Classification.
Family Dasypodidae
† indicates extinct taxon
Armadillos and humans.
In science.
Armadillos are often used in the study of leprosy, since they, along with mangabey monkeys, rabbits and mice (on their footpads), are among the few known species that can contract the disease systemically. They are particularly susceptible due to their unusually low body temperature, which is hospitable to the leprosy bacterium, "Mycobacterium leprae". (The leprosy bacterium is difficult to culture and armadillos have a body temperature of , similar to human skin.) Humans can acquire a leprosy infection from armadillos by handling them or consuming armadillo meat. Armadillos are a presumed vector and natural reservoir for the disease in Texas and Louisiana. Prior to the arrival of Europeans in the late 15th century, leprosy was unknown in the New World. Given that armadillos are native to the New World, at some point they must have acquired the disease from humans.
The armadillo is also a natural reservoir for Chagas disease.
The nine-banded armadillo also serves science through its unusual reproductive system, in which four genetically identical offspring are born, the result of one original egg.
Because they are always genetically identical, the group of four young provides a good subject for scientific, behavioral or medical tests that need consistent biological and genetic makeup in the test subjects. This is the only reliable manifestation of polyembryony in the class Mammalia, and only exists within the genus "Dasypus" and not in all armadillos, as is commonly believed. Other species that display this trait include parasitoid wasps, certain flatworms and various aquatic invertebrates.
Armadillos (mainly "Dasypus") are common roadkill due to their habit of jumping three to four feet vertically when startled, which puts them into collision with the underside of vehicles. Wildlife enthusiasts are using the northward march of the armadillo as an opportunity to educate others about the animals, which can be a burrowing nuisance to property owners and managers.
As musical instruments.
Armadillo shells have traditionally been used to make the back of the "charango", an Andean lute instrument.

</doc>
