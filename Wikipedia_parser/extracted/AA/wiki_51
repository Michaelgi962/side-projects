<doc id="4147" url="http://en.wikipedia.org/wiki?curid=4147" title="Bali">
Bali

Bali is an island and province of Indonesia, and includes a few smaller neighbouring islands, notably Nusa Penida. It is located at the westernmost end of the Lesser Sunda Islands, between Java to the west and Lombok to the east. Its capital of Denpasar is located at the southern part of the island.
With a population of 3,890,757 in the 2010 census, and currently 4,225,000. The island is home to most of Indonesia's Hindu minority. According to the 2010 Census, 84.5% of Bali's population adhered to Balinese Hinduism, 12% to Islam, and most of the remainder followed Christianity.
Bali is the largest tourist destination in the country and is renowned for its highly developed arts, including traditional and modern dance, sculpture, painting, leather, metalworking, and music. Since the late 20th century, the province has had a rise in tourism.
Bali is part of the Coral Triangle, the area with the highest biodiversity of marine species. In this area alone over 500 reef building coral species can be found. For comparison, this is about 7 times as many as in the entire Caribbean. There is a wide range of dive sites with high quality reefs, all with their own specific attractions. Many sites can have strong currents and swell, so diving without a knowledgeable guide is unadvisable. Bali is the host of 2011 ASEAN Summit, 2013 APEC and Miss World 2013.
History.
Bali was inhabited around 2000 BC by Austronesian people who migrated originally from Southeast Asia and Oceania through Maritime Southeast Asia. Culturally and linguistically, the Balinese are closely related to the people of the Indonesian archipelago, Malaysia, the Philippines, and Oceania. Stone tools dating from this time have been found near the village of Cekik in the island's west.
In ancient Bali, nine Hindu sects existed, namely Pasupata, Bhairawa, Siwa Shidanta, Waisnawa, Bodha, Brahma, Resi, Sora and Ganapatya. Each sect revered a specific deity as its personal Godhead.
Balinese culture was strongly influenced by Indian, Chinese, and particularly Hindu culture, beginning around the 1st century AD. The name "Bali dwipa" ("Bali island") has been discovered from various inscriptions, including the Blanjong pillar inscription written by Sri Kesari Warmadewa in 914 AD and mentioning "Walidwipa". It was during this time that the people developed their complex irrigation system "subak" to grow rice in wet-field cultivation. Some religious and cultural traditions still practiced today can be traced to this period.
The Hindu Majapahit Empire (1293–1520 AD) on eastern Java founded a Balinese colony in 1343. When the empire declined, there was an exodus of intellectuals, artists, priests, and musicians from Java to Bali in the 15th century.
The first European contact with Bali is thought to have been made in 1585 when a Portuguese ship foundered off the Bukit Peninsula and left a few Portuguese in the service of Dewa Agung. In 1597 the Dutch explorer Cornelis de Houtman arrived at Bali and, the Dutch East India Company was established in 1602. The Dutch government expanded its control across the Indonesian archipelago during the second half of the 19th century (see Dutch East Indies). Dutch political and economic control over Bali began in the 1840s on the island's north coast, when the Dutch pitted various competing Balinese realms against each other. In the late 1890s, struggles between Balinese kingdoms in the island's south were exploited by the Dutch to increase their control.
In June 1860 the famous Welsh naturalist, Alfred Russel Wallace, travelled to Bali from Singapore, landing at Bileling on the northcoast of the island. Wallace's trip to Bali was instrumental in helping him devise his Wallace Line theory. The Wallace Line is a faunal boundary that runs through the strait between Bali and Lombok. It has been found to be a boundary between species of Asiatic origin in the east and a mixture of Australian and Asian species to the west. In his travel memoir "The Malay Archipelago," Wallace wrote of his experience in Bali:
I was both astonished and delighted; for as my visit to Java was some years later, I had never beheld so beautiful and well-cultivated a district out of Europe. A slightly undulating plain extends from the seacoast about ten or twelve miles inland, where it is bounded by a fine range of wooded and cultivated hills. Houses and villages, marked out by dense clumps of coconut palms, tamarind and other fruit trees, are dotted about in every direction; while between them extend luxurious rice-grounds, watered by an elaborate system of irrigation that would be the pride of the best cultivated parts of Europe. 
The Dutch mounted large naval and ground assaults at the Sanur region in 1906 and were met by the thousands of members of the royal family and their followers who fought against the superior Dutch force in a suicidal "puputan" defensive assault rather than face the humiliation of surrender. Despite Dutch demands for surrender, an estimated 200 Balinese marched to their death against the invaders. In the Dutch intervention in Bali, a similar massacre occurred in the face of a Dutch assault in Klungkung. Afterward the Dutch governors exercised administrative control over the island, but local control over religion and culture generally remained intact. Dutch rule over Bali came later and was never as well established as in other parts of Indonesia such as Java and Maluku.
In the 1930s, anthropologists Margaret Mead and Gregory Bateson, artists Miguel Covarrubias and Walter Spies, and musicologist Colin McPhee all spent time here. Their accounts of the island and its peoples created a western image of Bali as "an enchanted land of aesthetes at peace with themselves and nature." Western tourists began to visit the island.
Imperial Japan occupied Bali during World War II. it was not originally a target in their Netherlands East Indies Campaign, but as the airfields on Borneo were inoperative due to heavy rains, the Imperial Japanese Army decided to occupy Bali, which did not suffer from comparable weather. The island had no regular Royal Netherlands East Indies Army (KNIL) troops. There was only a Native Auxiliary Corps "Prajoda" (Korps Prajoda) consisting of about 600 native soldiers and several Dutch KNIL officers under command of KNIL Lieutenant Colonel W.P. Roodenburg. On 19 February 1942 the Japanese forces landed near the town of Senoer . The island was quickly captured.
During the Japanese occupation, a Balinese military officer, Gusti Ngurah Rai, formed a Balinese 'freedom army'. The lack of institutional changes and the harshness of war requisitions made Japanese rule worse than the Dutch one. Following Japan's Pacific surrender in August 1945, the Dutch returned to Indonesia, including Bali, to reinstate their pre-war colonial administration. This was resisted by the Balinese rebels, who now used recovered Japanese weapons. On 20 November 1946, the Battle of Marga was fought in Tabanan in central Bali. Colonel I Gusti Ngurah Rai, by then 29 years old, finally rallied his forces in east Bali at Marga Rana, where they made a suicide attack on the heavily armed Dutch. The Balinese battalion was entirely wiped out, breaking the last thread of Balinese military resistance.
In 1946 the Dutch constituted Bali as one of the 13 administrative districts of the newly proclaimed State of East Indonesia, a rival state to the Republic of Indonesia, which was proclaimed and headed by Sukarno and Hatta. Bali was included in the "Republic of the United States of Indonesia" when the Netherlands recognised Indonesian independence on 29 December 1949.
The 1963 eruption of Mount Agung killed thousands, created economic havoc and forced many displaced Balinese to be "transmigrated" to other parts of Indonesia. Mirroring the widening of social divisions across Indonesia in the 1950s and early 1960s, Bali saw conflict between supporters of the traditional caste system, and those rejecting this system. Politically, the opposition was represented by supporters of the Indonesian Communist Party (PKI) and the Indonesian Nationalist Party (PNI), with tensions and ill-feeling further increased by the PKI's land reform programs. An attempted coup in Jakarta was put down by forces led by General Suharto.
The army became the dominant power as it instigated a violent anti-communist purge, in which the army blamed the PKI for the coup. Most estimates suggest that at least 500,000 people were killed across Indonesia, with an estimated 80,000 killed in Bali, equivalent to 5% of the island's population. With no Islamic forces involved as in Java and Sumatra, upper-caste PNI landlords led the extermination of PKI members.
As a result of the 1965/66 upheavals, Suharto was able to manoeuvre Sukarno out of the presidency. His "New Order" government reestablished relations with western countries. The pre-War Bali as "paradise" was revived in a modern form. The resulting large growth in tourism has led to a dramatic increase in Balinese standards of living and significant foreign exchange earned for the country. A bombing in 2002 by militant Islamists in the tourist area of Kuta killed 202 people, mostly foreigners. This attack, and another in 2005, severely reduced tourism, producing much economic hardship to the island.
Geography.
The island of Bali lies 3.2 km (2 mi) east of Java, and is approximately 8 degrees south of the equator. Bali and Java are separated by the Bali Strait. East to west, the island is approximately 153 km (95 mi) wide and spans approximately 112 km (69 mi) north to south; administratively it covers 5,780 km2, or 5,577 km2 without Nusa Penida District, its population density is roughly 750 people/km2.
Bali's central mountains include several peaks over 3,000 metres in elevation. The highest is Mount Agung (3,031 m), known as the "mother mountain" which is an active volcano. Mountains range from centre to the eastern side, with Mount Agung the easternmost peak. Bali's volcanic nature has contributed to its exceptional fertility and its tall mountain ranges provide the high rainfall that supports the highly productive agriculture sector. South of the mountains is a broad, steadily descending area where most of Bali's large rice crop is grown. The northern side of the mountains slopes more steeply to the sea and is the main coffee producing area of the island, along with rice, vegetables and cattle. The longest river, Ayung River, flows approximately 75 km.
The island is surrounded by coral reefs. Beaches in the south tend to have white sand while those in the north and west have black sand. Bali has no major waterways, although the Ho River is navigable by small "sampan" boats. Black sand beaches between Pasut and Klatingdukuh are being developed for tourism, but apart from the seaside temple of Tanah Lot, they are not yet used for significant tourism.
The largest city is the provincial capital, Denpasar, near the southern coast. Its population is around 491,500 (2002). Bali's second-largest city is the old colonial capital, Singaraja, which is located on the north coast and is home to around 100,000 people. Other important cities include the beach resort, Kuta, which is practically part of Denpasar's urban area, and Ubud, situated at the north of Denpasar, is the island's cultural centre.
Three small islands lie to the immediate south east and all are administratively part of the Klungkung regency of Bali: Nusa Penida, Nusa Lembongan and Nusa Ceningan. These islands are separated from Bali by the Badung Strait.
To the east, the Lombok Strait separates Bali from Lombok and marks the biogeographical division between the fauna of the Indomalayan ecozone and the distinctly different fauna of Australasia. The transition is known as the Wallace Line, named after Alfred Russel Wallace, who first proposed a transition zone between these two major biomes. When sea levels dropped during the Pleistocene ice age, Bali was connected to Java and Sumatra and to the mainland of Asia and shared the Asian fauna, but the deep water of the Lombok Strait continued to keep Lombok Island and the Lesser Sunda archipelago isolated.
Ecology.
Bali lies just to the west of the Wallace Line, and thus has a fauna that is Asian in character, with very little Australasian influence, and has more in common with Java than with Lombok. An exception is the Yellow-crested Cockatoo, a member of a primarily Australasian family. There are around 280 species of birds, including the critically endangered Bali Starling, which is endemic. Others Include Barn Swallow, Black-naped Oriole, Black Racket-tailed Treepie, Crested Serpent-eagle, Crested Treeswift, Dollarbird, Java Sparrow, Lesser Adjutant, Long-tailed Shrike, Milky Stork, Pacific Swallow, Red-rumped Swallow, Sacred Kingfisher, Sea Eagle, Woodswallow, Savanna Nightjar, Stork-billed Kingfisher, Yellow-vented Bulbul, White Heron, Great Egret.
Until the early 20th century, Bali was home to several large mammals: the wild Banteng, leopard and the endemic Bali tiger. The Banteng still occurs in its domestic form, whereas leopards are found only in neighbouring Java, and the Bali tiger is extinct. The last definite record of a tiger on Bali dates from 1937, when one was shot, though the subspecies may have survived until the 1940s or 1950s. The relatively small size of the island, conflict with humans, poaching and habitat reduction drove the Bali tiger to extinction. This was the smallest and rarest of all tiger subspecies and was never caught on film or displayed in zoos, whereas few skins or bones remain in museums around the world. Today, the largest mammals are the Javan Rusa deer and the Wild Boar. A second, smaller species of deer, the Indian Muntjac, also occurs. Saltwater crocodiles were once present on the island, but became locally extinct sometime during the last century.
Squirrels are quite commonly encountered, less often is the Asian Palm Civet, which is also kept in coffee farms to produce Kopi Luwak. Bats are well represented, perhaps the most famous place to encounter them remaining the Goa Lawah (Temple of the Bats) where they are worshipped by the locals and also constitute a tourist attraction. They also occur in other cave temples, for instance at Gangga Beach. Two species of monkey occur. The Crab-eating Macaque, known locally as "kera", is quite common around human settlements and temples, where it becomes accustomed to being fed by humans, particularly in any of the three "monkey forest" temples, such as the popular one in the Ubud area. They are also quite often kept as pets by locals. The second monkey, endemic to Java and some surrounding islands such as Bali, is far rarer and more elusive is the Javan Langur, locally known as "lutung". They occur in few places apart from the Bali Barat National Park. They are born an orange colour, though by their first year they would have already changed to a more blackish colouration. In Java however, there is more of a tendency for this species to retain its juvenile orange colour into adulthood, and so you can see a mixture of black and orange monkeys together as a family. Other rarer mammals include the Leopard Cat, Sunda Pangolin and Black Giant Squirrel.
Snakes include the King Cobra and Reticulated Python. The Water Monitor can grow to at least in length and and can move quickly.
The rich coral reefs around the coast, particularly around popular diving spots such as Tulamben, Amed, Menjangan or neighbouring Nusa Penida, host a wide range of marine life, for instance Hawksbill Turtle, Giant Sunfish, Giant Manta Ray, Giant Moray Eel, Bumphead Parrotfish, Hammerhead Shark, Reef Shark, barracuda, and sea snakes. Dolphins are commonly encountered on the north coast near Singaraja and Lovina.
A team of scientists conducted a survey from 29 April 2011 to 11 May 2011 at 33 sea sites around Bali. They discovered 952 species of reef fish of which 8 were new discoveries at Pemuteran, Gilimanuk, Nusa Dua, Tulamben and Candidasa, and 393 coral species, including two new ones at Padangbai and between Padangbai and Amed.
The average coverage level of healthy coral was 36% (better than in Raja Ampat and Halmahera by 29% or in Fakfak and Kaimana by 25%) with the highest coverage found in Gili Selang and Gili Mimpang in Candidasa, Karangasem regency.
Many plants have been introduced by humans within the last centuries, particularly since the 20th century, making it sometimes hard to distinguish what plants are really native. Among the larger trees the most common are: Banyan trees, Jackfruit, coconuts, bamboo species, acacia trees and also endless rows of coconuts and banana species. Numerous flowers can be seen: hibiscus, frangipani, bougainvillea, poinsettia, oleander, jasmine, water lily, lotus, roses, begonias, orchids and hydrangeas exist. On higher grounds that receive more moisture, for instance around Kintamani, certain species of fern trees, mushrooms and even pine trees thrive well. Rice comes in many varieties. Other plants with agricultural value include: salak, mangosteen, corn, Kintamani orange, coffee and water spinach.
Environment.
Some of the worst erosion has occurred in Lebih Beach, where up to 7 metres of land is lost every year. Decades ago, this beach was used for holy pilgrimages with more than 10,000 people, but they have now moved to Masceti Beach.
From ranked third in previous review, in 2010 Bali got score 99.65 of Indonesia's environmental quality index and the highest of all the 33 provinces. The score measured 3 water quality parameters: the level of total suspended solids (TSS), dissolved oxygen (DO) and chemical oxygen demand (COD).
Because of over-exploitation by the tourist industry which covers a massive land area, 200 out of 400 rivers on the island have dried up and based on research, the southern part of Bali would face a water shortage up to 2,500 litres of clean water per second by 2015.
To ease the shortage, the central government plans to build a water catchment and processing facility at Petanu River in Gianyar. The 300 litres capacity of water per second will be channelled to Denpasar, Badung and Gianyar in 2013.
Administrative divisions.
The province is divided into 8 regencies ("kabupaten") and 1 city ("kota"). These are:
Economy.
Three decades ago, the Balinese economy was largely agriculture-based in terms of both output and employment. Tourism is now the largest single industry in terms of income, and as a result, Bali is one of Indonesia's wealthiest regions. In 2003, around 80% of Bali's economy was tourism related. By end of June 2011, non-performing loan of all banks in Bali were 2.23%, lower than the average of Indonesian banking industry non-performing loan (about 5%). The economy, however, suffered significantly as a result of the terrorist bombings 2002 and 2005. The tourism industry has since recovered from these events.
Agriculture.
Although tourism produces the GDP's largest output, agriculture is still the island's biggest employer; most notably rice cultivation. Crops grown in smaller amounts include fruit, vegetables, "Coffea arabica" and other cash and subsistence crops. Fishing also provides a significant number of jobs. Bali is also famous for its artisans who produce a vast array of handicrafts, including batik and ikat cloth and clothing, wooden carvings, stone carvings, painted art and silverware. Notably, individual villages typically adopt a single product, such as wind chimes or wooden furniture.
The Arabica coffee production region is the highland region of Kintamani near Mount Batur. Generally, Balinese coffee is processed using the wet method. This results in a sweet, soft coffee with good consistency. Typical flavours include lemon and other citrus notes. Many coffee farmers in Kintamani are members of a traditional farming system called Subak Abian, which is based on the Hindu philosophy of "Tri Hita Karana". According to this philosophy, the three causes of happiness are good relations with God, other people and the environment. The Subak Abian system is ideally suited to the production of fair trade and organic coffee production. Arabica coffee from Kintamani is the first product in Indonesia to request a Geographical Indication.
Tourism.
The tourism industry is primarily focused in the south, while significant in the other parts of the island as well. The main tourist locations are the town of Kuta (with its beach), and its outer suburbs of Legian and Seminyak (which were once independent townships), the east coast town of Sanur (once the only tourist hub), in the center of the island Ubud, to the south of the Ngurah Rai International Airport, Jimbaran, and the newer development of Nusa Dua and Pecatu.
The American government lifted its travel warnings in 2008. The Australian government last issued an advice on Friday, 4 May 2012. The overall level of the advice was lowered to 'Exercise a high degree of caution'. The Swedish government issued a new warning on Sunday, 10 June 2012 because of one more tourist who has been killed by methanol poisoning.
In the last half of 2008, Indonesia's currency had dropped approximately 30% against the US dollar, providing many overseas visitors value for their currencies. Visitor arrivals for 2009 were forecast to drop 8% (which would be higher than 2007 levels), due to the worldwide economic crisis which has also affected the global tourist industry, but not due to any travel warnings.
Bali's tourism economy survived the terrorist bombings of 2002 and 2005, and the tourism industry has in fact slowly recovered and surpassed its pre-terrorist bombing levels; the longterm trend has been a steady increase of visitor arrivals. In 2010, Bali received 2.57 million foreign tourists, which surpassed the target of 2.0–2.3 million tourists. The average occupancy of starred hotels achieved 65%, so the island is still able to accommodate tourists for some years without any addition of new rooms/hotels, although at the peak season some of them are fully booked.
Bali received the Best Island award from Travel and Leisure in 2010. The island of Bali won because of its attractive surroundings (both mountain and coastal areas), diverse tourist attractions, excellent international and local restaurants, and the friendliness of the local people. According to BBC Travel released in 2011, Bali is one of the World's Best Islands, rank in second after Greece.
In August 2010, the film version of Eat, Pray, Love (EPL) was released in theatres. The movie was based on Elizabeth Gilbert's best-selling memoir of the same name. It took place at Ubud and Padang-Padang Beach at Bali. The 2006 book, which spent 57 weeks at the No. 1 spot on the New York Times paperback nonfiction best-seller list, had already fuelled a boom in EPL tourism in Ubud, the hill town and cultural and tourist center that was the focus of Gilbert's quest for balance through traditional spirituality and healing that leads to love.
Since 2011, China has displaced Japan as the second-largest supplier of tourists to Bali, while Australia still tops the list. Chinese tourists increased by 17% from last year due to the impact of ACFTA and new direct flights to Bali.
In January 2012, Chinese tourists year on year (yoy) increased by 222.18% compared to January 2011, while Japanese tourists declined by 23.54% yoy.
Bali reported that it has 2.88 million foreign tourists and 5 million domestic tourists in 2012, marginally surpassing the expectations of 2.8 million foreign tourists. Forecasts for 2013 are at 3.1 million.
Based on Bank Indonesia survey in May 2013, 34.39 percent of tourists are upper-middle class with spending between $1,286 to $5,592 and dominated by Australia, France, China, Germany and the US with some China tourists move from low spending before to higher spending currently. While 30.26 percent are middle class with spending between $662 to $1,285.
Transportation.
The Ngurah Rai International Airport is located near Jimbaran, on the isthmus at the southernmost part of the island. Lt.Col. Wisnu Airfield is found in north-west Bali.
A coastal road circles the island, and three major two-lane arteries cross the central mountains at passes reaching to 1,750m in height (at Penelokan). The Ngurah Rai Bypass is a four-lane expressway that partly encircles Denpasar and enables cars to travel quickly in the heavily populated south. Bali has no railway lines yet.
December 2010: the Government of Indonesia has invited investors to build Tanah Ampo Cruise Terminal at Karangasem, Bali amounted $30 million. In 17 July 2011 the first cruise ship (Sun Princess) anchored about 400 meters away from the wharf of Tanah Ampo harbour. The current pier is only 154 meters and will eventually be 300 to 350 meters to accommodate international cruise ships. The harbour would be safer than Benoa and has a scenic backdrop of a panoramic view of mountainous area with green rice fields. By December 2011 the auction process will be settled and Tanah Ampo is predicted to become the main hub for cruise ships in Indonesia by 2013.
A Memorandum of Understanding has been signed by two ministers, Bali's Governor and Indonesian Train Company to build 565 kilometres of railway along the coast around the island. It should be operating by 2015.
On 16 March 2011 (Tanjung) Benoa port received the "Best Port Welcome 2010" award from London's "Dream World Cruise Destination" magazine. Government plans to expand the role of Benoa port as export-import port to boost Bali's trade and industry sector. The Tourism and Creative Economy Ministry has confirmed that 306 cruise liners are heading for Indonesia in 2013 – an increase of 43 percent compared to the previous year.
On May 2011, an integrated Areal Traffic Control System (ATCS) was implemented to reduce traffic jams at four crossing points: Ngurah Rai statue, Dewa Ruci Kuta crossing, Jimbaran crossing and Sanur crossing. ATCS is an integrated system connecting all traffic lights, CCTVs and other traffic signals with a monitoring office at the police headquarters. It has successfully been implemented in other ASEAN countries and will be implemented at other crossings in Bali.
On 21 December 2011 construction started on the Nusa Dua-Benoa-Ngurah Rai International Airport toll road which will also provide a special lane for motorcycles. This has been done by seven state-owned enterprises led by PT Jasa Marga with 60% of shares. PT Jasa Marga Bali Tol will construct the 9.91 kilometres toll road (totally 12.7 kilometres with access road). The construction is estimated to cost Rp.2.49 trillion ($273.9 million). The project goes through 2 kilometres of mangrove forest and through 2.3 kilometres of beach, both within 5.4 hectares area. The elevated toll road is built over the mangrove forest on 18,000 concrete pillars which occupied 2 hectares of mangroves forest. It compensated by new planting of 300,000 mangrove trees along the road. On 21 December 2011 the Dewa Ruci 450 meters underpass has also started on the busy Dewa Ruci junction near Bali Kuta Galeria with an estimated cost of Rp136 billion ($14.9 million) from the state budget. On 23 September 2013, the Bali Mandara Toll Road is opened and the Dewa Ruci Junction (Simpang Siur) underpass is opened before. Both are ease the heavy traffic congestion.
To solve chronic traffic problems, the province will also build a toll road connecting Serangan with Tohpati, a toll road connecting Kuta, Denpasar and Tohpati and a flyover connecting Kuta and Ngurah Rai Airport.
Demographics.
The population of Bali was 3,890,757 as of the 2010 Census; the latest estimate (for January 2014) is 4,225,384. There are an estimated 30,000 expatriates living in Bali.
Ethnic origins.
A DNA study in 2005 by Karafet et al. found that 12% of Balinese Y-chromosomes are of likely Indian origin, while 84% are of likely Austronesian origin, and 2% of likely Melanesian origin. The study does not correlate the DNA samples to the Balinese caste system.
Caste system.
Bali has a caste system based on the Indian Hindu model, with four castes:
Religion.
Unlike most of Muslim-majority Indonesia, about 83.5% of Bali's population adheres to Balinese Hinduism, formed as a combination of existing local beliefs and Hindu influences from mainland Southeast Asia and South Asia. Minority religions include Islam (13.3%), Christianity (1.7%), and Buddhism (0.5%). These figures do not include immigrants from other parts of Indonesia.
Balinese Hinduism is an amalgam in which gods and demigods are worshipped together with Buddhist heroes, the spirits of ancestors, indigenous agricultural deities and sacred places. Religion as it is practised in Bali is a composite belief system that embraces not only theology, philosophy, and mythology, but ancestor worship, animism and magic. It pervades nearly every aspect of traditional life. Caste is observed, though less strictly than in India. With an estimated 20,000 puras (temples) and shrines, Bali is known as the "Island of a Thousand Puras", or "Island of the Gods".
Balinese Hinduism has roots in Indian Hinduism and in Buddhism, and adopted the animistic traditions of the indigenous people. This influence strengthened the belief that the gods and goddesses are present in all things. Every element of nature, therefore, possesses its own power, which reflects the power of the gods. A rock, tree, dagger, or woven cloth is a potential home for spirits whose energy can be directed for good or evil. Balinese Hinduism is deeply interwoven with art and ritual. Ritualizing states of self-control are a notable feature of religious expression among the people, who for this reason have become famous for their graceful and decorous behaviour.
Apart from the majority of Balinese Hindus, there also exist Chinese immigrants whose traditions have melded with that of the locals. As a result, these Sino-Balinese not only embrace their original religion, which is a mixture of Buddhism, Christianity, Taoism and Confucianism, but also find a way to harmonise it with the local traditions. Hence, it is not uncommon to find local Sino-Balinese during the local temple's "odalan". Moreover, Balinese Hindu priests are invited to perform rites alongside a Chinese priest in the event of the death of a Sino-Balinese. Nevertheless, the Sino-Balinese claim to embrace Buddhism for administrative purposes, such as their Identity Cards.
Language.
Balinese and Indonesian are the most widely spoken languages in Bali, and the vast majority of Balinese people are bilingual or trilingual. The most common spoken language around the tourist areas is Indonesian, as many people in the tourist sector are not solely Balinese, but migrants from Java, Lombok, Sumatra, and other parts of Indonesia. There are several indigenous Balinese languages, but most Balinese can also use the most widely spoken option: modern common Balinese. The usage of different Balinese languages was traditionally determined by the Balinese caste system and by clan membership, but this tradition is diminishing. Kawi and Sanskrit are also commonly used by some Hindu priests in Bali, for Hinduism literature was mostly written in Sanskrit.
English is a common third language (and the primary foreign language) of many Balinese, owing to the requirements of the tourism industry. Other foreign languages, such as Chinese, Japanese, Korean, French or German are often used in multilingual signs for foreign tourists.
Culture.
Bali is renowned for its diverse and sophisticated art forms, such as painting, sculpture, woodcarving, handcrafts, and performing arts. Balinese cuisine is also distinctive. Balinese percussion orchestra music, known as "gamelan", is highly developed and varied. Balinese performing arts often portray stories from Hindu epics such as the Ramayana but with heavy Balinese influence. Famous Balinese dances include "pendet", "legong", "baris", "topeng", "barong", "gong keybar", and "kecak" (the monkey dance). Bali boasts one of the most diverse and innovative performing arts cultures in the world, with paid performances at thousands of temple festivals, private ceremonies, or public shows.
The Hindu New Year, "Nyepi", is celebrated in the spring by a day of silence. On this day everyone stays at home and tourists are encouraged to remain in their hotels. On the day before New Year, large and colourful sculptures of "ogoh-ogoh" monsters are paraded and finally burned in the evening to drive away evil spirits. Other festivals throughout the year are specified by the Balinese "pawukon" calendrical system.
Celebrations are held for many occasions such as a tooth-filing (coming-of-age ritual), cremation or "odalan" (temple festival). One of the most important concepts that Balinese ceremonies have in common is that of "désa kala patra", which refers to how ritual performances must be appropriate in both the specific and general social context. Many of the ceremonial art forms such as "wayang kulit" and "topeng" are highly improvisatory, providing flexibility for the performer to adapt the performance to the current situation. Many celebrations call for a loud, boisterous atmosphere with lots of activity and the resulting aesthetic, "ramé", is distinctively Balinese. Often two or more "gamelan" ensembles will be performing well within earshot, and sometimes compete with each other to be heard. Likewise, the audience members talk amongst themselves, get up and walk around, or even cheer on the performance, which adds to the many layers of activity and the liveliness typical of "ramé".
"Kaja" and "kelod" are the Balinese equivalents of North and South, which refer to ones orientation between the island's largest mountain Gunung Agung ("kaja"), and the sea ("kelod"). In addition to spatial orientation, "kaja" and "kelod" have the connotation of good and evil; gods and ancestors are believed to live on the mountain whereas demons live in the sea. Buildings such as temples and residential homes are spatially oriented by having the most sacred spaces closest to the mountain and the unclean places nearest to the sea.
Most temples have an inner courtyard and an outer courtyard which are arranged with the inner courtyard furthest "kaja". These spaces serve as performance venues since most Balinese rituals are accompanied by any combination of music, dance and drama. The performances that take place in the inner courtyard are classified as "wali", the most sacred rituals which are offerings exclusively for the gods, while the outer courtyard is where "bebali" ceremonies are held, which are intended for gods and people. Lastly, performances meant solely for the entertainment of humans take place outside the walls of the temple and are called "bali-balihan". This three-tiered system of classification was standardised in 1971 by a committee of Balinese officials and artists to better protect the sanctity of the oldest and most sacred Balinese rituals from being performed for a paying audience.
Tourism, Bali's chief industry, has provided the island with a foreign audience that is eager to pay for entertainment, thus creating new performance opportunities and more demand for performers. The impact of tourism is controversial since before it became integrated into the economy, the Balinese performing arts did not exist as a capitalist venture, and were not performed for entertainment outside of their respective ritual context. Since the 1930s sacred rituals such as the "barong" dance have been performed both in their original contexts, as well as exclusively for paying tourists. This has led to new versions of many of these performances which have developed according to the preferences of foreign audiences; some villages have a "barong" mask specifically for non-ritual performances as well as an older mask which is only used for sacred performances.
Balinese society continues to revolve around each family's ancestral village, to which the cycle of life and religion is closely tied. Coercive aspects of traditional society, such as customary law sanctions imposed by traditional authorities such as village councils (including "kasepekang", or shunning) have risen in importance as a consequence of the democratisation and decentralisation of Indonesia since 1998.
Sports.
As part of the Coral Triangle Bali, including Nusa Penida, offers a wide range of dive sites with varying types of reefs.
Bali was the host of 2008 Asian Beach Games. It was the second time Indonesia hosted an Asia-level multi-sport event, after Jakarta held the 1962 Asian Games.
Heritage sites.
On June 2012, Subak, the irrigation system for paddy fields in Bali was enlisted as a UNESCO world heritage site.
Beauty Pageant.
Bali was the host of Miss World 2013, It was the first time Indonesia hosted an International Beauty Pageant

</doc>
<doc id="4149" url="http://en.wikipedia.org/wiki?curid=4149" title="Bulgarian language">
Bulgarian language

Bulgarian (български език, ) is an Indo-European language, a member of the Southern branch of the Slavic language family.
Bulgarian, along with the closely related Macedonian language (collectively forming the East South Slavic languages), has several characteristics that set it apart from all other Slavic languages: changes include the elimination of case declension, the development of a suffixed definite article (see Balkan language area), and the lack of a verb infinitive, but it retains and has further developed the Proto-Slavic verb system. Various evidential verb forms exist to express unwitnessed, retold, and doubtful action.
Based on the 2011 census, "Ethnologue" estimates that Bulgarian is spoken as a native language by 6.8 million. In 1999, the "World Almanac" had estimated 9 million.
History.
The development of the Bulgarian language may be divided into several periods.
"Bulgarian" was the first "Slavic" language attested in writing. As Slavic linguistic unity lasted into late antiquity, in the oldest manuscripts this language was initially referred to as языкъ словяньскъ, "the Slavic language". In the Middle Bulgarian period this name was gradually replaced by the name , the "Bulgarian language". In some cases, the name was used not only with regard to the contemporary Middle Bulgarian language of the copyist but also to the period of Old Bulgarian. A most notable example of anachronism is the Service of St. Cyril from Skopje (Скопски миней), a 13th-century Middle Bulgarian manuscript from northern Macedonia according to which St. Cyril preached with "Bulgarian" books among the Moravian Slavs. The first mention of the language as the "Bulgarian language" instead of the "Slavonic language" comes in the work of the Greek clergy of the Bulgarian Archbishopric of Ohrid in the 11th century, for example in the Greek hagiography of Saint Clement of Ohrid by Theophylact of Ohrid (late 11th century).
During the Middle Bulgarian period, the language underwent dramatic changes, losing the Slavonic case system, but preserving the rich verb system (while the development was exactly the opposite in other Slavic languages) and developing a definite article. It was influenced by its non-Slavic neighbors in the Balkan language area (mostly grammatically) and later also by Turkish, which was the official language of the Ottoman Empire, in the form of the Ottoman Turkish language, mostly lexically. As a national revival occurred toward the end of the period of Ottoman rule (mostly during the 19th century), a modern Bulgarian literary language gradually emerged that drew heavily on Church Slavonic/Old Bulgarian (and to some extent on literary Russian, which had preserved many lexical items from Church Slavonic) and later reduced the number of Turkish and other Balkan loans. Today one difference between Bulgarian dialects in the country and literary spoken Bulgarian is the significant presence of Old Bulgarian words and even word forms in the latter. Russian loans are distinguished from Old Bulgarian ones on the basis of the presence of specifically Russian phonetic changes, as in оборот (turnover, rev), непонятен (incomprehensible), ядро (nucleus) and others. As usual in such cases, many other loans from French, English and the classical languages have subsequently entered the language as well.
Modern Bulgarian was based essentially on the Eastern dialects of the language, but its pronunciation is in many respects a compromise between East and West Bulgarian (see especially the phonetic sections below). Following the efforts of some figures of the National awakening of Bulgaria (the most notable among them being Neofit Rilski and Ivan Bogorov), there had been many attempts to codify a standard Bulgarian language; however, there was much argument surrounding the choice of norms. Between 1835–1878 more than 25 proposals were put forward and "linguistic chaos" ensued. Eventually the eastern dialects prevailed, and in 1899 the Ministry of Education officially codified a standard Bulgarian language based on the Drinov-Ivanchev orthography.
Dialects.
The language is mainly split into two broad dialect areas, based on the different reflexes of the Common Slavic yat vowel (). This split, which occurred at some point during the Middle Ages, led to the development of Bulgaria's:
The literary language norm, which is generally based on the Eastern dialects, also has the Eastern alternating reflex of "yat". However, it has not incorporated the general Eastern umlaut of "all" synchronic or even historic "ya" sounds into "e" before front vowels – e.g. поляна ("polyana") vs полени ("poleni") "meadow – meadows" or even жаба ("zhaba") vs жеби ("zhebi") "frog – frogs", even though it co-occurs with the yat alternation in almost all Eastern dialects that have it (except a few dialects along the yat border, e.g. in the Pleven region).
More examples of the "yat" umlaut in the literary language are:
Until 1945, Bulgarian orthography did not reveal this alternation and used the original Old Slavic Cyrillic letter "yat" (), which was commonly called двойно е ("dvoyno e") at the time, to express the historical "yat" vowel or at least root vowels displaying the "ya – e" alternation. The letter was used in each occurrence of such a root, regardless of the actual pronunciation of the vowel: thus, both "mlyako" and "mlekar" were spelled with (). Among other things, this was seen as a way to "reconcile" the Western and the Eastern dialects and maintain language unity at a time when much of Bulgaria's Western dialect area was controlled by Serbia and Greece, but there were still hopes and occasional attempts to recover it. With the 1945 orthographic reform, this letter was abolished and the present spelling was introduced, reflecting the alternation in pronunciation.
This had implications for some grammatical constructions:
Sometimes, with the changes, words began to be spelled as other words with different meanings, e.g.:
In spite of the literary norm regarding the yat vowel, many people living in Western Bulgaria, including the capital Sofia, will fail to observe its rules. While the norm requires the realizations "vidyal" vs "videli" (he has seen; they have seen), some natives of Western Bulgaria will preserve their local dialect pronunciation with "e" for all instances of "yat" (e.g. "videl", "videli"). Others, attempting to adhere to the norm, will actually use the "ya" sound even in cases where the standard language has "e" (e.g. "vidyal", "vidyali"). The latter hypercorrection is called свръхякане ("svrah-yakane" ≈"over-softening").
Bulgarian is the only Slavic language whose literary standard does not naturally contain the iotated sound (or its palatalized variant , except in non-Slavic foreign-loaned words). The sound is common in all modern Slavic languages (e.g. Czech "medvěd" "bear", Polish "pięć" "five", Serbo-Croatian "jelen" "deer", Ukrainian "немає" "there is not...", Macedonian "пишување" "writing", etc.), as well as some Western Bulgarian dialectal forms – e.g. "орàн’е" (standard Bulgarian: "орaне" , "ploughing"), however it is not represented in standard Bulgarian speech or writing. Even where occurs in other Slavic words, in Standard Bulgarian it is usually transcribed and pronounced as pure – e.g. Boris Yeltsin is "Eltsin" (Борис Елцин), Yekaterinburg is "Ekaterinburg" (Екатеринбург) and Sarajevo is "Saraevo" (Сараево), although Jelena Janković is "Yelena" – Йелена Янкович.
Relationship to Macedonian.
Until the period immediately following the Second World War, all Bulgarian and the majority of foreign linguists referred to the South Slavic dialect continuum spanning the area of modern Bulgaria, the Republic of Macedonia and parts of Northern Greece as a group of Bulgarian dialects. In contrast, Serbian sources tended to label them "south Serbian" dialects. Some local naming conventions included "bolgarski", "bugarski" and so forth. The codifiers of the standard Bulgarian language, however, did not wish to make any allowances for a pluricentric "Bulgaro-Macedonian" compromise. After 1944 the People's Republic of Bulgaria and the Socialist Federal Republic of Yugoslavia began a policy of making Macedonia into the connecting link for the establishment of new Balkan Federative Republic and stimulating here a development of distinct Slav Macedonian consciousness. After 1958, when the pressure from Moscow decreased, Sofia reverted to the view that the Macedonian language did not exist as a separate language. Nowadays, some linguists still consider Macedonian dialects as Bulgarian. The current academic consensus (outside of Bulgaria) is that Macedonian is an autonomous language within the South Slavic dialect continuum.
Alphabet.
In 886 AD, the Bulgarian Empire introduced the Glagolitic alphabet which was devised by the Saints Cyril and Methodius in the 850s. The Glagolitic alphabet was gradually superseded in later centuries by the Cyrillic script, developed around the Preslav Literary School, Bulgaria in the beginning of the 10th century.
Several Cyrillic alphabets with 28 to 44 letters were used in the beginning and the middle of the 19th century during the efforts on the codification of Modern Bulgarian until an alphabet with 32 letters, proposed by Marin Drinov, gained prominence in the 1870s. The alphabet of Marin Drinov was used until the orthographic reform of 1945 when the letters , called "ят" 'yat' or "двойно е" (or yet "е-двойно") 'double e', and , called "Голям юс" 'big yus', "голяма носовка" 'big nasal sign', "ъ кръстато" 'crossed yer' or "широко ъ" 'long yer', were removed from the alphabet, reducing the number of letters to 30.
With the accession of Bulgaria to the European Union on January 1, 2007, Cyrillic became the third official alphabet of the EU.
The following table gives the letters of the Bulgarian alphabet, along with the values for the sound of each letter:
1 The romanizations of these characters differ from the current version, , as it was never officially adopted as a Bulgarian standard.
Most letters in the Bulgarian alphabet stand for just one specific sound. Three letters stand for the single expression of combinations of sounds, namely щ (sht), ю (yu), and я (ya). Two sounds do not correspond to separate letters, but are expressed as the combination of two letters, namely дж () and дз (). The letter ь marks the softening (palatalization) of any consonant (besides ж, ч, and ш) before the letter о, while ю and я after consonants mark the palatalization of the preceding consonant in addition to representing the vowels /u/ and /a/.
A letter that represents a voiced consonant can represent its voiceless counterpart and vice versa when adjacent to a voiceless or voiced consonant, respectively, or when a voiced consonant is syllable final, for example – вторник /ftornik/ – Tuesday, нож /nɔʃ/ – knife, сграда /zgradɐ/ – building, сватба /svadbɐ/ – wedding.
The names of most letters are simple representations of their phonetic values, with consonants being followed by – thus the alphabet goes: – – , etc. However, the name of the letter Й is "и-kratko" ("short /i/"), the name of Ъ is "er-golyam" ("large Er"), and the name of Ь is "er-malak" ("small Er"). People often refer to Ъ simply as .
The accented letter "Ѝ" is used to distinguish the conjunction 'и' (and) from the pronoun 'ѝ' (to her). It is not considered a separate letter but rather a special form of "И".
Writing.
Bulgarian is usually described as having a phonemic orthography, meaning that words are spelt the way they are pronounced. This is largely true, but does have exceptions. Three of the most cited examples are:
Modern developments.
Since the time of Bulgaria's liberation in the late 19th century, the Bulgarian language has taken on a large number of words from Western European languages. All of these are transcribed phonetically into Cyrillic, e.g.:
Notable is the transliteration of many English names through German, e.g.:
In the years since the end of communism and the rise of technology, the tendency for borrowing has shifted mainly to English, where much computer-related terminology has entered and been inflected accordingly – again, in a wholly phonetic way. Examples include:
The computer-related neologisms are often used interchangeably with traditional Bulgarian words, e.g. "download" and "upload" can be simply свалям and качвам ("svalyam" & "kachvam" – "to bring down" & "to put up").
Use of Roman script in Bulgarian.
The insertion of English words directly into a Cyrillic Bulgarian sentence, while frowned upon, has been increasingly used in the media. This is done for several reasons, including –
Phonology.
Bulgarian possesses a phonology similar to that of the rest of the South Slavic languages, notably lacking Serbo-Croatian's phonemic vowel length and tones and alveo-palatal affricates. Macedonian on the other side exhibits a phonology very similar to that of Bulgarian, which has spurred controversial debates regarding its status as a separate language. An interesting geographic pattern of dialectal distribution shows a tendency of western dialects to approach Serbo-Croatian's "hard" sound in contrast to the eastern dialect's "soft" sound due to pre-palatalization and rising of (similar to Russian) and ikanye (a merger of the two front vowels and ).
Bulgarian is typically analyzed as having six vowels, but at least two more reduced vowels can be encountered in everyday speech.
Grammar.
The parts of speech in Bulgarian are divided in 10 different types, which are categorized in two broad classes: mutable and immutable. The difference is that mutable parts of speech vary grammatically, whereas the immutable ones do not change, regardless of their use. The five classes of mutables are: "nouns", "adjectives", "numerals", "pronouns" and "verbs". Syntactically, the first four of these form the group of the noun or the nominal group. The immutables are: "adverbs", "prepositions", "conjunctions", "particles" and "interjections". Verbs and adverbs form the group of the verb or the verbal group.
Nominal morphology.
Nouns and adjectives have the categories grammatical gender, number, case (only vocative) and definiteness in Bulgarian. Adjectives and adjectival pronouns agree with nouns in number and gender. Pronouns have gender and number and retain (as in nearly all Indo-European languages) a more significant part of the case system.
Nominal inflection.
Gender.
There are three grammatical genders in Bulgarian: "masculine", "feminine" and "neuter". The gender of the noun can largely be inferred from its ending: nouns ending in a consonant ("zero ending") are generally masculine (for example, град 'city', син 'son', мъж 'man'; those ending in –а/–я (-a/-ya) (жена 'woman', дъщеря 'daughter', улица 'street') are normally feminine; and nouns ending in –е, –о are almost always neuter (дете 'child', езеро 'lake'), as are those rare words (usually loanwords) that end in –и, –у, and –ю (цунами 'tsunami', табу 'taboo', меню 'menu'). Perhaps the most significant exception from the above are the relatively numerous nouns that end in a consonant and yet are feminine: these comprise, firstly, a large group of nouns with zero ending expressing quality, degree or an abstraction, including all nouns ending on –ост/–ест -{ost/est} (мъдрост 'wisdom', низост 'vileness', прелест 'loveliness', болест 'sickness', любов 'love'), and secondly, a much smaller group of irregular nouns with zero ending which define tangible objects or concepts (кръв 'blood', кост 'bone', вечер 'evening', нoщ 'night'). There are also some commonly used words that end in a vowel and yet are masculine: баща 'father', дядо 'grandfather', чичо / вуйчо 'uncle', and others.
The plural forms of the nouns do not express their gender as clearly as the singular ones, but may also provide some clues to it: the ending –и (-i) is more likely to be used with a masculine or feminine noun (факти 'facts', болести 'sicknesses'), while one in –а/–я belongs more often to a neuter noun (езера 'lakes'). Also, the plural ending –ове occurs only in masculine nouns.
Number.
Two numbers are distinguished in Bulgarian – singular and plural. A variety of plural suffixes is used, and the choice between them is partly determined by their ending in singular and partly influenced by gender; in addition, irregular declension and alternative plural forms are common. Words ending in –а/–я (which are usually feminine) generally have the plural ending –и, upon dropping of the singular ending. Of nouns ending in a consonant, the feminine ones also use –и, whereas the masculine ones usually have –и for polysyllables and –ове for monosyllables (however, exceptions are especially common in this group). Nouns ending in –о/–е (most of which are neuter) mostly use the suffixes –а, –я (both of which require the dropping of the singular endings) and –та.
With cardinal numbers and related words such as няколко ('several'), masculine nouns use a special count form in –а/–я, which stems from the Proto-Slavonic dual: два/три стола ('two/three chairs') versus тези столове ('these chairs'); cf. feminine две/три/тези книги ('two/three/these books') and neuter две/три/тези легла ('two/three/these beds'). However, a recently developed language norm requires that count forms should only be used with masculine nouns that do not denote persons. Thus, двама/трима ученици ('two/three students') is perceived as more correct than двама/трима ученика, while the distinction is retained in cases such as два/три молива ('two/three pencils') versus тези моливи ('these pencils').
Case.
Cases exist only in the personal pronouns (as they do in many other modern Indo-European languages), with nominative, accusative, dative and vocative forms. Vestiges are present in the masculine personal interrogative pronoun кой ("who" as in formal English, "whom")) and in a number of phraseological units and sayings. The major exception are vocative forms, which are still in use for masculine (with the endings -e, -o and -ю) and feminine nouns (-[ь/й]o and -e) in the singular. However, there is a tendency to avoid them in many personal names, as the use of feminine name forms in -[ь/й]o and of the potential vocative forms of foreign names has come to be considered rude or rustic. Thus, Иване means 'hey, Ivan', while the corresponding feminine forms Елено ('hey, Elena'),
Маргарито ('hey, Margarita') are today seen as rude or, at best, unceremonious, and declining foreign names as in *Джоне ('hey, John') or *Саймъне ('hey, Simon') could only be considered humorous. Interestingly, the prohibition on constructing vocative forms for foreign names does not apply to names from Classical Antiquity, with the source languages having the vocative case as well: cf Цезаре' ('Oh Caesar'), Перикле ('Oh Pericles'), Зевсе ('Oh Zeus'), etc.
Case remnants<br>
Some key words do retain their cases, which today are no longer considered nominative, accusative and dative, but rather as being subject, direct object and indirect object parts of speech:
Definiteness (article).
In modern Bulgarian, definiteness is expressed by a definite article which is postfixed to the noun, much like in the Scandinavian languages or Romanian (indefinite: човек, 'person'; definite: човекът, ""the" person") or to the first nominal constituent of definite noun phrases (indefinite: добър човек, 'a good person'; definite: добрият човек, ""the" good person"). There are four singular definite articles. Again, the choice between them is largely determined by the noun's ending in the singular. Nouns that end in a consonant and are masculine use –ът/–ят, when they are grammatical subjects, and –а/–я elsewhere. Nouns that end in a consonant and are feminine, as well as nouns that end in –а/–я (most of which are feminine, too) use –та. Nouns that end in –е/–о use –то.
The plural definite article is –те for all nouns except for those, whose plural form ends in –а/–я; these get –тa instead. When postfixed to adjectives the definite articles are –ят/–я for masculine gender (again, with the longer form being reserved for grammatical subjects), –та for feminine gender, –то for neuter gender, and –те for plural.
In Bulgarian adjective-noun phrases, only the adjective takes a definite article ending –
Many of the English loanwords which have been adopted into the language since the end of communism, however, do not readily lend themselves to taking adjectival endings. This has caused an unprecedented shift in the language whereby, in certain cases, the adjective remains uninflected while the noun following it takes the grammatical ending. Examples include –
This type of combination is sometimes favoured even when the possibility of a traditional phrase structure exists, e.g. –
In this case, the brand name "btv" cannot be inflected and, being a brand, remains in Roman script within the sentence.
Adjective and numeral inflection.
Both groups agree in gender and number with the noun they are appended to. They may also take the definite article as explained above.
Pronouns.
Pronouns may vary in gender, number, definiteness and are the only parts of speech that have retained case inflections. Three cases are exhibited by some groups of pronouns – nominative, accusative and dative. The distinguishable types of pronouns include the following: personal, relative, reflexive, interrogative, negative, indefinitive, summative and possessive.
Verbal morphology and grammar.
The Bulgarian verb can take up to 3,000 distinct forms, as it varies in person, number, voice, aspect, mood, tense and even gender.
Finite verbal forms.
Finite verbal forms are "simple" or "compound" and agree with subjects in person (first, second and third) and number (singular, plural) in Bulgarian. In addition to that, past compound forms using participles vary in gender (masculine, feminine, neuter) and voice (active and passive) as well as aspect (perfective/aorist and imperfective).
Aspect.
Bulgarian verbs express lexical aspect: perfective verbs signify the completion of the action of the verb and form past perfective (aorist) forms; imperfective ones are neutral with regard to it and form past imperfective forms. Most Bulgarian verbs can be grouped in perfective-imperfective pairs (imperfective/perfective: идвам/дойда "come", пристигам/пристигна “arrive”). Perfective verbs can be usually formed from imperfective ones by suffixation or prefixation, but the resultant verb often deviates in meaning from the original. In the pair examples above, aspect is stem-specific and therefore there is no difference in meaning.
In Bulgarian, there is also grammatical aspect. Three grammatical aspects are distinguishable: neutral, perfect and pluperfect. The neutral aspect comprises the three simple tenses and the future tense. The pluperfect is manifest in tenses that use double or triple auxiliary "be" participles like the past pluperfect subjunctive. Perfect constructions use a single auxiliary "be".
Mood.
The traditional interpretation is that in addition to the four moods (наклонения ) shared by most other European languages – indicative (изявително, ) imperative (повелително ), subjunctive (подчинително ) and conditional (условно, ) – in Bulgarian there is one more to describe a general category of unwitnessed events – the inferential (преизказно ) mood.
Tense.
There are three grammatically distinctive positions in time – present, past and future – which combine with aspect and mood to produce a number of formations. Normally, in grammar books these formations are viewed as separate tenses – i. e. "past imperfect" would mean that the verb is in past tense, in the imperfective aspect, and in the indicative mood (since no other mood is shown). There are more than 40 different tenses across Bulgarian's two aspects and five moods.
In the indicative mood, there are three simple tenses:
In the indicative there are also the following compound tenses:
The four perfect constructions above can vary in aspect depending on the aspect of the main-verb participle; they are in fact pairs of imperfective and perfective aspects. Verbs in forms using past participles also vary in voice and gender.
There is only one simple tense in the imperative mood – the present – and there are simple forms only for the second person using the suffixes -и/-й (-i, -y/i) for singular and -ете/-йте (-ete, -yte) for plural; e.g., уча ('to study'): учи , sg., учете , pl.; играя 'to play': играй , играйте . There are compound imperative forms for all persons and numbers in the present compound imperative (да играе, ), the present perfect compound imperative (да е играл, ) and the rarely used present pluperfect compound imperative (да е бил играл, ).
The conditional mood consists of five compound tenses, most of which are not grammatically distinguishable. The present, future and past conditional use a special past form of the stem би- (bi – "be") and the past participle (бих учил, , 'I would study'). The past future conditional and the past future perfect conditional coincide in form with the respective indicative tenses.
The subjunctive mood is rarely documented as a separate verb form in Bulgarian, (being, morphologically, a sub-instance of the quasi-infinitive construction with the particle да and a normal finite verb form), but nevertheless it is used regularly. The most common form, often mistaken for the present tense, is the present subjunctive ([пo-добре] да отидa , 'I had better go'). The difference between the present indicative and the present subjunctive tense is that the subjunctive can be formed by "both" perfective and imperfective verbs. It has completely replaced the infinitive and the supine from complex expressions (see below). It is also employed to express opinion about "possible" future events. The past perfect subjunctive ([пo-добре] да бях отишъл , 'I'd had better be gone') refers to "possible" events in the past, which "did not" take place, and the present pluperfect subjunctive (да съм бил отишъл ), which may be used about both past and future events arousing feelings of incontinence, suspicion, etc. and has no perfect to English translation.
The inferential mood has five pure tenses. Two of them are simple – "past aorist inferential" and "past imperfect inferential" – and are formed by the past participles of perfective and imperfective verbs, respectively. There are also three compound tenses – "past future inferential", "past future perfect inferential" and "past perfect inferential". All these tenses' forms are gender-specific in the singular. There are also conditional and compound-imperative crossovers. The existence of inferential forms has been attributed to Turkic influences by most Bulgarian linguists. Morphologically, they are derived from the perfect.
Non-finite verbal forms.
Bulgarian has the following participles:
The participles are inflected by gender, number, and definiteness, and are coordinated with the subject when forming compound tenses (see tenses above). When used in attributive role the inflection attributes are coordinated with the noun that is being attributed.
Reflexive verbs.
Bulgarian uses reflexive verbal forms (i.e. actions which are performed by the agent onto him- or herself) which behave in a similar way as they do in many other Indo-European languages, such as French and Spanish. It uses the invariable particle se in order to indicate all actions performed onto oneself, both in the singular and plural. Thus –
When the action is performed onto others, other particles are used, just like in any normal verb, e.g. –
Sometimes, the reflexive verb form has a similar but not necessarily identical meaning to the non-reflexive verb –
In other cases, the reflexive verb has a completely different meaning from its non-reflexive counterpart –
When the action is performed on an indirect object, the particles change to si and its derivatives –
In some cases, the particle "si" has the double meaning of a possessive –
The difference between transitive and intransitive verbs can lead to significant differences in meaning with minimal change, e.g. –
The particle "si" is often used to indicate a more personal relationship to the action, e.g. –
Adverbs.
The most productive way to form adverbs is to derive them from the neuter singular form of the corresponding adjective—e.g. бързо (fast), силно (hard), странно (strange)—but adjectives ending in -ки use the masculine singular form (i.e. ending in -ки), instead—e.g. юнашки (heroically), мъжки (bravely, like a man), майсторски (skillfully). The same pattern is used to form adverbs from the (adjective-like) ordinal numerals, e.g. първо (firstly), второ (secondly), трето (thirdly), and in some cases from (adjective-like) cardinal numerals, e.g. двойно (twice as/double), тройно (three times as), петорно (five times as).
The remaining adverbs are formed in ways that are no longer productive in the language. A small number are original (not derived from other words), for example: тук (here), там (there), вътре (inside), вън (outside), много (very/much) etc. The rest are mostly fossilized case forms, such as:
Adverbs can sometimes be reduplicated to emphasize the qualitative or quantitative properties of actions, moods or relations as performed by the subject of the sentence: "бавно-бавно" ("rather slowly"), "едва-едва" ("with great difficulty"), "съвсем-съвсем" ("quite", "thoroughly").
Syntax.
Bulgarian employs clitic doubling, mostly for emphatic purposes. For example, the following constructions are common in colloquial Bulgarian:
The phenomenon is practically obligatory in the spoken language in the case of inversion signalling information structure (in writing, clitic doubling may be skipped in such instances, with a somewhat bookish effect):
Sometimes, the doubling signals syntactic relations, thus:
This is contrasted with:
In this case, clitic doubling can be a colloquial alternative of the more formal or bookish passive voice, which would be constructed as follows:
Clitic doubling is also fully obligatory, both in the spoken and in the written norm, in clauses including several special expressions that use the short accusative and dative pronouns such as играе ми се (I feel like playing), студено ми е (I am cold), and боли ме ръката (my arm hurts):
Except the above examples, clitic doubling is considered inappropriate in a formal context. Bulgarian grammars usually do not treat this phenomenon extensively.
Other features.
Questions.
Questions in Bulgarian which do not use a question word (such as who? what? etc.) are formed with the particle ли after the verb; a subject is not necessary, as the verbal conjugation suggests who is performing the action:
While the particle "ли" generally goes after the verb, it can go after a noun or adjective if a contrast is needed:
A verb is not always necessary, e.g. when presenting a choice:
Rhetorical questions can be formed by adding ли to a question word, thus forming a "double interrogative" –
The same construction +не ('no') is an emphasised positive –
Significant verbs.
The verb съм – 'to be' is also used as an auxiliary for forming the perfect, the passive and the conditional:
Two alternate forms of съм exist:
The impersonal verb щe (lit. 'it wants') is used to for forming the (positive) future tense:
The negative future is formed with the invariable construction няма да (see няма below):
The past tense of this verb – щях is conjugated to form the past conditional ('would have' – again, with да, since it is "irrealis"):
Имам and нямам
The verbs имам ('to have') and нямам ('to not have'):
Diminutives and augmentatives.
Diminutive
Usually done by adding -че, -це or -(ч)ка. The gender of the word is thus changed, usually to the neuter:
Affectionate Form
Sometimes proper nouns and words referring to friends or family members can have a diminutive ending added to show affection. These constructions are all referred to as ""na galeno"" (lit. "caressing" form):
Such words can be used "both" from parent to child, and vice-versa, as can:
Personal names are shortened and made neuter:
There is an interesting trend (which is comparatively modern, although it might well have deeper, dormant roots) where the feminine ending "-ka" and the definite article suffix "-ta" ("the") are added to male names – note that this is affectionate and not at all insulting (in fact, the endings are not even really considered as being "feminine"):
The female equivalent would be to add the neuter ending "-to" to the diminutive form:
Augmentative
This is to present words to sound larger – usually by adding "-shte":
Some words only exist in an augmentative form – e.g.
Conjunctions and particles.
"But"
In Bulgarian, there are several conjunctions all translating into English as "but", which are all used in distinct situations. They are "но (no), ама (amà), а (a), ами (amì)", and "ала (alà)" (and "обаче (obache)" – "however", identical in use to "но").
While there is some overlapping between their uses, in many cases they are specific. For example, ami is used for a choice – "ne tova, ami onova" – "not this one, but that one" (comp. Spanish "sino"), while ama is often used to provide extra information or an opinion – "kazah go, ama sgreshih" – "I said it, but I was wrong". Meanwhile, a provides contrast between two situations, and in some sentences can even be translated as "although", "while" or even "and" – "az rabotya, a toy blee" – "I'm working, and he's daydreaming".
Very often, different words can be used to alter the emphasis of a sentence – e.g. while ""pusha, no ne tryabva"" and ""pusha, a ne tryabva"" both mean "I smoke, but I shouldn't", the first sounds more like a statement of fact ("...but I mustn't"), while the second feels more like a "judgement" ("...but I oughtn't"). Similarly, "az ne iskam, ama toy iska" and "az ne iskam, a toy iska" both mean "I don't want to, but he does", however the first emphasises the fact that "he" wants to, while the second emphasises the "wanting" rather than the person.
"Ala" is interesting in that, while it feels archaic, it is often used in poetry and frequently in children's stories, since it has quite a moral/ominous feel to it.
Some common expressions use these words, and some can be used alone as interjections:
Bulgarian has several abstract particles which are used to strengthen a statement. These have no precise translation in English. The particles are strictly informal and can even be considered rude by some people and in some situations. They are mostly used at the end of questions or instructions.
Modal Particles
These are "tagged" on to the beginning or end of a sentence to express the mood of the speaker in relation to the situation. They are mostly interrogative or slightly imperative in nature. There is no change in the grammatical mood when these are used (although they may be expressed through different grammatical moods in other languages).
These express intent or desire, perhaps even pleading. They can be seen as a sort of cohortative side to the language. (Since they can be used by themselves, they could even be considered as verbs in their own right.) They are also highly informal.
These particles can be combined with the vocative particles for greater effect, e.g. "ya da vidya, be" (let me see), or even exclusively in combinations with them, with no other elements, e.g. "haide, de!" (come on!); "nedey, de!" (I told you not to!).
Pronouns of Quality.
Bulgarian has several pronouns of quality which have no direct parallels in English – "kakuv" (what sort of); "takuv" (this sort of); "onakuv" (that sort of – colloq.); "nyakakuv" (some sort of); "nikakuv" (no sort of); "vsyakakuv" (every sort of); and the relative pronoun "kakuvto" (the sort of...that...). The adjective "ednakuv" ("the same") derives from the same radical.
Example phrases include:
An interesting phenomenon is that these can be strung along one after another in quite long constructions, e.g.,
An extreme (colloquial) sentence, with almost no "physical" meaning in it whatsoever – yet which "does" have perfect meaning to the Bulgarian ear – would be :
—Note: the subject of the sentence is simply the pronoun "taya" (lit. "this one here"; colloq. "she").
Similar "meaningless" expressions are extremely common in spoken Bulgarian, especially when the speaker is finding it difficult to describe something.
Agglutination.
Although not considered an agglutinative language, Bulgarian does have agglutinative features. In the simplest terms, this can be seen in the way that most nouns and verbs are formed – namely by adding prefixes and suffixes to a rather limited number of roots, which creates almost a dozen new words, along with a couple of dozen derivatives thereof. Here are some examples using the root word "klyuch" (ключ) "key/switch" –
Nouns –
Adjectives –
Verbs –
An extreme example using this root might be –
Adjectives can also take up to three endings, including infixes, which are added to the masculine root, e.g. –
Verbs can take several prefixes, thus expressing increasingly complex ideas. For example, the "–bol–" root, which has to do with ailments ("bol-ka" – pain; "bol-est" – illness; "bol-i" – it hurts, etc.), can be used to express various different stages of falling ill –
Similarly, the root –kri–, referring to hiding/discovery –
Lexis.
Most of the vocabulary of modern Bulgarian consists of derivations of some 2,000 words inherited from proto-Slavic through the mediation of Old and Middle Bulgarian. Thus, the native lexical terms in Bulgarian account for 70% to 75% of the lexicon.
The remaining 25% to 30% are loanwords from a number of languages, as well as derivations of such words. The languages which have contributed most to Bulgarian are Russian, French and to a lesser extent Turkish and English. Also Latin and Greek are the source of many words, used mostly in international terminology. Many of the numerous loanwords from Turkish (and, via Turkish, from Arabic and Persian) which were adopted into Bulgarian during the long period of Ottoman rule, have been replaced with native terms. In addition, both specialized (usually coming from the field of science) and commonplace English words (notably abstract, commodity/service-related or technical terms) have also penetrated Bulgarian since the second half of the 20th century, especially since 1989. A noteworthy portion of this English-derived terminology has attained some unique features in the process of its introduction to native speakers, and this has resulted in peculiar derivations that slightly set the newly formed loanwords apart from the original words (mainly in pronunciation), although many loanwords are completely identical to the source words. A growing number of international neologisms are also being widely adopted.
Borrowings.
Some very frequent expressions have been borrowed from other languages. Most of them are somewhat informal.
External links.
Linguistic reports
Dictionaries
Courses

</doc>
<doc id="4153" url="http://en.wikipedia.org/wiki?curid=4153" title="Bipyramid">
Bipyramid

An "n"-gonal bipyramid or dipyramid is a polyhedron formed by joining an "n"-gonal pyramid and its mirror image base-to-base.
The referenced "n"-gon in the name of the bipyramids is not an external face but an internal one, existing on the primary symmetry plane which connects the two pyramid halves.
The face-transitive bipyramids are the dual polyhedra of the uniform prisms and will generally have isosceles triangle faces.
A bipyramid can be projected on a sphere or globe as "n" equally spaced lines of longitude going from pole to pole, and bisected by a line around the equator.
Bipyramid faces, projected as spherical triangles, represent the fundamental domains in the dihedral symmetry Dnh.
Volume.
The volume of a bipyramid is formula_1 where "B" is the area of the base and "h" the height from the base to the apex. This works for any location of the apex, provided that "h" is measured as the perpendicular distance from the plane which contains the base.
The volume of a bipyramid whose base is a regular "n"-sided polygon with side length "s" and whose height is "h" is therefore: 
Equilateral triangle bipyramids.
Only three kinds of bipyramids can have all edges of the same length (which implies that all faces are equilateral triangles, and thus the bipyramid is a deltahedron): the triangular, tetragonal, and pentagonal bipyramids. The tetragonal bipyramid with identical edges, or regular octahedron, counts among the Platonic solids, while the triangular and pentagonal bipyramids with identical edges count among the Johnson solids (J12 and J13).
Kalidescopic symmetry.
If the base is regular and the line through the apexes intersects the base at its center, the symmetry group of the "n"-agonal bipyramid has dihedral symmetry D"n"h of order 4"n", except in the case of a regular octahedron, which has the larger octahedral symmetry group Oh of order 48, which has three versions of D4h as subgroups. The rotation group is D"n" of order 2"n", except in the case of a regular octahedron, which has the larger symmetry group O of order 24, which has three versions of D4 as subgroups.
The digonal faces of a spherical "2n"-bipyramid represents the fundamental domains of dihedral symmetry in three dimensions: Dnh, [n,2], (*n22), order "4n". The reflection domains can be shown as alternately colored triangles as mirror images.
Star bipyramids.
Self-intersecting bipyramids exist with a star polygon central figure, defined by triangular faces connecting each polygon edge to these two points. A {p/q} bipyramid has Coxeter-Dynkin diagram .
Polychora with bipyramid cells.
The dual of the rectification of each convex regular polychoron is a cell-transitive polychoron with bipyramidal cells. In the following, the apex vertex of the bipyramid is A and an equator vertex is E. The distance between adjacent vertices on the equator EE=1, the apex to equator edge is AE and the distance between the apices is AA. The bipyramid polychoron will have VA vertices where the apices of NA bipyramids meet. It will have VE vertices where the type E vertices of NE bipyramids meet. NAE bipyramids meet along each type AE edge. NEE bipyramids meet along each type EE edge. CAE is the cosine of the dihedral angle along an AE edge. CEE is the cosine of the dihedral angle along an EE edge. As cells must fit around an edge, 
NAA cos−1(CAA) ≤ 2π, NAE cos−1(CAE) ≤ 2π.
Higher dimensions.
In general, a "bipyramid" can be seen as an "n"-polytope constructed with a ("n"−1)-polytope in a hyperplane with two points in opposite directions, equal distance perpendicular from the hyperplane. If the ("n"−1)-polytope is a regular polytope, it will have identical pyramids facets.

</doc>
<doc id="4154" url="http://en.wikipedia.org/wiki?curid=4154" title="Beast of Bodmin">
Beast of Bodmin

The Beast of Bodmin, also known as the Beast of Bodmin Moor () is a phantom wild cat purported to live in Cornwall, in the United Kingdom. Bodmin Moor became a centre of these sightings with occasional reports of mutilated slain livestock: the alleged panther-like cats of the same region came to be popularly known as the Beast of Bodmin Moor.
In general, scientists reject such claims because of the improbably large numbers necessary to maintain a breeding population and because climate and food supply issues would make such purported creatures' survival in reported habitats unlikely.
Investigation.
A long held hypothesis suggests the possibility that alien big cats at large in the United Kingdom could have been imported as part of private collections or zoos, later escaped or set free. An escaped big cat would not be reported to the authorities due to the illegality of owning and importing the animals.
The Ministry of Agriculture, Fisheries and Food conducted an official investigation in 1995. The study found that there was 'no verifiable evidence' of exotic felines loose in Britain, and that the mauled farm animals could have been attacked by common indigenous species. The report stated that 'the investigation could not prove that a "big cat" is not present.'
Skull.
Less than a week after the government report, a boy was walking by the River Fowey when he discovered a large cat skull. Measuring about long by wide, the skull was lacking its lower jaw but possessed two sharp, prominent canines that suggested that it might have been a leopard. The story hit the national press at about the same time of the official denial of alien big cat evidence on Bodmin Moor.
The skull was sent to the Natural History Museum in London for verification. They determined that it was a genuine skull from a young male leopard, but also found that the cat had not died in Britain and that the skull had been imported as part of a leopard-skin rug. The back of the skull was cleanly cut off in a way that is commonly used to mount the head on a rug. There was an egg case inside the skull that had been laid by a tropical cockroach that could not possibly be found in Britain. There were also cut marks on the skull indicating the flesh had been scraped off with a knife, and the skull had begun to decompose only after a recent submersion in water.

</doc>
<doc id="4157" url="http://en.wikipedia.org/wiki?curid=4157" title="Brown University">
Brown University

Brown University is a private Ivy League research university in Providence, Rhode Island.
Founded in 1764 prior to American independence from the British Empire as the "College in the English Colony of Rhode Island and Providence Plantations", Brown is the third oldest institution of higher education in New England and seventh oldest in the United States. The university consists of The College, Graduate School, Alpert Medical School, the School of Engineering, and the Brown University School of Public Health. Brown's international programs are organized through the Watson Institute for International Studies.
Brown accepts 8.6% of undergraduate applicants, placing it among the world's most selective universities, and was the first college in America to accept students regardless of religious affiliation. The New Curriculum, instituted in 1969, eliminated distribution requirements and allows any course to be taken on a satisfactory/no credit basis. In addition, there are no pluses or minuses in the letter grading system. The school has the oldest undergraduate engineering program in the Ivy League (1847). Pembroke College, Brown's women's college, merged with the university in 1971. While Brown is considered a small research university with 713 full-time faculty and 1,947 graduate students, five of its professors and two of its alumni have been honored as Nobel Laureates. The faculty added 100 new professors in the past 10 years under the Boldly Brown campaign.
Completed concentrations of undergraduates by area are Social Sciences (42%), Humanities (26%), Life Sciences (17%), and the Physical Sciences (14%). Brown's main campus is located on College Hill on the East Side of Providence. Several of the buildings on the Brown campus from its founding 18th century period through the 20th century offer fine representation of the Georgian style of American colonial era architecture. The university's 37 varsity athletic teams are known as the Brown Bears. The school colors are seal brown, cardinal red, and white. Brown's mascot is the bear, which dates back to 1904. The costumed mascot named "Bruno" frequently makes appearances at athletic games. People associated with the University are known as Brunonians.
History.
Founding.
Brown owes its founding to the support of learning among a Baptist Church association but in 1762, the Baptist Minister Morgan Edwards was at first ridiculed for suggesting the founding of a college. In his "Materials for a History of the Baptists in Rhode Island", Edwards wrote:"The first mover himself for it Baptist college in 1762 was laughed at as a projector of a thing impracticable. Nay, many of the Baptists themselves discouraged the design (prophesying evil to the churches in case it should take place) from an unhappy prejudice against learning." Nonetheless, Edwards joined several others as an original fellow or trustee for the chartering of the "College in the English Colony of Rhode Island and Providence Plantations" (the former name for Brown University), the first Baptist college in the original thirteen colonies, and now one of the Ivy League universities.
In 1763, The Reverend James Manning, a Baptist minister, and an alumnus of the College of New Jersey (predecessor to today's Princeton University), was sent to Rhode Island by the Philadelphia Association of Baptist Churches in order to found the college.
At the same time, local Congregationalists, led by the theologist Ezra Stiles, were working toward a similar end. The inaugural board meeting of the Corporation of the College in the English Colony of Rhode Island & Providence Plantations was held in the Old Colony House in Newport, Rhode Island. Former colonial governors of Rhode Island Stephen Hopkins and Samuel Ward, as well as the Reverend Isaac Backus and the Reverend Samuel Stillman, were among those who played an instrumental role in Brown's foundation and later became American revolutionaries. On March 3, 1764, a charter was filed to create the College in Warren, Rhode Island, reflecting the work of both Stiles and Manning. Contrary to popular belief, the college did not gain its charter by grant of King George III; rather, its charter was granted in the form of an Act passed by the Colony's General Assembly.
The charter had more than sixty signatories, including the brothers John, Nicholas and Moses of the Brown family, who would later inspire the College's modern name following a gift bestowed by Nicholas Brown, Jr. The college's mission, the charter stated, was to prepare students "for discharging the Offices of Life with usefulness & reputation" by providing instruction "in the Vernacular and Learned Languages, and in the liberal Arts and Sciences." The charter required that the makeup of the board of 36 trustees include, 22 Baptists, five Friends, four Congregationalists, and five Church of England members, and by 12 Fellows, of whom eight, including the President, should be Baptists "and the rest indifferently of any or all denominations." It specified that "into this liberal and catholic institution shall never be admitted any religious tests, but on the contrary, all the members hereof shall forever enjoy full, free, absolute, and uninterrupted liberty of conscience." One of the Baptist founders, John Gano, had also been the founding minister of the First Baptist Church in the City of New York. The Encyclopædia Britannica Eleventh Edition remarks that "At the time it was framed the charter was considered extraordinarily liberal" and that "the government has always been largely non-sectarian in spirit." In commemoration of this history, each spring faculty and the graduating class proceed down the hill, in academic dress, to the grounds of the First Baptist Meeting House (erected in 1774, "for the publick Worship of Almighty GOD and also for holding Commencement in") for the conferral of the bachelors degree.
James Manning was sworn in as the College's first president in 1765. His tenure lasted until 1791. During his presidency, the College moved to its present location on College Hill in the East Side of Providence in 1770 and construction of the first building, the College Edifice, began. This building was renamed University Hall in 1823.
The Brown family — Nicholas Sr., John, Joseph, and Moses,— were instrumental in the move to Providence, funding and organizing much of the construction of the new buildings on the former Rev. Chad Brown farm. The family's connection with the college was strong: Joseph Brown became a professor of Physics at the University, and John Brown served as treasurer from 1775 to 1796. In 1804, a year after John Brown's death, the University was renamed Brown University in honor of John's nephew, Nicholas Brown, Jr., who was a member of the class of 1786 and in 1804 contributed $5,000 toward an endowed professorship. In 1904, the John Carter Brown Library was opened as a research center on Americas based on the libraries of John Carter Brown and his son John Nicholas Brown. The Brown family was involved in various business ventures in Rhode Island, and made a small part of its wealth in businesses related to the slave trade. The family itself was divided on the issue. John Brown had unapologetically defended slavery, while Moses Brown and Nicholas Brown Jr. were fervent abolitionists. In recognition of this complex history, under President Ruth Simmons, the University established the University Steering Committee on Slavery and Justice in 2003.
Brown began to admit women when it established a Women's College in Brown University in 1891, which was later named Pembroke College in Brown University. "The College" (the undergraduate school) merged with Pembroke College in 1971 and became co-educational.
The language of the Brown University charter has long been interpreted by the university as discouraging the founding of a business school or law school. Brown continues to be one of only two Ivy League colleges with neither a business school nor a law school (the other being Princeton). Nevertheless, Brown recently developed an Executive MBA program in conjunction with one of the leading Business Schools in Europe; IE Business School in Madrid. In this partnership, Brown provides the traditional coursework while IE provides most of the business related subjects.
American Revolution.
Stephen Hopkins, Chief Justice and Governor of the "English Colony of Rhode Island and Providence Plantations", was a Delegate to the Colonial Congress in Albany in 1754 and to the Continental Congress from 1774 to 1776. He was a signatory to the United States Declaration of Independence on behalf of the state of Rhode Island. He also served as the first chancellor of Brown from 1764 to 1785. His house is a minor historical site, located just off the main green at Brown.
In 1781, allied American and French armies under the command of General George Washington and the Comte de Rochambeau, who led troops sent by King Louis XVI of France, embarked on a march from Rhode Island to Virginia, where they fought and defeated British forces sent by King George III of the United Kingdom on the Yorktown, Virginia peninsula. The victory ended the major battles of the American Revolutionary War. Prior to the march, Brown University served as an encampment site for French troops, and the College Edifice, now University Hall, was turned into a military hospital.
Other founders of Brown who played significant roles in the American revolutionary effort included John Brown in the Gaspee Affair, Chief Justice Dr. Joshua Babcock as major general in the state militia and William Ellery as a signatory to the Declaration of Independence.
James Mitchell Varnum, who graduated with honors in Brown's first graduating class of 1769, served as one of General George Washington's Continental Army Brigadier Generals and later as Major General in command of the entire Rhode Island militia. David Howell, who graduated with an A.M. in the same year as General Varnum, served as a delegate to the Continental Congress from 1782 to 1785.
In 1786, President James Manning was elected and served as representative for Rhode Island to the seventh session of the United States in Congress Assembled, held in New York. In that capacity, he served on the Grand Committee, which proposed fundamental amendments to the Articles of Confederation and presaged the Constitution of the United States.
New curriculum.
In 1850, Brown President Francis Wayland wrote: "The various courses should be so arranged that, insofar as practicable, every student might study what he chose, all that he chose, and nothing but what he chose." In 1969, the adoption of the New Curriculum marked a milestone in the University's institutional history and is seen as a significant step towards realizing Wayland's vision. The curriculum was the result of a paper written by Ira Magaziner and Elliot Maxwell entitled "Draft of a Working Paper for Education at Brown University." The paper came out of a year-long Group Independent Study Project (GISP) involving 80 students and 15 professors. The group was inspired by student-initiated experimental schools, especially San Francisco State College, and sought ways to improve education for students at Brown. The philosophy they formed sought to "put students at the center of their education" and to "teach students how to think rather than just teaching facts."
The paper made a number of suggestions for improving education at Brown, including a new kind of interdisciplinary freshman course that would introduce new modes of inquiry and bring faculty from different fields together. Their goal was to transform the survey course, which traditionally sought to cover a large amount of basic material, into specialized courses that would introduce the important modes of inquiry used in different disciplines.
Following a student rally in support of reform, President Ray Heffner appointed the Special Committee on Curricular Philosophy with the task of developing specific reforms. These reforms, known as the Maeder Report (after the chair of the committee), were then brought to the faculty for a vote. On May 7, 1969, following a marathon meeting with 260 faculty members present, the New Curriculum was passed. Its key features included the following:
Except for the Modes of Thought courses, a key component of the reforms which have been discontinued, these elements of the New Curriculum are still in place.
Additionally, due to the school's proximity and close partnership with the Rhode Island School of Design (RISD), Brown students have the opportunity to take up to four courses at RISD and have the credit count towards a Brown degree. Likewise, RISD students can also take courses at Brown. Since the two campuses are effectively adjacent to each other, the two institutions often partner to provide both student bodies with services (such as the local Brown/RISD after-hours and downtown transportation shuttles). In July 2007 the two institutions announced the formation of the Brown/RISD Dual Degree Program, which allowed students to pursue an A.B. degree at Brown and a B.F.A. degree at RISD simultaneously, a five-year program. The first students in the new program matriculated in 2008.
As recently as 2006, there has been some debate on reintroducing plus/minus grading to the curriculum. Advocates argue that adding pluses and minuses would reduce grade inflation and allow professors to give more specific grades, while critics say that this plan would have no effect on grade inflation while increasing unnecessary competition among students and violating the principle of the New Curriculum. Ultimately, the addition of pluses and minuses to the grading system was voted down by the College Curriculum Council.
The University is currently in the process of broadening and expanding its curricular offerings as part of the "Plan for Academic Enrichment." The number of faculty has been greatly expanded. Seminars aimed at freshmen have begun to be offered widely by most departments.
As a part of the re-accreditation process, Brown University is undergoing an expansive reevaluation of its undergraduate education offerings through the newly appointed Task Force on Undergraduate Education. This Task Force is charged with assessing the areas of general education, concentrations, advising, and pedagogy and assessment.
Presidents.
Brown's current president Christina Hull Paxson took office in 2012. She had previously been dean of the Woodrow Wilson School at Princeton University and a past-chair of Princeton's economics department. In 2014 Paxson will preside during the 250th anniversary of Brown's founding. Her immediate predecessor as president was Ruth J. Simmons, the first African American president of an Ivy League institution. Simmons will remain at Brown as a professor of Comparative Literature and Africana Studies.
Academics.
The College.
Founded in 1764, The College is the oldest school of Brown University. Nearly 6,000 undergraduate students are currently enrolled in the college, and approximately 80 concentrations (majors) are offered. Completed concentrations of undergraduates by area are Social Sciences (42%), Humanities (26%), Life Sciences (17%), and the Physical Sciences (14%). The concentrations with the greatest number of students are Biology, History, and International Relations. Brown is one of the few schools in the United States with an undergraduate concentration (major) in Egyptology. Undergraduates can also design an independent concentration if the existing standard programs do not fit their interests.
35% of undergraduates pursue graduate or professional study immediately, 60% within 5 years, and 80% within 10 years. For the Class of 1998, 75% of all graduates enrolled in a graduate or professional degree program since graduating from Brown. The most degrees acquired were a Master's (35%) in any field, a Medical (28%), Doctoral (22%), or a Law (14%) degree, in highest order. There are not many who pursued the Ph.D compared to a Master's (for instance, business), or a Medical degree.
The highest fields of employment for graduates of the College are Business (36%), Education (19%), Health/Medical (6%), Arts (6%), Government (6%), and Communications/Media (5%) in highest order.
Graduate School.
Established in 1887, The Graduate School currently has around 2,000 students studying over 50 disciplines. 20 different master's degrees are offered as well as Ph.D. degrees in over 40 subjects ranging from applied mathematics to public policy. Overall, admission to the Graduate School is most competitive with an acceptance rate of about 18%.
Alpert Medical School.
The University's medical program started in 1811, but the school was suspended by President Wayland in 1827 after the program's faculty declined to live on campus (a new requirement under Wayland). In 1975, the first M.D. degrees from the new Program in Medicine were awarded to a graduating class of 58 students. In 1991, the school was officially renamed the Brown University School of Medicine, then renamed once more to Brown Medical School in October 2000. In January 2007, self-made entrepreneur Warren Alpert donated $100 million to Brown Medical School on behalf of the Warren Alpert Foundation, tying Sidney Frank for the largest single monetary contribution ever made to the University. In recognition of the gift, the faculty of Brown University approved changing the name of the Brown Medical School to The Warren Alpert Medical School of Brown University. It is currently ranked 29th among U.S. medical schools in research and 28th in primary care according to U.S. News & World Report. Admissions to Alpert is one of the most competitive in the nation, with only less than 2% of those applying through the Standard Route accepted in 2008 (5,902 applications for 94 spots).
The medical school is known for its eight-year Program in Liberal Medical Education (PLME), which was started in 1984 and is one of the most selective programs in the nation. Each year, approximately 60 high school students matriculate into the PLME out of an applicant pool of about 1,600. Since 1976, the Early Identification Program (EIP) has encouraged Rhode Island residents to pursue careers in medicine by recruiting sophomores from Providence College, Rhode Island College, the University of Rhode Island, and Tougaloo College. In 2004, the school once again began to accept applications from premedical students at other colleges and universities via AMCAS like most other medical schools. The medical school also offers combined degree programs leading to the M.D./Ph.D., M.D./M.P.H. and M.D./M.P.P. degrees.
School of Engineering.
Brown has the oldest engineering program in the Ivy League. In 1916, multiple Departments of Engineering were consolidated into the Division of Engineering. As part of a broader growth initiative, in 2010, the Division of Engineering was authorized to begin operating as the School of Engineering.
Research centers and institutes.
Marine Biological Laboratory.
The Marine Biological Laboratory (MBL) is an independent research institution established in 1882 at Woods Hole, Massachusetts. The laboratory is linked to 54 current or past Nobel Laureates at its research or teaching faculty. Since 2005, the MBL and Brown University have collaborated in a Ph.D.-awarding Graduate Program in Biological and Environmental Sciences, which brings together faculty from both institutions. In 2010, the joint program was extended to include more professors participating in the partnership. The current faculty includes those from the Ecosystems Center, the Bay Paul Center, the Program in Cellular Dynamics, and the Marine Resources Center.
Watson Institute for International Studies.
The Watson Institute for International Studies, usually referred to as the Watson Institute, is a center for the analysis of international issues at Brown University. Its original benefactor was Thomas Watson, Jr., former Ambassador to the Soviet Union and president of IBM.
Pembroke Center for Teaching and Research on Women.
The Pembroke Center for Teaching and Research on Women, was established at Brown in 1981 as a research center on gender. It was named in honor of Pembroke College (Brown University), a decade after its merger with Brown University, and to recognize the history of women's efforts to gain access to higher education. Along with its numerous academic programs, including its sponsorship of post-doctoral research fellowships, the undergraduate concentration in Gender and Sexuality Studies, and the annual Pembroke Seminar, the Pembroke Center also organizes a number of programs throughout the year to recognize the historical achievements of women. Leading historian and social scientist Joan Wallach Scott was founding director of the Center. The Pembroke Center is affiliated with the Sarah Doyle Women's Center.
Computing.
Several projects of note involving hypertext and other forms of electronic text have been developed at Brown, including FRESS, Brown University Interactive Language (BRUIN), Hypertext Editing System, and Women Writers Project. In addition, the Computer Science department at Brown is home to The CAVE. This project is a complete virtual reality room, one of few in the world, and is used for everything from three-dimensional drawing classes to tours of the circulatory system for medical students.
In 2000, a group of students from the university's Technology House converted the south side of the Sciences Library into a giant video display which allowed bystanders to play Tetris, the largest of its kind ever in the Western Hemisphere. Constructed from 11 custom-built circuit boards, a 12-story data network, a personal computer running Linux, a radio-frequency video game controller, and over 10,000 Christmas lights, the project was named La Bastille and could be seen for several miles.
Academics, administration, and ranking.
"U.S. News & World Report" ranked Brown 14th among national universities in its 2014 edition (published in August 2014). Undergraduates make up a larger proportion of the student body at Brown than at any of the other Ivy League universities, leading some Brown administrators to question the fairness of the ranking in light of the University's focus on undergraduate education.
The same edition also ranked Brown 4th among national universities for undergraduate teaching (tying with Yale University).
Internationally, in 2012 Brown ranked 51st in the Times Higher Education World University Rankings and the Academic Ranking of World Universities ranked Brown 65th. In 2012, QS World University Rankings placed Brown at 42nd. According to the 2005 paper "Academic Ranking of World Universities – Methodologies and Problems" by the rankers, Brown's PCP (performance per-capita) score is equal to that of Columbia University, at 32.1, or 28th in the world. According to the 2011-2012 Times Higher Education Supplement ranking, Brown University's citation per capita score, counting for 30% of the overall score, is 93.9, or 32nd of the Top 200 universities, tied with Imperial College London.
Brown ranked 7th in the country (between Princeton and Columbia) in a study of high school seniors' revealed preferences for matriculation conducted by economists at Harvard, Wharton, and Boston University, and published in 2005 by the National Bureau of Economic Research. The 2008 Center for College Affordability and Productivity (CCAP) ranked Brown 5th in the country among national universities."
Brown ranked 5th in the country in Newsweek/The Daily Beast's "America's Brainiac Schools". The rankings are calculated based on the number of prestigious scholarships, adjusted for population size, won by students, including Rhodes Scholarships, Truman Scholarships, Marshall Scholarships, Gates Scholarships (since 2001), and the number of students receiving Fulbright scholarships (since 1993). Also factored in are scores on admissions tests, admission rates, and the proportion of students in the top 10% of their graduating high school class. The 4 schools besting Brown were, in order of rank, Yale University, Princeton University, Harvard University, and Stanford University.
As it had in 2007 and 2010, the 2011 Princeton Review email poll of college students ranked Brown 1st in the country for "Happiest Students." Brown is 3rd in the country (tied with Stanford) in the number of students awarded Fulbright grants, according to the October 2010 ranking compiled by the "Chronicle of Higher Education".
Graduate programs that ranked the top 10 in the 2010 U.S. News & World Report graduate school rankings included applied mathematics at 5th and growth economics at 8th. Those that are ranked in the top 20 are history at 14th, economics at 17th, English at 13th, engineering at 20th, mathematics at 14th, and computer science at 20th.
Admission and financial aid.
Brown is one of the most selective universities in the world. The admission rate for the undergraduate class of 2015 was 8.7 percent. For the class of 2014, 96 percent of accepted students were in the top 10 percent of their high school class, and 38 percent were either valedictorian or salutatorian. Brown began using the Common Application in the Fall of 2008. The Graduate School is also intensely competitive, with graduate programs accepting 18% of the 7,283 students who applied in 2008. The Warren Alpert Medical School of Brown University accepted less than 2% of more than 5,000 applicants.
Brown is need-blind for all domestic applicants. Brown's financial aid policy eliminates loans for all students whose family incomes are under $100,000, as well as all parental contributions for families whose incomes fall under $60,000. For these purposes, income is calculated by summing the adjusted gross income plus all untaxed income. In 2012, the program awarded need-based scholarships worth around $90 million.
According to the university, Brown seeks diverse applicants from "all walks of life, backgrounds, interests, and cultural heritages" but has "no quotas of any kind".
Campus.
Brown is the largest institutional landowner in Providence, with properties in the East Side and the Jewelry District. Unlike some other schools, there are also no clear physical landmarks to determine where Brown's campus begins or ends.
There is no official designation of different campus areas from the University, but the institution's buildings can be roughly categorized as follows.
Main campus.
Brown's main campus is located on College Hill, in the East Side, across the Providence River from downtown Providence. This is the where the University was relocated in 1770 after it was first established in Warren, Rhode Island, in 1764. The main campus consists of 235 buildings and covers . A salient feature of Brown's campus is that many of the academic departments reside in smaller, Victorian-era houses that the University has acquired over the years from the surrounding neighborhood.
The main campus area can be subdivided further into the inner, traditional campus greens and the outer neighborhood. The two greens, the "Main Green" and "Ruth J. Simmons Quadrangle" (formerly "Lincoln Field"), are large grass fields perpendicular to each other. These two areas contain many of the larger and more traditional academic and dormitory buildings, including University Hall (1770). This part of the main campus is enclosed by brick and wrought iron fence, with the Van Wickle Gates serving as the prominent entrance on College Street. It is this area that is featured in most publications and photographs of Brown's campus.
Outside of the gates, but still considered part of the main campus, are other University buildings and libraries that have been built at Brown over the centuries. This includes the Wriston Quad to the south of the Main Green; the John Hay Library and John D. Rockefeller, Jr. Library directly across the street from the Van Wickle Gates; and the Sciences Library and Thomas J. Watson, Sr. Center for Information Technology (CIT) adjacent to the Soldiers Memorial Gate. Because this area is not confined by the gates, Brown has been able to acquire larger plots of land and construct much larger buildings as the University has expanded.
Adjacent to Brown's main campus, and further down the Hill to the west by the Providence River, is the campus of the Rhode Island School of Design. Thayer Street, which runs through Brown's campus, is a commercial district that hosts many restaurants and shops popular with students and faculty from Brown and RISD.
Pembroke Campus.
When Pembroke College merged with Brown in 1971, the campus was absorbed as part of Brown's overall campus. For the most part, the campus is made up of dormitories, although notable exceptions include: Alumnae Hall, which houses a dance floor (and formerly a small University-run diner known as The Gate); Andrews Commons, which houses a study lounge and a retail dining eatery known as Andrews Dining Hall; Smith-Buonano hall, the gymnasium of Pembroke College that was later renovated to contain a common room, classrooms, and a lecture hall; and Pembroke Hall, the original classroom building for Pembroke College and now home to the Cogut Center for the Humanities and the Pembroke Center for Teaching and Research on Women. Furthermore, the campus has its own dining hall, Verney-Woolley Dining Hall, the second of Brown's main dining halls. Somewhere between 25 and 30% of the incoming Freshman class lives on Pembroke, though there are also many upperclassmen.
The Walk and surrounding area.
The Brown Walk connects Pembroke Campus to the main campus. It's a newer green space, extending north from Waterman Street. It is bordered by the building at 155 Angell St. (home to the Africana Studies Department and the Rites and Reason Theatre) and the UEL (Urban Environmental Lab, a.k.a. The Center for Environmental Studies, also facing Angell St) among other things. Between Pembroke Campus and Main Campus, next to the Brown Bookstore, the Granoff Center for the Creative Arts opened in January 2011. Intended renovations will allow pedestrians to see the Ruth Simmons Quadrangle (Lincoln Field) from outside of Granoff.
East Campus.
The East Campus was originally the main campus location of Brown's former neighbor Bryant College. Brown purchased Bryant's East Side campus in 1969 for $5.0 million when the latter school was moving to a new location. This added of land and additional 26 buildings adjacent to the main campus area. The area was officially designated East Campus in 1971.
Other areas.
On the East Side:
Also on the Hill, but further to the south and away from the main campus area, is Wickenden Street, another commercial district offering restaurants and shops. Brown Stadium, built in 1925 and home to the football team, is located approximately a mile to the northeast of the main campus. Marston Boathouse, the home of the crew teams, lies on the Blackstone/Seekonk River, to the southeast of campus.
Elsewhere in Providence:
More recently, Brown has expanded into the Jewelry District, located in southern downtown Providence, by acquiring and renovating five buildings to serve as administrative and research facilities.
Outside of Providence:
Brown also owns a property, the Mount Hope Grant, in Bristol, which is the setting of the Haffenreffer Museum of Anthropology's Collection Research Center.
John Hay Library.
The John Hay Library is the second oldest library on campus. It was named for John Hay (class of 1858, private secretary to Abraham Lincoln and Secretary of State under two Presidents) at the request of his friend Andrew Carnegie, who contributed half of the $300,000 cost of the building. Constructed with Vermont white marble in an English Renaissance style, the library was dedicated on November 10, 1910 and had an estimated collection of 300,000 volumes. It is now the repository of Brown University archives, rare books and manuscripts, and special collections. Noteworthy among the latter are the Anne S. K. Brown Military Collection (described as "the foremost American collection of material devoted to the history and iconography of soldiers and soldiering"), the Harris Collection of American Poetry and Plays (described as "the largest and most comprehensive collection of its kind in any research library"), the Lownes Collection of the History of Science (described as "one of the three most important private collections of books of science in America"), and (for popularity of requests) the papers of H.P. Lovecraft. The Hay Library is home to one of the broadest collections of incunabula (15th-century printed books) in the Americas, as well as such rarities as the manuscript of Orwell's "Nineteen Eighty-Four" and a Shakespeare First Folio. There are also three books bound in human skin.
The Pembroke Center for Teaching and Research on Women manages the Elizabeth Weed Feminist Theory Papers and the Christine Dunlap Farnham Archives, both rich resources for feminist scholars.
John Carter Brown Library.
The John Carter Brown Library, founded in 1846, is administered separately from the University, but has been located on the Main Green of the campus since 1904. It is generally regarded as the world's leading collection of primary historical sources pertaining to the Americas before 1825. It houses a very large percentage of the titles published before that date about the discovery, settlement, history, and natural history of the New World. The "JCB", as it is known, publishes "Bibliotheca Americana", the main bibliography in the field. Typical of its noteworthy holdings is the best preserved of the seven surviving copies of Bay Psalm Book, the first extant book printed in British North America. There is also a very fine Shakespeare First Folio, added to the collection by John Carter Brown's widow (a Shakespeare enthusiast) on the grounds that it includes "The Tempest", a play set in the New World. The JCB holdings comprise more than 50,000 early titles and about 16,000 modern books, as well as prints, manuscripts, maps, and other items in the library's specialty. The JCB occupies a Beaux-Arts style building designed by Shepley, Rutan, and Coolidge. The 1904 edifice was expanded in 1990 by architects Hartman-Cox of Washington, D.C.
Haffenreffer Museum of Anthropology.
The exhibition galleries of the Haffenreffer Museum of Anthropology, Brown's teaching museum, are located in Manning Hall on the campus's main green. Its one million artifacts, available for research and educational purposes, are located at its Collections Research Center in Bristol, RI. The museum's goal is to inspire creative and critical thinking about culture by fostering interdisciplinary understanding of the material world. It provides opportunities for faculty and students to work with collections and the public, teaching through objects and programs in classrooms and exhibitions. The museum sponsors lectures and events in all areas of anthropology, and also runs an extensive program of outreach to local schools.
Sustainability.
Brown University has committed to "minimize its energy use, reduce negative environmental impacts and promote environmental stewardship." The Energy and Environmental Advisory Committee has developed a set of ambitious goals for the university to reduce its carbon emissions and eventually achieve carbon neutrality. The Brown is Green website collects information about Brown's progress toward greenhouse gas emissions reductions and related campus initiatives like courses, research, projects and student groups. Brown received an A- on the 2009 College Sustainability Report Card, developed by the Sustainable Endowments Institute. Brown was one of only 15 schools to receive a grade above a B+. There were no schools in the report that received an "A".
Brown has a number of active environmental leadership groups on campus. These groups have begun a number of campus-wide environmental initiatives—including promoting the reduction of supply and demand of bottled water and investigating a composting program.
Boldly Brown.
Under President Ruth Simmons, the University has launched Boldly Brown: The Campaign for Academic Enrichment. This campaign consists of re-evaluating the existing curriculum and raising money for greater academic ambition. The money will be used for academic programs, research, new facilities, biology and medicine, students who need financial assistance, and expanding the faculty and staff. In June 2009, it was announced that the campaign had met its goal 19 months ahead of target, with record levels of giving despite the global economic crises of the fiscal year. The total sum raised currently stands at over US$1.5 billion.
Student life.
Atmosphere.
Brown University has recently been ranked #1 for America's Happiest College Students, according to the Princeton Review 2010 rankings. Brown was also named "the most fashionable school in the Ivy League" by the fashion trade journal "Women's Wear Daily" on the basis that students on campus seem to have the strongest sense of personal style.
Athletics.
Brown is a member of the National Collegiate Athletic Association (NCAA) Division I Ivy League athletic conference. It sponsors 37 varsity intercollegiate teams. Its athletic programs have been featured in the College Sports Honor Roll as one of the top 20 athletic programs in the country according to U.S. News & World Report. Brown Women's Rowing Team has won 6 national titles in the last 12 years, the Men's Rowing Team perennially finishes in the top 5 in the nation and swept the Eastern Sprints in 2009. Brown Football's reemergence, and its surge in northeast college popularity generally, is credited to its historic 1976 Ivy League championship team, which was Brown's first Ivy League Football Champions. The 1976 "Magnificent Andersons," so named for its coach, John Anderson, was 8–1, tying it with Yale, which the 1976 Brown team defeated head to head that year, and included an ABC Sports televised football game, defeating Harvard 16–14. Since the 1976 football championship season, Brown Football has won three Ivy League championships under the most successful coach in its history, Phil Estes: 1999, 2005, and 2008. Brown's Men's Soccer program is consistently ranked in the top 25 and has won 18 Ivy League titles overall, including 8 of the last 12. Recent graduates play professionally in Major League Soccer and overseas. The Men's Lacrosse team also has a long and storied history, and more recently the program has again attained national rankings and exposure. In 2007, Brown won its first Ivy League baseball championship in school history. Brown's Varsity Equestrian team won the Ivy League Championships for the past two years in a row, and has consistently performed extremely well within the team's zone and region. Brown also features several competitive intercollegiate club sports, including Sailing, Ultimate, and Women's Rugby teams. In 2000 and 2005, the Men's Club Ultimate Frisbee team, Brownian Motion, won the National Championships.
Student organizations.
There are over 300 registered student organizations on campus with diverse interests. The Student Activities Fair, during the orientation program, provides first-year students the opportunity to become acquainted with the wide range of organizations.
Residential and Greek societies.
12.7% of Brown students are in fraternities or sororities. There are 12 residential Greek houses: six all-male fraternities (Alpha Epsilon Pi, Delta Tau, Delta Phi, Theta Delta Chi, Sigma Chi, and Phi Kappa Psi), four sororities (Alpha Chi Omega, Kappa Alpha Theta, and, as of March 2013, Kappa Delta), one co-ed fraternity (Zeta Delta Xi), and one co-ed literary society (Alpha Delta Phi). Phi Sigma Kappa fraternity was present on campus from 1906 to 1939, but was unable to reactivate after WWII due to wartime losses. All recognized Greek letter organizations live on-campus in University-owned dorm housing. All ten Greek houses are overseen by the Greek Council and are located on Wriston Quadrangle.
An alternative to fraternity life at Brown are the program houses, which are organized around various themes. As with Greek houses, the existing residents of each house take applications from students, usually at the start of the Spring semester. Examples of program houses include: St. Anthony Hall (located in King House), Buxton International House, the Machado French/Hispanic House, Technology House, Harambee (African culture) House, Social Action House and Interfaith House.
Currently, there are three student cooperative houses at Brown. Two of the houses, Watermyn and Finlandia on Waterman Street, are owned by the Brown Association for Cooperative Housing (BACH), an independent non-profit corporation owned and operated by house members. The third co-op, West House, is located in a Brown-owned house on Brown Street. All three houses also run a vegetarian food co-op for residents and non-residents.
Secret societies.
Secret societies at Brown originated as literary clubs in the mid-18th century, and primarily existed to organize debates among their members. One early literary club was the Pronouncing Society, which disbanded in the mid-1770s. Another was Athenian at Queen's, founded in 1776 but also dissolved shortly afterwards. The Philermenian Society (founded as the Misokosmian Society) arose in 1794. In reaction to the Federalist Philermenians, a Democratic-Republican club called the United Brothers Society organized in 1806. In 1824 a third group, the Franklin Society, was formally recognized by the university president, and counted as honorary members Thomas Jefferson, John Quincy Adams, and Henry Clay. However, by the Civil War, most of these organizations had dissipated on account of newer Greek letter fraternities.
There remains some dispute over the presence of these groups today, and at least one student organization, Pacifica House, claims descent from early secret societies. The Undergraduate Council of Students, Brown's student government, also reflects this historical legacy. The UCS originated as the Cammarian Club in 1893, a semi-secret senior society that served as an intermediary between the student body and the administration, and which ritualistically "tapped" 15 new men each year until its dissolution after World War II.
Traditions.
Though the early history of Brown as a men's school includes a number of unusual hazing traditions, the University's present-day traditions tend to be non-violent while maintaining the spirit of zaniness.
Van Wickle Gates.
The Van Wickle Gates, dedicated on June 18, 1901, have a pair of center gates and a smaller gate on each side. The side gates remain open throughout the year, while the center gates remain closed except for two occasions each year. At the beginning of the academic year, the center gates open inward to admit students during Convocation. At the end of the second semester, the gates open outward for the Commencement Day procession. A traditional superstition is that students who pass through the gates for a second time before graduation do not graduate. The Brown University Band famously flouts this tradition by marching in the yearly commencement procession. Undergraduate members, however, walk through the gates backwards, thereby avoiding the hex.
Josiah S. Carberry.
One of Brown's most notable traditions is keeping alive the spirit and accomplishments of Josiah S. Carberry, the fictional Professor of Psychoceramics (the equally fictional study of cracked pots), who was born on a University Hall billboard in 1929. He is the namesake of "Josiah's", a University-run campus eatery. "Josiah" is also the name of the University's electronic library catalog.
According to Martha Mitchell's "Encyclopedia Brunoniana", "On Friday, May 13, 1955, an anonymous gift of $101.01 was received by the University from Professor Carberry to establish the Josiah S. Carberry Fund in memory of his 'future late wife.' A condition of the gift was that, henceforth, every Friday the 13th would be designated 'Carberry Day,' and on that day friends of the University would deposit their loose change in brown jugs to augment the fund, which is used to purchase 'such books as Professor Carberry might or might not approve of.'" Students have followed this tradition ever since, and the fund currently has over $10,000 in it.
Mitchell writes, "Professor Carberry has been the subject of articles in a number of periodicals, including "The New York Times", which proclaimed him 'The World's Greatest Traveler' on the front page of its Sunday travel section in 1974, and in "Yankee" magazine, where he was 'The Absent-Bodied Professor' in 1975. A recent honor which came to Professor Carberry was the award to him of an Ig Nobel Prize at the First Annual Ig Nobel Prize Ceremony in 1991. At this event sponsored by M.I.T. and the "Journal of Irreproducible Results", Carberry, the 1991 Ig Nobel Interdisciplinary Research Prize laureate, was cited as 'bold explorer and eclectic seeker of knowledge, for his pioneering work in the field of psychoceramics, the study of cracked pots.'"
Spring Weekend.
Starting in 1950, Brown replaced the traditional Junior Week and Junior Prom, which were discontinued during World War II, with Spring Weekend, which featured athletic contests and dances. Concerts featuring invited performers began in 1960, including Bob Dylan, U2, Bruce Springsteen, Janis Joplin, James Brown and Snoop Dogg.
Alma Mater.
The "Alma Mater" was written by James Andrews DeWolf (Class of 1861) in 1860, who named it "Old Brown" and set it to the tune of "Araby's Daughter" (which was later known as "The Old Oaken Bucket"). The song was renamed "Alma Mater", after the incipit, in 1869. It is sung and played after varsity athletic victories and at formal events such as Convocation and Commencement.
Notable alumni and faculty.
Brown undergraduate alumni are currently governors of 4 out of the 50 states: Bobby Jindal '91 of Louisiana, Maggie Hassan '80 of New Hampshire, Jack Markell '82 of Delaware, and Lincoln Chafee '75 of Rhode Island.
Chief Justice of the Supreme Court and U.S. Secretary of State Charles Evans Hughes (1881), father of American public school education Horace Mann (1819), philanthropist John D. Rockefeller Jr. (1897), Secretary of State John Hay (1852), Secretary of State and Attorney General Richard Olney (1856), "Lafayette of the Greek Revolution" and its historian Samuel Gridley Howe (1821), NASA head during first seven Apollo missions Thomas O. Paine '42, chief scientist NASA Mars and lunar programs James B. Garvin '78, Governor of Wyoming Territory and Governor of Nebraska John Milton Thayer (1841), Governor of Rhode Island Augustus Bourn (1855), diplomat Richard Holbrooke '62.
Prominent alums in business and finance include Chair of the Federal Reserve Janet Yellen '67, World Bank President Jim Yong Kim '82, Bank of America CEO Brian Moynihan '81, CNN founder and America's Cup yachtsman Ted Turner '60, and magazine editor John F. Kennedy, Jr. '83. Others include Tiffany & Co CEO Walter Hoving '20, McKinsey & Co. co-founder Marvin Bower '25, Trans World Airlines chairman Charles C. Tillinghast, Jr. '32, IBM chairman and CEO Thomas Watson, Jr. '37, Chase Manhattan Bank CEO Willard C. Butcher '48, NASDAQ's first CEO Gordon Macklin '50, Citibank chairman William R. Rhodes '57, Apple Inc. CEO John Sculley '61, financier and "car czar" Steven Rattner '74, billionaire media investor Jonathan M. Nelson '77, real estate tycoon Barry Sternlicht '82, and Facebook CFO David Ebersman '91.
Important figures in the history of education include civil libertarian and Amherst College president Alexander Meiklejohn, first president of the University of South Carolina Jonathan Maxcy (1787), Bates College founder Oren B. Cheney (1836), longest-serving University of Michigan president (1871–1909) James Burrill Angell (1849), University of California president (1899–1919) Benjamin Ide Wheeler (1875), and Morehouse College's first African-American president John Hope (1894)
Alumni in the computer sciences and industry include Apple Macintosh and Mac OS designer Andy Hertzfeld '75, architect of Intel 386, 486, and Pentium microprocessors John H. Crawford '75, first Microsoft Windows project chief Brad Silverberg, Apple Computer CEO (1983–1993) John Sculley '61, MIT computer science chair John Guttag '71, University of Washington computer science chair Ed Lazowska '72, inventor of the first silicon transistor Gordon Kidd Teal '31.
Alumni in the arts and media include actress Laura Linney '86, actor John Krasinski '01, "Modern Family" actress Julie Bowen '91, "Harry Potter" films actress Emma Watson '14, editor in chief of "The Onion" Cole Bolton '04, MSNBC program hosts Chris Hayes '01 and Alex Wagner '99, NPR program host Ira Glass '82, "About a Boy" actor David Walton '01, singer-composer Mary Chapin Carpenter '81, "" actor Hill Harper, musicians Damian Kulash '98 and Dhani Harrison '02, film directors Todd Haynes '85, Doug Liman '88, and Davis Guggenheim '86, and director-actor Tim Blake Nelson '86, "New Yorker" humorist and Marx Brothers screenwriter S.J. Perelman '25, novelists Nathanael West '24, Jeffrey Eugenides '83, Rick Moody '83, Edwidge Danticat (MFA '93), Marilynne Robinson '66, and Amity Gaige '95, playwrights Sarah Ruhl '97, Lynn Nottage '86, Richard Foreman '59, Alfred Uhry '58, and Nilo Cruz (MFA '94), actress Jo Beth Williams '70, composer Duncan Sheik '92, singer Lisa Loeb '90, Rockefeller Center and Tribune Tower architect Raymond Hood (1902), composer and synthesizer pioneer Wendy Carlos '62, Pulitzer Prize-winning journalist James Risen '77, composer Rusty Magee, political pundit Mara Liasson, 20th Century Fox Film Group president Tom Rothman '76, Black Entertainment Television chairman and CEO Debra L. Lee '76, HBO Sports president Ross Greenburg '77, MTV Films and Nick Movies president Scott Aversano '91, CNN US News Operations president Jonathan Klein '80, Bravo TV president Lauren Zalaznick '84.
Other notable alumni include sportscaster Chris Berman '77, Houston Texans head coach Bill O'Brien '92, former Penn State football coach Joe Paterno '50, Heisman Trophy namesake John W. Heisman '91, Pollard Award namesake, Pro Football Hall of Fame member and first black All-American and NFL head coach Fritz Pollard '19, National Security Council counter-terrorism director RP Eddy '94, presidential advisor Ira Magaziner '69, founder of The Gratitude Network and The Intersection event Randy Haykin '85. Also royals and nobles such as Prince Rahim Aga Khan, Prince Faisal bin Al Hussein, Prince Nikolaos of Greece and Denmark, Prince Nikita Romanov, Princess Theodora of Greece and Denmark, Prince Jaime of Bourbon-Parma, Duke of San Jaime and Count of Bardi, Prince Ra'ad bin Zeid, Lady Gabriella Windsor, Prince Alexander von Fürstenberg and Countess Cosima von Bülow Pavoncelli.
Nobel Laureates Craig Mello '82 and Jerry White '87, Cooley-Tukey FFT algorithm co-originator John Wilder Tukey '36, Gurney Professor of History and Political Science at Harvard Adam Ulam '44, physicist Lewis E. Little '62, Lasker Award winning biologist and founder of microbial pathogenesis Stanley Falkow (PhD '59), MIT neuroscience department chair Mark F. Bear (B.A. '78, Ph.D '84), Penn psychologist, Lasker Award winner and cognitive therapy originator Aaron Beck '50, John Bates Clark Medal winning MIT economist Jerry A. Hausman '68, University of Chicago School of Law dean Daniel Fischel, Chicago Booth economist Randall Kroszner '84, Stanford Law School dean Larry Kramer (legal scholar), '80, and Arthur L. Horwich.
Notable past or current faculty have included Nobel Laureates Lars Onsager, George Stigler, Vernon L. Smith, George Snell and Leon Cooper, Fields Medal winning mathematician David Mumford, mathematician Ulf Grenander, Pulitzer Prize winning historian Gordon S. Wood, Sakurai Prize winning physicist Gerald Guralnik for co-elucidation of the Higgs mechanism, award-winning physicist John M. Kosterlitz of the Kosterlitz-Thouless transition, computer scientist and inventor of hypertext Andries van Dam, computer scientist Robert Sedgewick, prominent engineers Daniel C. Drucker, L. Ben Freund, and Mayo D. Hersey, BrainGate inventor John Donoghue (Ph.D 79'), neuroscientist Mark F. Bear (B.A '78, Ph.D '82), biologist and prominent advocate of biological evolution Kenneth R. Miller, first president of the American Sociological Association Lester Frank Ward, economists Hyman Minsky, Peter MacAvoy, who was a former member of the US Council of Economic Advisers, William Poole (economist), Ross Levine, Oded Galor and Peter Howitt (economist), former Prime Minister of Italy and former EU chief Romano Prodi, former President of Brazil Fernando Cardoso, former President of Chile Ricardo Lagos, writers Carlos Fuentes, Chinua Achebe, Robert Coover, Robert Creeley and Keith Waldrop, former Presidents of the American Philosophical Association Jaegwon Kim and Ernest Sosa, philosophers Curt Ducasse, Roderick Chisholm, and Martha Nussbaum, linguist Hans Kurath, political scientist James Morone and Senior Fellow Sergei Khrushchev.
References.
Notes

</doc>
<doc id="4158" url="http://en.wikipedia.org/wiki?curid=4158" title="Bill Atkinson">
Bill Atkinson

Bill Atkinson (born 1951) is an American computer engineer and photographer. Atkinson worked at Apple Computer from 1978 to 1990. He received his undergraduate degree from the University of California, San Diego, where Apple Macintosh developer Jef Raskin was one of his professors. Atkinson continued his studies as a graduate student at the University of Washington.
Atkinson was part of the Apple Macintosh development team, and was the creator of the ground-breaking MacPaint application, among others. He also designed and implemented QuickDraw, the fundamental toolbox that the Lisa and Macintosh used for graphics. QuickDraw's performance was essential for the success of the Macintosh's graphical user interface. He also was one of the main designers of the Lisa and Macintosh user interfaces. Atkinson also conceived, designed and implemented HyperCard, the first popular hypermedia system.
Around 1990, General Magic's founding, with Bill Atkinson as one of the three co-founders, met the following press in "Byte" magazine:
The obstacles to General Magic's success may appear daunting, but General Magic is not your typical start-up company. Its partners include some of the biggest players in the worlds of computing, communications, and consumer electronics, and it's loaded with top-notch engineers who have been given a clean slate to reinvent traditional approaches to ubiquitous worldwide communications.
In 2007 Atkinson began working as an outside developer with Numenta, a startup working on computer intelligence. On his work there Atkinson said, "what Numenta is doing is more fundamentally important to society than the personal computer and the rise of the Internet."
Some of Atkinson's noteworthy contributions to the field of computing include:
Atkinson now works as a nature photographer.

</doc>
<doc id="4160" url="http://en.wikipedia.org/wiki?curid=4160" title="Battle of Lostwithiel">
Battle of Lostwithiel

The Battles of Lostwithiel or Lostwithiel Campaign, took place near Lostwithiel and Fowey during the First English Civil War in 1644.
After defeating the Army of Sir William Waller at the Battle of Cropredy Bridge, King Charles marched west in pursuit of the Parliamentarian army of the Earl of Essex, who was invading the Royalist stronghold of Cornwall.
Essex had been misled into believing that he could expect substantial support from the people of Cornwall. When he had reached Bodmin on 28 July, he found that there was no chance of supplies or recruits, and he also learned that the Royalist army was at Launceston, close to his rear. He withdrew to Lostwithiel, covering the port of Fowey. Essex had previously arranged to rendezvous at Fowey with the Parliamentarian fleet under the Earl of Warwick, but no ships appeared. Warwick was unable to leave Portsmouth because of westerly winds.
King Charles's army had been reinforced as it marched, and outnumbered that of Essex by nearly two to one. The first clashes took place on 2 August, but little action took place for several days, as the King waited for all his forces to arrive and Essex waited for the fleet. On 13 August, the Royalists began to attack in earnest, occupying several outposts on the east bank of the River Fowey, making it even more difficult for help to reach Essex. A Parliamentarian attempt to send a relieving force under Lieutenant General Middleton was defeated at Bridgwater in Somerset.
On 21 August, the Royalists attacked Essex's positions north of Lostwithiel, capturing the ruins of Restormel Castle. Royalist cavalry threatened to cut the Parliamentarians off from Fowey. Essex realised that there was no hope of relief and ordered his cavalry to break out of the encirclement. Under Sir William Balfour, they broke through the Royalist lines on the night of 31 August, eventually reaching Plymouth 30 miles to the east.
The increasingly demoralised Parliamentarian infantry fell back towards Fowey in pouring rain. They were forced to abandon several guns which became bogged down in the muddy roads. On 1 September, the pursuing Royalists captured Castle Dore, another ruined fortification which the Parliamentarians were using to anchor their lines. Essex left Sir Philip Skippon, his Sergeant Major General of Foot, in command while he himself escaped to Plymouth in a fishing boat.
On 2 September, Skippon, having been told that his infantry were unable to break out as the cavalry had done, and having been offered generous terms by the King, surrendered 6,000 infantry and all his army's guns and train. The disarmed soldiers marched eastward to Portsmouth in continuing bad weather, being continually robbed and threatened by local people. About 1,000 died of exposure and hunger, and 1,000 more deserted or fell sick.
Charles meanwhile wheeled about and marched toward London.
This setback for Parliament in Cornwall, and the last major victory for the Royalists, was reversed by Sir Thomas Fairfax leading the New Model Army at or near Tresillian Bridge, close to Truro on 12 March 1645.

</doc>
<doc id="4162" url="http://en.wikipedia.org/wiki?curid=4162" title="Beeb">
Beeb

The nickname Beeb may refer to:

</doc>
<doc id="4163" url="http://en.wikipedia.org/wiki?curid=4163" title="Bertrand Russell">
Bertrand Russell

Bertrand Arthur William Russell, 3rd Earl Russell, OM, FRS (; 18 May 1872 – 2 February 1970) was a British philosopher, logician, mathematician, historian, social critic and political activist. At various points in his life he considered himself a liberal, a socialist, and a pacifist, but he also admitted that he had never been any of these in any profound sense. He was born in Monmouthshire, into one of the most prominent aristocratic families in Britain.
Russell led the British "revolt against idealism" in the early 20th century. He is considered one of the founders of analytic philosophy along with his predecessor Gottlob Frege, colleague G. E. Moore, and his protégé Ludwig Wittgenstein. He is widely held to be one of the 20th century's premier logicians. With A. N. Whitehead he wrote "Principia Mathematica", an attempt to create a logical basis for mathematics. His philosophical essay "On Denoting" has been considered a "paradigm of philosophy". His work has had a considerable influence on logic, mathematics, set theory, linguistics, artificial intelligence, cognitive science, computer science (see type theory and type system), and philosophy, especially philosophy of language, epistemology, and metaphysics.
Russell was a prominent anti-war activist; he championed anti-imperialism and went to prison for his pacifism during World War I. Later, he campaigned against Adolf Hitler, then criticised Stalinist totalitarianism, attacked the involvement of the United States in the Vietnam War, and was an outspoken proponent of nuclear disarmament. In 1950 Russell was awarded the Nobel Prize in Literature "in recognition of his varied and significant writings in which he champions humanitarian ideals and freedom of thought".
Biography.
Early life and background.
Bertrand Russell was born on 18 May 1872 at Ravenscroft, Trellech, Monmouthshire, into an influential and liberal family of the British aristocracy. His parents, Viscount and Viscountess Amberley, were radical for their times. Lord Amberley consented to his wife's affair with their children's tutor, the biologist Douglas Spalding. Both were early advocates of birth control at a time when this was considered scandalous. Lord Amberley was an atheist and his atheism was evident when he asked the philosopher John Stuart Mill to act as Russell's secular godfather. Mill died the year after Russell's birth, but his writings had a great effect on Russell's life.
His paternal grandfather, the Earl Russell, had been asked twice by Queen Victoria to form a government, serving her as Prime Minister in the 1840s and 1860s.
The Russells had been prominent in England for several centuries before this, coming to power and the peerage with the rise of the Tudor dynasty. They established themselves as one of Britain's leading Whig families, and participated in every great political event from the Dissolution of the Monasteries in 1536–40 to the Glorious Revolution in 1688–89 and the Great Reform Act in 1832.
Lady Amberley was the daughter of Lord and Lady Stanley of Alderley. Russell often feared the ridicule of his maternal grandmother, one of the campaigners for education of women.
Childhood and adolescence.
Russell had two siblings: brother Frank (nearly seven years older than Bertrand), and sister Rachel (four years older). In June 1874 Russell's mother died of diphtheria, followed shortly by Rachel's death. In January 1876, his father died of bronchitis following a long period of depression. Frank and Bertrand were placed in the care of their staunchly Victorian paternal grandparents, who lived at Pembroke Lodge in Richmond Park. His grandfather, former Prime Minister Earl Russell, died in 1878, and was remembered by Russell as a kindly old man in a wheelchair. His grandmother, the Countess Russell (née Lady Frances Elliot), was the dominant family figure for the rest of Russell's childhood and youth.
The countess was from a Scottish Presbyterian family, and successfully petitioned the Court of Chancery to set aside a provision in Amberley's will requiring the children to be raised as agnostics. Despite her religious conservatism, she held progressive views in other areas (accepting Darwinism and supporting Irish Home Rule), and her influence on Bertrand Russell's outlook on social justice and standing up for principle remained with him throughout his life. (One could challenge the view that Bertrand stood up for his principles, based on his own well-known quotation: "I would never die for my beliefs, I could be wrong".) Her favourite Bible verse, 'Thou shalt not follow a multitude to do evil' (Exodus 23:2), became his motto. The atmosphere at Pembroke Lodge was one of frequent prayer, emotional repression, and formality; Frank reacted to this with open rebellion, but the young Bertrand learned to hide his feelings.
Russell's adolescence was very lonely, and he often contemplated suicide. He remarked in his autobiography that his keenest interests were in religion and mathematics, and that only his wish to know more mathematics kept him from suicide. He was educated at home by a series of tutors. At age eleven, his brother Frank introduced him to the work of Euclid, which transformed Russell's life.
During these formative years he also discovered the works of Percy Bysshe Shelley. In his autobiography, he writes: "I spent all my spare time reading him, and learning him by heart, knowing no one to whom I could speak of what I thought or felt, I used to reflect how wonderful it would have been to know Shelley, and to wonder whether I should meet any live human being with whom I should feel so much sympathy". Russell claimed that beginning at age 15, he spent considerable time thinking about the validity of Christian religious dogma, which he found very unconvincing. At this age, he came to the conclusion that there is no free will and, two years later, that there is no life after death. Finally, at the age of 18, after reading Mill's "Autobiography", he abandoned the "First Cause" argument and became an atheist.
University and first marriage.
Russell won a scholarship to read for the Mathematical Tripos at Trinity College, Cambridge, and commenced his studies there in 1890, taking as coach Robert Rumsey Webb. He became acquainted with the younger George Edward Moore and came under the influence of Alfred North Whitehead, who recommended him to the Cambridge Apostles. He quickly distinguished himself in mathematics and philosophy, graduating as a high Wrangler in 1893 and becoming a Fellow in the latter in 1895.
Russell first met the American Quaker Alys Pearsall Smith when he was 17 years old. He became a friend of the Pearsall Smith family—they knew him primarily as 'Lord John's grandson' and enjoyed showing him off—and travelled with them to the continent; it was in their company that Russell visited the Paris Exhibition of 1889 and was able to climb the Eiffel Tower soon after it was completed.
He soon fell in love with the puritanical, high-minded Alys, who was a graduate of Bryn Mawr College near Philadelphia, and, contrary to his grandmother's wishes, married her on 13 December 1894. Their marriage began to fall apart in 1901 when it occurred to Russell, while he was cycling, that he no longer loved her. She asked him if he loved her and he replied that he didn't. Russell also disliked Alys's mother, finding her controlling and cruel. It was to be a hollow shell of a marriage and they finally divorced in 1921, after a lengthy period of separation.
During this period, Russell had passionate (and often simultaneous) affairs with a number of women, including Lady Ottoline Morrell and the actress Lady Constance Malleson.
Early career.
Russell began his published work in 1896 with "German Social Democracy", a study in politics that was an early indication of a lifelong interest in political and social theory. In 1896 he taught German social democracy at the London School of Economics, where he also lectured on the science of power in the autumn of 1937. He was a member of the Coefficients dining club of social reformers set up in 1902 by the Fabian campaigners Sidney and Beatrice Webb.
He now started an intensive study of the foundations of mathematics at Trinity.
In 1898 he wrote "An Essay on the Foundations of Geometry" which discussed the Cayley-Klein metrics used for non-Euclidean geometry.
He attended the International Congress of Philosophy in Paris in 1900 where he met Giuseppe Peano and Alessandro Padoa. The Italians had responded to Georg Cantor, making a science of set theory; they gave Russell their literature including the Formulario mathematico. Russell was impressed by the precision of Peano's arguments at the Congress, read the literature upon returning to England, and came upon Russell's paradox. In 1903 he published "The Principles of Mathematics", a work on foundations of mathematics. It advanced a thesis of logicism, that mathematics and logic are one and the same.
At the age of 29, in February 1901, Russell underwent what he called a "sort of mystic illumination", after witnessing Whitehead's wife's acute suffering in an angina attack. "I found myself filled with semi-mystical feelings about beauty... and with a desire almost as profound as that of the Buddha to find some philosophy which should make human life endurable", Russell would later recall. "At the end of those five minutes, I had become a completely different person."
In 1905 he wrote the essay "On Denoting", which was published in the philosophical journal "Mind". Russell became a fellow of the Royal Society in 1908. The three-volume "Principia Mathematica", written with Whitehead, was published between 1910 and 1913. This, along with the earlier "The Principles of Mathematics", soon made Russell world-famous in his field.
In 1910 he became a lecturer in the University of Cambridge, where he was approached by the Austrian engineering student Ludwig Wittgenstein, who became his PhD student. Russell viewed Wittgenstein as a genius and a successor who would continue his work on logic. He spent hours dealing with Wittgenstein's various phobias and his frequent bouts of despair. This was often a drain on Russell's energy, but Russell continued to be fascinated by him and encouraged his academic development, including the publication of Wittgenstein's "Tractatus Logico-Philosophicus" in 1922. Russell delivered his lectures on Logical Atomism, his version of these ideas, in 1918, before the end of the First World War. Wittgenstein was, at that time, serving in the Austrian Army and subsequently spent nine months in an Italian prisoner of war camp at the end of the conflict.
First World War.
During the First World War, Russell was one of the very few people to engage in active pacifist activities, and in 1916, he was dismissed from Trinity College following his conviction under the Defence of the Realm Act.
Russell played a significant part in the "Leeds Convention" in June 1917—an historic event which saw well over a thousand "anti-war socialists" gather; many being delegates from the Independent Labour Party and the Socialist Party, united in their pacifist beliefs and advocating a peace settlement. The international press reported that Russell appeared alongside a number of Labour MPs, including both the future Prime Minister, Ramsey McDonald, and the future Chancellor of the Exchequer, Philip Snowden and that former Liberal MP, and anti-conscription campaigner, Professor Arnold Lupton, was also a guest. After the event, Russell told Lady Ottoline that, "to my surprise, when I got up to speak, I was given the greatest ovation that was possible to give anybody".
The Trinity incident resulted in Russell being charged a fine of £100, which he refused to pay, hoping that he would be sent to prison. However, his books were sold at auction to raise the money. The books were bought by friends; he later treasured his copy of the King James Bible that was stamped "Confiscated by Cambridge Police".
A later conviction for publicly lecturing against inviting the US to enter the war on Britain's side resulted in six months' imprisonment in Brixton prison (see "Bertrand Russell's views on society") in 1918.
While in prison, Russell read enormously, and wrote the book "Introduction to Mathematical Philosophy".
He was reinstated in 1919, resigned in 1920, was Tarner Lecturer 1926, and became a Fellow again 1944–49.
In 1924, Bertrand again gained press attention when attending a "banquet" in the House of Commons with well-known campaigners, including Arnold Lupton, who had been both a Member of Parliament and had also endured imprisonment for "passive resistance to military or naval service".
Between the wars and second marriage.
In August 1920 Russell travelled to Russia as part of an official delegation sent by the British government to investigate the effects of the Russian Revolution. He met Vladimir Lenin and had an hour-long conversation with him. In his autobiography, he mentions that he found Lenin rather disappointing, sensing an "impish cruelty" in him and comparing him to "an opinionated professor". He cruised down the Volga on a steamship. Russell's lover Dora Black, a British author, feminist and socialist campaigner, visited Russia independently at the same time—she was enthusiastic about the revolution, but Russell's experiences destroyed his previous tentative support for it. He wrote a book "The Practice and Theory of Bolshevism" about his experiences on this trip, taken with a group of 24 others from Britain, all of whom came home thinking well of the régime, despite Russell's attempts to change their minds. For example, he told them that he heard shots fired in the middle of the night and was sure these were clandestine executions, but the others maintained that it was only cars backfiring.
Russell subsequently lectured in Beijing on philosophy for one year, accompanied by Dora. He went there with optimism and hope, as China was then on a new path. Other scholars present in China at the time included Rabindranath Tagore, the Nobel laureate Indian poet. While in China, Russell became gravely ill with pneumonia, and incorrect reports of his death were published in the Japanese press. When the couple visited Japan on their return journey, Dora notified the world that "Mr. Bertrand Russell, having died according to the Japanese press, is unable to give interviews to Japanese journalists". The press, not appreciating the sarcasm, were not amused.
Dora was six months pregnant when the couple returned to England on 26 August 1921. Russell arranged a hasty divorce from Alys, marrying Dora six days after the divorce was finalised, on 27 September 1921. Their children were John Conrad Russell, 4th Earl Russell, born on 16 November 1921, and Katharine Jane Russell (now Lady Katharine Tait), born on 29 December 1923. Russell supported his family during this time by writing popular books explaining matters of physics, ethics, and education to the layman. Some have suggested that at this point he had an affair with Vivienne Haigh-Wood, the English governess and writer, and first wife of T. S. Eliot.
Together with Dora, he founded the experimental Beacon Hill School in 1927. The school was run from a succession of different locations, including its original premises at the Russells' residence, Telegraph House, near Harting, West Sussex. On 8 July 1930 Dora gave birth to her third child Harriet Ruth. After he left the school in 1932, Dora continued it until 1943.
Upon the death of his elder brother Frank, in 1931, Russell became the 3rd Earl Russell. He once said that his title was primarily useful for securing hotel rooms.
Russell's marriage to Dora grew increasingly tenuous, and it reached a breaking point over her having two children with an American journalist, Griffin Barry. They separated in 1932 and finally divorced. On 18 January 1936, Russell married his third wife, an Oxford undergraduate named Patricia ("Peter") Spence, who had been his children's governess since 1930. Russell and Peter had one son, Conrad Sebastian Robert Russell, 5th Earl Russell, who became a prominent historian and one of the leading figures in the Liberal Democratic party.
During the 1930s, Russell became a close friend and collaborator of V. K. Krishna Menon, then secretary of the All-India Muslim League, the foremost lobby for Indian independence in Great Britain.
Second World War.
Russell opposed rearmament against Nazi Germany, but in 1940 changed his view that avoiding a full-scale world war was more important than defeating Hitler. He concluded that Adolf Hitler taking over all of Europe would be a permanent threat to democracy. In 1943, he adopted a stance toward large-scale warfare, "Relative Political Pacifism": War was always a great evil, but in some particularly extreme circumstances, it may be the lesser of two evils.
Before World War II, Russell taught at the University of Chicago, later moving on to Los Angeles to lecture at the UCLA Department of Philosophy. He was appointed professor at the City College of New York (CCNY) in 1940, but after a public outcry the appointment was annulled by a court judgment that pronounced him "morally unfit" to teach at the college due to his opinions—notably those relating to sexual morality, detailed in "Marriage and Morals" (1929). The protest was started by the mother of a student who would not have been eligible for his graduate-level course in mathematical logic; many intellectuals, led by John Dewey, protested his treatment. Albert Einstein's oft-quoted aphorism that "great spirits have always encountered violent opposition from mediocre minds" originated in his open letter supporting Russell's appointment dated March 19, 1940, to Morris Raphael Cohen, a professor emeritus at CCNY. Dewey and Horace M. Kallen edited a collection of articles on the CCNY affair in "The Bertrand Russell Case". He soon joined the Barnes Foundation, lecturing to a varied audience on the history of philosophy; these lectures formed the basis of "A History of Western Philosophy". His relationship with the eccentric Albert C. Barnes soon soured, and he returned to Britain in 1944 to rejoin the faculty of Trinity College.
Later life.
During the 1940s and 1950s, Russell participated in many broadcasts over the BBC, particularly "The Brains Trust" and the Third Programme, on various topical and philosophical subjects. By this time Russell was world-famous outside of academic circles, frequently the subject or author of magazine and newspaper articles, and was called upon to offer opinions on a wide variety of subjects, even mundane ones. En route to one of his lectures in Trondheim, Russell was one of 24 survivors (among a total of 43 passengers) in an aeroplane crash in Hommelvik in October 1948. He said he owed his life to smoking since the people who drowned were in the non-smoking part of the plane. "A History of Western Philosophy" (1945) became a bestseller and provided Russell with a steady income for the remainder of his life.
In 1943, Russell expressed support for Zionism: "I have come gradually to see that, in a dangerous and largely hostile world, it is essential to Jews to have some country which is theirs, some region where they are not suspected aliens, some state which embodies what is distinctive in their culture".
In a speech in 1948, Russell said that if the USSR's aggression continued, it would be morally worse to go to war after the USSR possessed an atomic bomb than before it possessed one, because if the USSR had no bomb the West's victory would come more swiftly and with fewer casualties than if there were atom bombs on both sides. At that time, only the United States possessed an atomic bomb, and the USSR was pursuing an extremely aggressive policy towards the countries in Eastern Europe which it was absorbing into its sphere of influence. Many understood Russell's comments to mean that Russell approved of a first strike in a war with the USSR, including Nigel Lawson, who was present when Russell spoke. Others, including Griffin, who obtained a transcript of the speech, have argued that he was merely explaining the usefulness of America's atomic arsenal in deterring the USSR from continuing its domination of Eastern Europe.
In 1948, Russell was invited by the BBC to deliver the inaugural Reith Lectures—what was to become an annual series of lectures, still broadcast by the BBC. His series of six broadcasts, titled "Authority and the Individual", explored themes such as the role of individual initiative in the development of a community and the role of state control in a progressive society. Russell continued to write about philosophy. He wrote a foreword to "Words and Things" by Ernest Gellner, which was highly critical of the later thought of Ludwig Wittgenstein and of ordinary language philosophy. Gilbert Ryle refused to have the book reviewed in the philosophical journal "Mind", which caused Russell to respond via "The Times". The result was a month-long correspondence in "The Times" between the supporters and detractors of ordinary language philosophy, which was only ended when the paper published an editorial critical of both sides but agreeing with the opponents of ordinary language philosophy.
In the King's Birthday Honours of 9 June 1949, Russell was awarded the Order of Merit, and the following year he was awarded the Nobel Prize in Literature. When he was given the Order of Merit, George VI was affable but slightly embarrassed at decorating a former jailbird, saying, "You have sometimes behaved in a manner that would not do if generally adopted". Russell merely smiled, but afterwards claimed that the reply "That's right, just like your brother" immediately came to mind.
In 1952 Russell was divorced by Spence, with whom he had been very unhappy. Conrad, Russell's son by Spence, did not see his father between the time of the divorce and 1968 (at which time his decision to meet his father caused a permanent breach with his mother).
Russell married his fourth wife, Edith Finch, soon after the divorce, on 15 December 1952. They had known each other since 1925, and Edith had taught English at Bryn Mawr College near Philadelphia, sharing a house for 20 years with Russell's old friend Lucy Donnelly. Edith remained with him until his death, and, by all accounts, their marriage was a happy, close, and loving one. Russell's eldest son John suffered from serious mental illness, which was the source of ongoing disputes between Russell and his former wife Dora. John's wife Susan was also mentally ill, and eventually Russell and Edith became the legal guardians of their three daughters, two of whom were later diagnosed with schizophrenia.
In September 1961, at the age of 89, Russell was jailed for seven days in Brixton Prison after taking part in an anti-nuclear demonstration in London, for "breach of peace". The magistrate offered to exempt him from jail if he pledged himself to "good behaviour", to which Russell replied: "No, I won't."
In 1962 Russell played a public role in the Cuban Missile Crisis: in an exchange of telegrams with Soviet leader Nikita Khrushchev, Khrushchev assured him that the Soviet government would not be reckless. Russell sent this telegram to President Kennedy: 
YOUR ACTION DESPERATE. THREAT TO HUMAN SURVIVAL. NO CONCEIVABLE JUSTIFICATION. CIVILIZED MAN CONDEMNS IT. WE WILL NOT HAVE MASS MURDER. ULTIMATUM MEANS WAR... END THIS MADNESS.
According to historian Peter Knight, after JFK's assassination, Russell, "prompted by the emerging work of the lawyer Mark Lane in the US ... rallied support from other noteworthy and left-leaning compatriots to form a "Who Killed Kennedy Committee" in June 1964, members of which included Michael Foot MP, Caroline Benn, the publisher Victor Gollancz, the writers John Arden and J. B. Priestley, and the Oxford history professor Hugh Trevor-Roper. Russell published a highly critical article weeks before the Warren Commission Report was published, setting forth "16 Questions on the Assassination" and equating the Oswald case with the Dreyfus affair of late 19th-century France, in which the state wrongly convicted an innocent man. Russell also criticized the American press for failing to heed any voices critical of the official version.
Political causes.
Russell spent the 1950s and 1960s engaged in political causes primarily related to nuclear disarmament and opposing the Vietnam War. The 1955 Russell–Einstein Manifesto was a document calling for nuclear disarmament and was signed by eleven of the most prominent nuclear physicists and intellectuals of the time. In 1966-67, Russell worked with Jean-Paul Sartre and many other intellectual figures to form the Russell Vietnam War Crimes Tribunal to investigate the conduct of the United States in Vietnam. He wrote a great many letters to world leaders during this period.
In 1956, immediately before and during the Suez Crisis, Russell expressed his opposition to what he viewed as European imperialism in the Middle East. He viewed the crisis as another reminder of what he saw as a pressing need for a more effective mechanism for international governance, and to restrict national sovereignty to places such as the Suez Canal area "where general interest is involved". At the same time the Suez Crisis was taking place, the world was also captivated by the Hungarian Revolution and the subsequent crushing of the revolt by intervening Soviet forces. Russell attracted criticism for speaking out fervently against the Suez war while ignoring Soviet repression in Hungary, to which he responded that he did not criticize the Soviets "because there was no need. Most of the so-called Western World was fulminating". Although he later feigned a lack of concern, at the time he was disgusted by the brutal Soviet response, and on November 16, 1956, he expressed approval for a declaration of support for Hungarian scholars which Michael Polanyi had cabled to the Soviet embassy in London twelve days previously, shortly after Soviet troops had already entered Budapest.
In November 1957 Russell wrote an article addressing US President Dwight D. Eisenhower and Soviet Premier Nikita Khrushchev, urging a summit to consider "the conditions of co-existence". Khrushchev responded that peace could indeed be served by such a meeting. In January 1958 Russell elaborated his views in "The Observer", proposing a cessation of all nuclear-weapons production, with Britain taking the first step by unilaterally suspending its own nuclear-weapons program if necessary, and with Germany "freed from all alien armed forces and pledged to neutrality in any conflict between East and West". US Secretary of State John Foster Dulles replied for Eisenhower. The exchange of letters was published as "The Vital Letters of Russell, Khrushchev, and Dulles".
Russell was asked by "The New Republic", a liberal American magazine, to elaborate his views on world peace. He suggested that all nuclear-weapons testing and constant flights by planes armed with nuclear weapons be halted immediately, and negotiations be opened for the destruction of all Hydrogen bombs, with the number of conventional nuclear devices limited to ensure a balance of power. He proposed that Germany be reunified and accept the Oder-Neisse line as its border, and that a neutral zone be established in Central Europe, consisting at the minimum of Germany, Poland, Hungary, and Czechoslovakia, with each of these countries being free of foreign troops and influence, and prohibited from forming alliances with countries outside the zone. In the Middle East, Russell suggested that the West avoid opposing Arab nationalism, and proposed a United Nations peacekeeping force to guard Israel's frontiers to ensure that Israel was protected from aggression and prevented from committing it. He also suggested Western recognition of the People's Republic of China, and that it be admitted to the UN with a permanent seat on the UN Security Council.
He was in contact with Lionel Rogosin while the latter was filming his anti-war film "Good Times, Wonderful Times" in the 1960s. He became a hero to many of the youthful members of the New Left. In early 1963, in particular, Russell became increasingly vocal in his disapproval of the Vietnam War, and felt that the US government's policies there were near-genocidal. In 1963 he became the inaugural recipient of the Jerusalem Prize, an award for writers concerned with the freedom of the individual in society. In 1964 he was one of eleven world figures who issued an appeal to Israel and the Arab countries to accept an arms embargo and international supervision of nuclear plants and rocket weaponry. In October 1965 he tore up his Labour Party card because he suspected Harold Wilson's Labour government was going to send troops to support the United States in Vietnam.
Final years and death.
Russell published his three-volume autobiography in 1967, 1968, and 1969. Russell made a cameo appearance playing himself in the anti-war Hindi film "Aman" which was released in India in 1967. This was Russell's only appearance in a feature film.
On 23 November 1969 he wrote to "The Times" newspaper saying that the preparation for show trials in Czechoslovakia was "highly alarming". The same month, he appealed to Secretary General U Thant of the United Nations to support an international war crimes commission to investigate alleged torture and genocide by the United States in South Vietnam during the Vietnam War. The following month, he protested to Alexei Kosygin over the expulsion of Aleksandr Solzhenitsyn from the Writers Union.
On 31 January 1970 Russell issued a statement condemning Israel's aggression in the Middle East, and in particular, Israeli bombing raids being carried out deep in Egyptian territory as part of the War of Attrition. He called for an Israeli withdrawal to the pre-Six-Day War borders. This was Russell's final political statement or act. It was read out at the International Conference of Parliamentarians in Cairo on 3 February 1970, the day after his death.
Russell died of influenza on 2 February 1970 at his home, Plas Penrhyn, in Penrhyndeudraeth, Merionethshire, Wales. His body was cremated in Colwyn Bay on 5 February 1970. In accordance with his will, there was no religious ceremony; his ashes were scattered over the Welsh mountains later that year.
In 1980 a memorial to Russell was commissioned by a committee including the philosopher A. J. Ayer. It consists of a bust of Russell in Red Lion Square in London sculpted by Marcelle Quinton.
Titles and honours from birth.
Russell held throughout his life the following styles and honours:
Views.
Views on philosophy.
Russell is generally credited with being one of the founders of analytic philosophy. He was deeply impressed by Gottfried Leibniz (1646–1716), and wrote on every major area of philosophy except aesthetics. He was particularly prolific in the field of metaphysics, the logic and the philosophy of mathematics, the philosophy of language, ethics and epistemology. When Brand Blanshard asked Russell why he didn't write on aesthetics, Russell replied that he didn't know anything about it, "but that is not a very good excuse, for my friends tell me it has not deterred me from writing on other subjects".
Views on religion.
Russell described himself as an agnostic, "speaking to a purely philosophical audience", but as an atheist "speaking popularly", on the basis that he could not disprove the Christian God similar to the way that he could not disprove the Olympic Gods either. For most of his adult life Russell maintained that religion is little more than superstition and, despite any positive effects that religion might have, it is largely harmful to people. He believed that religion and the religious outlook serve to impede knowledge and foster fear and dependency, and are responsible for much of our world's wars, oppression, and misery. He was a member of the Advisory Council of the British Humanist Association and President of Cardiff Humanists until his death.
Views on society.
Political and social activism occupied much of Russell's time for most of his life. Russell remained politically active almost to the end of his life, writing to and exhorting world leaders and lending his name to various causes.
Russell argued for a "scientific society", where war would be abolished, population growth limited, and prosperity shared. He suggested the establishment of a "single supreme world government" able to enforce peace, claiming that "the only thing that will redeem mankind is co-operation".
Russell was an active supporter of the Homosexual Law Reform Society, being one of the signatories of A.E. Dyson's 1958 letter to "The Times" calling for a change in the law regarding male homosexual practices, which were partly legalized in 1967, when Russell was still alive.
In "Reflections on My Eightieth Birthday" ("Postscript" in his "Autobiography"), Russell wrote: "I have lived in the pursuit of a vision, both personal and social. Personal: to care for what is noble, for what is beautiful, for what is gentle; to allow moments of insight to give wisdom at more mundane times. Social: to see in imagination the society that is to be created, where individuals grow freely, and where hate and greed and envy die because there is nothing to nourish them. These things I believe, and the world, for all its horrors, has left me unshaken".
Selected bibliography.
A selected bibliography of Russell's books in English, sorted by year of first publication:
Russell also wrote many pamphlets, introductions, articles, and letters to the editor. One pamphlet titled, "I Appeal unto Caesar: The Case of the Conscientious Objectors", ghostwritten for Margaret Hobhouse, the mother of imprisoned peace activist Stephen Henry Hobhouse allegedly helped secure the release of hundreds of conscientious objectors from prison.
His works can be found in anthologies and collections, perhaps most notably "The Collected Papers of Bertrand Russell", which McMaster University began publishing in 1983. This collection of his shorter and previously unpublished works is now up to 16 volumes, and many more are forthcoming. An additional three volumes catalogue just his bibliography. The Russell Archives at McMaster University possess over 30,000 of his letters.

</doc>
<doc id="4165" url="http://en.wikipedia.org/wiki?curid=4165" title="Boeing 767">
Boeing 767

The Boeing 767 is a mid- to large-size, long-range, wide-body twin-engine jet airliner built by Boeing Commercial Airplanes. It was the manufacturer's first wide-body twinjet and its first airliner with a two-crew glass cockpit. The aircraft has two turbofan engines, a conventional tail, and, for reduced aerodynamic drag, a supercritical wing design. Designed as a smaller wide-body airliner than earlier aircraft such as the 747, the 767 has seating capacity for 181 to 409 persons and a design range of , depending on variant. Development of the 767 occurred in tandem with a narrow-body twinjet, the 757, resulting in shared design features which allow pilots to obtain a common type rating to operate both aircraft.
The 767 is produced in three fuselage lengths. The original 767-200 entered service in 1982, followed by the 767-300 in 1986 and the 767-400ER, an extended-range (ER) variant, in 2000. The extended-range 767-200ER and 767-300ER models entered service in 1984 and 1988, respectively, while a production freighter version, the 767-300F, debuted in 1995. Conversion programs have modified passenger 767-200 and 767-300 series aircraft for cargo use, while military derivatives include the E-767 surveillance aircraft, the KC-767 and KC-46 aerial tankers, and VIP transports. Engines featured on the 767 include the General Electric CF6, Pratt & Whitney JT9D and PW4000, and Rolls-Royce RB211 turbofans.
United Airlines first placed the 767 in commercial service in 1982. The aircraft was initially flown on domestic and transcontinental routes, during which it demonstrated the reliability of its twinjet design. In 1985, the 767 became the first twin-engined airliner to receive regulatory approval for extended overseas flights. The aircraft was then used to expand non-stop service on medium- to long-haul intercontinental routes. In 1986, Boeing initiated studies for a higher-capacity 767, ultimately leading to the development of the 777, a larger wide-body twinjet. In the 1990s, the 767 became the most frequently used airliner for transatlantic flights between North America and Europe.
The 767 is the first twinjet wide-body type to reach 1,000 aircraft delivered. As of December 2013, Boeing has received 1,110 orders for the 767 from 71 customers; 1,061 have been delivered. A total of 838 of these aircraft were in service in July 2012; the most popular variant is the 767-300ER, with 582 delivered; Delta Air Lines is the largest operator, with 94 aircraft. Competitors have included the Airbus A300, A310, and A330-200, while a successor, the 787 Dreamliner, entered service in October 2011.
Development.
Background.
In 1970, Boeing's 747 became the first wide-body jetliner to enter service. The 747 was the first passenger jet that was wide enough to feature a twin-aisle cabin. Two years later, the manufacturer began a development study, code-named 7X7, for a new wide-body aircraft intended to replace the 707 and other early generation narrow-body jets. The aircraft would also provide twin-aisle seating, but in a smaller fuselage than the existing 747, McDonnell Douglas DC-10, and Lockheed L-1011 TriStar wide-bodies. To defray the high cost of development, Boeing signed risk-sharing agreements with Italian corporation Aeritalia and the Civil Transport Development Corporation (CTDC), a consortium of Japanese aerospace companies. This marked the manufacturer's first major international joint venture, and both Aeritalia and the CTDC received supply contracts in return for their early participation. The initial 7X7 was conceived as a short take-off and landing airliner intended for short-distance flights, but customers were unenthusiastic about the concept, leading to its redefinition as a mid-size, transcontinental-range airliner. At this stage the proposed aircraft featured two or three engines, with possible configurations including over-wing engines and a T-tail.
By 1976, a twinjet layout, similar to the one which had debuted on the Airbus A300, became the baseline configuration. The decision to use two engines reflected increased industry confidence in the reliability and economics of new-generation jet powerplants. While airline requirements for new wide-body aircraft remained ambiguous, the 7X7 was generally focused on mid-size, high-density markets. As such, it was intended to transport large numbers of passengers between major cities. Advancements in civil aerospace technology, including high-bypass-ratio turbofan engines, new flight deck systems, aerodynamic improvements, and lighter construction materials were to be applied to the 7X7. Many of these features were also included in a parallel development effort for a new mid-size narrow-body airliner, code-named 7N7, which would become the 757. Work on both proposals proceeded through the airline industry upturn in the late 1970s.
In January 1978, Boeing announced a major extension of its Everett factory—which was then dedicated to the manufacture of the 747—to accommodate its new wide-body family. In February 1978, the new jetliner received the 767 model designation, and three variants were planned: a 767-100 with 190 seats, a 767-200 with 210 seats, and a trijet 767MR/LR version with 200 seats intended for intercontinental routes. The 767MR/LR was subsequently renamed 777 for differentiation purposes. The 767 was officially launched on July 14, 1978, when United Airlines ordered 30 of the 767-200 variant, followed by 50 more 767-200 orders from American Airlines and Delta Air Lines later that year. The 767-100 was ultimately not offered for sale, as its capacity was too close to the 757's seating, while the 777 trijet was eventually dropped in favor of standardizing around the twinjet configuration.
Design effort.
In the late 1970s, operating cost replaced capacity as the primary factor in airliner purchases. As a result, the 767's design process emphasized fuel efficiency from the outset. Boeing targeted a 20 to 30 percent cost saving over earlier aircraft, mainly through new engine and wing technology. As development progressed, engineers used computer-aided design for over one-third of the 767's design drawings, and performed 26,000 hours of wind tunnel tests. Design work occurred concurrently with the 757 twinjet, leading Boeing to treat both as almost one program to reduce risk and cost. Both aircraft would ultimately receive shared design features, including avionics, flight management systems, instruments, and handling characteristics. Combined development costs were estimated at $3.5 to $4 billion.
Early 767 customers were given the choice of Pratt & Whitney JT9D or General Electric CF6 turbofans, marking the first time that Boeing had offered more than one engine option at the launch of a new airliner. Both jet engine models had a maximum output of of thrust. The engines were mounted approximately one-third the length of the wing from the fuselage, similar to previous wide-body trijets. The larger wings were designed using an aft-loaded shape which reduced aerodynamic drag and distributed lift more evenly across their surface span than any of the manufacturer's previous aircraft. The wings provided higher-altitude cruise performance, added fuel capacity, and expansion room for future stretched variants. The initial 767-200 was designed for sufficient range to fly across North America or across the northern Atlantic, and would be capable of operating routes up to .
The 767's fuselage width was set midway between that of the 707 and the 747 at . While it was narrower than previous wide-body designs, seven abreast seating with two aisles could be fitted, and the reduced width produced less aerodynamic drag. However, the fuselage was not wide enough to accommodate two standard LD3 wide-body unit load devices side-by-side. As a result, a smaller container, the LD2, was created specifically for the 767. The adoption of a conventional tail design also allowed the rear fuselage to be tapered over a shorter section, providing for parallel aisles along the full length of the passenger cabin, and eliminating irregular seat rows toward the rear of the aircraft.
The 767 was the first Boeing wide-body to be designed with a two-crew digital glass cockpit. Cathode ray tube (CRT) color displays and new electronics replaced the role of the flight engineer by enabling the pilot and co-pilot to monitor aircraft systems directly. Despite the promise of reduced crew costs, United Airlines initially demanded a conventional three-person cockpit, citing concerns about the risks associated with introducing a new aircraft. The carrier maintained this position until July 1981, when a U.S. presidential task force determined that a crew of two was safe for operating wide-body jets. A three-crew cockpit remained as an option and was fitted to the first production models. Ansett Australia ordered 767s with three-crew cockpits due to union demands; it was the only airline to operate 767s so configured. The 767's two-crew cockpit was also applied to the 757, allowing pilots to operate both aircraft after a short conversion course, and adding incentive for airlines to purchase both types.
Production and testing.
To produce the 767, Boeing formed a network of subcontractors which included domestic suppliers and international contributions from Italy's Aeritalia and Japan's CTDC. The wings and cabin floor were produced in-house, while Aeritalia provided control surfaces, Boeing Vertol made the leading edge for the wings, and Boeing Wichita produced the forward fuselage. The CTDC provided multiple assemblies through its constituent companies, namely Fuji Heavy Industries (wing fairings and gear doors), Kawasaki Heavy Industries (center fuselage), and Mitsubishi Heavy Industries (rear fuselage, doors, and tail). Components were integrated during final assembly at the Everett factory. For expedited production of wing spars, the main structural member of aircraft wings, the Everett factory received robotic machinery to automate the process of drilling holes and inserting fasteners. This method of wing construction expanded on techniques developed for the 747. Final assembly of the first aircraft began on July 6, 1979.
The prototype aircraft, registered N767BA and equipped with JT9D turbofans, rolled out on August 4, 1981. By this time, the 767 program had accumulated 173 firm orders from 17 customers, including Air Canada, All Nippon Airways, Britannia Airways, Transbrasil, and Trans World Airlines (TWA). On September 26, 1981, the prototype took its maiden flight under the command of company test pilots Tommy Edmonds, Lew Wallick, and John Brit. The maiden flight was largely uneventful, save for the inability to retract the landing gear owing to a hydraulic fluid leak. The prototype was used for subsequent flight tests.
The 10-month 767 flight test program utilized the first six aircraft built. The first four aircraft were equipped with JT9D engines, while the fifth and sixth were fitted with CF6 engines. The test fleet was largely used to evaluate avionics, flight systems, handling, and performance, while the sixth aircraft was used for route-proving flights. During testing, pilots described the 767 as generally easy to fly, with its maneuverability unencumbered by the bulkiness associated with larger wide-body jets. Following the successful completion of 1,600 hours of flight tests, the JT9D-powered 767-200 received certification from the U.S. Federal Aviation Administration (FAA) and the U.K. Civil Aviation Authority (CAA) in July 1982. The first delivery occurred on August 19, 1982, to United Airlines. The CF6-powered 767-200 received certification in September 1982, followed by the first delivery to Delta Air Lines on October 25, 1982.
Service entry and operations.
The 767 entered service with United Airlines on September 8, 1982. The aircraft's first commercial flight used a JT9D-powered 767-200 on the Chicago-to-Denver route. The CF6-powered 767-200 commenced service three months later with Delta Air Lines. Upon delivery, early 767s were mainly deployed on domestic routes, including U.S. transcontinental services. American Airlines and TWA began flying the 767-200 in late 1982, while Air Canada, China Airlines, and El Al began operating the aircraft in 1983. The aircraft's introduction was relatively smooth, with few operational glitches and greater dispatch reliability than prior jetliners. In its first year, the 767 logged a 96.1 percent rate of takeoff without delay due to technical issues, which exceeded the industry average for new aircraft. Operators reported generally favorable ratings for the twinjet's sound levels, interior comfort, and economic performance. Resolved issues were minor and included the recalibration of a leading edge sensor to prevent false readings, the replacement of an evacuation slide latch, and the repair of a tailplane pivot to match production specifications.
Seeking to capitalize on its new wide-body's potential for growth, Boeing offered an extended-range model, the 767-200ER, in its first year of service. Ethiopian Airlines placed the first order for the type in December 1982. Featuring increased gross weight specifications and greater fuel capacity, the extended-range model could carry heavier payloads at distances up to , and was targeted at overseas customers. The 767-200ER entered service with El Al on March 27, 1984. The type was mainly ordered by international airlines operating medium-traffic, long-distance flights.
In the mid-1980s, the 767 spearheaded the growth of twinjet flights across the northern Atlantic under extended-range twin-engine operational performance standards (ETOPS) regulations, the FAA's safety rules governing transoceanic flights by aircraft with two engines. Before the 767, over-water flight paths of twinjets could be no more than 90 minutes away from diversion airports. In May 1985, the FAA granted its first approval for 120-minute ETOPS flights to 767 operators, on an individual airline basis starting with TWA, provided that the operator met flight safety criteria. This allowed the aircraft to fly overseas routes at up to two hours' distance from land. The larger safety margins were permitted because of the improved reliability demonstrated by the twinjet and its turbofan engines. The FAA lengthened the ETOPS time to 180 minutes for CF6-powered 767s in 1989, making the type the first to be certified under the longer duration, and all available engines received approval by 1993. Regulatory approval spurred the expansion of transoceanic 767 flights and boosted the aircraft's sales.
Stretched derivatives.
Forecasting airline interest in larger-capacity models, Boeing announced the stretched 767-300 in 1983 and the extended-range 767-300ER in 1984. Both models offered a 20 percent passenger capacity increase, while the extended-range version was capable of operating flights up to . Japan Airlines placed the first order for the 767-300 in September 1983. Following its first flight on January 30, 1986, the type entered service with Japan Airlines on October 20, 1986. The 767-300ER completed its first flight on December 9, 1986, but it was not until March 1987 that the first firm order, from American Airlines, was placed. The type entered service with American Airlines on March 3, 1988. The 767-300 and 767-300ER gained popularity after entering service, and came to account for approximately two-thirds of all 767s sold.
After the debut of the first stretched 767s, Boeing sought to address airline requests for even more capacity by proposing larger models, including a partial double-deck version informally named the "Hunchback of Mukilteo" (from a town near Boeing's Everett factory) with a 757 body section mounted over the aft main fuselage. In 1986, the manufacturer announced the 767-X, a revised model with extended wings and a wider cabin, but received little interest. By 1988, the 767-X had evolved into an all-new twinjet, which revived the 777 designation. Until the 777's 1995 debut, the 767-300 and 767-300ER remained Boeing's second-largest wide-bodies behind the 747.
Buoyed by a recovering global economy and ETOPS approval, 767 sales accelerated in the mid-to-late 1980s, with 1989 being the most prolific year with 132 firm orders. By the early 1990s, the wide-body twinjet had become its manufacturer's annual best-selling aircraft, despite a slight decrease due to economic recession. During this period, the 767 became the most common airliner for transatlantic flights between North America and Europe. By the end of the decade, 767s crossed the Atlantic more frequently than all other aircraft types combined. The 767 also propelled the growth of point-to-point flights which bypassed major airline hubs in favor of direct routes. Taking advantage of the aircraft's lower operating costs and smaller capacity, operators added non-stop flights to secondary population centers, thereby eliminating the need for connecting flights. The increase in the number of cities receiving non-stop services caused a paradigm shift in the airline industry as point-to-point travel gained prominence at the expense of the traditional hub-and-spoke model.
In February 1990, the first 767 equipped with Rolls-Royce RB211 turbofans, a 767-300, was delivered to British Airways. Six months later, the carrier temporarily grounded its entire 767 fleet after discovering cracks in the engine pylons of several aircraft. The cracks were related to the extra weight of the RB211 engines, which are heavier than other 767 engines. During the grounding, interim repairs were conducted to alleviate stress on engine pylon components, and a parts redesign in 1991 prevented further cracks. Boeing also performed a structural reassessment, resulting in production changes and modifications to the engine pylons of all 767s in service.
In January 1993, following an order from UPS Airlines, Boeing launched a freighter variant, the 767-300F, which entered service with UPS on October 16, 1995. The 767-300F featured a main deck cargo hold, upgraded landing gear, and strengthened wing structure. In November 1993, the Japanese government launched the first 767 military derivative when it placed orders for the , an Airborne Early Warning and Control (AWACS) variant based on the 767-200ER. The first two , featuring extensive modifications to accommodate surveillance radar and other monitoring equipment, were delivered in 1998 to the Japan Self-Defense Forces.
In November 1995, after abandoning development of a smaller version of the 777, Boeing announced that it was revisiting studies for a larger 767. The proposed 767-400X, a second stretch of the aircraft, offered an over 12 percent capacity increase versus the 767-300, and featured an upgraded flight deck, enhanced interior, and wider wingspan. The variant was specifically aimed at Delta Air Lines' pending replacement of its aging Lockheed L-1011 TriStars, and faced competition from the A330-200, a shortened derivative of the Airbus A330. In March 1997, Delta Air Lines launched the 767-400ER when it ordered the type to replace its L-1011 fleet. In October 1997, Continental Airlines also ordered the 767-400ER to replace its McDonnell Douglas DC-10 fleet. The type completed its first flight on October 9, 1999, and entered service with Continental Airlines on September 14, 2000.
Further developments.
In the early 2000s, cumulative 767 deliveries approached 900, but new sales declined during an airline industry downturn. In 2001, Boeing dropped plans for a longer-range model, the 767-400ERX, in favor of the proposed Sonic Cruiser, a new jetliner which aimed to fly 15 percent faster while having comparable fuel costs as the 767. The following year, the manufacturer announced the KC-767 Tanker Transport, a second military derivative of the 767-200ER. Launched with an order in October 2002 from the Italian Air Force, the KC-767 was intended for the dual role of refueling other aircraft and carrying cargo. The Japanese government became the second customer for the type in March 2003. In May 2003, the United States Air Force (USAF) announced its intent to lease KC-767s to replace its aging KC-135 tankers. The plan was suspended in March 2004 amid a conflict of interest scandal, resulting in multiple U.S. government investigations and the departure of several Boeing officials, including Philip Condit, the company's chief executive officer, and chief financial officer Michael Sears. The first KC-767s were delivered in 2008 to the Japan Self-Defense Forces.
In late 2002, after airlines expressed reservations about its emphasis on speed over cost reduction, Boeing halted development of the Sonic Cruiser. The following year, the manufacturer announced the 7E7, a mid-size 767 successor made from composite materials which promised to be 20 percent more fuel efficient. The new jetliner was the first stage of a replacement aircraft initiative called the Boeing Yellowstone Project. Customers embraced the 7E7, later renamed 787 Dreamliner, and within two years it had become the fastest-selling airliner in the company's history. In 2005, Boeing opted to continue 767 production despite record Dreamliner sales, citing a need to provide customers waiting for the 787 with a more readily available option. Subsequently, the 767-300ER was offered to customers affected by 787 delays, including All Nippon Airways and Japan Airlines. Some aging 767s, exceeding 20 years in age, were also kept in service past planned retirement dates due to the delays. To extend the operational lives of older aircraft, airlines increased heavy maintenance procedures, including D-check teardowns and inspections for corrosion, a recurring issue on aging 767s. The first 787s would ultimately enter service with All Nippon Airways in October 2011, three-and-a-half years behind schedule.
In 2007, the 767 received a production boost when UPS and DHL Aviation placed a combined 33 orders for the 767-300F. Renewed freighter interest led Boeing to consider enhanced versions of the 767-200 and 767-300F with increased gross weights, 767-400ER wing extensions, and 777 avionics. However, net orders for the 767 declined from 24 in 2008 to just three in 2010. During the same period, operators upgraded aircraft already in service; in 2008, the first 767-300ER retrofitted with blended winglets from Aviation Partners Incorporated debuted with American Airlines. The manufacturer-sanctioned winglets, at in height, improved fuel efficiency by an estimated 6.5 percent. Other carriers including All Nippon Airways and Delta Air Lines also ordered winglet kits.
On February 2, 2011, the 1,000th 767 rolled out, destined for All Nippon Airways. The aircraft was the 91st 767-300ER ordered by the Japanese carrier, and with its completion the 767 became the second wide-body airliner to reach the thousand-unit milestone after the 747. The 1,000th aircraft also marked the last model produced on the original 767 assembly line. Beginning with the 1,001st aircraft, production moved to another area in the Everett factory which occupied nearly half the space as before. The new assembly line made room for 787 production and aimed to boost manufacturing efficiency by over 20 percent.
At the inauguration of its new assembly line, the 767's order backlog numbered approximately 50, only enough for production to last until 2013. Despite the reduced backlog, Boeing officials expressed optimism that additional orders were forthcoming. On February 24, 2011, the USAF announced its selection of the KC-767 Advanced Tanker, an upgraded variant of the KC-767, for its KC-X fleet renewal program. The selection followed two rounds of tanker competition between Boeing and Airbus parent EADS, and came eight years after the USAF's original 2003 announcement of its plan to lease KC-767s. The tanker order encompassed 179 aircraft and was expected to sustain 767 production past 2013. In December 2011, FedEx Express announced a 767-300F order for 27 aircraft to replace its DC-10 freighters, citing the USAF tanker order and Boeing's decision to continue production as contributing factors. FedEx Express announced an agreement to buy an additional 19 of the −300F variant in June 2012. Fifteen of these have been added to Boeing's orders and deliveries table as of June 30, 2012.
Design.
Overview.
The 767 is a low-wing cantilever monoplane with a conventional tail unit featuring a single fin and rudder. The wings are swept at 31.5 degrees and optimized for a cruising speed of Mach 0.8 (). Each wing features a supercritical cross-section and is equipped with six-panel leading edge slats, single- and double-slotted flaps, inboard and outboard ailerons, and six spoilers. The airframe further incorporates carbon-fiber reinforced plastic composite wing surfaces, Kevlar fairings and access panels, plus improved aluminum alloys, which together reduce overall weight by versus preceding aircraft.
To distribute the aircraft's weight on the ground, the 767 has a retractable tricycle landing gear with four wheels on each main gear and two for the nose gear. The original wing and gear design accommodated the stretched 767-300 without major changes. The 767-400ER features a larger, more widely spaced main gear with 777 wheels, tires, and brakes. To prevent damage if the tail section contacts the runway surface during takeoff, 767-300 and 767-400ER models are fitted with a retractable tailskid. The 767 has exit doors near the front and rear of the aircraft on the left side.
In addition to shared avionics and computer technology, the 767 uses the same auxiliary power unit, electric power systems, and hydraulic parts as the 757. A raised cockpit floor and the same forward cockpit windows result in similar pilot viewing angles. Related design and functionality allows 767 pilots to obtain a common type rating to operate the 757 and share the same seniority roster with pilots of either aircraft.
Flight systems.
The original 767 flight deck uses six Rockwell Collins CRT screens to display electronic flight instrument system (EFIS) and engine indication and crew alerting system (EICAS) information, allowing pilots to handle monitoring tasks previously performed by the flight engineer. The CRTs replace conventional electromechanical instruments found on earlier aircraft. An enhanced flight management system, improved over versions used on early 747s, automates navigation and other functions, while an automatic landing system facilitates CAT IIIb instrument landings in low visibility situations. The 767 became the first aircraft to receive CAT IIIb certification from the FAA for landings with minimum visibility in 1984. On the 767-400ER, the cockpit layout is simplified further with six Rockwell Collins liquid crystal display (LCD) screens, and adapted for similarities with the 777 and the Next Generation 737. To retain operational commonality, the LCD screens can be programmed to display information in the same manner as earlier 767s. In 2012, Boeing and Rockwell Collins launched a further 787-based cockpit upgrade for the 767, featuring three landscape-format LCD screens that can display two windows each.
The 767 is equipped with three redundant hydraulic systems for operation of control surfaces, landing gear, and other equipment. Each engine powers a separate hydraulic system, and the third system uses electric pumps. A ram air turbine is fitted to provide power for basic controls in the event of an emergency. An early form of fly-by-wire is employed for spoiler operation, utilizing electric signaling instead of traditional control cables. The fly-by-wire system reduces weight and provides for the independent operation of individual spoilers.
Interior.
The 767 features a twin-aisle cabin with a typical configuration of six abreast in business class and seven across in economy. The standard seven abreast, 2–3–2 economy class layout places approximately 87 percent of all seats at a window or aisle. As a result, the aircraft can be largely occupied before center seats need to be filled, and each passenger is no more than one seat from the aisle. It is possible to configure the aircraft with extra seats for up to an eight abreast configuration, but this results in a cramped cabin and is therefore uncommon.
The 767 interior introduced larger overhead bins and more lavatories per passenger than previous aircraft. The bins are wider to accommodate garment bags without folding, and strengthened for heavier carry-on items. A single, large galley is installed near the aft doors, allowing for more efficient meal service and simpler resupply while at airports. Passenger and service doors are an overhead plug type, which retract upwards, and commonly-used doors can be equipped with an electric-assist system.
In 2000, a 777-style interior, known as the Boeing Signature Interior, debuted on the 767-400ER. Subsequently adopted for all new-build 767s, the Signature Interior features even larger overhead bins, indirect lighting, and sculpted, curved panels. The 767-400ER also received larger windows derived from the 777. Older 767s can be retrofitted with the Signature Interior. Some operators have adopted a simpler modification known as the Enhanced Interior, featuring curved ceiling panels and indirect lighting with minimal modification of cabin architecture, as well as aftermarket modifications such as the NuLook 767 package by Heath Tecna.
Variants.
The 767 has been produced in three fuselage lengths. These debuted in progressively larger form as the 767-200, 767-300, and 767-400ER, respectively. Longer-range variants include the 767-200ER and 767-300ER, while cargo models include the 767-300F, a production freighter, and conversions of passenger 767-200 and 767-300 models.
When referring to different variants, Boeing and airlines often collapse the model number (767) and the variant designator (e.g. –200 or –300) into a truncated form (e.g. "762" or "763"). Subsequent to the capacity number, designations may or may not append the range identifier. The International Civil Aviation Organization (ICAO) aircraft type designator system uses a similar numbering scheme, but adds a preceding manufacturer letter; all variants based on the 767-200 and 767-300 are classified under the codes "B762" and "B763", respectively, while the 767-400ER receives the designation of "B764."
767-200.
The 767-200 was the original model and entered service with United Airlines in 1982. The type has been used primarily by mainline U.S. carriers for domestic routes between major hub centers such as Los Angeles to Washington. The 767-200 was the first aircraft to be used on transatlantic ETOPS flights, beginning with TWA on February 1, 1985 under 90-minute diversion rules. Deliveries for the variant totaled 128 aircraft. There were 55 passenger and freighter conversions of the model in commercial service as of July 2013. The type's competitors included the Airbus A300 and A310.
The 767-200 ceased production in the late 1980s due to being superseded by the extended-range 767-200ER. Some early 767-200s were subsequently upgraded to extended-range specification. In 1998, Boeing began offering 767-200 conversions to 767-200SF (Special Freighter) specification for cargo use, and Israel Aerospace Industries has been licensed to perform cargo conversions since 2005. The conversion process entails the installation of a side cargo door, strengthened main deck floor, and added freight monitoring and safety equipment. The 767-200SF is positioned as a replacement for Douglas DC-8 freighters.
767-200ER.
The 767-200ER was the first extended-range model and entered service with El Al in 1984. The type's increased range is due to an additional center fuel tank and a higher maximum takeoff weight (MTOW) of up to . The type was originally offered with the same engines as the 767-200, while more powerful Pratt & Whitney PW4000 and General Electric CF6 engines later became available. The 767-200ER was the first 767 to complete a non-stop transatlantic journey, and broke the flying distance record for a twinjet airliner on April 17, 1988 with an Air Mauritius flight from Halifax, Nova Scotia to Port Louis, Mauritius, covering a distance of . The 767-200ER has been acquired by international operators seeking smaller wide-body aircraft for long-haul routes such as New York to Beijing. Deliveries of the type totaled 121 with no unfilled orders. As of July 2013, 47 examples of passenger and freighter conversion versions were in airline service. The type's competitors included the Airbus A300-600R and the A310-300.
767-300.
The 767-300, the first stretched version of the aircraft, entered service with Japan Airlines in 1986. The type features a fuselage extension over the 767-200, achieved by additional sections inserted before and after the wings, for an overall length of . Reflecting the growth potential built into the original 767 design, the wings, engines, and most systems were largely unchanged on the 767-300. An optional mid-cabin exit door is positioned ahead of the wings on the left, while more powerful Pratt & Whitney PW4000 and Rolls-Royce RB211 engines later became available. The 767-300's increased capacity has been used on high-density routes within Asia and Europe. Deliveries for the type totaled 104 aircraft with no unfilled orders remaining. As of July 2013, 59 of the variant were in airline service. The type's main competitor was the Airbus A300.
767-300ER.
The 767-300ER, the extended-range version of the 767-300, entered service with American Airlines in 1988. The type's increased range is made possible by greater fuel tankage and a higher MTOW of . Design improvements allowed the available MTOW to increase to by 1993. Power is provided by Pratt & Whitney PW4000, General Electric CF6, or Rolls-Royce RB211 engines. Typical routes for the type include Los Angeles to Frankfurt. The combination of increased capacity and range offered by the 767-300ER has been particularly attractive to both new and existing 767 operators, allowing it to become the most successful version of the aircraft. Airlines have placed more orders for the type than all other variants combined. As of October 2013, 767-300ER deliveries stand at 582 with 1 unfilled order. Airlines had 533 examples in service as of July 2013. The type's main competitor is the Airbus A330-200.
767-300F.
The 767-300F, the production freighter version of the 767-300ER, entered service with UPS Airlines in 1995. The 767-300F can hold up to 24 standard pallets on its main deck and up to 30 LD2 unit load devices on the lower deck, with a total cargo volume of . The freighter has a main deck cargo door and crew exit, while the lower deck features two port-side cargo doors and one starboard cargo door. A general market version with onboard freight-handling systems, refrigeration capability, and crew facilities was delivered to Asiana Airlines on August 23, 1996. As of October 2013, 767-300F deliveries stand at 86 with 44 unfilled orders. Airlines operated 90 examples of the freighter variant and freighter conversions in July 2013.
In June 2008, All Nippon Airways took delivery of the first 767-300BCF (Boeing Converted Freighter), a modified passenger-to-freighter model. The conversion work was performed in Singapore by ST Aerospace Services, the first supplier to offer a 767-300BCF program, and involved the addition of a main deck cargo door, strengthened main deck floor, and additional freight monitoring and safety equipment. Since then, Boeing, Israel Aerospace Industries, and Wagner Aeronautical have also offered passenger-to-freighter conversion programs for 767-300 series aircraft.
767-400ER.
[[File:Delta Air Lines 767-400ER N845MH MAC EGLL 29.05.11.jpg|thumb|right|A Delta Air Lines 767-400ER in pink Breast Cancer Research Foundation livery landing at London Heathrow Airport|alt= Twin-engine airliner with white and pink colors on approach with landing gear and flaps extended.
The 767-400ER, the first Boeing wide-body jet resulting from two fuselage stretches, entered service with Continental Airlines in 2000. The type features a stretch over the 767-300, for a total length of . The wingspan is also increased by through the addition of raked wingtips. Other differences include an updated cockpit, redesigned landing gear, and 777-style Signature Interior. Power is provided by uprated Pratt & Whitney PW4000 or General Electric CF6 engines.
The FAA granted approval for the 767-400ER to operate 180-minute ETOPS flights before it entered service. Because its fuel capacity was not increased over preceding models, the 767-400ER has a range of , less than previous extended-range 767s. Typical routings for the type include London to Tokyo. A longer-range version, the 767-400ERX, was offered for sale in 2000 but cancelled a year later, leaving the 767-400ER as the sole version of the largest 767. There is only the -400ER variant, and no -400 variant. The variant's only two airline customers, Continental Airlines (now merged with United Airlines) and Delta Air Lines, received 37 aircraft, with no unfilled orders. All 37 of the 767-400ER were in service as of July 2013. One additional example was produced as a military testbed, and later sold as a VIP transport. The type's closest competitor is the Airbus A330-200.
Military and government.
Versions of the 767 serve in a number of military and government applications, with responsibilities ranging from airborne surveillance and refueling to cargo and VIP transport. Several military 767s have been derived from the 767-200ER, the longest-range version of the aircraft.
Undeveloped variants.
767-400ERX.
Boeing offered the 767-400ERX, a longer-range version of the largest 767 model, for sale in 2000. Introduced along with the 747X, the type was to be powered by the 747X's engines, namely the Engine Alliance GP7000 and the Rolls-Royce Trent 600. An increased range of was specified. Kenya Airways provisionally ordered three 767-400ERXs to supplement its 767 fleet, but after Boeing cancelled the type's development in 2001, switched the order to the 777-200ER.
E-10 MC2A.
The Northrop Grumman E-10 MC2A was to be a 767-400ER-based replacement for the USAF's 707-based E-3 Sentry AWACS, E-8 Joint STARS, and RC-135 SIGINT aircraft. The E-10 MC2A would have included an all-new AWACS system, with a powerful Active Electronically Scanned Array (AESA) that was also capable of jamming enemy aircraft or missiles. One 767-400ER aircraft was produced as a testbed for systems integration, but the program was terminated in January 2009 and the prototype sold to Bahrain as a VIP transport.
Operators.
The customers that have ordered the most 767s are Delta Air Lines, All Nippon Airways, and United Airlines. Delta Air Lines is the largest customer, having received 117 aircraft. The Atlanta-based carrier is also the only customer to have ordered all passenger versions of the 767. Its 100th example, a 767-400ER, was delivered in October 2000. United Airlines was the only carrier operating all versions of the 767 ER series (762ER, 763ER, and 764ER) as of November 2012. The largest cargo customer is UPS Airlines, having received 59 aircraft as of October 2013.
A total of 821 aircraft (all 767 variants) were in airline service in July 2013, with airline operators Delta Air Lines (94), American Airlines (70), UPS Airlines (56), United Airlines (51), All Nippon Airways (50), Japan Airlines (48), LAN Airlines (43), ABX Air (34), Air Canada (30), and others with fewer aircraft of the type.
Incidents and accidents.
As of February 2014, the Boeing 767 has been in 38 aviation occurrences, including 14 hull-loss accidents. Six fatal crashes, including three hijackings, have resulted in a total of 851 occupant fatalities. The airliner's first fatal crash, Lauda Air Flight 004, occurred near Bangkok on May 26, 1991, following the in-flight deployment of the left engine thrust reverser on a 767-300ER; none of the 223 aboard survived; as a result of this accident all 767 thrust reversers were deactivated until a redesign was implemented. Investigators determined that an electronically-controlled valve, common to late-model Boeing aircraft, was to blame. A new locking device was installed on all affected jetliners, including 767s. On October 31, 1999, EgyptAir Flight 990, a 767-300ER, crashed off Nantucket Island, Massachusetts, in international waters killing all 217 people on board. The U.S. National Transportation Safety Board (NTSB) determined the probable cause to be due to a deliberate action by the first officer; Egypt disputed this conclusion. On April 15, 2002, Air China Flight 129, a 767-200ER, crashed into a hill amid inclement weather while trying to land at Gimhae International Airport in Busan, South Korea. The crash resulted in the death of 129 of the 166 people on board, and the cause was attributed to pilot error.
An early 767 incident was survived by all on board. On July 23, 1983, Air Canada Flight 143, a 767-200, ran out of fuel in-flight and had to glide with both engines out for almost to an emergency landing at Gimli, Manitoba. The pilots used the aircraft's ram air turbine to power the hydraulic systems for aerodynamic control. There were no fatalities and only minor injuries. This aircraft was nicknamed "Gimli Glider" for the airport at which it landed. The aircraft, registered C-GAUN, continued flying for Air Canada until its retirement in January 2008.
The 767 has been involved in six hijackings, three resulting in loss of life, for a combined total of 282 occupant fatalities. On November 23, 1996, Ethiopian Airlines Flight 961, a 767-200ER, was hijacked and crash-landed in the Indian Ocean near the Comoros Islands after running out of fuel, killing 125 out of the 175 persons onboard; survivors have been rare among instances of land-based aircraft ditching on water. Two 767s were involved in the September 11 attacks on the World Trade Center in 2001, resulting in the collapse of its two main towers. American Airlines Flight 11, a 767-200ER, crashed into the north tower, killing all 92 people on board, and United Airlines Flight 175, a 767-200, crashed into the south tower, with the death of all 65 on board. In addition, more than 2,600 people perished in the towers or on the ground. A foiled 2001 shoe bomb plot involving an American Airlines 767-300ER resulted in passengers being required to remove their shoes for scanning at U.S. security checkpoints.
On November 1, 2011, LOT Polish Airlines Flight 16, a 767-300ER, safely landed at Warsaw Frederic Chopin Airport in Warsaw, Poland after a mechanical failure of the landing gear forced an emergency landing with the landing gear up. There were no injuries, but the aircraft involved was damaged. It was possibly the first instance of a complete landing gear failure in the 767's service history. A preliminary investigation suggested a hydraulic leak and a deactivated circuit breaker as probable causes.
In January 2014, the U.S. Federal Aviation Administration issued a directive that ordered inspections of the elevators on more than 400 767s beginning in March 2014; the focus is on fasteners and other parts that can fail and cause the elevators to jam. The issue was first identified in 2000 and has been the subject of several Boeing service bulletins. The inspections and repairs are required to be completed within six years.
Retirement and display.
As new 767s roll off the assembly line, older models have been retired and scrapped. One complete aircraft is known to have been retained for exhibition, specifically N102DA, the first 767-200 to operate for Delta Air Lines and the twelfth example built. The exhibition aircraft, named "The Spirit of Delta" by the employees who helped purchase it in 1982, underwent restoration at the Delta Air Lines Air Transport Heritage Museum in Atlanta, Georgia. The restoration was completed in 2010. Featuring the original delivered interior as well as historical displays, the aircraft is viewable by visitors (self-guided) daily, during the museum's operating hours. Hangar renovations, begun in June 2013, are now complete, and the museum is accessible on a daily basis. 
In 2010, four retired American Airlines 767-200s were dismantled for parts in Roswell, New Mexico, and their nose sections removed intact for collector or film use. Of these four aircraft, the cockpit of N301AA, the eighth 767 built and the first of its type to be delivered to American Airlines, was transported to Victorville, California, to be restored for museum display. As of 2013, the cockpit section of N301AA is housed at the interim museum location of the American Museum of Aviation, a nonprofit organization in Las Vegas, Nevada, along with a display of American Airlines photographs. The organization is also attempting to restore the forward upper fuselage and cockpit section of N601UA, a former United Airlines aircraft and the second 767 built.
Specifications.
Sources: Boeing 767 general specifications, Boeing 767 variant specifications and other sources

</doc>
<doc id="4166" url="http://en.wikipedia.org/wiki?curid=4166" title="Bill Walsh (American football coach)">
Bill Walsh (American football coach)

William Ernest "Bill" Walsh (November 30, 1931 – July 30, 2007) was the head coach of the San Francisco 49ers and the Stanford Cardinal football team, during which time he popularized the West Coast offense. After retiring from the 49ers, Walsh returned as head coach at Stanford and later served as Cardinal athletic director.
Walsh went 102–63–1 with the 49ers, winning ten of his 14 postseason games along with six division titles, three NFC Championship titles, and three Super Bowls. He was named the NFL's Coach of the Year in 1981 and 1984. In 1993, he was elected to the Pro Football Hall of Fame.
Early career.
Born in Los Angeles, Walsh played running back in the San Francisco Bay Area for Hayward High School in Hayward.
Walsh played quarterback at the College of San Mateo for two seasons. Both John Madden and Walsh played and coached at the College of San Mateo early in their careers. After playing at the College of San Mateo, Walsh transferred to San José State University, where he played tight end and defensive end. He also participated in intercollegiate boxing. Walsh graduated from San Jose State with a bachelor's degree in physical education in 1955. He served under Bob Bronzan as a graduate assistant coach on the Spartans football coaching staff and graduated with a master's degree in physical education from San Jose State in 1959. His master's thesis was entitled "Flank Formation Football -- Stress:: Defense". Thesis 796.W228f
Following graduation, Walsh coached at Washington High School in Fremont, leading the football and swim teams.
Walsh was coaching in Fremont when he interviewed for an assistant coaching position with Marv Levy, who had just been hired as the head coach at the University of California, Berkeley.
"I was very impressed, individually, by his knowledge, by his intelligence, by his personality and hired him," Levy said.
After Cal, Walsh did a stint at Stanford as an assistant coach, before beginning his pro coaching career.
Professional football career.
Walsh began his pro coaching career in 1966 as an assistant with the AFL's Oakland Raiders. As a Raider assistant, Walsh was trained in the vertical passing offense favored by Al Davis, putting Walsh in Davis's mentor Sid Gillman's coaching tree.
In 1968, Walsh moved to the AFL expansion Cincinnati Bengals, joining the staff of legendary coach Paul Brown. It was there that Walsh developed the philosophy now known as the "West Coast Offense", as a matter of necessity. Cincinnati's new quarterback, Virgil Carter, was known for his great mobility and accuracy but lacked a strong arm necessary to throw deep passes. Thus, Walsh modified the vertical passing scheme he had learned during his time with the Raiders, designing a horizontal passing system that relied on quick, short throws - often spreading the ball across the entire width of the field. The new offense was much better suited to Carter's physical abilities; he led the league in pass completion percentage in 1971.
Walsh spent eight seasons as an assistant with the Bengals. Ken Anderson eventually replaced Carter as starting quarterback, and together with star wide receiver Isaac Curtis, produced a consistent, effective offensive attack. Initially, Walsh started out as the wide receivers coach from 1968 to 1970 before also coaching the quarterbacks from 1971 to 1975.
When Brown retired as head coach following the 1975 season and appointed Bill "Tiger" Johnson as his successor, Walsh resigned and served as an assistant coach for Tommy Prothro with the San Diego Chargers in 1976. In a 2006 interview, Walsh claimed that during his tenure with the Bengals, Brown "worked against my candidacy" to be a head coach anywhere in the league. "All the way through I had opportunities, and I never knew about them," Walsh said. "And then when I left him, he called whoever he thought was necessary to keep me out of the NFL."
In 1977, Walsh was hired as the head coach at Stanford where he stayed for two seasons. His two Stanford teams were successful, posting a 9–3 record in 1977 with a win in the Sun Bowl, and 8–4 in 1978 with a win in the Bluebonnet Bowl. His notable players at Stanford included quarterbacks Guy Benjamin and Steve Dils, wide receivers James Lofton and Ken Margerum, linebacker Gordy Ceresino, in addition to running back Darrin Nelson. Walsh was the Pac-8 Conference Coach of the Year in 1977.
In 1979, Walsh was hired as head coach of the San Francisco 49ers. The long-suffering 49ers went 2–14 in 1978, the season before Walsh's arrival and repeated the same dismal record in his first season. Walsh got the entire organization to buy into his philosophy and vowed to turn around a miserable situation. Despite their second consecutive 2-14 record, the 49ers were playing more competitive football. 
In 1979, Walsh drafted quarterback Joe Montana from Notre Dame in the third round. After a 59-14 blowout loss to Dallas in week 6 of the 1980 season, Walsh promoted Montana to starting QB. On a Monday Night Football game, December 7, 1980, vs. the New Orleans Saints, Montana brought the 49ers back from a 35-7 halftime deficit to win 38-35 in overtime. The 49ers improved in 1980 to 6–10, but more importantly, Walsh had the 49ers making great strides and they were getting better every week. San Francisco won its first championship in 1981, just two years after winning two games.
Under Walsh the 49ers won Super Bowl championships in 1981, 1984 and 1988. Walsh served as 49ers head coach for ten years, and during his tenure he and his coaching staff perfected the style of play known popularly as the West Coast offense. Walsh was nicknamed "The Genius" for both his innovative play calling and design. Walsh would regularly script the first 10-15 offensive plays before the start of each game. In the ten years during which Walsh was the 49ers' head coach, San Francisco scored 3,714 points (24.4 per game), the most of any team in the league during that span.
In addition to drafting Joe Montana, Walsh drafted Ronnie Lott, Charles Haley, and Jerry Rice. He also traded a 2nd and 4th round pick in the 1987 draft for Steve Young. His success with the 49ers was rewarded with his election to the Professional Football Hall of Fame in 1993.
1981 championship.
The 1981 season saw Walsh lead the 49ers to a Super Bowl championship; the team rose from the cellar to the top of the NFL in just two seasons. Four important wins during the 1981 season were two wins each over the Los Angeles Rams and the Dallas Cowboys. The Rams were only one year removed from a Super Bowl appearance, and had dominated the series with the 49ers since 1967 winning 23, losing 3 and tying 1. The 49ers' two wins over the Rams in 1981 marked the shift of dominance in favor of the 49ers that lasted until 1998 with 30 wins (including 17 consecutively) against only 6 defeats.
In 1981, the 49ers blew out the Cowboys in week 6 of the regular season. On "Monday Night Football" that week, the 49ers' win was not included in the famous halftime highlights. Walsh felt that this was because the Cowboys were scheduled to play the Rams the next week in a rare Sunday night game and that showing the highlights of the 49ers' win would potentially hurt the game's ratings. However, Walsh used this as a motivating factor for his team, who felt they were disrespected.
The 49ers faced the Cowboys again that same season in the NFC title game. The game was very close, and in the fourth quarter Walsh called a series of running plays as the 49ers marched down the field against the Cowboys prevent defense, which had been expecting the 49ers to mainly pass. The 49ers came from behind to win the game on Dwight Clark's memorable TD reception (The Catch), propelling Walsh to his first Super Bowl. Walsh and the 49ers defeated Cincinnati in the Super Bowl, which was played in Pontiac, Michigan. Walsh would later write that the 49ers' two wins over the Rams showed a shift of power in their division, while the wins over the Cowboys showed a shift of power in the conference.
Prominent assistant coaches.
Many of Bill Walsh's assistant coaches went on to be head coaches themselves, including George Seifert, Mike Holmgren, Ray Rhodes, and Dennis Green. After Walsh's retirement from the 49ers, Seifert succeeded him as 49ers head coach, and guided San Francisco to victories in Super Bowl XXIV and Super Bowl XXIX. Holmgren won a Super Bowl with the Green Bay Packers, and made 3 Super Bowl appearances as a head coach: 2 with the Packers, and another with the Seattle Seahawks. These coaches in turn have their own disciples who have used Walsh's West Coast system, such as former Washington Redskins head coach Mike Shanahan and former Houston Texans head coach Gary Kubiak. Mike Shanahan was an offensive coordinator under George Seifert and went on to win Super Bowl XXXII and Super Bowl XXXIII during his time as head coach of the Denver Broncos. Kubiak was first a quarterback coach with the 49ers, then offensive coordinator for Shanahan with the Denver Broncos. Dennis Green trained Tony Dungy, who won a Super Bowl with the Indianapolis Colts, and Brian Billick with his brother-in law and linebackers coach Mike Smith. Billick won a Super Bowl as head coach of the Baltimore Ravens. Mike Holmgren trained many of his assistants to become head coaches, including Jon Gruden and Andy Reid. Gruden won a Super Bowl with the Tampa Bay Buccaneers. Reid served as head coach of the Philadelphia Eagles from 1999-2012, and guided the Eagles to multiple winning seasons and numerous playoff appearances. In addition to this, Marc Trestman, current head coach of the Chicago Bears, served as Offensive Coordinator under Seifert in the 90's. Gruden himself would train Mike Tomlin, who led the Pittsburgh Steelers to their sixth Super Bowl championship, and Jim Harbaugh, whose 49ers would face his brother, John Harbaugh, whom Reid himself trained, and the Baltimore Ravens at Super Bowl XLVII, which marked the Ravens' second World Championship.
Bill Walsh was viewed as a strong advocate for African-American head coaches in the NFL and NCAA. Thus, the impact of Walsh also changed the NFL into an equal opportunity for African-American coaches. Along with Ray Rhodes and Dennis Green, Tyrone Willingham became the head coach at Stanford, then later Notre Dame and Washington. One of Mike Shanahan's assistants, Karl Dorrell went on to be the head coach at UCLA. Walsh directly helped propel Dennis Green into the NFL head coaching ranks by offering to take on the head coaching job at Stanford.
Bill Walsh coaching tree.
Many former and current NFL head coaches trace their lineage back to Bill Walsh on his coaching tree, shown below. Walsh, in turn, belonged to the coaching tree of American Football League great and Hall of Fame coach Sid Gillman of the AFL's Los Angeles/San Diego Chargers.
Later career.
After leaving the coaching ranks immediately following his team's victory in Super Bowl XXIII, Walsh went to work as a broadcaster for NBC (teaming with Dick Enberg to form the lead broadcasting team while replacing Merlin Olsen in the booth). Walsh returned to Stanford once again as head coach in 1992 (Bob Trumpy subsequently replaced him on the NBC telecasts, and would, in turn be replaced by Paul Maguire who would later be joined by Phil Simms), leading the Cardinal to a 10-3 record and a Pacific-10 Conference co-championship. Stanford finished the season with an upset victory over Penn State in the Blockbuster Bowl on January 1, 1993 and a # 9 ranking in the final AP Poll. In 1994, after consecutive losing seasons, Walsh left Stanford and retired from coaching.
Walsh would also return to the 49ers, serving as Vice President and General Manager from 1999 to 2001 and was a special consultant to the team for three years afterwards. In 2004, Walsh was appointed as special assistant to the athletic director at Stanford. In 2005, after then-athletic director Ted Leland stepped down to take a position at the University of the Pacific, Walsh was named interim athletic director. He also acted as a consultant for his alma mater San Jose State University in their search for an Athletic Director and Head Football Coach in 2005.
Bill Walsh was also the author of three books, a motivational speaker, and taught classes at the Stanford Graduate School of Business.
Walsh was a Board Member for the Lott IMPACT Trophy, which is named after Pro Football Hall of Fame defensive back Ronnie Lott, and is awarded annually to college football's Defensive IMPACT Player of the Year. Walsh served as a keynote speaker at the award's banquet.
Leukemia.
Death.
Bill Walsh died of leukemia at 10:45 am on July 30, 2007, at his home in Woodside, California. Following Walsh's death, the playing field at Candlestick Park was renamed "Bill Walsh Field". Additionally, the regular San Jose State versus Stanford football game was renamed the "Bill Walsh Legacy Game".
Family.
Walsh is survived by his wife Geri, his son Craig and his daughter Elizabeth. Walsh also lost a son, Steve, in 2002. Craig Walsh flipped the coin at Super Bowl XLIII in Glendale, Arizona, accompanied by his sister, their mother and several ex-49ers.

</doc>
<doc id="4168" url="http://en.wikipedia.org/wiki?curid=4168" title="Utility knife">
Utility knife

A utility knife is a knife used for general or utility purposes. The utility knife was originally a fixed blade knife with a cutting edge suitable for general work such as cutting hides and cordage, scraping hides, butchering animals, cleaning fish, and other tasks. Craft knives are tools mostly used for crafts.
Today, the term "utility knife" also includes small folding or retractable-blade knives suited for use in the modern workplace or in the construction industry.
History.
The fixed-blade utility knife was developed some 500,000 years ago, when humans began to make knives made of stone. These knives were general-purpose tools, designed for cutting and shaping wooden implements, scraping hides, preparing food, and for other utilitarian purposes.
By the 19th century the fixed-blade utility knife had evolved into a steel-bladed outdoors field knife capable of butchering game, cutting wood, and preparing campfires and meals. With the invention of the backspring, pocket-size utility knives were introduced with folding blades and other folding tools designed to increase the utility of the overall design. The folding pocketknife and utility tool is typified by the "Camper" or "Boy Scout" pocketknife, the U.S. folding utility knife, the Swiss Army Knife, and by multi-tools fitted with knife blades. The development of stronger locking blade mechanisms for folding knives—as with the Spanish navaja, the Opinel, and the Buck 110 Folding Hunter—significantly increased the utility of such knives when employed for heavy-duty tasks such as preparing game or cutting through dense or tough materials.
Contemporary utility knives.
The fixed or folding blade utility knife is popular for both indoor and outdoor use. One of the most popular types of workplace utility knife is the retractable or folding utility knife (also known as a "Stanley knife", "box cutter", "X-Acto knife", or by various other names). These types of utility knives are designed as multi-purpose cutting tools for use in a variety of trades and crafts. Designed to be lightweight and easy to carry and use, utility knives are commonly used in factories, warehouses, construction projects, and other situations where a tool is routinely needed to mark cut lines, trim plastic or wood materials, or to cut tape, cord, strapping, cardboard, or other packaging material.
Names.
In British, Australian and New Zealand English, along with Dutch and Austrian German, a utility knife frequently used in the construction industry is known as a "Stanley knife". This name is a genericised trademark named after Stanley Works, a manufacturer of such knives. In Israel and Switzerland, these knives are known as "Japanese knives". In Brazil they are known as "estiletes" or "cortadores Olfa" (the latter, being another genericised trademark). In Portugal and Canada they are also known as "X-Acto" (yet another genericised trademark). In India, the Philippines, France, Italy, and Egypt, they are simply called "cutter". In general Spanish, they are known as "cortaplumas" (penknife, when it comes to folding blades); in Spain, Mexico, and Costa Rica, they are colloquially known as "cutters"; in Argentina and Uruguay the segmented fixed-blade knives are known as "Trinchetas". 
Other names for the tool are "box cutter" or "boxcutter", "razor blade knife", "razor knife", "carpet knife", "pen knife", "stationery knife", "sheetrock knife", or "drywall knife". Some of these names refer to a different kind of knife depending on the region. For example, in the mid-Atlantic US, the X-Acto name is likelier to evoke only a specific subset of these knives (the pencil-shaped hobby knife), which may explain why the "utility knife" name, with its specificity, is more common there for the larger type. Also, in this region, "box cutter" usually evokes only a specific subset of these knives (the simpler type whose body consists only of a flat sleeve stamped from sheet steel), and "pen knife" usually evokes only a folding pocket knife.
Design.
Utility knives may use fixed, folding, or retractable or replaceable blades, and come in a wide variety of lengths and styles suited to the particular set of tasks they are designed to perform. Thus, an outdoors utility knife suited for camping or hunting might use a broad fixed blade, while a utility knife designed for the construction industry might feature a replaceable utility or razor blade for cutting packaging, cutting shingles, marking cut lines, or scraping paint.
Fixed blade utility knife.
Large fixed-blade utility knives are most often employed in an outdoors context, such as fishing, camping, or hunting. Outdoor utility knives typically feature sturdy blades from in length, with edge geometry designed to resist chipping and breakage. 
The term "utility knife" may also refer to small fixed-blade knives used for crafts, model-making and other artisanal projects. These small knives feature light-duty blades best suited for cutting thin, lightweight materials. The small, thin blade and specialized handle permit cuts requiring a high degree of precision and control.
Workplace utility knives.
The largest construction or workplace utility knife typically feature retractable and replaceable blades, made of either die-cast metal or molded plastic. Some use standard razor blades, others specialized double-ended utility blades. The user can adjust how far the blade extends from the handle, so that, for example, the knife can be used to cut the tape sealing a package without damaging the contents of the package. When the blade becomes dull, it can be quickly reversed or switched for a new one. Spare or used blades are stored in the hollow handle of some models, and can be accessed by removing a screw and opening the handle. Other models feature a quick-change mechanism that allows replacing the blade without tools, as well as a flip-out blade storage tray. The blades for this type of utility knife come in both double- and single-ended versions, and are interchangeable with many, but not all, of the later copies. Specialized blades also exist for cutting string, linoleum, and other materials.
Another style is a snap-off utility knife that contains a long, segmented blade that slides out from it. As the endmost edge becomes dull, it can be broken off the remaining blade, exposing the next section, which is sharp and ready for use. The snapping is best accomplished with a blade snapper that is often built-in, or a pair of pliers, and the break occurs at the score lines, where the metal is thinnest. When all the individual segments are used, the knife may be thrown away, or, more often, refilled with a replacement blade. This design was introduced by Japanese manufacturer Olfa Corporation in 1956 as the world's first snap-off blade and was inspired from analyzing the sharp cutting edge produced when glass is broken and how pieces of a chocolate bar break into segments.
Another utility knife often used for cutting open boxes consists of a simple sleeve around a rectangular handle into which single-edge utility blades can be inserted. The sleeve slides up and down on the handle, holding the blade in place during use and covering the blade when not in use. The blade holder may either retract or fold into the handle, much like a folding-blade pocketknife. The blade holder is designed to expose just enough edge to cut through one layer of corrugated fiberboard, to minimize chances of damaging contents of cardboard boxes.
Use as weapon.
Most utility knives are not well suited to use as offensive weapons, with the exception of some outdoor-type utility knives employing longer blades. However, even small razor-blade type utility knives may sometimes find use as slashing weapons. It has been suggested by United States government officials that "box-cutter knives" were used in the September 11, 2001 terrorist attacks against the United States, though the exact design of the knives actually used is unclear. 
Small work-type utility knives have also been used to commit robbery and other crimes. In June 2004, a Japanese student was slashed to death with a segmented-type utility knife.
In the United Kingdom, the law was changed to raise the age limit for purchasing knives, including utility knives, from 16 to 18.

</doc>
<doc id="4169" url="http://en.wikipedia.org/wiki?curid=4169" title="Bronze">
Bronze

Bronze is an alloy consisting primarily of copper. The addition of other metals (usually tin, sometimes arsenic), produces an alloy much harder than plain copper. The historical period where the archeological record contains many bronze artifacts is known as the Bronze Age.
Because historical pieces were often made of brasses (copper and zinc) and bronzes with different compositions, modern museum and scholarly descriptions of older objects increasingly use the more inclusive term "copper alloy" instead.
The word "bronze" (1730–40) is borrowed from French "bronze" (1511), itself borrowed from Italian "bronzo" "bell metal, brass" (13th century) (transcribed in Medieval Latin as "bronzium"), from either:
History.
The discovery of bronze enabled people to create metal objects which were harder and more durable than previously possible. Bronze tools, weapons, armor, and building materials such as decorative tiles were harder and more durable than their stone and copper ("Chalcolithic") predecessors. Initially, bronze was made out of copper and arsenic, forming arsenic bronze, or from naturally or artificially mixed ores of copper and arsenic. It was only later that tin was used, becoming the major non-copper ingredient of bronze in the late 3rd millennium BC. Tin bronze was superior to arsenic bronze in that the alloying process could be more easily controlled, and the resulting alloy was stronger and easier to cast. Also, unlike arsenic, tin is not toxic.
The earliest tin-alloy bronze dates to 4500 BCE in a Vinča culture site in Pločnik (Serbia). Other early examples date to the late 4th millennium BC in Susa (Iran) and some ancient sites in China, Luristan (Iran) and Mesopotamia (Iraq).
Ores of copper and the far rarer tin are not often found together (exceptions include one ancient site in Thailand and one in Iran), so serious bronze work has always involved trade. Tin sources and trade in ancient times had a major influence on the development of cultures. In Europe, a major source of tin was England's deposits of ore in Cornwall, which were traded as far as Phoenicia in the Eastern Mediterranean.
Though bronze is generally harder than wrought iron, with Vickers hardness of 60–258 vs. 30–80, the Bronze Age gave way to the Iron Age because iron was easier to find and easier to process into a usable grade of metal (it can be made into higher grades, but doing so takes significantly more effort and skill). Pure iron is soft, and the process of beating and folding sponge iron to make wrought iron removes carbon and other impurities from the metal which need to be re-introduced to improve hardness. Careful control of the alloying and tempering eventually allowed for wrought iron with properties comparable to modern steel.
Bronze was still used during the Iron Age. For many purposes, the weaker wrought iron was found to be sufficiently strong. Archaeologists suspect that a serious disruption of the tin trade precipitated the transition. The population migrations around 1200–1100 BC reduced the shipping of tin around the Mediterranean (and from Great Britain), limiting supplies and raising prices. As the art of working in iron improved, iron became cheaper, and as cultures advanced from wrought iron (typically forged by hand – "wrought" – by blacksmiths) to machine forged iron (typically made with trip hammers powered by water), the blacksmiths learned how to make steel, which is stronger than bronze and holds a sharper edge longer.
Composition.
There are many different bronze alloys, but typically modern bronze is 88% copper and 12% tin. Alpha bronze consists of the alpha solid solution of tin in copper. Alpha bronze alloys of 4–5% tin are used to make coins, springs, turbines and blades. Historical "bronzes" are highly variable in composition, as most metalworkers probably used whatever scrap was on hand; the metal of the 12th-century English Gloucester Candlestick is bronze containing a mixture of copper, zinc, tin, lead, nickel, iron, antimony, arsenic with an unusually large amount of silver – between 22.5% in the base and 5.76% in the pan below the candle. The proportions of this mixture may suggest that the candlestick was made from a hoard of old coins. The Benin Bronzes are really brass, and the Romanesque Baptismal font at St Bartholomew's Church, Liège is described as both bronze and brass.
In the Bronze Age, two forms of bronze were commonly used: "classic bronze", about 10% tin, was used in casting; and "mild bronze", about 6% tin, was hammered from ingots to make sheets. Bladed weapons were mostly cast from classic bronze, while helmets and armor were hammered from mild bronze.
Commercial bronze (90% copper and 10% zinc) and architectural bronze (57% copper, 3% lead, 40% zinc) are more properly regarded as brass alloys because they contain zinc as the main alloying ingredient. They are commonly used in architectural applications.
Bismuth bronze is a bronze alloy with a composition of 52% copper, 30% nickel, 12% zinc, 5% lead, and 1% bismuth. It is able to hold a good polish and so is sometimes used in light reflectors and mirrors.
Plastic bronze is bronze containing a significant quantity of lead which makes for improved plasticity possibly used by the ancient Greeks in their ship construction.
Other bronze alloys include aluminium bronze, phosphor bronze, manganese bronze, bell metal, arsenical bronze, speculum metal and cymbal alloys.
Properties.
Typically bronze only oxidizes superficially; once a copper oxide (eventually becoming copper carbonate) layer is formed, the underlying metal is protected from further corrosion. However, if copper chlorides are formed, a corrosion-mode called "bronze disease" will eventually completely destroy it. Copper-based alloys have lower melting points than steel or iron, and are more readily produced from their constituent metals. They are generally about 10 percent heavier than steel, although alloys using aluminium or silicon may be slightly less dense. Bronzes are softer and weaker than steel—bronze springs, for example, are less stiff (and so store less energy) for the same bulk. Bronze resists corrosion (especially seawater corrosion) and metal fatigue more than steel and is a better conductor of heat and electricity than most steels. The cost of copper-base alloys is generally higher than that of steels but lower than that of nickel-base alloys.
Copper and its alloys have a huge variety of uses that reflect their versatile physical, mechanical, and chemical properties. Some common examples are the high electrical conductivity of pure copper, the low-friction properties of bearing bronze (bronze which has a high lead content— 6-8%), the resonant qualities of bell bronze (20% tin, 80% copper), and the resistance to corrosion by sea water of several bronze alloys.
The melting point of bronze varies depending on the ratio of the alloy components and is about . Bronze may be nonmagnetic, but certain alloys containing iron or nickel may have magnetic properties.
Uses.
Bronze was especially suitable for use in boat and ship fittings prior to the wide employment of stainless steel owing to its combination of toughness and resistance to salt water corrosion. Bronze is still commonly used in ship propellers and submerged bearings.
In the 20th century, silicon was introduced as the primary alloying element, creating an alloy with wide application in industry and the major form used in contemporary statuary. Sculptors may prefer silicon bronze because of the ready availability of silicon bronze brazing rod, which allows color-matched repair of defects in castings. Aluminium is also used for the structural metal aluminium bronze.
It is also widely used for cast bronze sculpture. Many common bronze alloys have the unusual and very desirable property of expanding slightly just before they set, thus filling in the finest details of a mold. Bronze parts are tough and typically used for bearings, clips, electrical connectors and springs.
Bronze also has very low metal-on-metal friction, which made it invaluable for the building of cannon where iron cannonballs would otherwise stick in the barrel. It is still widely used today for springs, bearings, bushings, automobile transmission pilot bearings, and similar fittings, and is particularly common in the bearings of small electric motors. Phosphor bronze is particularly suited to precision-grade bearings and springs. It is also used in guitar and piano strings.
Unlike steel, bronze struck against a hard surface will not generate sparks, so it (along with beryllium copper) is used to make hammers, mallets, wrenches and other durable tools to be used in explosive atmospheres or in the presence of flammable vapors.
Bronze is used to make bronze wool for woodworking applications where steel wool would discolor oak.
Bronze statues.
In India, bronze sculptures from the Kushana (Chausa hoard) and Gupta periods (Brahma from Mirpur-Khas, Akota Hoard, Sultanganj Buddha) and later periods (Hansi Hoard) have been found.
Indian Hindu artisans from the period of the Chola empire in Tamil Nadu used bronze to create intricate statues via the lost wax casting method with ornate detailing depicting the deities of Hinduism mostly, but also the lifestyle of the period. The art form survives to this day, with many silpis, craftsmen, working in the areas of Swamimalai and Chennai.
The Assyrian king Sennacherib (704–681 BC) claims to have been the first to cast monumental bronze statues (of up to 30 tonnes) using two-part moulds instead of the lost-wax method.
In antiquity other cultures also produced works of high art using bronze. For example: in Africa, the bronze heads of the Kingdom of Benin; in Europe, Grecian bronzes typically of figures from Greek mythology; in east Asia, Chinese bronzes of the Shang and Zhou dynasty—more often ceremonial vessels but including some figurine examples. Bronze sculptures, although known for their longevity, still undergo microbial degradation; such as from certain species of yeasts.
Bronze continues into modern times as one of the materials of choice for monumental statuary.
Musical instruments.
Bronze is the preferred metal for top-quality bells, particularly bell metal, which is about 23% tin.
Nearly all professional cymbals are made from bronze, which gives a desirable balance of durability and timbre. Several types of bronze are used, commonly B20 bronze, which is roughly 20% tin, 80% copper, with traces of silver, or the tougher B8 bronze which is made from 8% tin and 92% copper. As the tin content in a bell or cymbal rises, the timbre drops.
Bronze is also used for the windings of steel and nylon strings of various stringed instruments such as the double bass, piano, harpsichord, and the guitar. Bronze strings are commonly reserved on pianoforte for the lower pitch tones, as they possess a superior sustain quality to that of high-tensile steel.
Bronzes of various metallurgical properties are widely used in struck idiophones around the world, notably bells, singing bowls, gongs, cymbals and other idiophones from Asia. Examples include Tibetan singing bowls, temple bells of many sizes and shapes, gongs, Javanese gamelan and other bronze musical instruments. The earliest bronze archeological finds in Indonesia date from 1–2 BCE, including flat plates probably suspended and struck by a wooden or bone mallet. Ancient bronze drums from Thailand and Vietnam date back 2,000 years. Bronze bells from Thailand and Cambodia date back to 3,600 BCE.
Some companies are now making saxophones from phosphor bronze (3.5 to 10% tin and up to 1% phosphorus content). Bell bronze is used to make the tone rings of many professional model banjos. The tone ring is a heavy (usually 3 lbs.) folded or arched metal ring attached to a thick wood rim, over which a skin, or most often, a plastic membrane (or head) is stretched - it is the bell bronze that gives the banjo a crisp powerful lower register and clear, bell-like treble register-especially in bluegrass music.
Medals.
Bronze has been used in the manufacture of various types of medals for centuries, and are known in contemporary times for being awarded for third place in sporting competitions and other events. The later usage was in part attributed to the choices of gold, silver and bronze to represent the first three Ages of Man in Greek mythology: the Golden Age, when men lived among the gods; the Silver age, where youth lasted a hundred years; and the Bronze Age, the era of heroes, and was first adopted at the 1904 Summer Olympics. At the 1896 event, silver was awarded to winners and bronze to runners-up, while at 1900 other prizes were given, not medals.
Industrial.
Various kinds of bronze are used in many different industrial applications.
Phosphor bronze is used for ships' propellers, musical instruments, and electrical contacts.
Bearings are often made of bronze for its friction properties. It can be filled with oil to make the proprietary Oilite and similar material for bearings.
Aluminium bronze is very hard and is used for bearings and machine tool ways.

</doc>
<doc id="4170" url="http://en.wikipedia.org/wiki?curid=4170" title="Benelux">
Benelux

Benelux (sometimes also written as "Bénélux" in French) is a union of states comprising three neighbouring countries in midwestern Europe: Belgium, the Netherlands and Luxembourg. The union's name is formed from joining the first syllable of each country's nameBelgium Netherlands Luxembourgand was first used to name the customs agreement that initiated the union (signed in 1944). It is now used in a more general way to refer to the geographic, economic and cultural grouping of the three countries.
In 1951, these countries joined West Germany, France, and Italy to form the European Coal and Steel Community, the predecessor of the European Economic Community (EEC) and today's European Union (EU).
The main institutions of the Union are the Committee of Ministers, the Parliament, the Council of the Union and the Secretariat-General, while the Benelux Organization for Intellectual Property and the Benelux Court of Justice are cover the same territory but are not part of the Economic Union.
The Benelux Secretary-General is located in Brussels. It is the central administrative pillar of the Benelux Economic Union. It handles the secretariat of the Committee of Ministers, the Council of Economic Union and the various committees and working parties. Moreover, it ensures the registry of the Benelux Court of Justice.
Politics.
A Benelux Parliament (originally referred to as an "Interparliamentary Consultative Council") was created in 1955. This parliamentary assembly is composed of 21 members of the Dutch parliament, 21 members of the Belgian national and regional parliaments, and 7 members of the Luxembourgish parliament.
In 1944, the three countries signed the London Customs Convention, the treaty that established the Benelux Customs Union. Ratified in 1947, the treaty was in force from 1948 until being supplanted by the Benelux Economic Union. The treaty establishing the Benelux Economic Union ("Benelux Economische Unie/Union Économique Benelux") was signed on 3 February 1958 in The Hague and came into force on 1 November 1960 to promote the free movement of workers, capital, services, and goods in the region. Under the Treaty the Union implies the co-operation of economic, financial and social policies.
Law.
The Benelux Economic Union involves an intergovernmental cooperation. Decisions are taken unanimously.
The unification of the law of the three Benelux countries is mainly achieved by regulations of its Committee of Ministers, that only bind the three states, but are not directly applicable in their internal legal orders. They only become legally valid after having been incorporated into national law.
The Treaty establishing the Benelux Economic Union has provided the Committee of Ministers with the following legal instruments: decisions, conventions, recommendations and directives.
The Committee of Ministers can promulgate decisions in the fields for which it has competence - those fields are explicitly set down in the Union Treaty or the additional conventions. When the Committee of Ministers adopts a decision, it immediately becomes binding on the three governments. For a decision to be also applicable to the citizen, it must be transposed into national law.
The Union Treaty is not exhaustive. For this reason, Article 19 of the Treaty provides that the Committee of Ministers may conclude additional conventions. These therefore constitute extensions of the Union Treaty. They are submitted to the national parliaments for approval in keeping with the ratification procedure applied in each of the Member States. Thus, there is a large number of Benelux conventions in a wide range of subject matters.
Approval of a recommendation by the Committee of Ministers is not legally binding, but rather a moral stance by the three governments. Recommendations are not devoid of any binding effect in that their approval implies an undertaking in view of their execution.
The Committee of Ministers can issue directives to the Council of Economic Union, the Committees, the General Secretariat and the joint services.
In 1965, the treaty establishing a Benelux Court of Justice was signed. It entered into force in 1975. The Court, composed of judges from the highest courts of the three States, has to guarantee the uniform interpretation of common legal rules. This international judicial institution is located in Brussels.
The Benelux is particularly active in the field of intellectual property. The three countries established a "Benelux Trademarks Office" and a "Benelux Designs Office", both situated in The Hague. In 2005, they concluded a treaty establishing a "Benelux Organization for Intellectual Property" which replaced both offices upon its entry into force on 1 September 2006. This Organization is the official body for the registration of trademarks and designs in the Benelux. In addition, it offers the possibility to formally record the existence of ideas, concepts, designs, prototypes and the like.
Demographics and geography.
The Benelux region has a total population of about 28,365,937 and occupies an area of approximately . Thus, the Benelux has a population density of 380/km² (983/sq mi).
Sports.
In 2000, Belgium and the Netherlands jointly hosted the UEFA European Championship. In June 2007, representatives of the three countries announced they would bid, as a single political entity, for the 2018 FIFA World Cup.
Renewal of the agreement.
The Treaty between the Benelux countries establishing the Benelux Economic Union was limited to a period of 50 years. During the following years, and even more so after the creation of the European Union, the Benelux cooperation focused on developing other fields of activity within a constantly changing international context.
At the end of the 50 years, the governments of the three Benelux countries decided to renew the agreement, taking into account the new aspects of the Benelux-cooperation – such as security – and the new federal government structure of Belgium. The original establishing treaty, set to expire in 2010, was replaced by a new legal framework (called the Treaty revising the Treaty establishing the Benelux Economic Union), which was signed on 17 June 2008.
The new treaty has no set time limit and the name of the "Benelux Economic Union" changed to "Benelux Union" to reflect the broad scope on the union. The main objectives of the treaty are the continuation and enlargement of the cooperation between the three member states within a larger European context. The renewed treaty explicitly foresees the possibility that the Benelux countries will cooperate with other European member States or with regional cooperation structures. The new Benelux cooperation focuses on three main topics: internal market and economic union, sustainability, justice and internal affairs. The number of structures in the renewed Treaty has been reduced and thus simplified. Five Benelux institutions remain: the Benelux Committee of Ministers, the Benelux Council, the Benelux Parliament, the Benelux Court of Justice, the Benelux Secretariat General. Beside these five institutions, the Benelux Organization for Intellectual Property is also present in this Treaty.

</doc>
<doc id="4171" url="http://en.wikipedia.org/wiki?curid=4171" title="Boston Herald">
Boston Herald

The Boston Herald is a daily newspaper whose primary market is Boston, Massachusetts, United States, and its surrounding area. It was started in 1846 and is one of the oldest daily newspapers in the United States. It has been awarded eight Pulitzer Prizes in its history, including four for editorial writing and three for photography before it was converted to tabloid format in 1981. The Herald was named one of the "10 Newspapers That 'Do It Right'" in 2012 by "Editor & Publisher".
History.
The "Herald"'s history can be traced back through two lineages, the "Daily Advertiser" and the old "Boston Herald", and two media moguls, William Randolph Hearst and Rupert Murdoch.
The Original "Boston Herald".
The original "Boston Herald" was founded in 1846 by a group of Boston printers jointly under the name of John A. French & Company. The paper was published as a single two-sided sheet, selling for one cent. Its first editor, William O. Eaton, just 22 years old, said "The "Herald" will be independent in politics and religion; liberal, industrious, enterprising, critically concerned with literacy and dramatic matters, and diligent in its mission to report and analyze the news, local and global."
In 1847 the "Boston Herald" absorbed the Boston "American Eagle" and the Boston "Daily Times".
"The Boston Herald and Boston Journal".
In October 1917, John H. Higgins, the publisher and treasurer of the Boston Herald bought out its next door neighbor "The Boston Journal" and created "The Boston Herald and Boston Journal"
"The American Traveler".
Even earlier than the "Herald", the weekly "American Traveler" was founded in 1825 as a bulletin for stagecoach listings.
The "Boston Evening Traveller".
The "Boston Evening Traveler" was founded in 1845. The " Boston Evening Traveler" was the successor to the weekly "American Traveler" and the semi-weekly "Boston Traveler". In 1912, the "Herald" acquired the "Traveler", continuing to publish both under their own names. For many years, the newspaper was controlled by many of the investors in United Shoe Machinery Co. After a newspaper strike in 1967, Herald-Traveler Corp. suspended the afternoon "Traveler" and absorbed the evening edition into the Herald to create the "Boston Herald Traveler."
"The Boston Daily Advertiser".
The "Boston Daily Advertiser" was established in 1813 in Boston by Nathan Hale. The paper grew to prominence throughout the 19th century, taking over other Boston area papers. In 1832 The Advertiser took over control of "The Boston Patriot", and then in 1840 it took over and absorbed "The Boston Gazette". The paper was purchased by William Randolph Hearst in 1917. In 1920 the "Advertiser" was merged with "The Boston Record", initially the combined newspaper was called the "Boston Advertiser" however when the combined newspaper became an illustrated tabloid in 1921 it was renamed "The Boston American". Hearst Corp. continued using the name "Advertiser" for its Sunday paper until the early 1970s.
"The Boston Record".
On September 3, 1884 "The Boston Evening Record" was started by the "Boston Advertiser" as a campaign newspaper. The "Record" was so popular that it was made a permanent publication.
"The Boston American".
In 1904, William Randolph Hearst began publishing his own newspaper in Boston called "The American". Hearst ultimately ended up purchasing the "Daily Advertiser" in 1917. By 1938, the "Daily Advertiser" had changed to the "Daily Record", and "The American" had become the "Sunday Advertiser". A third paper owned by Hearst, called the "Afternoon Record", which had been renamed the "Evening American", merged in 1961 with the "Daily Record" to form the "Record American". The "Sunday Advertiser" and "Record American" would ultimately be merged in 1972 into "The Boston Herald Traveler" a line of newspapers that stretched back to the old "Boston Herald".
"The Boston Herald Traveler".
In 1946, Herald-Traveler Corporation acquired Boston radio station WHDH. Two years later, WHDH-FM was licensed, and on November 26, 1957, WHDH-TV made its début as an ABC affiliate on channel 5. In 1961, WHDH-TV's affiliation switched to CBS. Herald-Traveler Corp. operated for years under temporary authority from the Federal Communications Commission stemming from controversy over luncheon meetings the newspaper's chief executive had with an FCC commissioner during the original licensing process (Some Boston broadcast historians accuse the "Boston Globe" of being covertly behind the proceeding. The "Herald Traveler" was Republican in sympathies, and the "Globe" then had a firm policy of not endorsing political candidates.) The FCC ordered comparative hearings, and in 1969 a competing applicant, Boston Broadcasters, Inc. was granted a construction permit to replace WHDH-TV on channel 5. Herald-Traveler Corp. fought the decision in court—by this time, revenues from channel 5 were all but keeping the newspaper afloat—but its final appeal ran out in 1972, and on March 19 WHDH-TV was forced to surrender channel 5 to the new WCVB-TV.
"The Boston Herald Traveler and Record American".
Without a television station to subsidize the newspaper, the "Herald Traveler" was no longer able to remain in business, and the newspaper was sold to Hearst Corporation, which published the rival all-day newspaper, the "Record American". The two papers were merged to become an all-day paper called the "Boston Herald Traveler and Record American" in the morning and "Record-American and Boston Herald Traveler" in the afternoon. The first editions published under the new combined name were those of June 19, 1972. The afternoon edition was soon dropped and the unwieldy name shortened to "Boston Herald American", with the Sunday edition called the "Sunday Herald Advertiser". The "Herald American" was printed in broadsheet format, and failed to target a particular readership; where the "Record American" had been a typical city tabloid, the "Herald Traveler" was a Republican paper.
Murdoch purchases "The Herald American".
The "Herald American" converted to tabloid format in September 1981, but Hearst faced steep declines in circulation and advertising. The company announced it would close the "Herald American"—making Boston a one-newspaper town—on December 3, 1982. When the deadline came, Australian media baron Rupert Murdoch was negotiating to buy the paper and save it. He closed on the deal after 30 hours of talks with Hearst and newspaper unions—and five hours after Hearst had sent out notices to newsroom employees telling them they were terminated. The newspaper announced its own survival the next day with a full-page headline: "You Bet We're Alive!"
The "Boston Herald" once again.
Murdoch changed the paper's name back to the "Boston Herald". The "Herald" continued to grow, expanding its coverage and increasing its circulation until 2001, when nearly all newspapers fell victim to declining circulations and revenue.
Independent ownership.
In February 1994, Murdoch's News Corporation was forced to sell the paper, in order that its subsidiary Fox Television Stations could legally consummate its purchase of Fox affiliate WFXT (Channel 25) because Massachusetts Senator Ted Kennedy included language in an appropriations barring one company from owning a newspaper and television station in the same market. Patrick J. Purcell, who was the publisher of the "Boston Herald" and a former News Corporation executive, purchased the "Herald" and established it as an independent newspaper. Several years later, Purcell would give the "Herald" a suburban presence it never had by purchasing the money-losing Community Newspaper Company from Fidelity Investments. Although the companies merged under the banner of Herald Media, Inc., the suburban papers maintained their distinct editorial and marketing identity.
After years of operating profits at Community Newspaper and losses at the "Herald", Purcell in 2006 sold the suburban chain to newspaper conglomerate Liberty Group Publishing of Illinois, which soon after changed its name to GateHouse Media. The deal, which also saw GateHouse acquiring "The Patriot Ledger" and "The Enterprise" in south suburban Quincy and Brockton, netted $225 million for Purcell, who vowed to use the funds to clear the "Herald"'s debt and reinvest in the Paper.
Awards.
The "Herald"'s four Pulitzer Prizes for editorial writing, in 1924, 1927, 1949 and 1954, are among the most awarded to a single newspaper in the category. In 1957 Harry Trask was a young staff photographer at the "Traveler" when he was awarded a Pulitzer Prize for his photo sequence of the sinking of in July 1956. "Herald" photographer Stanley Forman received two Pulitzer Prizes consecutively in 1976 and 1977, the first for "Fire Escape Collapse", a dramatic shot of a young child falling in mid-air from her mother's arms on the upper stories of a burning apartment building to the waiting arms of firefighters below. The 1977 Pulitzer was awarded for "The Soiling of Old Glory", as Ted Landsmark, an African American civil rights lawyer, was charged at by a protester with an American flag during the Boston busing crisis. 
In 2006 the "Herald" won two SABEW awards from the Society of American Business Editors and Writers: one for its breaking news coverage of the takeover of the Boston-based Gillette Company by Procter & Gamble, and another for "overall excellence."
"Boston Herald" in Education Program.
The Boston Herald Newspapers in Education (NIE) program provides teachers with classroom newspapers and educational materials designed to help students of all ages and abilities excel. This is made possible through donations from Herald readers and other sponsors. The Boston Herald is available in two formats: the print edition and the online Smart Edition. The website can be found at http://bostonheraldnie.com/
Prices.
The "Boston Herald" prices are: $1.00 daily, $2.00 Sunday.

</doc>
<doc id="4173" url="http://en.wikipedia.org/wiki?curid=4173" title="Babe Ruth">
Babe Ruth

George Herman "Babe" Ruth, Jr. (February 6, 1895 – August 16, 1948), was an American baseball outfielder and pitcher who played 22 seasons in Major League Baseball (MLB) from 1914 to 1935. Nicknamed "the Bambino" and "the Sultan of Swat", he began his career as a stellar left-handed pitcher for the Boston Red Sox, but achieved his greatest fame as a slugging outfielder for the New York Yankees. Ruth established many MLB batting (and some pitching) records, including career home runs (714), slugging percentage (.690), runs batted in (RBIs) (2,213), bases on balls (2,062), and on-base plus slugging (OPS) (1.164), some of which have been broken. He was one of the first five inductees into the National Baseball Hall of Fame in 1936.
At age seven, Ruth was sent to St. Mary's Industrial School for Boys, a reformatory where he learned life lessons and baseball skills from Brother Matthias Boutlier, the school's disciplinarian and a capable baseball player. In 1914, Ruth was signed to play minor-league baseball for the Baltimore Orioles. Soon sold to the Red Sox, by 1916 he had built a reputation as an outstanding pitcher who sometimes hit long home runs, a feat unusual for any player in the pre-1920 dead-ball era. Although Ruth twice won 20 games as a pitcher and was a member of three World Series championship teams with Boston, he wanted to play every day and was allowed to convert to an outfielder. He responded by breaking the MLB single-season home run record in 1919.
After that season, Red Sox owner Harry Frazee controversially sold Ruth to the Yankees. In his 15 years with New York, Ruth helped the Yankees win seven league championships and four World Series championships. His big swing led to escalating home run totals that not only drew fans to the ballpark and boosted the sport's popularity but also helped usher in the live-ball era of baseball, in which it evolved from a low-scoring game of strategy to a sport where the home run was a major factor. As part of the Yankees' vaunted "Murderer's Row" lineup of 1927, Ruth hit 60 home runs, extending his MLB single-season record. He retired in 1935 after a short stint with the Boston Braves. During his career, Ruth led the league in home runs during a season twelve times.
Ruth's legendary power and charismatic personality made him a larger-than-life figure in the "Roaring Twenties". During his career, he was the target of intense press and public attention for his baseball exploits and off-field penchants for drinking and womanizing. His often reckless lifestyle was tempered by his willingness to do good by visiting children at hospitals and orphanages. He was denied a job in baseball for most of his retirement, most likely due to poor behavior during parts of his playing career. In his final years, Ruth made many public appearances, especially in support of American efforts in World War II. In 1946, he became ill with cancer, and died two years later. Ruth is regarded as one of the greatest sports heroes in American culture, and is considered by many to be the greatest baseball player of all time.
Early years.
George Herman Ruth, Jr., was born at 216 Emory Street in Pigtown, a rough neighborhood of Baltimore, Maryland. Ruth's parents, George Herman Ruth, Sr., and Katherine Schamberger, were both German-American. George Ruth, Sr., had a series of jobs, including lightning rod salesman and streetcar operator,
before becoming a counterman in a family-owned combination grocery and saloon on Frederick Street. George Jr. was born in the house of his maternal grandfather, Pius Schamberger, a German immigrant and trade unionist. Only one of young George's seven siblings, his sister Mamie, survived infancy.
Many aspects of Ruth's childhood are undetermined, including even the date of his parents' marriage. The family moved to 339 South Goodyear Street, not far from the rail yards, when young George was a toddler; by the time he was six, his father had a saloon with an upstairs apartment at 426 West Camden Street. Details about why he was sent, at the age of seven, to St. Mary's Industrial School for Boys, a reformatory and orphanage, are similarly scanty. Babe Ruth, as an adult, suggested that not only was he running the streets and rarely attending school, he was drinking beer when his father was not looking. Stories exist that after a violent incident at the saloon, the city authorities decided the environment was unsuitable for a small child. At St. Mary's, which he entered on June 13, 1902, he was recorded as "incorrigible"; he spent much of the next twelve years there.
Although St. Mary's inmates received an education, a substantial amount of time was devoted to work, particularly once the boys turned 12. Ruth became a shirtmaker, and was also proficient as a carpenter. He would adjust his own shirt collars, rather than having a tailor do it, even during his well-paid baseball career. The boys, aged 5 to 21, did most work around the facility, from cooking to shoemaking, and renovated St. Mary's in 1912. The food was simple, and the Xaverian Brothers who ran the school insisted on strict discipline; corporal punishment was omnipresent. Ruth's nickname there was "Niggerlips", as he had large facial features and was darker than most boys at the all-white reformatory.
Ruth was sometimes allowed to rejoin his family, or was placed at St. James's Home, a supervised residence with work in the community, but he was always returned to St. Mary's. He rarely was visited by his family; his mother died when he was 12 and by some accounts, he was permitted to leave St. Mary's only to attend the funeral. How Ruth came to play baseball there is uncertain: according to one account, his placement at St. Mary's was due in part to repeatedly breaking Baltimore's windows with long hits while playing street ball; by another, he was told to join a team on his first day at St. Mary's by the school's athletic director, Brother Herman, becoming a catcher even though left-handers rarely play that position. During his time there he also played third base and shortstop, again unusual for a left-hander, and was forced to wear mitts and gloves made for right-handers. He was encouraged in his pursuits by the school's Prefect of Discipline, Brother Matthias Boutlier, a native of Nova Scotia. A large man, Brother Matthias was greatly respected by the boys both for his strength and for his fairness. For the rest of his life, Ruth would praise Brother Matthias, and his running and hitting styles closely resembled his teacher's. Ruth stated, "I think I was born as a hitter the first day I ever saw him hit a baseball." The older man became a mentor and role model to George; biographer Robert W. Creamer commented on the closeness between the two:
The school's influence remained with Ruth in other ways: a lifelong Catholic, he would sometimes attend Mass after carousing all night, and he became a well-known member of the Knights of Columbus. He would visit orphanages, schools, and hospitals throughout his life, often avoiding publicity. He was generous to St. Mary's as he became famous and rich, donating money and his presence at fundraisers, and spending $5,000 to buy Brother Matthias a Cadillac in 1926—subsequently replacing it when it was destroyed in an accident. Nevertheless, his biographer Leigh Montville suggests that many of the off-the-field excesses of Ruth's career were driven by the deprivations of his time at St. Mary's.
Most of the boys at St. Mary's played baseball, with organized leagues at different levels of proficiency. Ruth later estimated that he played 200 games a year as he steadily climbed the ladder of success. Although he played all positions at one time or another (including infield positions generally reserved for right-handers), he gained stardom as a pitcher. According to Brother Matthias, Ruth was standing to one side laughing at the bumbling pitching efforts of fellow students, and Matthias told him to go in and see if he could do better. After becoming the best pitcher at St. Mary's, in 1913, when Ruth was 18, he was allowed to leave the premises to play weekend games on teams drawn from the community. He was mentioned in several newspaper articles, for both his pitching prowess and ability to hit long home runs.
Baltimore Orioles.
In early 1914, Ruth was signed to a professional baseball contract by Jack Dunn, owner and manager of the minor-league Baltimore Orioles, an International League team. The circumstances of Ruth's signing cannot be stated with certainty, with historical fact obscured by stories that cannot all be true. By some accounts, Dunn was urged to attend a game between an all-star team from St. Mary's and one from another Xaverian facility, Mount St. Mary's College. Some versions have Ruth running away before the eagerly awaited game, to return in time to be punished, and then pitching St. Mary's to victory as Dunn watched. Others have Washington Senators pitcher Joe Engel, a Mount St. Mary's graduate, pitching in an alumni game after watching a preliminary contest between the college's freshmen and a team from St. Mary's, including Ruth. Engel watched Ruth play, then told Dunn about him at a chance meeting in Washington. Ruth, in his autobiography, stated that he worked out for Dunn for a half hour, and was signed. According to biographer Kal Wagenheim, there were legal difficulties to be straightened out as Ruth was supposed to remain at the school until he turned 21. Ruth was to receive a salary of $250 per month.
The train journey to spring training in Fayetteville, North Carolina, in early March was likely Ruth's first outside the Baltimore area. The rookie ballplayer was the subject of various pranks by the veterans, who were probably also the source of his famous nickname. There are various accounts of how Ruth came to be called Babe, but most center on his being referred to as "Dunnie's babe" or a variant. "Babe" was at that time a common nickname in baseball, with perhaps the most famous to that point being Pittsburgh Pirates pitcher and 1909 World Series hero Babe Adams, who appeared younger than he was.
Babe Ruth's first appearance as a professional ballplayer was in an intersquad game on March 7, 1914. Ruth played shortstop, and pitched the last two innings of a 15–9 victory. In his second at bat, Ruth hit a long home run to right, which was reported locally to be longer than a legendary shot hit in Fayetteville by Jim Thorpe. His first appearance against a team in organized baseball was an exhibition against the major-league Philadelphia Phillies: Ruth pitched the middle three innings, giving up two runs in the fourth, but then settling down and pitching a scoreless fifth and sixth. The following afternoon, Ruth was put in during the sixth inning against the Phillies and did not allow a run the rest of the way. The Orioles scored seven runs in the bottom of the eighth to overcome a 6–0 deficit, making Ruth the winning pitcher.
Once the regular season began, Ruth was a star pitcher who was also dangerous at the plate. The team performed well, yet received almost no attention from the Baltimore press. A third major league, the Federal League, had begun play, and the local franchise, the Baltimore Terrapins, restored that city to the major leagues for the first time since 1902. Few fans visited Oriole Park, where Ruth and his teammates labored in relative obscurity. Ruth may have been offered a bonus and a larger salary to jump to the Terrapins; when rumors to that effect swept Baltimore, giving Ruth the most publicity he had experienced to date, a Terrapins official denied it, stating it was their policy not to sign players under contract to Dunn.
The competition from the Terrapins caused Dunn to sustain large losses. Although by late June the Orioles were in first place, having won over two-thirds of their games, the paid attendance dropped as low as 150. Dunn explored a possible move by the Orioles to Richmond, Virginia, as well as the sale of a minority interest in the club. These possibilities fell through, leaving Dunn with little choice other than to sell his best players to major league teams to raise money. He offered Ruth to the reigning World Series champions, Connie Mack's Philadelphia Athletics, but Mack had his own financial problems. The Cincinnati Reds and New York Giants expressed interest in Ruth, but Dunn sold his contract, along with those of pitchers Ernie Shore and Ben Egan, to the Boston Red Sox of the American League (AL) on July 4. The sale price was announced as $25,000 but other reports lower the amount to half that, or possibly $8,500 plus the cancellation of a $3,000 loan. Ruth remained with the Orioles for several days while the Red Sox completed a road trip, and reported to the team in Boston on July 11.
Major League career.
Boston Red Sox (1914–19).
Developing star.
Ruth arrived in Boston on July 11, 1914, along with Egan and Shore. Ruth later told of meeting the woman he would first marry, Helen Woodford, that morning—she was then a 16-year-old waitress at Landers Coffee Shop, and Ruth related that she served him when he had breakfast there. Other stories, though, suggest the meeting happened on another day, and perhaps under other circumstances. Regardless of when he began to woo his first wife, he won his first game for the Red Sox that afternoon, 4–3, over the Cleveland Naps. He pitched to catcher Bill Carrigan, who was also the Red Sox manager. Shore was given a start by Carrigan the next day; he won that and his second start and thereafter was pitched regularly. Ruth lost his second start, and was thereafter little used. As a batter, in his major-league debut, Ruth went 0-for-2 against left-hander Willie Mitchell, striking out in his first at bat, before being removed for a pinch hitter in the seventh inning. Ruth was not much noticed by the fans, as Bostonians watched the Red Sox's crosstown rivals, the Braves, begin a legendary comeback that would take them from last place on the Fourth of July to the 1914 World Series championship.
Egan was traded to Cleveland after two weeks on the Boston roster. During his time as a Red Sox, he kept an eye on the inexperienced Ruth, much as Dunn had in Baltimore. When he was traded, no one took his place as supervisor. Ruth's new teammates considered him brash, and would have preferred him, as a rookie, to remain quiet and inconspicuous. When Ruth insisted on taking batting practice despite his being both a rookie who did not play regularly, and a pitcher, he arrived to find his bats sawn in half. His teammates nicknamed him "the Big Baboon", a name the swarthy Ruth, who had disliked the nickname "Niggerlips" at St. Mary's, detested. Ruth had received a raise on promotion to the major leagues, and quickly acquired tastes for fine food, liquor, and women, among other temptations.
Manager Carrigan allowed Ruth to pitch two exhibition games in mid-August. Although Ruth won both against minor-league competition, he was not restored to the pitching rotation. It is uncertain why Carrigan did not give Ruth additional opportunities to pitch. There are legends—filmed for the screen in "The Babe Ruth Story" (1948)—that the young pitcher had a habit of signaling his intent to throw a curveball by sticking out his tongue slightly, and that he was easy to hit until this changed. Creamer pointed out that it is common for inexperienced pitchers to display such habits, and the need to break Ruth of his would not constitute a reason to not use him at all. The biographer suggested that Carrigan was unwilling to use Ruth due to poor behavior by the rookie.
On July 30, 1914, Boston owner Joseph Lannin had purchased the minor-league Providence Grays, members of the International League. The Providence team had been owned by several people associated with the Detroit Tigers, including star hitter Ty Cobb, and as part of the transaction, a Providence pitcher was sent to the Tigers. To soothe Providence fans upset at losing a star, Lannin announced that the Red Sox would soon send a replacement to the Grays. This was intended to be Ruth, but his departure for Providence was delayed when Cincinnati Reds owner Garry Herrmann claimed him off waivers. After Lannin wrote to Herrmann explaining that the Red Sox wanted Ruth in Providence so he could develop as a player, and would not release him to a major league club, Herrmann allowed Ruth to be sent to the minors. Carrigan later stated that Ruth was not sent down to Providence to make him a better player, but to help the Grays win the International League pennant (league championship).
Ruth joined the Grays on August 18, 1914. What was left of the Baltimore Orioles after Dunn's deals had managed to hold on to first place until August 15, after which they continued to fade, leaving the pennant race between Providence and Rochester. Ruth was deeply impressed by Providence manager "Wild Bill" Donovan, previously a star pitcher with a 25–4 win–loss record for Detroit in 1907; in later years, he credited Donovan with teaching him much about pitching. Ruth was called upon often to pitch, in one stretch starting (and winning) four games in eight days. On September 5 in Toronto, Ruth pitched a one-hit 9–0 victory, and hit his first professional home run, his only one as a minor leaguer, off Ellis Johnson. Recalled to Boston after Providence finished the season in first place, he pitched and won a game for the Red Sox against the New York Yankees on October 2, getting his first major league hit, a double. Ruth finished the season with a record of 2–1 as a major leaguer and 23–8 in the International League (for Baltimore and Providence). Once the season concluded, Ruth married Helen in Ellicott City, Maryland. Creamer speculated that they did not marry in Baltimore, where the newlyweds boarded with George Ruth, Sr., to avoid possible interference from those at St. Mary's—both bride and groom were not yet of age and Ruth remained on parole from that institution until his 21st birthday.
Ruth reported to his first major league spring training in Hot Springs, Arkansas, in March 1915. Despite a relatively successful first season, he was not slated to start regularly for the Red Sox, who had two stellar left-handed pitchers already: the established stars Dutch Leonard, who had broken the record for the lowest earned run average (ERA) in a single season; and Ray Collins, a 20-game winner in both 1913 and 1914. Ruth was ineffective in his first start, taking the loss in the third game of the season. Injuries and ineffective pitching by other Boston pitchers gave Ruth another chance, and after some good relief appearances, Carrigan allowed Ruth another start, and he won a rain-shortened seven inning game. Ten days later, the manager had him start against the New York Yankees at the Polo Grounds. Ruth took a 3–2 lead into the ninth, but lost the game 4–3 in 13 innings. Ruth, hitting ninth as was customary for pitchers, hit a massive home run into the upper deck in right field off of Jack Warhop. At the time, home runs were rare in baseball, and Ruth's majestic shot awed the crowd. The winning pitcher, Warhop, would in August 1915 conclude a major league career of eight seasons, undistinguished but for being the first major league pitcher to give up a home run to Babe Ruth.
Carrigan was sufficiently impressed by Ruth's pitching to give him a spot in the starting rotation. Ruth finished the 1915 season 18–8 as a pitcher; as a hitter, he batted .315 and had four home runs. The Red Sox won the AL pennant, but with the pitching staff healthy, Ruth was not called upon to pitch in the 1915 World Series against the Philadelphia Phillies. Boston won in five games; Ruth was used as a pinch hitter in Game Five, but grounded out against Phillies ace Grover Cleveland Alexander. Despite his success as a pitcher, Ruth was acquiring a reputation for long home runs; at Sportsman's Park against the St. Louis Browns, a Ruth hit soared over Grand Avenue, breaking the window of a Chevrolet dealership.
In 1916, there was attention focused on Ruth for his pitching, as he engaged in repeated pitching duels with the ace of the Washington Senators, Walter Johnson. The two met five times during the season, with Ruth winning four and Johnson one (Ruth had a no decision in Johnson's victory). Two of Ruth's victories were by the score of 1–0, one in a 13-inning game. Of the 1–0 shutout decided without extra innings, AL President Ban Johnson stated, "That was one of the best ball games I have ever seen." For the season, Ruth went 23–12, with a 1.75 ERA and nine shutouts, both of which led the league. Ruth's nine shutouts in 1916 set a league record for left-handers that would remain unmatched until Ron Guidry tied it in 1978. The Red Sox won the pennant and World Series again, this time defeating the Brooklyn Superbas (as the Dodgers were then known) in five games. Ruth started and won Game 2, 2–1, in 14 innings. Until another game of that length was played in 2005, this was the longest World Series game, and Ruth's pitching performance is still the longest postseason complete game victory.
Carrigan retired as player and manager after 1916, returning to his native Maine to be a businessman. Ruth, who played under four managers who are in the National Baseball Hall of Fame, always maintained that Carrigan, who is not enshrined there, was the best skipper he ever played for. There were other changes in the Red Sox organization that offseason, as Lannin sold the team to a three-man group headed by New York theatrical promoter Harry Frazee. Jack Barry was hired by Frazee as manager.
Emergence as a hitter.
Ruth went 24–13 with a 2.01 ERA and six shutouts in 1917, but the Sox finished in second place in the league, nine games behind the Chicago White Sox in the standings. On June 23 at Washington, Ruth made a memorable pitching start. When the home plate umpire called the first four pitches as balls, Ruth threw a punch at him, and was ejected from the game and later suspended for ten days. Ernie Shore was called in to relieve Ruth, and was allowed eight warm-up pitches. The runner who had reached base on the walk was caught stealing, and Shore retired all 26 batters he faced to win the game. Shore's feat was listed as a perfect game for many years; in 1991, Major League Baseball's (MLB) Committee on Statistical Accuracy caused it to be listed as a combined no-hitter. In 1917, Ruth was used little as a batter, other than his plate appearances while pitching, and hit .325 with two home runs.
The entry of the United States into World War I occurred at the start of the season, and overshadowed the sport. Conscription was introduced in September 1917, and most baseball players in the big leagues were of draft age. This included Barry, who was a player-manager, and who joined the Naval Reserve in an attempt to avoid the draft, only to be called up after the 1917 season. Frazee hired International League President Ed Barrow as Red Sox manager. Barrow had spent the previous 30 years in a variety of baseball jobs, though he never played the game professionally. With the major leagues shorthanded due to the war, Barrow had many holes in the Red Sox lineup to fill. Ruth also noticed these vacancies in the lineup, and, dissatisfied in the role of a pitcher who appeared every four or five days, wanted to play every day at another position. Barrow tried Ruth at first base and in the outfield during the exhibition season, but as the team moved towards Boston and the season opener, restricted him to pitching. At the time, Ruth was possibly the best left-handed pitcher in baseball; allowing him to play another position was an experiment that could have backfired.
Inexperienced as a manager, Barrow had player Harry Hooper advise him on baseball game strategy. Hooper urged his manager to allow Ruth to play another position when he was not pitching, arguing to Barrow, who had invested in the club, that the crowds were larger on days when Ruth played, attracted by his hitting. Barrow gave in early in May; Ruth promptly hit home runs in four consecutive games (one an exhibition), the last off of Walter Johnson. For the first time in his career (disregarding pinch-hitting appearances), Ruth was allowed a place in the batting order higher than ninth.
Although Barrow predicted that Ruth would beg to return to pitching the first time he experienced a batting slump, that did not occur. Barrow used Ruth primarily as an outfielder in the war-shortened 1918 season. Ruth hit .300, with 11 home runs, enough to secure him a share of the major league home run title with Tillie Walker of the Philadelphia Athletics. He was still occasionally used as a pitcher, and had a 13–7 record with a 2.22 ERA.
The Red Sox won their third pennant in four years, and faced the Chicago Cubs in the 1918 World Series, beginning on September 5, the earliest in history. The season was shortened as the government had ruled that baseball players eligible for the military would have to be inducted or work in critical war industries, such as armaments plants. Ruth pitched Game One for the Red Sox, a 1–0 shutout. Before Game Four, Ruth injured his left hand in a fight; he pitched anyway. He gave up seven hits and six walks, but was helped by outstanding fielding behind him and by his own batting efforts, as a fourth-inning triple by Ruth gave his team a 2–0 lead. The Cubs tied the game in the eighth inning, but the Red Sox scored to take a 3–2 again in the bottom of that inning. After Ruth gave up a hit and a walk to start the ninth inning, he was relieved on the mound by Joe Bush. To keep Ruth and his bat in the game, he was sent to play left field. Bush retired the side to give Ruth his second win of the Series, and the third and last World Series pitching victory of his career, against no defeats, in three pitching appearances. Ruth's effort gave his team a three-games-to-one lead, and two days later the Red Sox won their third Series in four years, four games to two. Before allowing the Cubs to score in Game Four, Ruth pitched consecutive scoreless innings, a record for the World Series that stood until broken, after Ruth's death, by Whitey Ford in 1961. Ruth was prouder of that record than he was of any of his batting feats.
With the World Series over, Ruth made himself exempt from conscription by accepting a nominal position with a Pennsylvania steel mill. Many industrial establishments took pride in their baseball teams and sought to engage major leaguers. The end of the war in November set Ruth free to play baseball without such contrivances.
During the 1919 season, Ruth pitched in only 17 of his 130 games, compiling an 8–5 record as Barrow used him as a pitcher mostly in the early part of the season, when the Red Sox manager still had hopes of a second consecutive pennant. By late June, the Red Sox were clearly out of the race, and Barrow had no objection to Ruth concentrating on his hitting, if only because it drew people to the ballpark. Ruth had hit a home run against the Yankees on Opening Day, and another during a month-long batting slump that soon followed. Relieved of his pitching duties, Ruth began an unprecedented spell of slugging home runs, which gave him widespread public and press attention. Even his failures were seen as majestic—one sportswriter noted, "When Ruth misses a swipe at the ball, the stands quiver".
Two home runs by Ruth on July 5, and one in each of two consecutive games a week later, raised his season total to 11, tying his career best from 1918. The first record to fall was the AL single-season mark of 16, set by Ralph "Socks" Seybold in 1902. Ruth matched that on July 29, then pulled ahead toward the major league record of 24, set by Buck Freeman in 1899. Ruth reached this on September 8, by which time, writers had discovered that Ned Williamson of the 1884 Chicago White Stockings had hit 27—though in a ballpark where the distance to right field was only . On September 20, "Babe Ruth Day" at Fenway Park, Ruth won the game with a home run in the bottom of the ninth inning, tying Williamson. He broke the record four days later against the Yankees at the Polo Grounds, and hit one more against the Senators to finish with 29. The home run at Washington made Ruth the first major league player to hit a home run at all eight ballparks in his league. In spite of Ruth's hitting heroics, the Red Sox finished sixth, games behind the league champion White Sox.
Sale to New York.
As an out-of-towner from New York City, Frazee had been regarded with suspicion by Boston's sportswriters and baseball fans when he bought the team. He won them over with success on the field and a willingness to build the Red Sox by purchasing or trading for players. He offered the Senators $60,000 for Walter Johnson, but Washington owner Clark Griffith was unwilling. Even so, Frazee was successful in bringing other players to Boston, especially as replacements for players in the military. This willingness to spend for players helped the Red Sox secure the 1918 title. The 1919 baseball saw record-breaking attendance, and Ruth's home runs for Boston made him a national sensation. Nevertheless, on December 26, 1919, Frazee sold Ruth's contract to the New York Yankees.
Not all of the circumstances of how it was Frazee sold Ruth to the Yankees are known, but the most common version involves brewer and former congressman Jacob Ruppert, the New York team's principal owner, asking Yankee manager Miller Huggins what the team needed to be successful. "Get Ruth from Boston", Huggins supposedly stated, noting that Frazee was perennially in need of money to finance his theatrical productions. The transaction was not without precedent in the Frazee era in Boston: when Boston pitcher Carl Mays left the Red Sox in a 1919 dispute, the matter was settled by selling the player to the Yankees, though over the opposition of AL President Johnson.
According to one of Ruth's biographers, Jim Reisler, "just why Frazee needed cash in 1919—and large infusions of it quickly—is still, more than 80 years later, a bit of a mystery". The often-told story is that Frazee needed money to finance the musical "No, No, Nanette", which was a major hit and brought Frazee financial security. That play did not open until 1925, by which time Frazee had sold the Red Sox. Montville points out that the story may be true in essence: "No, No, Nanette" was based on a Frazee-produced play, "My Lady Friends", which opened in 1919.
There were other financial pressures on Frazee, despite his team's success. Ruth, fully aware of baseball's popularity and his role in it, wanted to renegotiate his contract, signed before the 1919 season for $10,000 per year through 1921. He demanded that his salary be doubled, or he would sit out the season and cash in on his popularity through other ventures. Ruth's salary demands were causing other players to ask for more money. Additionally, Frazee still owed Lannin as much as $125,000 from the purchase of the club.
Although Ruppert and his co-owner, Colonel Tillinghast Huston, were both wealthy, and had aggressively purchased and traded for players in 1918 and 1919 to build a winning team, Ruppert faced losses in his brewing interests as Prohibition was implemented, and if their team left the Polo Grounds, where the Yankees were the tenants of the New York Giants, building a stadium in New York would be expensive. Nevertheless, when Frazee, who moved in the same social circles as Huston, hinted to the colonel that Ruth was available for the right price, the Yankees owners quickly pursued the purchase.
Frazee sold the rights to Babe Ruth for $100,000, the largest sum ever paid for a baseball player. The deal also involved a $350,000 loan from Ruppert to Frazee, secured by a mortgage on Fenway Park. Once it was agreed, Frazee informed Barrow, who, stunned, told the owner that he was getting the worse end of the bargain. Cynics have suggested that Barrow may have played a larger role in the Ruth sale, as less than a year after, he became the Yankee general manager, and in the following years made a number of purchases of Red Sox players from Frazee. The $100,000 price included $25,000 in cash, and notes for the same amount due November 1 in 1920, 1921 and 1922; Ruppert and Huston assisted Frazee in selling the notes to banks for immediate cash.
The transaction was contingent on Ruth signing a new contract, which was quickly accomplished—Ruth agreed to fulfill the remaining two years on his contract, but was given a $20,000 bonus, payable over two seasons. The deal was announced on January 6, 1920. Reaction in Boston was mixed: some fans were embittered at the loss of Ruth; others conceded that the slugger had become difficult to deal with. "The New York Times" suggested presciently, "The short right field wall at the Polo Grounds should prove an easy target for Ruth next season and, playing seventy-seven games at home, it would not be surprising if Ruth surpassed his home run record of twenty-nine circuit clouts next Summer." According to Reisler, "The Yankees had pulled off the sports steal of the century."
According to Marty Appel in his history of the Yankees, the transaction, "changed the fortunes of two high-profile franchises for decades". The Red Sox, winners of five of the first sixteen World Series, those played between 1903 and 1919, would not win another pennant until 1946, or another World Series until 2004, a drought attributed in baseball superstition to Frazee's sale of Ruth and sometimes dubbed the "Curse of the Bambino". The Yankees, on the other hand, had not won the AL championship prior to their acquisition of Ruth. They won seven AL pennants and four World Series with Ruth, and lead baseball with 40 pennants and 27 World Series titles in their history.
New York Yankees (1920–34).
Initial success (1920–23).
As a Yankee, Ruth's transition from a pitcher to a power-hitting outfielder became complete. In his fifteen-year Yankee career, consisting of over 2,000 games, Ruth broke many batting records, while making only five widely scattered appearances on the mound, winning all of them.
At the end of April 1920, the Yankees were 4–7, with the Red Sox leading the league with a 10–2 mark. Ruth had done little, having injured himself swinging the bat. Both situations began to change on May 1, when Ruth hit a ball completely out of the Polo Grounds, a feat believed only to have been previously accomplished by Joe Jackson. The Yankees won, 6–0, taking three out of four from the Red Sox. Ruth hit his second home run on May 2, and by the end of the month had set a major league record for home runs in a month with 11, and promptly broke it with 13 in June. Fans responded with record attendance: on May 16, Ruth and the Yankees drew 38,600 to the Polo Grounds, a record for the ballpark, and 15,000 fans were turned away. Large crowds jammed stadiums to see Ruth play when the Yankees were on the road.
The home runs kept coming; Ruth tied his own record of 29 on July 15, and broke it with home runs in both games of a doubleheader four days later. By the end of July, he had 37, but his pace slackened somewhat after that. Nevertheless, on September 4, he both tied and broke the organized baseball record for home runs in a season, snapping Perry Werden's 1895 mark of 44 in the minor Western League. The Yankees played well as a team, battling for the league lead early in the summer, but slumped in August in the AL pennant battle with Chicago and Cleveland. The championship was won by Cleveland, surging ahead after the Black Sox Scandal broke on September 28 and led to the suspension of many of the team's top players, including Joe Jackson. The Yankees finished third, but drew 1.2 million fans to the Polo Grounds, the first time a team had drawn a seven figure attendance. The rest of the league sold 600,000 more tickets, many fans there to see Ruth, who led the league with 54 home runs, 158 runs, and 137 runs batted in (RBIs).
Ruth was aided in his exploits, in 1920 and afterwards, by the fact that the A.J. Reach Company, maker of baseballs used in the major leagues, was using a more efficient machine to wind the yarn found within the baseball. When these went into play in 1920, the start of the live-ball era, the number of home runs increased by 184 over the previous year across the major leagues. Baseball statistician Bill James points out that while Ruth was likely aided by the change in the baseball, there were other factors at work, including the gradual abolition of the spitball (accelerated after the death of Ray Chapman, struck by a pitched ball thrown by Mays in August 1920) and the more frequent use of new baseballs (also a response to Chapman's death). Nevertheless, James theorizes that Ruth's 1920 explosion might have happened in 1919, had a full season of 154 games been played rather than 140, had Ruth refrained from pitching 133 innings that season, and if he were playing with any other home field but Fenway Park, where he hit only 9 of 29 home runs.
Yankees business manager Harry Sparrow had died early in the 1920 season; to replace him, Ruppert and Huston hired Barrow. Ruppert and Barrow quickly made a deal with Frazee for New York to acquire some of the players who would be mainstays of the early Yankee pennant-winning teams, including catcher Wally Schang and pitcher Waite Hoyt. The 21-year old Hoyt became close to Ruth:
Ruth hit home runs early and often in the 1921 season, during which he broke Roger Connor's mark for home runs in a career, 138. Each of the almost 600 home runs Ruth hit in his career after that extended his own record. After a slow start, the Yankees were soon locked in a tight pennant race with Cleveland, winners of the 1920 World Series. On September 15, Ruth hit his 55th home run, shattering his year-old single season record. In late September, the Yankees visited Cleveland and won three out of four games, giving them the upper hand in the race, and clinched their first pennant a few days later. Ruth finished the regular season with 59 home runs, batting .378 and with a slugging percentage of .846.
The Yankees had high expectations when they met the New York Giants in the 1921 World Series, and the Yankees won the first two games with Ruth in the lineup. However, Ruth badly scraped his elbow during Game 2, sliding into third base (he had walked and stolen both second and third bases). After the game, he was told by the team physician not to play the rest of the series. Despite this advice, he did play in the next three games, and pinch-hit in Game Eight of the best-of-nine series, but the Yankees lost, five games to three. Ruth hit .316, drove in five runs and hit his first World Series home run.
After the Series, Ruth and teammates Bob Meusel and Bill Piercy participated in a barnstorming tour in the Northeast. A rule then in force prohibited World Series participants from playing in exhibition games during the offseason, the purpose being to prevent Series participants from replicating the Series and undermining its value. Baseball Commissioner Kenesaw Mountain Landis suspended the trio until May 20, 1922, and fined them their 1921 World Series checks. In August 1922, the rule was changed to allow limited barnstorming for World Series participants, with Landis's permission required.
On March 6, 1922, Ruth signed a new contract, for three years at $52,000 a year. The largest sum ever paid a ballplayer to that point, it represented 40% of the team's player payroll. Despite his suspension, Ruth was named the Yankees' new on-field captain prior to the 1922 season. During the suspension, he worked out with the team in the morning, and played exhibition games with the Yankees on their off days. He and Meusel returned on May 20, to a sellout crowd at the Polo Grounds, but Ruth batted 0-for-4, and was booed. On May 25, he was thrown out of the game for throwing dust in umpire George Hildebrand's face, then climbed into the stands to confront a heckler. Ban Johnson ordered him fined, suspended, and stripped of his captaincy. In his shortened season, Ruth appeared in 110 games, batted .315, with 35 home runs, and drove in 99 runs, but compared to his previous two dominating years, the 1922 season was a disappointment. Despite Ruth's off-year, Yankees managed to win the pennant to face the New York Giants for the second straight year in the World Series. In the Series, Giants manager John McGraw instructed his pitchers to throw him nothing but curveballs, and Ruth never adjusted. Ruth had just two hits in seventeen at bats, and the Yankees lost to the Giants for the second straight year, by 4–0 (with one tie game). Sportswriter Joe Vila called him, "an exploded phenomenon".
After the season, Ruth was a guest at an Elks Club banquet, set up by Ruth's agent with Yankee team support. There, each speaker, concluding with future New York mayor Jimmy Walker, censured him for his poor behavior. An emotional Ruth promised reform, and, to the surprise of many, followed through. When he reported to spring training, he was in his best shape as a Yankee, weighing only .
The Yankees's status as tenants of the Giants at the Polo Grounds had become increasingly uneasy, and in 1922 Giants owner Charles Stoneham stated that the Yankees's lease, expiring after that season, would not be renewed. Ruppert and Huston had long contemplated a new stadium, and had taken an option on property at 161st Street and River Avenue in the Bronx. Yankee Stadium was completed in time for the home opener on April 18, 1923, at which the Babe hit the first home run in what was quickly dubbed "the House that Ruth Built". The ballpark was designed with Ruth in mind: although the venue's left-field fence was further from home plate than at the Polo Grounds, Yankee Stadium's right-field fence was closer, making home runs easier to hit for left-handed batters. To spare Ruth's eyes, right field–his defensive position–was not pointed into the afternoon sun, as was traditional; left fielder Meusel was soon suffering headaches from squinting toward home plate.
The Yankees were never challenged, leading the league for most of the 1923 season and winning the AL pennant by 17 games. Ruth finished the season with a career-high .393 batting average and major-league leading 41 home runs (tied with Cy Williams). Another career high for Ruth in 1923 was his 45 doubles, and he reached base 379 times, then a major league record. For the third straight year, the Yankees faced the Giants in the World Series, which Ruth dominated. He batted .368, walked eight times, scored eight runs, hit three home runs and slugged 1.000 during the series, as the Yankees won their first World Series championship, four games to two.
Batting title and "bellyache" (1924–25).
In 1924, the Yankees were favored to become the first team to win four consecutive pennants. Plagued by injuries, they found themselves in a battle with the Senators. Although the Yankees won 18 of 22 at one point in September, the Senators beat out the Yankees by two games. Ruth hit .378, winning his only AL batting title, with a league-leading 46 home runs.
Ruth had kept up his efforts to stay in shape in 1923 and 1924, but by early 1925 weighed nearly . His annual visit to Hot Springs, Arkansas, early in the year, where he exercised and took saunas, did him no good as he spent much of the time carousing. He became ill while there, and suffered relapses during spring training. Ruth collapsed in Asheville, North Carolina, as the team journeyed north. He was put on a train for New York, where he was briefly hospitalized. A rumor circulated that he had died, prompting British newspapers to print a premature obituary. In New York, Ruth collapsed again and was found unconscious in his hotel bathroom. He was taken to a hospital where he suffered multiple convulsions. After sportswriter W. O. McGeehan wrote that Ruth's illness was due to binging on hot dogs and soda pop before a game, it became known as "the bellyache heard 'round the world". However, the exact cause of his ailment has never been confirmed and remains a mystery. Glenn Stout, in his history of the Yankees, notes that the Ruth legend is "still one of the most sheltered in sports"; he suggests that alcohol was at the root of Ruth's illness, pointing to the fact that Ruth remained six weeks at St. Vincent's Hospital but was allowed to leave, under supervision, for workouts with the team for part of that time. He concludes that the hospitalization was behavior-related. Playing just 98 games, Ruth had his worst season as a Yankee; he finished with a .290 average and 25 home runs. The Yankees finished next to last in the AL with a 69–85 record, their last season with a losing record until 1965.
Murderer's Row (1926–28).
Ruth spent part of the offseason of 1925–26 working out at Artie McGovern's gym, getting back into shape. Barrow and Huggins had rebuilt the team, surrounding the veteran core with good young players like Tony Lazzeri and Lou Gehrig. Nevertheless, New York was not expected to win the pennant.
Babe Ruth returned to his normal production during 1926, batting .372 with 47 home runs and 146 RBIs. The Yankees built a ten-game lead by mid-June, and coasted to win the pennant by three games. The St. Louis Cardinals had won the National League with the lowest winning percentage for a pennant winner to that point (.578) and the Yankees were expected to win the World Series easily. Although the Yankees won the opener in New York, St. Louis took Games Two and Three. In Game Four, Ruth hit three home runs, the first time this had been done in a World Series game, to lead the Yankees to victory; in the fifth game Ruth caught a ball as he crashed into the fence, described by baseball writers as a defensive gem. New York took that game, but Grover Cleveland Alexander won Game Six for St. Louis to tie the Series at three games each, then got very drunk. He was nevertheless inserted into Game Seven in the seventh inning and shut down the Yankees to win the game, 3–2, and win the Series. Ruth had hit his fourth home run of the Series earlier in the game, and was the only Yankee to reach base off Alexander, walking in the ninth inning before being caught stealing to end the game. Although Ruth's attempt to steal second is often deemed a baserunning blunder, Creamer pointed out that the Yankees's chances of tying the game would have been greatly improved with a runner in scoring position.
The 1926 Series was also known for Ruth's promise to Johnny Sylvester, a hospitalized 11-year-old, that he would hit a home run on his behalf. Sylvester had been injured in a fall from a horse, and a friend of Sylvester's father gave the boy two autographed baseballs signed by Yankees and Cardinals, and relayed a promise from Ruth, who did not know the boy, to hit a home run for him. After the Series, Ruth visited the boy in the hospital. When the matter became public, the press greatly inflated it, and by some accounts, Ruth saved a dying boy's life by visiting him, emotionally promising to hit a home run, and doing so.
The 1927 New York Yankees team is considered one of the greatest squads that ever took the field. Known as Murderer's Row because of the power of its lineup, the team won a then-AL-record 110 games, and took the AL pennant by 19 games, clinching first place on Labor Day. With little suspense as to the pennant race, the nation's attention turned to Ruth's pursuit of his own single-season home run record of 59. He was not alone in this chase: Gehrig proved to be a slugger capable of challenging Ruth for his home run crown, tying Ruth with 24 home runs late in June. Through July and August, they were never separated by more than two home runs. Gehrig took the lead, 45–44, in the first game of a doubleheader at Fenway Park early in September; Ruth responded with two of his own to take the lead, as it proved permanently—Gehrig finished with 47. Even so, as of September 6, Ruth was still several games off his 1921 pace, and going into the final series against the Senators, had only 57. He hit two in the first game of the series, including one off of Paul Hopkins, facing his first major league batter, to tie the record. The following day, September 30, he broke it with his 60th homer, in the eighth inning off Tom Zachary to break a 2–2 tie. "Sixty! Let's see some son of a bitch try to top that one", Ruth exulted after the game. In addition to his career-high 60 home runs, Ruth batted .356, drove in 164 runs and slugged .772. In the 1927 World Series, the Yankees swept the Pittsburgh Pirates in four games; the National Leaguers were disheartened after watching the Yankees take batting practice before Game One, with ball after ball leaving Forbes Field. According to Appel, "The 1927 New York Yankees. Even today, the words inspire awe ... all baseball success is measured against the '27 team."
Before the 1928 season, Ruth signed a new contract for an unprecedented $80,000 per year. The season started off well for the Yankees, who led the league in the early going. But the Yankees were plagued by injuries, erratic pitching and inconsistent play. The Philadelphia Athletics, rebuilding after some lean years, erased the Yankees' big lead and even took over first place briefly in early September. The Yankees, however, regained first place when they beat the Athletics three out of four games in a pivotal series at Yankee Stadium later that month, and clinched the pennant in the final weekend of the season. Ruth's play in 1928 mirrored his team's performance. He got off to a hot start and on August 1, he had 42 home runs. This put him ahead of his 60 home run pace from the previous season. He then slumped for the latter part of the season, and he hit just twelve home runs in the last two months. Ruth's batting average also fell to .323, well below his career average. Nevertheless, he ended the season with 54 home runs. The Yankees swept the favored Cardinals in four games in the World Series, with Ruth batting .625 and hitting three home runs in Game Four, including one off Alexander.
"Called shot" and final Yankee years (1929–34).
Before the 1929 season, Ruppert, who had bought out Huston in 1923, announced that the Yankees would wear uniform numbers to allow fans at cavernous Yankee Stadium to tell one player from another. The Cardinals and Indians had each experimented with uniform numbers; the Yankees were the first to use them on both home and away uniforms. As Ruth batted third, he was given number 3. Ruth himself affected the Yankee uniform in one particular: to make him look slimmer, Ruppert added the iconic pinstripes.
Although the Yankees started well, the Athletics soon proved they were the better team in 1929, splitting two series with the Yankees in the first month of the season, then taking advantage of a Yankee losing streak in mid-May to gain first place. Although Ruth performed well, the Yankees were not able to catch the Athletics—Connie Mack had built another great team. Tragedy struck the Yankees late in the year as manager Huggins died of erysipelas, a bacterial skin infection, on September 25, only ten days after he had last led the team. Despite past differences, Ruth praised Huggins and described him as a "great guy". The Yankees finished second, 18 games behind the Athletics. Ruth hit .345 during the season, with 46 home runs and 154 RBIs.
The Yankees hired Bob Shawkey as manager, their fourth choice. Ruth politicked for the job of player-manager, but was not seriously considered by Ruppert and Barrow; Stout deems this the first hint Ruth would have no future with the Yankees once he was done as a player. Shawkey, a former Yankees player and teammate of Ruth, was unable to command the slugger's respect. The Athletics won their second consecutive pennant and World Series, as the Yankees finished in third place, sixteen games back. During that season Ruth was asked by a reporter what he thought of his yearly salary of $80,000 being more than President Hoover's $75,000. His response was, "I know, but I had a better year than Hoover." In 1930, Ruth hit .359 with 49 home runs (his best in his years after 1928) and 153 RBIs, and pitched his first game in nine years, a complete game victory. At the end of the season, Shawkey was fired and replaced with Cubs manager Joe McCarthy, though Ruth again unsuccessfully sought the job.
McCarthy was a disciplinarian, but chose not to interfere with Ruth, and the slugger for his part did not seek conflict with the manager. The team improved in 1931, but was no match for the Athletics, who won 107 games, games in front of the Yankees. Ruth, for his part, hit .373, with 46 home runs and 163 RBIs. He had 31 doubles, his most since 1924. In the 1932 season, the Yankees went 107–47 and won the pennant. Ruth's effectiveness had decreased somewhat, but he still hit .341 with 41 home runs and 137 RBIs. Nevertheless, he twice was sidelined due to injury during the season.
The Yankees faced the Cubs, McCarthy's former team, in the 1932 World Series. There was bad blood between the two teams as the Yankees resented the Cubs only awarding half a World Series share to Mark Koenig, a former Yankee. The games at Yankee Stadium had not been sellouts; both were won by the home team, with Ruth collecting two singles, but scoring four runs as he was walked four times by the Cubs pitchers. In Chicago, Ruth was resentful at the hostile crowds that met the Yankees's train and jeered them at the hotel. The crowd for Game Three included New York Governor Franklin D. Roosevelt, the Democratic candidate for president, who sat with Chicago Mayor Anton Cermak. Many in the crowd threw lemons at Ruth, a sign of derision, and others (as well as the Cubs themselves) shouted abuse at Ruth and other Yankees. They were briefly silenced when Ruth hit a three-run home run off Charlie Root in the first inning, but soon revived, and the Cubs tied the score at 4–4 in the fourth inning. When Ruth came to the plate in the top of the fifth, the Chicago crowd and players, led by pitcher Guy Bush, were screaming insults at Ruth. With the count at two balls and one strike, Ruth gestured, possibly in the direction of center field, and after the next pitch (a strike), may have pointed there with one hand. Ruth hit the fifth pitch over the center field fence; estimates were that it traveled nearly . Whether or not Ruth intended to indicate where he planned to (and did) hit the ball, the incident has gone down in legend as Babe Ruth's called shot. The Yankees won Game Three, and the following day clinched the Series with another victory. During that game, Bush hit Ruth on the arm with a pitch, causing words to be exchanged and provoking a game-winning Yankee rally.
Ruth remained productive in 1933, as he batted .301, with 34 home runs, 103 RBIs, and a league-leading 114 walks, as the Yankees finished second, seven games behind the Senators. He was selected to play right field by Athletics manager Connie Mack in the first Major League Baseball All-Star Game, held on July 6, 1933, at Comiskey Park in Chicago. He hit the first home run in the All-Star Game's history, a two-run blast against Bill Hallahan during the third inning, which helped the AL win the game 4–2. During the final game of the 1933 season, as a publicity stunt organized by his team, Ruth was called upon and pitched a complete game victory against the Red Sox, his final appearance as a pitcher. Despite unremarkable pitching numbers, Ruth had a 5–0 record in five games for the Yankees, raising his career totals to 94–46.
In 1934, Ruth played in his last full season. He accepted a pay cut from Ruppert to $35,000, but was still the highest-paid player in the major leagues. He could still handle a bat, recording a .288 batting average with 22 home runs, statistics Reisler described as "merely mortal". Ruth was selected to the AL All-Star team for the second consecutive year. During the game, New York Giants pitcher Carl Hubbell struck out Ruth and four other future Hall-of-Famers consecutively. The Yankees finished second again, seven games behind the Tigers.
Boston Braves (1935).
Although Ruth knew he was nearly finished as a player, he desired to remain in baseball as a manager. He was often spoken of as a possible candidate as managerial jobs opened up, but in 1932, when he was mentioned as a contender for the Red Sox position, stated that he was not yet ready to leave the field. There were rumors that Ruth was a likely candidate each time when the Cleveland Indians, Cincinnati Reds and Detroit Tigers were looking for a manager, but nothing came of them.
Just before the 1934 season, Ruppert offered to make Ruth manager of the Yankees' top minor-league team, the Newark Bears, but he was talked out of it by his wife, Claire (Helen had died in 1929), and his business manager. Early in the 1934 season, Ruth began openly campaigning to become manager of the Yankees. However, the Yankee job was never a serious possibility. Ruppert always supported McCarthy, who would remain in his position for another 12 seasons. Ruth and McCarthy had never gotten along, and Ruth's managerial ambitions further chilled their relations. By the end of the season, Ruth hinted that he would retire unless Ruppert named him manager of the Yankees. For his part, Ruppert wanted his slugger to leave the team without drama and hard feelings when the time came.
During the 1934–35 offseason, Ruth circled the world with his wife, including a barnstorming tour of the Far East. At his final stop before returning home, in the United Kingdom, Ruth was introduced to cricket by Australian player Alan Fairfax, and after having little luck in a cricketer's stance, stood as a baseball batter and launched some massive shots around the field, destroying the bat in the process. Although Fairfax regretted that he could not have the time to make Ruth a cricket player, Ruth had lost any interest in such a career upon learning that the best batsmen made only about $40 per week.
Also during the offseason, Ruppert had been sounding out the other clubs in hopes of finding one that would be willing to take Ruth as a manager and/or a player. However, the only teams that seriously considered hiring Ruth were the Tigers and Athletics. Connie Mack gave some thought to stepping down as manager in favor of Ruth, but later dropped the idea, saying that Ruth's wife would be running the team in a month if Ruth ever took over.
While the barnstorming tour was under way, Ruppert began negotiating with Boston Braves owner Judge Emil Fuchs, who wanted Ruth as a gate attraction. Although the Braves had enjoyed modest recent success, finishing fourth in the National League in both 1933 and 1934, the team performed poorly at the box office. Unable to afford the rent at Braves Field, Fuchs had considered holding dog races there when the Braves were not at home, only to be turned down by Landis. After a series of phone calls, letters, and meetings, the Yankees traded Ruth to the Braves on February 26, 1935. Ruppert had stated that he would not release Ruth to go to another team as a full-time player. For this reason, it was announced that Ruth would become a team vice president and would be consulted on all club transactions, in addition to playing. He was also made assistant manager to Braves skipper Bill McKechnie. In a long letter to Ruth a few days before the press conference, Fuchs promised Ruth a share in the Braves' profits, with the possibility of becoming co-owner of the team. Fuchs also raised the possibility of Ruth succeeding McKechnie as manager, perhaps as early as 1936. Ruppert called the deal "the greatest opportunity Ruth ever had".
There was considerable attention as Ruth reported for spring training. He did not hit his first home run of the spring until after the team had left Florida, and was beginning the road north in Savannah. He hit two in an exhibition against the Bears. Amid much press attention, Ruth played his first home game in Boston in over 16 years. Before an opening-day crowd of over 25,000, including five of New England's six state governors, Ruth accounted for all of the Braves' runs in a 4–2 defeat of the New York Giants, hitting a two-run home run, singling to drive in a third run and later in the inning scoring the fourth. Although age and weight had slowed him, he made a running catch in left field which sportswriters deemed the defensive highlight of the game.
Although Ruth had two hits in the second game of the season, it soon settled down to a routine of Ruth performing poorly when he played at all, and the Braves losing most games. As the spring progressed, Ruth's deterioration became even more pronounced. He remained productive at the plate early on, but could do little else. His condition had deteriorated to the point that he could barely trot around the bases. His fielding had become so poor that three Braves pitchers threatened not to take the mound if he was in the lineup. Before long, Ruth stopped hitting as well. He grew increasingly annoyed that McKechnie ignored most of his advice. (McKechnie later said that Ruth's presence made enforcing discipline nearly impossible.)
Ruth soon realized that Fuchs had deceived him, and had no intention of giving him off-the-field responsibility or the manager's job. He later stated that his duties as vice president consisted of making public appearances and autographing tickets. Ruth also found out that far from giving him a share of the profits, Fuchs wanted him to invest some of his money in the team in a last-ditch effort to improve its balance sheet. As it turned out, both Fuchs and Ruppert had known all along that Ruth's non-playing positions were meaningless.
By the end of the first month of the season, Ruth believed he was finished even as a part-time player. As early as May 12, he asked Fuchs to let him retire. Ultimately, Fuchs persuaded Ruth to remain at least until after the Memorial Day doubleheader in Philadelphia. In the interim was a western road trip, at which the rival teams had scheduled days to honor him. In Chicago and St. Louis, Ruth performed poorly, and his batting average sank to .155, with only three home runs. In the first two games in Pittsburgh, Ruth had only one hit, though a long fly caught by Paul Waner probably would have been a home run in any other ballpark besides Forbes Field.
Ruth played in the third game of the Pittsburgh series on May 25, 1935, and added one more tale to his playing legend. Ruth went 4-for-4, including three home runs, though the Braves lost the game 11–7. The last two were off Ruth's old Cubs nemesis, Guy Bush. The final home run, both of the game and of Ruth's career, sailed over the upper deck in right field and out of the ballpark, the first time anyone had hit a fair ball completely out of Forbes Field. Ruth was urged to make this his last game, but he had given his word to Fuchs and played in Cincinnati and Philadelphia. The first game of the doubleheader in Philadelphia—the Braves lost both—was his final major league appearance. On June 2, after an argument with Fuchs, Ruth retired. He finished 1935 with a .181 average—easily his worst as a full-time position player—and the final six of his 714 home runs. The Braves, 10–27 when Ruth left, finished 38–115, at .248 the worst winning percentage in modern National League history. Fuchs gave up control of the Braves before the end of the season, insolvent like his team; the National League took over the franchise at the end of the year.
Retirement.
1935–46.
Although Fuchs had given Ruth his unconditional release, no major league team expressed an interest in hiring him in any capacity. Ruth still hoped to be hired as a manager if he could not play anymore, but only one managerial position, Cleveland, became available between Ruth's retirement and the end of the 1937 season. Asked if he had considered Ruth for the job, Indians owner Alva Bradley replied in the negative. Creamer believed Ruth was unfairly treated in never being given an opportunity to manage a major league club. The author felt there was not a relationship between personal conduct and managerial success, noting that McGraw, Billy Martin and Bobby Valentine were winners despite character flaws. Team owners and general managers saw Ruth's lifestyle was seen as a reason for denying him a managerial job; Barrow said of him, "How can he manage other men when he can't even manage himself?"
Ruth played much golf and in a few exhibition baseball games, demonstrating a continuing ability to draw large crowds. This was a major factor in his hiring as first base coach by the Dodgers, in 1938. Brooklyn general manager Larry MacPhail made it clear when Ruth was hired that he would not be considered for the manager's job if, as expected, Burleigh Grimes retired at the end of the season. Although much was said about what Ruth could teach the younger players, in practice, his duties were to appear on the field in uniform and encourage base runners—he was not called upon to relay signs. He got along well with everyone except team captain Leo Durocher, who was hired as Grimes' replacement at season's end. Ruth returned to retirement, never again to work in baseball.
On July 4, 1939, Ruth spoke on Lou Gehrig Day at Yankee Stadium as members of the 1927 Yankees and a sellout crowd turned out to honor the first baseman, forced into premature retirement by a disease which would kill him in two years. The next week, Ruth went to Cooperstown, New York, for the formal opening of the Baseball Hall of Fame—he had been one of the first five players elected three years previously. As radio broadcasts of baseball became popular, he sought a job in that field, arguing that his celebrity and knowledge of baseball would assure large audiences, but he was made no offers. During World War II, he made many personal appearances to advance the war effort, including his last appearance as a player at Yankee Stadium, in a 1943 exhibition for the Army–Navy Relief Fund. He hit a long fly ball off Walter Johnson; the blast left the field, curving foul, but Ruth circled the bases anyway. In 1946, he made a final effort at a job in baseball, contacting new Yankees boss MacPhail, but was sent a rejection letter.
Cancer and death (1946–48).
As early as the war years, doctors had cautioned Ruth to take better care of his health, and he grudgingly followed their advice, limiting his drinking and not going on a proposed trip to support the troops in the South Pacific. In 1946, Ruth began experiencing severe pain over his left eye, and had difficulty swallowing. In November 1946, he entered French Hospital in New York for tests, which revealed Ruth had an inoperable malignant tumor at the base of his skull and in his neck. His name and fame gave him access to experimental treatments, and he was one of the first cancer patients to receive both drugs and radiation treatment simultaneously. He was discharged from the hospital in February, having lost , and went to Florida to recuperate. He returned to New York and Yankee Stadium after the season started. The new commissioner, Happy Chandler (Judge Landis had died in 1944), proclaimed April 27, 1947, Babe Ruth Day around the major leagues, with the most significant observance to be in the Bronx. A number of teammates and others spoke in honor of Ruth, who briefly addressed the crowd of almost 60,000.
Around this time, developments in chemotherapy offered some hope, and Ruth, who had not been told he had cancer out of his family's fear he might do himself harm, was put on teropterin, a folic acid derivative—he may have been the first human subject. He showed dramatic improvement during the summer of 1947, so much so that his case was written up by his doctors, without using his name. He was able to travel around the country, doing promotional work for the Ford Motor Company on American Legion Baseball. He appeared again at another day in his honor at Yankee Stadium in September, but was not well enough to pitch in an old-timers game as he had hoped.
The improvement was only a temporary remission, and by late 1947, Ruth was unable to help with the writing of his autobiography, "The Babe Ruth Story", which was almost entirely ghostwritten. In and out of the hospital in New York, he left for Florida in February 1948, doing what activities he could, and returned to New York after six weeks to appear at a book-signing party. He also went to California to witness the filming of the book.
On June 5, 1948, a "gaunt and hollowed out" Ruth visited Yale University to donate a manuscript of "The Babe Ruth Story" to its library. On June 13, Ruth visited Yankee Stadium for the final time in his life, appearing at the 25th anniversary celebrations of "The House that Ruth Built". By this time he had lost much weight and had difficulty walking. Introduced along with his surviving teammates from 1923, Ruth used a bat as a cane. The photo of Ruth taken from behind, standing near home plate and facing "Ruthville" (right field) became one of baseball's most famous and widely circulated photographs, and won the Pulitzer Prize.
Ruth made one final trip on behalf of American Legion Baseball, then entered Memorial Sloan–Kettering Cancer Center, where he would die. He was never told he had cancer, but before his death, had surmised it. He was able to leave the hospital for a few short trips, including a final visit to Baltimore. On July 26, 1948, Ruth left the hospital to attend the premiere of the film "The Babe Ruth Story". Shortly thereafter, Ruth returned to the hospital for the final time. He was barely able to speak. Ruth's condition gradually became worse; only a few visitors were allowed to see him, one of whom was National League president and future Commissioner of Baseball Ford Frick. "Ruth was so thin it was unbelievable. He had been such a big man and his arms were just skinny little bones, and his face was so haggard", Frick said years later.
Thousands of New Yorkers, including many children, stood vigil outside the hospital in Ruth's final days. On August 16, 1948, at 8:01 p.m., Babe Ruth died in his sleep at the age of 53. Instead of a wake at a funeral home, his casket was taken to Yankee Stadium, where it remained for two days; 77,000 people filed past to pay him tribute. His funeral Mass took place at St. Patrick's Cathedral; a crowd estimated at 75,000 waited outside. Ruth rests with his second wife, Claire, on a hillside in Section 25 at the Gate of Heaven Cemetery in Hawthorne, New York.
Personal life.
Ruth met Helen Woodford, by some accounts, in a coffee shop in Boston where she was a waitress, and they were married on October 17, 1914. They adopted a daughter, Dorothy, in 1921. Ruth and Helen separated around 1925 reportedly due to his repeated infidelities. Their last public appearance together came during the 1926 World Series. Helen died in a fire in Watertown, Massachusetts, in 1929, in a house owned by Edward Kinder, a dentist with whom she had been living as "Mrs. Kinder". In her book, "My Dad, the Babe", Dorothy claimed that she was Ruth's biological child by a girlfriend named Juanita Jennings. She died in 1989.
On April 17, 1929, Ruth married actress and model Claire Merritt Hodgson (1897–1976) and adopted her daughter, Julia. By one account, Julia and Dorothy were, through no fault of their own, the reason for the seven-year rift in Ruth's relationship with teammate Lou Gehrig. Sometime in 1932 Gehrig's mother, during a conversation which she assumed was private, remarked, "It's a shame doesn't dress Dorothy as nicely as she dresses her own daughter." When the comment inevitably got back to Ruth, he angrily told Gehrig to tell his mother to mind her own business. Gehrig in turn took offense at what he perceived as Ruth's disrespectful treatment of his mother. The two men reportedly never spoke off the field until they reconciled at Yankee Stadium on Lou Gehrig Day in 1939.
Although he was married through most of his baseball career, Ruth stated when Colonel Huston asked him to tone down his lifestyle, "I'll promise to go easier on drinking and to get to bed earlier, but not for you, fifty thousand dollars, or two-hundred and fifty thousand dollars will I give up women. They're too much fun."
Memorial and museum.
On April 19, 1949, the Yankees unveiled a granite monument in Ruth's honor in center field of Yankee Stadium. The monument was located in the field of play next to a flagpole and similar tributes to Huggins and Gehrig until the stadium was remodeled from 1974–1975, which resulted in the outfield fences moving inward and enclosing the monuments from the playing field. This area was known thereafter as Monument Park. Yankee Stadium, "the House that Ruth Built", was replaced after the 2008 season with a new Yankee Stadium across the street from the old one; Monument Park was subsequently moved to the new venue behind the center field fence. Ruth's uniform number 3 has been retired by the Yankees, and he is one of five Yankees players or managers to have a granite monument within the stadium.
The Babe Ruth Birthplace Museum is located at 216 Emory Street, a Baltimore row house where Ruth was born, and three blocks west of Oriole Park at Camden Yards, where the AL's Baltimore Orioles play. The property was restored and opened to the public in 1973 by the non-profit Babe Ruth Birthplace Foundation, Inc. Ruth's widow, Claire, his two daughters, Dorothy and Julia, and his sister, Mamie, helped select and install exhibits for the museum.
Contemporary impact.
Ruth was the first baseball star to be the subject of overwhelming interest by the public. Baseball had seen star players before, such as Cobb and "Shoeless Joe" Jackson, but both men had uneasy relations with fans, in Cobb's case sometimes marked by violence. Ruth's biographers agree that he benefited from the timing of his ascension to "Home Run King", with an America hit hard by both the war and the 1918 flu pandemic longing for something to help put these traumas behind it. He also resonated in a country which felt, in the aftermath of the war, that it took second place to no one. Montville argues that as a larger-than-life figure capable of unprecedented athletic feats in what was the nation's largest city, Ruth became an icon of the significant social changes which marked the early 1920s. Glenn Stout notes in his history of the Yankees, "Ruth was New York incarnate—uncouth and raw, flamboyant and flashy, oversized, out of scale, and absolutely unstoppable".
Ruth became such a symbol of the United States during his lifetime that during World War II, Japanese soldiers yelled in English "To hell with Babe Ruth" to anger American soldiers. (Ruth replied that he hoped that "every Jap that mention my name gets shot"). Creamer recorded that "Babe Ruth transcended sport, moved far beyond the artificial limits of baselines and outfield fences and sports pages". Wagenheim stated, "He appealed to a deeply rooted American yearning for the definitive climax: clean, quick, unarguable." According to Glenn Stout, "Ruth's home runs were exalted, uplifting experience that meant more to fans than any runs they were responsible for. A Babe Ruth home run was an event unto itself, one that meant anything was possible."
Ruth's penchant for hitting home runs altered how baseball is played. Prior to 1920, home runs were unusual, and managers tried to win games by building a run by getting a runner on base, and bring him around to score through such means as the stolen base, the bunt, and the hit and run. Advocates of what was dubbed "inside baseball", such as Giants manager McGraw, disliked the home run, considering it a blot on the purity of the game. According to sportswriter W. A. Phelon after the 1920 season, Ruth's breakout performance that season and the response in excitement and attendance, "settled, for all time to come, that the American public is nuttier over the Home Run than the Clever Fielding or the Hitless Pitching. Viva el Home Run and two times viva Babe Ruth, exponent of the home run, and overshadowing star." Bill James notes, "When the owners discovered that the fans "liked" to see home runs, and when the foundations of the games were simultaneously imperiled by disgrace the Black Sox Scandal, then there was no turning back." While a few, such as McGraw and Cobb, decried the passing of the old-style play, teams quickly began to seek and develop sluggers.
According to contemporary sportswriter Grantland Rice, only two sports figures of the 1920s approached Ruth in popularity—boxer Jack Dempsey and racehorse Man o' War. One of the factors that caused Ruth to gain his broad appeal was the uncertainty that surrounds his early life and his family. It allowed Ruth to exemplify the American success story, that even an uneducated, unsophisticated youth, without any family wealth or connections, can do something better than anyone else in the world. Montville notes that "the fog his childhood will make him forever accessible, universal. He will be the patron saint of American possibility." Similarly, the fact that Ruth played when a relatively small portion of his fans had the opportunity to see him play in the era before television coverage of baseball allowed his legend to grow through word of mouth and the hyperbole of sports reporters. Reisler notes that recent sluggers who surpassed Ruth's 60 home run mark, such as Mark McGwire and Barry Bonds, generated much less excitement than when Ruth repeatedly broke the single-season home run record in the 1920s; Ruth dominated a relatively small sports world, while Americans of the present era have many sports to choose to watch.
Legacy.
Creamer termed Ruth "a unique figure in the social history of the United States". Ruth has even entered the language: a dominant figure in a field, whether within or outside sports, is often referred to as "the Babe Ruth" of that field. Similarly, "Ruthian" has come to mean in sports, "colossal, dramatic, prodigious, magnificent; with great power."
More books, Montville noted in 2006, have been written about Ruth than about any other member of the Baseball Hall of Fame. At least five of these books (including Creamer's and Wagenheim's) were written in 1973 and 1974, timed to capitalize on the increase in public interest in Ruth as Henry Aaron approached his career home run mark, which he broke on April 8, 1974. Aaron stated as he approached Ruth's record, "I can't remember a day this year or last when I did not hear the name of Babe Ruth."
Montville suggests that Ruth is probably even more popular today than he was when his career home run record was broken by Aaron. The longball era that Ruth started continues in baseball, to the delight of the fans. Owners build ballparks to encourage home runs, which are featured on "SportsCenter" and "Baseball Tonight" each evening during the season. The questions of performance enhancing drug use which have dogged recent home run hitters such as McGwire and Bonds do nothing to diminish Ruth's reputation; his overindulgences with beer and hot dogs seem part of a simpler time.
Ruth has been named the greatest baseball player of all time in various surveys and rankings. In 1998, "The Sporting News" ranked him number one on the list of "Baseball's 100 Greatest Players". In 1999, baseball fans named Ruth to the Major League Baseball All-Century Team. He was named baseball's Greatest Player Ever in a ballot commemorating the 100th anniversary of professional baseball, in 1969. The Associated Press reported in 1993 that Muhammad Ali was tied with Babe Ruth as the most recognized athletes in America. In a 1999 ESPN poll, he was ranked as the second-greatest U.S. athlete of the century, behind Michael Jordan. In 1983, the United States Postal Service honored Ruth with the issuance of a twenty-cent stamp.
One long-term survivor of the craze over Ruth may be the Baby Ruth candy bar. Although the original company to market the confectionery, the Curtis Candy Company, maintained that the bar was named after Ruth Cleveland, daughter of former president Grover Cleveland, Ruth Cleveland had died in 1904 and the bar was first marketed in 1921, at the height of the Ruth craze. The slugger later sought to market candy bearing his name; he was refused a patent because of the existence of the Baby Ruth bar. Corporate files from 1921 are no longer extant; the brand has changed hands several times and is now owned by the Nestlé company. Due to a marketing arrangement, in 2005, the Baby Ruth bar became the official candy bar of Major League Baseball.
Montville notes the continuing relevance of Babe Ruth in American culture, over three-quarters of a century after he last swung a bat in a major league game:

</doc>
<doc id="4177" url="http://en.wikipedia.org/wiki?curid=4177" title="Barge">
Barge

A barge is a flat-bottomed boat, built mainly for river and canal transport of heavy goods. Some barges are not self-propelled and need to be towed or pushed by towboats. Canal barges, towed by draft animals on an adjacent towpath, contended with the railway in the early industrial revolution, but were outcompeted in the carriage of high-value items due to the higher speed, falling costs, and route flexibility of rail.
Etymology.
"Barge" is attested from 1300, from Old French "barge", from Vulgar Latin "barga". The word originally could refer to any small boat; the modern meaning arose around 1480. "Bark" "small ship" is attested from 1420, from Old French "barque", from Vulgar Latin "barca" (400 AD). The more precise meaning "three-masted ship" arose in the 17th century, and often takes the French spelling for disambiguation. Both are probably derived from the Latin "barica", from Greek "baris" "Egyptian boat", from Coptic "bari" "small boat", hieroglyphic Egyptian D58-G29-M17-M17-D21-P1 and similar "ba-y-r" for "basket-shaped boat". By extension, the term "embark" literally means to board the kind of boat called a "barque".
The long pole used to maneuver or propel a barge have given rise to the saying "I wouldn't touch that [subject/thing] with a barge pole."
Types.
On the Great British canal system, the term 'barge' is used to describe a boat wider than a narrowboat, and the people who move barges are often known as lightermen. In the United States, deckhands perform the labor and are supervised by a leadman or the mate. The captain and pilot steer the towboat, which pushes one or more barges held together with rigging, collectively called 'the tow'. The crew live aboard the towboat as it travels along the inland river system or the intracoastal waterways. These towboats travel between ports and are also called line-haul boats.
Poles are used on barges to fend off the barge as it nears other vessels or a wharf. These are often called 'pike poles'. On shallow canals in the United Kingdom, long punt poles are used to manoeuvre or propel the barge.
Modern use.
Barges are used today for low-value bulk items, as the cost of hauling goods by barge is very low. Barges are also used for very heavy or bulky items; a typical barge measures 195 by 35 feet (59.4 m × 10.6 m), and can carry up to about 1500 tons of cargo. 
As an example, on June 26, 2006, a 565-ton catalytic cracking unit reactor was shipped by barge from the Tulsa Port of Catoosa in Oklahoma to a refinery in Pascagoula, Mississippi. Extremely large objects are normally shipped in sections and assembled onsite, but shipping an assembled unit reduced costs and avoided reliance on construction labor at the delivery site (which in this case was still recovering from Hurricane Katrina). Of the reactor's journey, only about 40 miles were traveled overland, from the final port to the refinery.
Self-propelled barges may be used as such when traveling downstream or upstream in placid waters; they are operated as an unpowered barge, with the assistance of a tugboat, when traveling upstream in faster waters. Canal barges are usually made for the particular canal in which they will operate.
Many barges, primarily Dutch Barges, which were originally designed for carrying cargo along the canals of Europe, are no longer large enough to compete in this industry with larger newer vessels. Many of these barges have been renovated and are now used as luxury Hotel Barges carrying holiday makers along the same canals they once carried grain or coal.
Towed or otherwise unpowered barges in the United States.
In primitive regions today and in all pre-development (lacking highways or railways) regions worldwide in times before industrial development and highways, barges were the predominant and most efficient means of inland transportation in many regions. This holds true today, for many areas of the world. 
In such pre-industrialized, or poorly developed infrastructure regions, many barges are purpose-designed to be powered on waterways by long slender poles — thereby becoming known on American waterways as poleboats as the extensive west of North America was settled using the vast tributary river systems of the Mississippi drainage basin. Poleboats use muscle power of "walkers" along the sides of the craft pushing against a pole against the streambed, canal, or lake bottom to move the vessel where desired. In settling the American west it was generally faster to navigate downriver from Brownsville, Pennsylvania, to the Ohio River confluence with the Mississippi and then pole upriver against the current to St. Louis than to travel overland on the rare primitive dirt roads for many decades after the American revolution.
Once the New York Central and Pennsylvania Railroads reached Chicago, that time dynamic changed, and American poleboats became less common, relegated to smaller rivers and more remote streams. On the Mississippi riverine system today, including that of other sheltered waterways, industrial barge trafficking in bulk raw materials such as coal, coke, timber, iron ore and other minerals is extremely common; in the developed world using huge cargo barges that connect in groups and trains-of-barges in ways that allow cargo volumes and weights considerably greater than those used by pioneers of modern barge systems and methods in the Victorian era.
Such barges need to be towed by tugboats or pushed by towboats. Canal barges, towed by draft animals on a waterway adjacent towpath were of fundamental importance in the early industrial revolution, whose major early engineering projects were efforts to build viaducts, aqueducts and especially canals to fuel and feed raw materials to nascent factories in the early industrial takeoff and take their goods to ports and cities for distribution.
The barge and canal system contended favorably with the railways in the early industrial revolution before around the 1850s–1860s — for example, the Erie Canal in New York State is credited by economic historians with giving the growth boost needed for New York City to eclipse Philadelphia as America's largest port and city — but such canal systems with their locks, need for maintenance and dredging, pumps and sanitary issues were eventually outcompeted in the carriage of high-value items by the railways due to the higher speed, falling costs, and route flexibility of rail transport. Barge and canal systems were nonetheless of great, perhaps even primary, economic importance until after World War I in Europe, particularly in the more developed nations of the Low Countries, France, Germany, Poland, and especially Great Britain which more or less made the system characteristically its own.

</doc>
<doc id="4178" url="http://en.wikipedia.org/wiki?curid=4178" title="Bill Schelter">
Bill Schelter

William Frederick Schelter (1947 – July 30, 2001) was a professor of mathematics at The University of Texas at Austin and a Lisp developer and programmer. Schelter is credited with the development of the GNU Common Lisp (gcl) implementation of Common Lisp and the GPL'd version of the computer algebra system Macsyma called Maxima. Schelter authored Austin Kyoto Common Lisp (AKCL) under contract with IBM. AKCL formed the foundation for Axiom, another computer algebra system. AKCL eventually became GNU Common Lisp. He is also credited with the first port of the GNU C compiler to the Intel 386 architecture, used in the original implementation of the Linux kernel [http://alamos.math.arizona.edu/symcomp/announcement.txt].
Schelter obtained his Ph.D. at McGill University in 1972. His mathematical specialties were noncommutative ring theory and computational algebra and its applications, including automated theorem proving in geometry.
In the summer of 2001, age 54, he died suddenly of a heart attack while traveling in Russia.

</doc>
<doc id="4179" url="http://en.wikipedia.org/wiki?curid=4179" title="British English">
British English

British English or English (BE, en-UK or en-GB) is the broad term used to distinguish the forms of the English language used in the United Kingdom from forms used elsewhere. The "Oxford English Dictionary" applies the term to English as "spoken or written in the British Isles; esp the forms of English usual in Great Britain", reserving "Hiberno-English" for the "English language as spoken and written in Ireland". Nevertheless, Hiberno-English forms part of the broad British English continuum. Others, such as the "Cambridge Academic Content Dictionary", define it as the "English language as it is spoken and written in England." The European Union basically uses 'British English' as its standard variety of English (including also Irish English).
There are slight regional variations in formal written English in the United Kingdom. For example, although the words "wee" and "little" are interchangeable in some contexts, "wee" (as an adjective) is almost exclusively used by some people from some parts of northern Great Britain (and especially Scotland) or from Northern Ireland, whereas in Southern England and Wales, "little" is used predominantly. Nevertheless, there is a meaningful degree of uniformity in "written" English within the United Kingdom, and this could be described by the term "British English". The forms of "spoken" English, however, vary considerably more than in most other areas of the world where English is spoken, so a uniform concept of British English is more difficult to apply to the spoken language. According to Tom McArthur in the "Oxford Guide to World English", "For many people . . . especially in England ["British English"] is tautologous," and it shares "all the ambiguities and tensions in the word "British", and as a result can be used and interpreted in two ways, more broadly or more narrowly, within a range of blurring and ambiguity." The term "British English" is sometimes used as a synonym for "Commonwealth English"; that is, English as spoken and written in the Commonwealth of Nations, with the exception of those Commonwealth countries which have developed their own distinctive dialects such as Australia and Canada.
History.
English is a West Germanic language that originated from the Anglo-Frisian dialects brought to Britain by Germanic settlers from various parts of what is now northwest Germany and the northern Netherlands. The resident population at this time was generally speaking Common Brittonic—the insular variety of continental Celtic which was influenced by the Roman occupation. This group of languages (Welsh, Cornish, Cumbric) cohabited alongside English into the modern period, but due to their remoteness from the Germanic languages, influence on English was notably limited. However, the degree of influence remains debated, and it has recently been argued that its grammatical influence accounts for the substantial innovations noted between English and the other West Germanic languages. Initially, Old English was a diverse group of dialects, reflecting the varied origins of the Anglo-Saxon Kingdoms of England. One of these dialects, Late West Saxon, eventually came to dominate. The original Old English language was then influenced by two waves of invasion: the first was by speakers of the Scandinavian branch of the Germanic family, who conquered and colonised parts of Britain in the 8th and 9th centuries; the second was the Normans in the 11th century, who spoke Old Norman and ultimately developed an English variety of this called Anglo-Norman. These two invasions caused English to become "mixed" to some degree (though it was never a truly mixed language in the strictest sense of the word; mixed languages arise from the cohabitation of speakers of different languages, who develop a hybrid tongue for basic communication).
The more idiomatic, concrete and descriptive English is, the more it is from Anglo-Saxon origins. The more intellectual and abstract English is, the more it contains Latin and French influences (e.g. pig is the animal bred by the occupied Anglo-Saxons and pork is the animal eaten by the occupying Normans).
Cohabitation with the Scandinavians resulted in a significant grammatical simplification and lexical enrichment of the Anglo-Frisian core of English; the later Norman occupation led to the grafting onto that Germanic core of a more elaborate layer of words from the Romance branch of the European languages. This Norman influence entered English largely through the courts and government. Thus, English developed into a "borrowing" language of great flexibility and with a huge vocabulary.
Dialects.
Dialects and accents vary amongst the four countries of the United Kingdom, as well as within the countries themselves.
The major divisions are normally classified as English English (or English as spoken in England, which encompasses Southern English dialects, West Country dialects, East and West Midlands English dialects and Northern English dialects), Welsh English (not to be confused with the Welsh language), Irish English and Scottish English (not to be confused with the Scots language). The various British dialects also differ in the words that they have borrowed from other languages.
Following its last major survey of English Dialects (1949–1950), the University of Leeds has started work on a new project. In May 2007 the Arts and Humanities Research Council awarded a grant to a team led by Sally Johnson, Professor of Linguistics and Phonetics at Leeds University, to study British regional dialects.
Johnson's team are sifting through a large collection of examples of regional slang words and phrases turned up by the "Voices project" run by the BBC, in which they invited the public to send in examples of English still spoken throughout the country. The BBC Voices project also collected hundreds of news articles about how the British speak English from swearing through to items on language schools. This information will also be collated and analysed by Johnson's team both for content and for where it was reported. "Perhaps the most remarkable finding in the Voices study is that the English language is as diverse as ever, despite our increased mobility and constant exposure to other accents and dialects through TV and radio." Work by the team on this project is not expected to end before 2010.
Regional.
The form of English most commonly associated with the upper class in the southern counties of England is called Received Pronunciation (RP). It derives from a mixture of the Midland and Southern dialects which were spoken in London in the early modern period and is frequently used as a model for teaching English to foreign learners. Although speakers from elsewhere in England may not speak with an RP accent, it is now a class dialect more than a local dialect. It may also be referred to as "the Queen's (or King's) English", "Public School English", "Posh" or "BBC English" as this was originally the form of English used on radio and television, although a wider variety of accents can be heard these days. About 2% of Britons speak RP, and it has evolved quite markedly over the last 40 years.
In the South East there are significantly different accents; the Cockney accent spoken by some East Londoners is strikingly different from RP. The Cockney rhyming slang can be (and was initially intended to be) difficult for outsiders to understand, although the extent of its use is often somewhat exaggerated.
Estuary English has been gaining prominence in recent decades: it has some features of RP and some of Cockney. In London itself, the broad local accent is still changing, partly influenced by Caribbean speech. Immigrants to the UK in recent decades have brought many more languages to the country. Surveys started in 1979 by the Inner London Education Authority discovered over 100 languages being spoken domestically by the families of the inner city's schoolchildren. As a result, Londoners speak with a mixture of accents, depending on ethnicity, neighbourhood, class, age, upbringing, and sundry other factors.
Since the mass internal immigration to Northamptonshire in the 1940s and its position between several major accent regions, it has become a source of various accent developments. In Northampton the older accent has been influenced by overspill Londoners. There is an accent known locally as the Kettering accent, which is a transitional accent between the East Midlands and East Anglian. It is the last southern midland accent to use the broad "a" in words like "bath"/"grass" (i.e. barth/grarss). Conversely "crass"/"plastic" use a slender "a". A few miles northwest in Leicestershire the slender "a" becomes more widespread generally. In the town of Corby, five miles (8 km) north, one can find Corbyite, which unlike the Kettering accent, is largely influenced by the West Scottish accent.
In addition, most British people can to some degree temporarily "swing" their accent towards a more neutral form of English at will, to reduce difficulty where very different accents are involved, or when speaking to foreigners.
Glottal stop.
In a number of forms of spoken British English, it is common for the sound /t/ to be replaced by a glottal stop when it is in the intervocalic position, in a process called T-glottalisation. Once regarded as a Cockney feature, it has become much more widespread. It is still stigmatised when used in words like "later", but becoming very widespread at the end of words such as "not" (as in no/ʔ/ interested). Other consonants subject to this usage in Cockney English are "p", as in pa/ʔ/er, "k" as in ba/ʔ/er and "t" as in bu/ʔʔ/er.
Standardisation.
As with English around the world, the English language as used in the United Kingdom is governed by convention rather than formal code: there is no body equivalent to the Académie française or the Real Academia Española, and the authoritative dictionaries (for example, "Oxford English Dictionary", "Longman Dictionary of Contemporary English", "Chambers Dictionary", "Collins Dictionary") record usage rather than attempting to prescribe it. In addition, vocabulary and usage change with time: words are freely borrowed from other languages and other strains of English, and neologisms are frequent.
For historical reasons dating back to the rise of London in the 9th century, the form of language spoken in London and the East Midlands became standard English within the Court, and ultimately became the basis for generally accepted use in the law, government, literature and education in Britain. To a considerable extent, modern British spelling was standardised in Samuel Johnson's "A Dictionary of the English Language" (1755), although previous writers had also played a significant role in this and much has changed since 1755. Scotland, which underwent parliamentary union with England only in 1707, still has a few independent standards, especially within its separate legal system.
Since the early 20th century, numerous books by British authors intended as guides to English grammar and usage have been published, a few of which have achieved sufficient acclaim to have remained in print for long periods and to have been reissued in new editions after some decades. These include, most notably of all, Fowler's "Modern English Usage" and The Complete Plain Words by Sir Ernest Gowers. Detailed guidance on many aspects of writing British English for publication is included in style guides issued by various publishers including "The Times" newspaper, the Oxford University Press and the Cambridge University Press. The Oxford University Press guidelines were originally drafted as a single broadsheet page by Horace Henry Hart, and were at the time (1893) the first guide of their type in English; they were gradually expanded and eventually published, first as "Hart's Rules", and in 2002 as part of "The Oxford Manual of Style". Comparable in authority and stature to "The Chicago Manual of Style" for published American English, the Oxford Manual is a fairly exhaustive standard for published British English, to which writers can turn in the absence of any specific guidance issued by their publishing house.
Notes.
Citations

</doc>
<doc id="4181" url="http://en.wikipedia.org/wiki?curid=4181" title="Battle">
Battle

Generally, a battle is a conceptual component in the hierarchy of combat in warfare between two or more armed forces, or combatants. A war sometimes consists of many battles. Battles generally are well defined in duration, area, and force commitment. 
Wars and military campaigns are guided by strategy, whereas battles take place on a level of planning and execution known as operational mobility. German strategist Carl von Clausewitz stated that "the employment of battles ... to achieve the object of war" was the essence of strategy.
Etymology.
The definition of a battle cannot be arrived at solely through the names of historical battles, many of which are misnomers. The word "battle" is a loanword in English from the Old French "bataille", first attested in 1297, from Late Latin "battualia", meaning "exercise of soldiers and gladiators in fighting and fencing", from Late Latin (taken from Germanic) "battuere" "beat", from which the English word "battery" is also derived via Middle English "batri", and comes from the staged battles in the Colosseum in Rome that may have numbered 10,000 individuals.
Characteristics.
The defining characteristic of the fight as a concept in Military science has been a dynamic one through the course of military history, changing with the changes in the organisation, employment and technology of military forces. 
While the English military historian Sir John Keegan suggested an ideal definition of battle as "something which happens between two armies leading to the moral then physical disintegration of one or the other of them", the origins and outcomes of battles can rarely be summarized so neatly.
In general a battle during the 20th century was, and continues to be, defined by the combat between opposing forces representing major components of total forces committed to a military campaign, used to achieve specific military objectives. Where the duration of the battle is longer than a week, it is often for reasons of staff operational planning called an "operation". Battles can be planned, encountered, or forced by one force on the other when the latter is unable to withdraw from combat. 
A battle always has as its purpose the reaching of a mission goal by use of military force. A victory in the battle is achieved when one of the opposing sides forces the other to abandon its mission, or to surrender its forces, or routs the other, i.e., forces it to retreat or renders it militarily ineffective for further combat operations. However, a battle may end in a Pyrrhic victory, which ultimately favors the defeated party. If no resolution is reached in a battle, it can result in a stalemate. A conflict in which one side is unwilling to reach a decision by a direct battle using conventional warfare often becomes an insurgency.
Until the 19th century the majority of battles were of short duration, many lasting a part of a day. (The Battle of Nations (1813) and the Battle of Gettysburg (1863) were exceptional in lasting three days.) This was mainly due to the difficulty of supplying armies in the field, or conducting night operations. The means of prolonging a battle was typically by employment of siege warfare. Improvements in transportation and the sudden evolving of trench warfare, with its siege-like nature during World War I in the 20th century, lengthened the duration of battles to days and weeks. This created the requirement for unit rotation to prevent combat fatigue, with troops preferably not remaining in a combat area of operations for more than a month. Trench warfare had become largely obsolete in conflicts between advanced armies by the start of the Second World War.
The use of the term "battle" in military history has led to its misuse when referring to almost any scale of combat, notably by strategic forces involving hundreds of thousands of troops that may be engaged in either a single battle at one time (Battle of Leipzig) or multiple operations (Battle of Kursk). The space a battle occupies depends on the range of the weapons of the combatants. A "battle" in this broader sense may occupy a large piece of spacetime, as in the case of the Battle of Britain or the Battle of the Atlantic. Until the advent of artillery and aircraft, battles were fought with the two sides within sight, if not reach, of each other. The depth of the battlefield has also increased in modern warfare with inclusion of the supporting units in the rear areas; supply, artillery, medical personnel etc. often outnumber the front-line combat troops.
Battles are, on the whole, made up of a multitude of individual combats, skirmishes and small engagements within the context of which the combatants will usually only experience a small part of the events of the battle's entirety. To the infantryman, there may be little to distinguish between combat as part of a minor raid or as a major offensive, nor is it likely that he anticipates the future course of the battle; few of the British infantry who went over the top on the first day on the Somme, July 1, 1916, would have anticipated that they would be fighting the same battle in five months' time. Conversely, some of the Allied infantry who had just dealt a crushing defeat to the French at the Battle of Waterloo fully expected to have to fight again the next day (at the Battle of Wavre).
Battlespace.
Battlespace is a unified strategy to integrate and combine armed forces for the military theatre of operations, including air, information, land, sea and space. It includes the environment, factors and conditions that must be understood to successfully apply combat power, protect the force, or complete the mission. This includes enemy and friendly armed forces; facilities; weather; terrain; and the electromagnetic spectrum within the operational areas and areas of interest.
Factors.
Battles are decided by various factors. The number and quality of combatants and equipment, the skill of the commanders of each army, and the terrain advantages are among the most prominent factors. A unit may charge with high morale but less discipline and still emerge victorious. This tactic was effectively used by the early French Revolutionary Armies. 
Weapons and armour can be a decisive factor. On many occasions armies have achieved victories largely owing to the employment of more advanced weapons than those of their opponents. An extreme example was in the Battle of Omdurman, in which a large army of Sudanese Mahdists armed in a traditional manner were destroyed by an Anglo-Egyptian force equipped with Maxim guns.
On some occasions, simple weapons employed in an unorthodox fashion have proven advantageous, as with the Swiss pikemen who gained many victories through their ability to transform a traditionally defensive weapon into an offensive one. Likewise, the Zulus in the early 19th century were victorious in battles against their rivals in part because they adopted a new kind of spear, the iklwa. Even so, forces with inferior weapons have still emerged victorious at times, for example in the Wars of Scottish Independence and in the First Italo–Ethiopian War. Discipline within the troops is often of greater importance; at the Battle of Alesia, the Romans were greatly outnumbered but won because of superior training. 
Battles can also be determined by terrain. Capturing high ground, for example, has been the central strategy in innumerable battles. An army that holds the high ground forces the enemy to climb, and thus wear themselves down. Areas of dense vegetation, such as jungles and forest, act as force-multipliers, of benefit to inferior armies. Arguably, terrain is of less importance in modern warfare, due to the advent of aircraft, though terrain is still vital for camouflage, especially for guerrilla warfare. 
Generals and commanders also play a decisive role during combat. Hannibal, Julius Caesar, Khalid ibn Walid and Napoleon Bonaparte were all skilled generals and, consequently, their armies were extremely successful. An army that can trust the commands of their leaders with conviction in its success invariably has a higher morale than an army that doubts its every move. The British in the naval Battle of Trafalgar, for example, owed its success to the reputation of celebrated admiral Lord Nelson.
Types.
Battles can be fought on land, sea and in the modern age, in the air. Naval battles have occurred since before the 5th century BC. Air battles have been far less common, due to their late conception, the most prominent being the Battle of Britain in 1940. However since the Second World War land or sea battles have come to rely on air support. Indeed, during the Battle of Midway, five aircraft carriers were sunk without either fleet coming into direct contact.
There are numerous types of battles:
Battles frequently do not fit one particular type perfectly, and are usually hybrids of different types listed above.
A "decisive battle" is one of particular importance; often by bringing hostilities to an end, such as the Battle of Hastings or the Battle of Hattin, or as a turning point in the fortunes of the belligerents, such as the Battle of Stalingrad. A decisive battle can have political as well as military impact, changing the balance of power or boundaries between countries. The concept of the "decisive battle" became popular with the publication in 1851 of Edward Creasy's "The Fifteen Decisive Battles of the World". British military historians J.F.C. Fuller ("The Decisive Battles of the Western World") and B.H. Liddell Hart ("Decisive Wars of History"), among many others, have written books in the style of Creasy's work.
Land.
There is an obvious difference in the way battles have been fought throughout time. Early battles were probably fought between rival hunting bands as disorganized mobs. However, during the Battle of Megiddo, the first reliably documented battle in the fifteenth century BC, actual discipline was instilled in both armies. However, during the many wars of the Roman Empire, barbarians continued using mob tactics. 
As the Age of Enlightenment dawned, armies began to fight in highly disciplined lines. Each would follow the orders from their officers and fight as a single unit instead of individuals. Each army was successively divided into regiments, battalions, companies, and platoons. These armies would march, line up, and fire in divisions. 
Native Americans, on the other hand, did not fight in lines, utilizing instead guerrilla tactics. American colonists and European forces continued using disciplined lines, continuing into the American Civil War. 
A new style, during World War I, known as trench warfare, developed nearly half a century later. This also led to radio for communication between battalions. Chemical warfare also emerged with the use of poisonous gas during World War I. 
By World War II, the use of the smaller divisions, platoons and companies became much more important as precise operations became vital. Instead of the locked trench warfare of World War I, during World War II, a dynamic network of battles developed where small groups encountered other platoons. As a result, elite squads became much more recognized and distinguishable. 
Maneuver warfare also developed with an astonishing pace with the advent of the tank, replacing the archaic cannons of the Enlightenment Age. Artillery has since gradually replaced the use of frontal troops. Modern battles now continue to resemble those of World War II, though prominent innovations have been added. Indirect combat through the use of aircraft and missiles now constitutes a large portion of wars in place of battles, where battles are now mostly reserved for capturing cities.
Naval.
One significant difference of modern naval battles as opposed to earlier forms of combat is the use of marines, which introduced amphibious warfare. Today, a marine is actually an infantry regiment that sometimes fights solely on land and is no longer tied to the navy. A good example of an old naval battle is the Battle of Salamis. 
Most ancient naval battles were fought by fast ships using the battering ram to sink opposing fleets or steer close enough for boarding in hand-to-hand combat. Troops were often used to storm enemy ships as used by Romans and pirates. This tactic was usually used by civilizations that could not beat the enemy with ranged weaponry. 
Another invention in the late Middle Ages was the use of Greek fire by the Byzantines, which was used to set enemy fleets on fire. Empty demolition ships utilized the tactic to crash into opposing ships and set it afire with an explosion. After the invention of cannons, naval warfare became useful as support units for land warfare. 
During the 19th century, the development of mines led to a new type of naval warfare. The ironclad, first used in the American Civil War, resistant to cannons, soon made the wooden ship obsolete. The invention of military submarines, during World War I, brought naval warfare to both above and below the surface. With the development of military aircraft during World War II, battles were fought in the sky as well as below the ocean. Aircraft carriers have since become the central unit in naval warfare, acting as a mobile base for lethal aircraft.
Aerial.
Although the use of aircraft has for the most part always been used as a supplement to land or naval engagements, since their first major military use in World War I aircraft have increasingly taken on larger roles in warfare. During World War I, the primary use was for reconnaissance, and small-scale bombardment.
Aircraft began becoming much more prominent in the Spanish Civil War and especially World War II. Aircraft design began specializing, primarily into two types: bombers, which carried explosive payloads to bomb land targets or ships; and fighter-interceptors, which were used to either intercept incoming aircraft or to escort and protect bombers (engagements between fighter aircraft were known as dog fights). Some of the more notable aerial battles in this period include the Battle of Britain and the Battle of Midway.
Another important use of aircraft came with the development of the helicopter, which first became heavily used during the Vietnam War, and still continues to be widely used today to transport and augment ground forces.
Today, direct engagements between aircraft are rare - the most modern fighter-interceptors carry much more extensive bombing payloads, and are used to bomb precision land targets, rather than to fight other aircraft. Anti-aircraft batteries are used much more extensively to defend against incoming aircraft than interceptors. Despite this, aircraft today are much more extensively used as the primary tools for both army and navy, as evidenced by the prominent use of helicopters to transport and support troops, the use of aerial bombardment as the "first strike" in many engagements, and the replacement of the battleship with the aircraft carrier as the center of most modern navies.
Naming.
Battles are usually named after some feature of the battlefield geography, such as the name of a town, forest or river, commonly prefixed "Battle of...". Occasionally battles are named after the date on which they took place, such as The Glorious First of June. 
In the Middle Ages it was considered important to settle on a suitable name for a battle which could be used by the chroniclers. For example, after Henry V of England defeated a French army on October 25, 1415, he met with the senior French herald and they agreed to name the battle after the nearby castle and so it was called the Battle of Agincourt. 
In other cases, the sides adopted different names for the same battle, such as the Battle of Gallipoli which is known in Turkey as the Battle of Çanakkale. During the American Civil War, the Union tended to name the battles after the nearest watercourse, such as the Battle of Wilsons Creek and the Battle of Stones River, whereas the Confederates favoured the nearby towns, as in the Battles of Chancellorsville and Murfreesboro. Occasionally both names for the same battle entered the popular culture, such as the First and Second Battle of Bull Run, which are also referred to as the First and Second Battle of Manassas.
Sometimes in desert warfare, there is no nearby town name to use; map coordinates gave the name to the Battle of 73 Easting in the First Gulf War.
Some place names have become synonymous with the battles that took place there, such as the Passchendaele, Pearl Harbor, the Alamo, Thermopylae, or Waterloo. Military operations, many of which result in battle, are given codenames, which are not necessarily meaningful or indicative of the type or the location of the battle. Operation Market Garden and Operation Rolling Thunder are examples of battles known by their military codenames. 
When a battleground is the site of more than one battle in the same conflict, the instances are distinguished by ordinal number, such as the First and Second Battles of Bull Run. An extreme case are the twelve Battles of the Isonzo—First to Twelfth—between Italy and Austria-Hungary during the First World War.
Some battles are named for the convenience of military historians so that periods of combat can be neatly distinguished from one another. Following the First World War, the British Battles Nomenclature Committee was formed to decide on standard names for all battles and subsidiary actions. To the soldiers who did the fighting, the distinction was usually academic; a soldier fighting at Beaumont Hamel on November 13, 1916 was probably unaware he was taking part in what the committee would call the "Battle of the Ancre".
Many combats are too small to merit a name. Terms such as "action", "skirmish", "firefight", "raid" or "offensive patrol" are used to describe small-scale battle-like encounters. These combats often take place within the time and space of a battle and while they may have an objective, they are not necessarily "decisive". Sometimes the soldiers are unable to immediately gauge the significance of the combat; in the aftermath of the Battle of Waterloo, some British officers were in doubt as to whether the day's events merited the title of "battle" or would be passed off as merely an "action".
Effects.
Battles affect the individuals who take part, as well as the political actors. Personal effects of battle range from mild psychological issues to permanent and crippling injuries. Some battle-survivors have nightmares about the conditions they encountered, or abnormal reactions to certain sights or sounds. Some suffer flashbacks. Physical effects of battle can include scars, amputations, lesions, loss of bodily functions, blindness, paralysis — and death.
Battles also affect politics. A decisive battle can cause the losing side to surrender, while a Pyrrhic Victory such as the Battle of Asculum can cause the winning side to reconsider its long-term goals. Battles in civil wars have often decided the fate of monarchs or political factions. Famous examples include the War of the Roses, as well as the Jacobite Uprisings. Battles also affect the commitment of one side or the other to the continuance of a war, for example the Battle of Incheon and the Battle of Hue during the Tet Offensive.

</doc>
<doc id="4182" url="http://en.wikipedia.org/wiki?curid=4182" title="Berry Berenson">
Berry Berenson

Berinthia "Berry" Berenson Perkins (April 14, 1948 – September 11, 2001) was an American photographer, actress, and model. Perkins, who was the wife of actor Anthony Perkins, died in the September 11 attacks as a passenger on American Airlines Flight 11.
Early life.
Berenson was born in Murray Hill, Manhattan. Her father, Robert Lawrence Berenson, was an American career diplomat turned shipping executive; he was of Lithuanian Jewish descent, and his family's original surname was Valvrojenski. Her mother was born Countess Maria-Luisa Yvonne Radha de Wendt de Kerlor, better known as Gogo Schiaparelli, a socialite of Italian, Swiss, French, and Egyptian ancestry.
Her maternal grandmother was the Italian-born fashion designer Elsa Schiaparelli, and her maternal grandfather was Count Wilhelm de Wendt de Kerlor, a Theosophist and psychic medium. Her elder sister, Marisa Berenson, became a well-known model and actress. She also was a great-grandniece of Giovanni Schiaparelli, an Italian astronomer who believed he had discovered the supposed canals of Mars, and a second cousin, once removed, of art expert Bernard Berenson (1865–1959) and his sister Senda Berenson (1868–1954), an athlete and educator who was one of the first two women elected to the Basketball Hall of Fame.
Career.
Following a brief modeling career in the late 1960s, Berenson became a freelance photographer. By 1973, her photographs had been published in "Life", "Glamour", "Vogue" and "Newsweek".
She also appeared in several motion pictures, including "Cat People" with Malcolm McDowell. She starred opposite Anthony Perkins in the 1978 Alan Rudolph film "Remember My Name" and opposite Jeff Bridges in the 1979 film "Winter Kills".
Personal life and death.
On August 9, 1973, in Cape Cod, Massachusetts, Berenson married her "Remember My Name" costar Anthony Perkins. They had two sons: actor-musician Oz Perkins (born February 2, 1974) and folk/rock recording artist Elvis Perkins (born February 9, 1976). They remained married until Perkins' death from AIDS-related complications on September 12, 1992.
Berenson died at age 53 in the September 11 attacks aboard American Airlines Flight 11, one day before the ninth anniversary of Perkins' death. She was returning to her California home following a holiday on Cape Cod.
At the National September 11 Memorial & Museum, Berenson is memorialized at the North Pool, on Panel N-76.

</doc>
<doc id="4183" url="http://en.wikipedia.org/wiki?curid=4183" title="Botany">
Botany

Botany, also called plant science(s) or plant biology, is the science of plant life and a branch of biology. A botanist is a scientist who specializes in this field of study. The term "botany" comes from the Ancient Greek word ("botane") meaning "pasture", "grass", or "fodder"; is in turn derived from ("boskein"), "to feed" or "to graze". A person who studies plants may be called a botanist or a plant scientist. Traditionally, botany has included the study of fungi and algae, studied by mycologists, phycologists respectively, with the study of plants and these three groups of organisms remain within the sphere of interest of the International Botanical Congress. Nowadays, botanists study approximately 400,000 species of living organisms of which some 260,000 species are vascular plants and about 248,000 are flowering plants.
Botany originated in prehistory as herbalism with the efforts of early humans to identify – and later cultivate – edible, medicinal and poisonous plants, making it one of the oldest branches of science. Medieval physic gardens, often attached to monasteries, contained plants of medical importance. They were forerunners of the first botanical gardens attached to universities, founded from the 1540s onwards. One of the earliest was the Padua botanical garden. These gardens facilitated the academic study of plants. Efforts to catalogue and describe their collections were the beginnings of plant taxonomy, and led in 1753 to the binomial system of Carl Linnaeus that remains in use to this day.
In the 19th and 20th centuries, new techniques were developed for the study of plants, including methods of optical microscopy and live cell imaging, electron microscopy, analysis of chromosome number, plant chemistry and the structure and function of enzymes and other proteins. In the last two decades of the 20th century, botanists exploited the techniques of molecular genetic analysis, including genomics and proteomics and DNA sequences to classify plants more accurately.
Modern botany is a broad, multidisciplinary subject with inputs from most other areas of science and technology. Research topics include the study of plant structure, growth and differentiation, reproduction, biochemistry and primary metabolism, chemical products, development, diseases, evolutionary relationships, systematics, and plant taxonomy. Dominant themes in 21st century plant science are molecular genetics and epigenetics, which are the mechanisms and control of gene expression during differentiation of plant cells and tissues. Botanical research has diverse applications in providing staple foods and textiles, in modern horticulture, agriculture and forestry, plant propagation, breeding and genetic modification, in the synthesis of chemicals and raw materials for construction and energy production, in environmental management, and the maintenance of biodiversity.
History.
Early botany.
Botany originated as herbalism, the study and use of plants for their medicinal properties. The early recorded history of botany includes many ancient writings and plant classifications. Examples of early botanical works have been found in ancient sacred texts from India dating back to before 1100 BC, archaic Avestan writings, and works from China before it was unified in 221 BC.
Modern botany traces its roots back to Ancient Greece, specifically to Theophrastus (c. 371–287 BC), a student of Aristotle who invented and described many of its principles and is widely regarded in the scientific community as the "Father of Botany". His major works, "Enquiry into Plants" and "On the Causes of Plants", constitute the most important contributions to botanical science until the Middle Ages, almost seventeen centuries after they were written.
Another work from Ancient Greece that made an early impact on botany is "De Materia Medica", a five-volume encyclopedia about herbal medicine written in the middle of the first century by Greek physician and pharmacologist Pedanius Dioscorides. "De Materia Medica" was widely read for more than 1,500 years. Important contributions from the medieval Muslim world include Ibn Wahshiyya's "Nabatean Agriculture", Abū Ḥanīfa Dīnawarī's (828–896) the "Book of Plants", and Ibn Bassal's "The Classification of Soils". In the early 13th century, Abu al-Abbas al-Nabati, and Ibn al-Baitar (d. 1248) wrote on botany in a systematic and scientific manner.
In mid-16th century, "botanical gardens" were founded in a number of Italian universities – the Padua botanical garden in 1545 is usually considered to be the first which is still in its original location. These gardens continued the practical value of earlier "physic gardens", often associated with monasteries, in which plants were cultivated for medical use. They supported the growth of botany as an academic subject. Lectures were given about the plants grown in the gardens and their medical uses demonstrated. Botanical gardens came much later to northern Europe; the first in England was the University of Oxford Botanic Garden in 1621. Throughout this period, botany remained firmly subordinate to medicine.
German physician Leonhart Fuchs (1501–1566) was one of "the three German fathers of botany", along with theologian Otto Brunfels (1489–1534) and physician Hieronymus Bock (1498–1554) (also called Hieronymus Tragus). Fuchs and Brunfels broke away from the tradition of copying earlier works to make original observations of their own. Bock created his own system of plant classification.
Physician Valerius Cordus (1515–1544) authored a botanically and pharmacologically important herbal "Historia Plantarum" in 1544 and a pharmacopoeia of lasting importance, the "Dispensatorium" in 1546. Naturalist Conrad von Gesner (1516–1565) and herbalist John Gerard (1545–c. 1611) published herbals covering the medicinal uses of plants. Naturalist Ulisse Aldrovandi (1522–1605) was considered the "father of natural history", which included the study of plants. In 1665, using an early microscope, Polymath Robert Hooke discovered cells, a term he coined, in cork, and a short time later in living plant tissue.
Early modern botany.
During the 18th century, systems of plant identification were developed comparable to dichotomous keys, where unidentified plants are placed into taxonomic groups (e.g. family, genus and species) by making a series of choices between pairs of characters. The choice and sequence of the characters may be artificial in keys designed purely for identification (diagnostic keys) or more closely related to the natural or phyletic order of the taxa in synoptic keys. By the 18th century, new plants for study were arriving in Europe in increasing numbers from newly discovered countries and the European colonies worldwide. In 1753 Carl von Linné (Carl Linnaeus) published his Species Plantarum, a hierarchical classification of plant species that remains the reference point for modern botanical nomenclature. This established a standardised binomial or two-part naming scheme where the first name represented the genus and the second identified the species within the genus. For the purposes of identification, Linnaeus's "Systema Sexuale" classified plants into 24 groups according to the number of their male sexual organs. The 24th group, "Cryptogamia", included all plants with concealed reproductive parts, mosses, liverworts, ferns, algae and fungi.
Increasing knowledge of plant anatomy, morphology and life cycles led to the realisation that there were more natural affinities between plants than the artificial sexual system of Linnaeus had indicated. Adanson (1763), de Jussieu (1789), and Candolle (1819) all proposed various alternative natural systems of classification that grouped plants using a wider range of shared characters and were widely followed. The Candollean system reflected his ideas of the progression of morphological complexity and the later classification by Bentham and Hooker, which was influential until the mid-19th century, was influenced by Candolle's approach. Darwin's publication of the "Origin of Species" in 1859 and his concept of common descent required modifications to the Candollean system to reflect evolutionary relationships as distinct from mere morphological similarity.
Botany was greatly stimulated by the appearance of the first "modern" text book, Matthias Schleiden's "", published in English in 1849 as "Principles of Scientific Botany". Schleiden was a microscopist and an early plant anatomist who co-founded the cell theory with Theodor Schwann and Rudolf Virchow and was among the first to grasp the significance of the cell nucleus that had been described by Robert Brown in 1831.
In 1855, Adolf Fick formulated Fick's laws that enabled the calculation of the rates of molecular diffusion in biological systems.
Modern botany.
Building upon the gene-chromosome theory of heredity that originated with Gregor Mendel (1822–1884), August Weismann (1834–1914) proved that inheritance only takes place through gametes. No other cells can pass on inherited characters. The work of Katherine Esau (1898–1997) on plant anatomy is still a major foundation of modern botany. Her books "Plant Anatomy" and "Anatomy of Seed Plants" have been key plant structural biology texts for more than half a century.
The discipline of plant ecology was pioneered in the late 19th century by botanists such as Eugenius Warming, who produced the hypothesis that plants form communities, and his mentor and successor Christen C. Raunkiær whose system for describing plant life forms is still in use today. The concept that the composition of plant communities such as temperate broadleaf forest changes by a process of ecological succession was developed by Henry Chandler Cowles, Arthur Tansley and Frederic Clements. Clements is credited with the idea of climax vegetation as the most complex vegetation that an environment can support and Tansley introduced the concept of ecosystems to biology. Building on the extensive earlier work of Alphonse de Candolle, Nikolai Vavilov (1887–1943) produced accounts of the biogeography, centres of origin, and evolutionary history of economic plants.
Particularly since the mid-1960s there have been advances in understanding of the physics of plant physiological processes such as transpiration (the transport of water within plant tissues), the temperature dependence of rates of water evaporation from the leaf surface and the molecular diffusion of water vapour and carbon dioxide through stomatal apertures. These developments, coupled with new methods for measuring the size of stomatal apertures, and the rate of photosynthesis have enabled precise description of the rates of gas exchange between plants and the atmosphere. Innovations in statistical analysis by Ronald Fisher, Frank Yates and others at Rothamsted Experimental Station facilitated rational experimental design and data analysis in botanical research. The discovery and identification of the auxin plant hormones by Kenneth V. Thimann in 1948 enabled regulation of plant growth by externally applied chemicals. Frederick Campion Steward pioneered techniques of micropropagation and plant tissue culture controlled by plant hormones. The synthetic auxin 2,4-Dichlorophenoxyacetic acid or 2,4-D was one of the first commercial synthetic herbicides.
20th century developments in plant biochemistry have been driven by modern techniques of organic chemical analysis, such as spectroscopy, chromatography and electrophoresis. With the rise of the related molecular-scale biological approaches of molecular biology, genomics, proteomics and metabolomics, the relationship between the plant genome and most aspects of the biochemistry, physiology, morphology and behaviour of plants can be subjected to detailed experimental analysis. The concept originally stated by Gottlieb Haberlandt in 1902 that all plant cells are totipotent and can be grown "in vitro" ultimately enabled the use of genetic engineering experimentally to knock out a gene or genes responsible for a specific trait, or to add genes such as GFP that report when a gene of interest is being expressed. These technologies enable the biotechnological use of whole plants or plant cell cultures grown in bioreactors to synthesise pesticides, antibiotics or other pharmaceuticals, as well as the practical application of genetically modified crops designed for traits such as improved yield.
Modern morphology recognizes a continuum between the major morphological categories of root, stem (caulome), leaf (phyllome) and trichome. Furthermore, it emphasizes structural dynamics. Modern systematics aims to reflect and discover phylogenetic relationships between plants. Modern Molecular phylogenetics largely ignores morphological characters, relying on DNA sequences as data. Molecular analysis of DNA sequences from most families of flowering plants enabled the Angiosperm Phylogeny Group to publish in 1998 a phylogeny of flowering plants, answering many of the questions about relationships among angiosperm families and species. The theoretical possibility of a practical method for identification of plant species and commercial varieties by DNA barcoding is the subject of active current research.
Scope and importance.
The study of plants is vital because they underpin almost all animal life on Earth by generating a large proportion of the oxygen and food that provide humans and other organisms with aerobic respiration with the chemical energy they need to exist. Plants, algae and cyanobacteria are the major groups of organisms that carry out photosynthesis, a process that uses the energy of sunlight to convert water and carbon dioxide into sugars that can be used both as a source of chemical energy and of organic molecules that are used in the structural components of cells. As a by-product of photosynthesis, plants release oxygen into the atmosphere, a gas that is required by nearly all living things to carry out cellular respiration. In addition, they are influential in the global carbon and water cycles and plant roots bind and stabilise soils, preventing soil erosion. Plants are crucial to the future of human society as they provide food, oxygen, medicine, and products for people, as well as creating and preserving soil.
Historically, all living things were classified as either animals or plants and botany covered the study of all organisms not considered animals. Botanists examine both the internal functions and processes within plant organelles, cells, tissues, whole plants, plant populations and plant communities. At each of these levels, a botanist may be concerned with the classification (taxonomy), phylogeny and evolution, structure (anatomy and morphology), or function (physiology) of plant life.
The strictest definition of "plant" includes only the "land plants" or embryophytes, which include seed plants (gymnosperms, including the pines, and flowering plants) and the free-sporing cryptogams including ferns, clubmosses, liverworts, hornworts and mosses. Embryophytes are multicellular eukaryotes descended from an ancestor that obtained its energy from sunlight by photosynthesis. They have life cycles with alternating haploid and diploid phases. The sexual haploid phase of embryophytes, known as the gametophyte, nurtures the developing diploid embryo sporophyte within its tissues for at least part of its life, even in the seed plants, where the gametophyte itself is nurtured by its parent sporophyte. Other groups of organisms that were previously studied by botanists include bacteria (now studied in bacteriology), fungi (mycology) – including lichen-forming fungi (lichenology), non-chlorophyte algae (phycology), and viruses (virology). However, attention is still given to these groups by botanists, and fungi (including lichens) and photosynthetic protists are usually covered in introductory botany courses.
Paleobotanists study ancient plants in the fossil record to provide information about the evolutionary history of plants. Cyanobacteria, the first oxygen-releasing photosynthetic organisms on Earth, are thought to have given rise to the ancestor of plants by entering into an endosymbiotic relationship with an early eukaryote, ultimately becoming the chloroplasts in plant cells. The new photosynthetic plants (along with their algal relatives) accelerated the rise in atmospheric oxygen started by the cyanobacteria, changing the ancient oxygen-free, reducing, atmosphere to one in which free oxygen has been abundant for more than 2 billion years.
Among the important botanical questions of the 21st century are the role of plants as primary producers in the global cycling of life's basic ingredients: energy, carbon, oxygen, nitrogen and water, and ways that our plant stewardship can help address the global environmental issues of resource management, conservation, human food security, biologically invasive organisms, carbon sequestration, climate change, and sustainability.
Human nutrition.
Virtually all staple foods come either directly from primary production by plants, or indirectly from animals that eat them. Plants and other photosynthetic organisms are at the base of most food chains because they use the energy from the sun and nutrients from the soil and atmosphere, converting them into a form that can be used by animals. This is what ecologists call the first trophic level. The modern forms of the major staple foods, such as bananas, plantains, maize and other cereal grasses, and pulses, as well as flax and cotton grown for their fibres, are the outcome of prehistoric selection over thousands of years from among wild ancestral pants with the most desirable characteristics. Botanists study how plants produce food and how to increase yields, for example through plant breeding, making their work important to mankind's ability to feed the world and provide food security for future generations. Botanists also study weeds, which are a considerable problem in agriculture, and the biology and control of plant pathogens in agriculture and natural ecosystems. Ethnobotany is the study of the relationships between plants and people. When applied to the investigation of historical plant–people relationships ethnobotany may be referred to as archaeobotany or palaeoethnobotany.
Plant biochemistry.
Plant biochemistry is the study of the chemical processes used by plants. Some of these processes are used in their primary metabolism like the photosynthetic Calvin cycle and crassulacean acid metabolism. Others make specialized materials like the cellulose and lignin used to build their bodies, and secondary products like resins and aroma compounds.
Plants make various photosynthetic pigments, some of which can be seen here through paper chromatography.
Xanthophylls
Chlorophyll "a"
Chlorophyll "b"
Plants and various other groups of photosynthetic eukaryotes collectively known as "algae" have unique organelles known as chloroplasts. Chloroplasts are thought to be descended from cyanobacteria that formed endosymbiotic relationships with ancient plant and algal ancestors. Chloroplasts and cyanobacteria contain the blue-green pigment chlorophyll "a". Chlorophyll "a" (as well as its plant and green algal-specific cousin chlorophyll "b") absorbs light in the blue-violet and orange/red parts of the spectrum while reflecting and transmitting the green light that we see as the characteristic colour of these organisms. The energy in the red and blue light that these pigments absorb is used by chloroplasts to make energy-rich carbon compounds from carbon dioxide and water by oxygenic photosynthesis, a process that generates molecular oxygen (O2) as a by-product.
The light energy captured by chlorophyll "a" is initially in the form of electrons (and later a proton gradient) that's used to make molecules of ATP and NADPH which temporarily store and transport energy. Their energy is used in the light-independent reactions of the Calvin cycle by the enzyme rubisco to produce molecules of the 3-carbon sugar glyceraldehyde 3-phosphate (G3P). Glyceraldehyde 3-phosphate is the first product of photosynthesis and the raw material from which glucose and almost all other organic molecules of biological origin are synthesized. Some of the glucose is converted to starch which is stored in the chloroplast. Starch is the characteristic energy store of most land plants and algae, while inulin, a polymer of fructose is used for the same purpose in in the sunflower family Asteraceae. Some of the glucose is converted to sucrose (common table sugar) for export to the rest of the plant.
Unlike in animals (which lack chloroplasts), plants and their eukaryote relatives have delegated many biochemical roles to their chloroplasts, including synthesizing all their fatty acids, and most amino acids. The fatty acids that chloroplasts make are used for many things, such as providing material to build cell membranes out of and making the polymer cutin which is found in the plant cuticle that protects land plants from drying out. 
Plants synthesize a number of unique polymers like the polysaccharide molecules cellulose, pectin and xyloglucan from which the land plant cell wall is constructed.
Vascular land plants make lignin, a polymer used to strengthen the secondary cell walls of xylem tracheids and vessels to keep them from collapsing when a plant sucks water through them under water stress. Lignin is also used in other cell types like sclerenchyma fibers that provide structural support for a plant and is a major constituent of wood. Sporopollenin is a chemically resistant polymer found in the outer cell walls of spores and pollen of land plants responsible for the survival of early land plant spores and the pollen of seed plants in the fossil record. It is widely regarded as a marker for the start of land plant evolution during the Ordovician period.
The concentration of carbon dioxide in the atmosphere today is much lower than it was when plants emerged onto land during the Ordovician and Silurian periods. Many monocots like maize and the pineapple and some dicots like the Asteraceae have since independently evolved pathways like Crassulacean acid metabolism and the carbon fixation pathway for photosynthesis which avoid the losses resulting from photorespiration in the more common carbon fixation pathway. These biochemical strategies are unique to land plants.
Medicine and materials.
Phytochemistry is a branch of plant biochemistry primarily concerned with the chemical substances produced by plants during secondary metabolism. Some of these compounds are toxins such as the alkaloid coniine from hemlock. Others, such as the essential oils peppermint oil and lemon oil are useful for their aroma, as flavourings and spices (e.g., capsaicin), and in medicine as pharmaceuticals as in opium from opium poppies. Many medicinal and recreational drugs, such as tetrahydrocannabinol (active ingredient in cannabis), caffeine, morphine and nicotine come directly from plants. Others are simple derivatives of botanical natural products. For example, the pain killer aspirin is the acetyl ester of salicylic acid, originally isolated from the bark of willow trees, and a wide range of opiate painkillers like heroin are obtained by chemical modification of morphine obtained from the opium poppy. Popular stimulants come from plants, such as caffeine from coffee, tea and chocolate, and nicotine from tobacco. Most alcoholic beverages come from fermentation of carbohydrate-rich plant products such as barley (beer), rice (sake) and grapes (wine).
Plants can synthesise useful coloured dyes and pigments such as the anthocyanins responsible for the red colour of red wine, yellow weld and blue woad used together to produce Lincoln green, indoxyl, source of the blue dye indigo traditionally used to dye denim and the artist's pigments gamboge and rose madder.
Sugar, starch, cotton, linen, hemp, some types of rope, wood and particle boards, papyrus and paper, vegetable oils, wax, and natural rubber are examples of commercially important materials made from plant tissues or their secondary products. Charcoal, a pure form of carbon made by pyrolysis of wood, has a long history as a metal-smelting fuel, as a filter material and adsorbent and as an artist's material and is one of the three ingredients of gunpowder. Cellulose, the world's most abundant organic polymer, can be converted into energy, fuels, materials and chemical feedstock. Products made from cellulose include rayon and cellophane, wallpaper paste, biobutanol and gun cotton. Sugarcane, rapeseed and soy are some of the plants with a highly fermentable sugar or oil content that are used as sources of biofuels, important alternatives to fossil fuels, such as biodiesel.
Plant ecology.
Plant ecology is the science of the functional relationships between plants and their habitats—the environments where they complete their life cycles. Plant ecologists study the composition of local and regional floras, their biodiversity, genetic diversity and fitness, the adaptation of plants to their environment, and their competitive or mutualistic interactions with other species. The goals of plant ecology are to understand the causes of their distribution patterns, productivity, environmental impact, evolution, and responses to environmental change.
Plants depend on certain edaphic (soil) and climatic factors in their environment but can modify these factors too. For example, they can change their environment's albedo, increase runoff interception, stabilize mineral soils and develop their organic content, and affect local temperature. Plants compete with other organisms in their ecosystem for resources. They interact with their neighbours at a variety of spatial scales in groups, populations and communities that collectively constitute vegetation. Regions with characteristic vegetation types and dominant plants as well as similar abiotic and biotic factors, climate, and geography make up biomes like tundra or tropical rainforest.
Herbivores eat plants, but plants can defend themselves and some species are parasitic or even carnivorous. Other organisms form mutually beneficial relationships with plants. For example mycorrhizal fungi and rhizobia provide plants with nutrients in exchange for food, ants are recruited by ant plants to provide protection, honey bees, bats and other animals pollinate flowers and humans and other animals act as dispersal vectors to spread spores and seeds.
Plants, climate and environmental change.
Plant responses to climate and other environmental changes can inform our understanding of how these changes affect ecosystem function and productivity. For example, plant phenology can be a useful proxy for temperature in historical climatology, and the biological impact of climate change and global warming. Palynology, the analysis of fossil pollen deposits in sediments from thousands or millions of years ago allows the reconstruction of past climates. Estimates of atmospheric concentrations since the Palaeozoic have been obtained from stomatal densities and the leaf shapes and sizes of ancient land plants. Ozone depletion can expose plants to higher levels of ultraviolet radiation-B (UV-B), resulting in lower growth rates. Moreover, information from studies of community ecology, plant systematics, and taxonomy is essential to understanding vegetation change, habitat destruction and species extinction.
Genetics.
Inheritance in plants follows the same fundamental principles of genetics as in other multicellular organisms. Gregor Mendel discovered the genetic laws of inheritance by studying inherited traits such as shape in "Pisum sativum" (peas). What Mendel learned from studying plants has had far reaching benefits outside of botany. Similarly, "jumping genes" were discovered by Barbara McClintock while she was studying maize. Nevertheless there are some distinctive genetic differences between plants and other organisms.
Species boundaries in plants may be weaker than in animals, and cross species hybrids are often possible. A familiar example is peppermint, "Mentha" × "piperita", a sterile hybrid between "Mentha aquatica" and spearmint, "Mentha spicata". The many cultivated varieties of wheat are the result of multiple inter- and intra-specific crosses between wild species and their hybrids. Angiosperms with monoecious flowers often have self-incompatibility mechanisms that operate between the pollen and stigma so that the pollen either fails to reach the stigma or fails to germinate and produce male gametes. This is one of several methods used by plants to promote outcrossing. In many land plants the male and female gametes are produced by separate individuals. These species are said to be dioecious when referring to vascular plant sporophytes and dioicous when referring to bryophyte gametophytes.
Unlike in higher animals, where parthenogenesis is rare, asexual reproduction may occur in plants by several different mechanisms. The formation of stem tubers in potato is one example. Particularly in arctic or alpine habitats, where opportunities for fertilisation of flowers by animals are rare, plantlets or bulbs, may develop instead of flowers, replacing sexual reproduction with asexual reproduction and giving rise to clonal populations genetically identical to the parent. This is one of several types of apomixis that occur in plants. Apomixis can also happen in a seed, producing a seed that contains an embryo genetically identical to the parent.
Most sexually reproducing organisms are diploid, with paired chromosomes, but doubling of their chromosome number may occur due to errors in cytokinesis. This can occur early in development to produce an autopolyploid or partly autopolyploid organism, or during normal processes of cellular differentiation to produce some cell types that are polyploid (endopolyploidy), or during gamete formation. An allopolyploid plant may result from a hybridisation event between two different species. Both autopolyploid and allopolyploid plants can often reproduce normally, but may be unable to cross-breed successfully with the parent population because there is a mismatch in chromosome numbers. These plants that are reproductively isolated from the parent species but live within the same geographical area, may be sufficiently successful to form a new species. Some otherwise sterile plant polyploids can still reproduce vegetatively or by seed apomixis, forming clonal populations of identical individuals. Durum wheat is a fertile tetraploid allopolyploid, while bread wheat is a fertile hexaploid. The commercial banana is an example of a sterile, seedless triploid hybrid. Common dandelion is a triploid that produces viable seeds by apomictic seed.
As in other eukaryotes, the inheritance of endosymbiotic organelles like mitochondria and chloroplasts in plants is non-Mendelian. Chloroplasts are inherited through the male parent in gymnosperms but often through the female parent in flowering plants.
Molecular genetics.
A considerable amount of new knowledge about plant function comes from studies of the molecular genetics of model plants such as the Thale cress, "Arabidopsis thaliana", a weedy species in the mustard family (Brassicaceae). The genome or hereditary information contained in the genes of this species is encoded by about 135 million base pairs of DNA, forming one of the smallest genomes among flowering plants. "Arabidopsis" was the first plant to have its genome sequenced, in 2000. The sequencing of some other relatively small genomes, of rice ("Oryza sativa") and "Brachypodium distachyon", has made them important model species for understanding the genetics, cellular and molecular biology of cereals, grasses and monocots generally.
Model plants such as "Arabidopsis thaliana" are used for studying the molecular biology of plant cells and the chloroplast. Ideally, these organisms have small genomes that are well known or completely sequenced, small stature and short generation times. Corn has been used to study mechanisms of photosynthesis and phloem loading of sugar in plants. The single celled green alga "Chlamydomonas reinhardtii", while not an embryophyte itself, contains a green-pigmented chloroplast related to that of land plants, making it useful for study. A red alga "Cyanidioschyzon merolae" has also been used to study some basic chloroplast functions. Spinach, peas, soybeans and a moss "Physcomitrella patens" are commonly used to study plant cell biology.
"Agrobacterium tumefaciens", a soil rhizosphere bacterium, can attach to plant cells and infect them with a callus-inducing Ti plasmid by horizontal gene transfer, causing a callus infection called crown gall disease. Schell and Van Montagu (1977) hypothesised that the Ti plasmid could be a natural vector for introducing the Nif gene responsible for nitrogen fixation in the root nodules of legumes and other plant species. Today, genetic modification of the Ti plasmid is one of the main techniques for introduction of transgenes to plants and the creation of genetically modified crops.
Epigenetics.
Epigenetics is the study of mitotically and/or meiotically heritable changes in gene function that cannot be explained by changes in the underlying DNA sequence but cause the organism's genes to behave (or "express themselves") differently. One example of epigenetic change is the marking of the genes by DNA methylation which determines whether they will be expressed or not. Gene expression can also be controlled by repressor proteins that attach to silencer regions of the DNA and prevent that region of the DNA code from being expressed. Epigenetic marks may be added or removed from the DNA during programmed stages of development of the plant, and are responsible, for example, for the differences between anthers, petals and normal leaves, despite the fact that they all have the same underlying genetic code. Epigenetic changes may be temporary or may remain through successive cell divisions for the remainder of the cell's life. Some epigenetic changes have been shown to be heritable, while others are reset in the germ cells.
Epigenetic changes in eukaryotic biology serve to regulate the process of cellular differentiation. During morphogenesis, totipotent stem cells become the various pluripotent cell lines of the embryo, which in turn become fully differentiated cells. A single fertilized egg cell, the zygote, gives rise to the many different plant cell types including parenchyma, xylem vessel elements, phloem sieve tubes, guard cells of the epidermis, etc. as it continues to divide. The process results from the epigenetic activation of some genes and inhibition of others.
Unlike animals, many plant cells, particularly those of the parenchyma, do not terminally differentiate, remaining totipotent with the ability to give rise to a new individual plant. Exceptions include highly lignified cells, the sclerenchyma and xylem which are dead at maturity, and the phloem sieve tubes which lack nuclei. While plants use many of the same epigenetic mechanisms as animals, such as chromatin remodeling, an alternative hypothesis is that plants set their gene expression patterns using positional information from the environment and surrounding cells to determine their developmental fate.
Evolution.
The chloroplasts of plants have a number of biochemical, structural and genetic similarities to cyanobacteria, (commonly but incorrectly known as "blue-green algae") and are thought to be derived from an ancient endosymbiotic relationship between an ancestral eukaryotic cell and a cyanobacterial resident.
The algae are a polyphyletic group and are placed in various divisions, some more closely related to plants than others. There are many differences between them in features such as cell wall composition, biochemistry, pigmentation, chloroplast structure and nutrient reserves. The algal division Charophyta, sister to the green algal division Chlorophyta, is considered to contain the ancestor of true plants. The Charophyte class Charophyceae and the land plant sub-kingdom Embryophyta together form the monophyletic group or clade Streptophytina.
Nonvascular land plants are embryophytes that lack the vascular tissues xylem and phloem. They include mosses, liverworts and hornworts. Pteridophytic vascular plants with true xylem and phloem that reproduced by spores germinating into free-living gametophytes evolved during the Silurian period and diversified into several lineages during the late Silurian and early Devonian. Representatives of the lycopods have survived to the present day. By the end of the Devonian period, several groups, including the lycopods, sphenophylls and progymnosperms, had independently evolved "megaspory" – their spores were of two distinct sizes, larger megaspores and smaller microspores. Their reduced gametophytes developed from megaspores retained within the spore-producing organs (megasporangia) of the sporophyte, a condition known as endospory. Seeds consist of an endosporic megasporangium surrounded by one or two sheathing layers (integuments). The young sporophyte develops within the seed, which on germination splits to release it. The earliest known seed plants date from the latest Devonian Famennian stage. Following the evolution of the seed habit, seed plants diversified, giving rise to a number of now-extinct groups, including seed ferns, as well as the modern gymnosperms and angiosperms. Gymnosperms produce "naked seeds" not fully enclosed in an ovary; modern representatives include conifers, cycads, "Ginkgo", and Gnetales. Angiosperms produce seeds enclosed in a structure such as a carpel or an ovary. Ongoing research on the molecular phylogenetics of living plants appears to show that the angiosperms are a sister clade to the gymnosperms.
Plant physiology.
Plant physiology encompasses all the internal chemical and physical activities of plants associated with life. Chemicals obtained from the air, soil and water form the basis of all plant metabolism. The energy of sunlight, captured by oxygenic photosynthesis and released by cellular respiration, is the basis of almost all life. Photoautotrophs, including all green plants, algae and cyanobacteria gather energy directly from sunlight by photosynthesis. Heterotrophs including all animals, all fungi, all completely parasitic plants, and non-photosynthetic bacteria take in organic molecules produced by photoautotrophs and respire them or use them in the construction of cells and tissues. Respiration is the oxidation of carbon compounds by breaking them down into simpler structures to release the energy they contain, essentially the opposite of photosynthesis.
Molecules are moved within plants by transport processes that operate at a variety of spatial scales. Subcellular transport of ions, electrons and molecules such as water and enzymes occurs across cell membranes. Minerals and water are transported from roots to other parts of the plant in the transpiration stream. Diffusion, osmosis, and active transport and mass flow are all different ways transport can occur. Examples of elements that plants need to transport are nitrogen, phosphorus, potassium, calcium, magnesium, and sulphur. In vascular plants, these elements are extracted from the soil as soluble ions by the roots and transported throughout the plant in the xylem. Most of the elements required for plant nutrition come from the chemical breakdown of soil minerals. Sucrose produced by photosynthesis is transported from the leaves to other parts of the plant in the phloem and plant hormones are transported by a variety of processes.
Plant hormones.
Plants are not passive, but respond to external signals such as light, touch, and injury by moving or growing towards or away from the stimulus, as appropriate. Tangible evidence of touch sensitivity is the almost instantaneous collapse of leaflets of "Mimosa pudica", the insect traps of Venus flytrap and bladderworts, and the pollinia of orchids.
The hypothesis that plant growth and development is coordinated by plant hormones or plant growth regulators first emerged in the late 19th century. Darwin experimented on the movements of plant shoots and roots towards light and gravity, and concluded "It is hardly an exaggeration to say that the tip of the radicle . . acts like the brain of one of the lower animals . . directing the several movements". About the same time, the role of auxins (from the Greek auxein, to grow) in control of plant growth was first outlined by the Dutch scientist Frits Went. The first known auxin, indole-3-acetic acid (IAA), which promotes cell growth, was only isolated from plants about 50 years later. This compound mediates the tropic responses of shoots and roots towards light and gravity. The finding in 1939 that plant callus could be maintained in culture containing IAA, followed by the observation in 1947 that it could be induced to form roots and shoots by controlling the concentration of growth hormones were key steps in the development of plant biotechnology and genetic modification.
Another class of phytohormones is the jasmonates, first isolated from the oil of "Jasminum grandiflorum" which regulates wound responses in plants by unblocking the expression of genes required in the systemic acquired resistance response to pathogen attack.
In addition to being the primary energy source for plants, light functions as a signalling device, providing information to the plant, such as how much sunlight the plant receives each day. This can result in adaptive changes in a process known as photomorphogenesis. Phytochromes are the photoreceptors in a plant that are sensitive to light.
Plant anatomy and morphology.
Plant anatomy is the study of the structure of plant cells and tissues, whereas plant morphology is the study of their external form. 
All plants are multicellular eukaryotes, their DNA stored in nuclei. The characteristic features of plant cells that distinguish them from those of animals and fungi include a primary cell wall composed of the polysaccharides cellulose, hemicellulose and pectin, larger vacuoles than in animal cells and the presence of plastids with unique photosynthetic and biosynthetic functions as in the chloroplasts. Other plastids contain storage products such as starch (amyloplasts) or lipids (elaioplasts). Uniquely, streptophyte cells and those of the green algal order Trentepohliales divide by construction of a phragmoplast as a template for building a cell plate late in cell division.
The bodies of vascular plants including clubmosses, ferns and seed plants (gymnosperms and angiosperms) generally have aerial and subterranean subsystems. The shoots consist of stems bearing green photosynthesising leaves and reproductive structures. The underground vascularised roots bear root hairs at their tips and generally lack chlorophyll. Non-vascular plants, the liverworts, hornworts and mosses do not produce ground-penetrating vascular roots and most of the plant participates in photosynthesis. The sporophyte generation is nonphotosynthetic in liverworts but may be able to contribute part of its energy needs by photosynthesis in mosses and hornworts.
The root system and the shoot system are interdependent – the usually nonphotosynthetic root system depends on the shoot system for food, and the usually photosynthetic shoot system depends on water and minerals from the root system. Cells in each system are capable of creating cells of the other and producing adventitious shoots or roots. Stolons and tubers are examples of shoots that can grow roots. Roots that spread out close to the surface, such as those of willows, can produce shoots and ultimately new plants. In the event that one of the systems is lost, the other can often regrow it. In fact it is possible to grow an entire plant from a single leaf, as is the case with "Saintpaulia", or even a single cell – which can dedifferentiate into a callus (a mass of unspecialised cells) that can grow into a new plant.
In vascular plants, the xylem and phloem are the conductive tissues that transport resources between shoots and roots. Roots are often adapted to store food such as sugars or starch, as in sugar beets and carrots.
Stems mainly provide support to the leaves and reproductive structures, but can store water in succulent plants such as cacti, food as in potato tubers, or reproduce vegetatively as in the stolons of strawberry plants or in the process of layering. Leaves gather sunlight and carry out photosynthesis. Large, flat, flexible, green leaves are called foliage leaves. Gymnosperms, such as conifers, cycads, "Ginkgo", and gnetophytes are seed-producing plants with open seeds. Angiosperms are seed-producing plants that produce flowers and have enclosed seeds. Woody plants, such as azaleas and oaks, undergo a secondary growth phase resulting in two additional types of tissues: wood (secondary xylem) and bark (secondary phloem and cork). All gymnosperms and many angiosperms are woody plants. Some plants reproduce sexually, some asexually, and some via both means.
Although reference to major morphological categories such as root, stem, leaf, and trichome are useful, one has to keep in mind that these categories are linked through intermediate forms so that a continuum between the categories results. Furthermore, structures can be seen as processes, that is, process combinations.
Systematic botany.
Systematic botany is part of systematic biology, which is concerned with the range and diversity of organisms and their relationships, particularly as determined by their evolutionary history. It involves, or is related to, biological classification, scientific taxonomy and phylogenetics. Biological classification is the method by which botanists group organisms into categories such as genera or species. Biological classification is a form of scientific taxonomy. Modern taxonomy is rooted in the work of Carolus Linnaeus, who grouped species according to shared physical characteristics. These groupings have since been revised to align better with the Darwinian principle of common descent – grouping organisms by ancestry rather than superficial characteristics. While scientists do not always agree on how to classify organisms, molecular phylogenetics, which uses DNA sequences as data, has driven many recent revisions along evolutionary lines and is likely to continue to do so. The dominant classification system is called Linnaean taxonomy. It includes ranks and binomial nomenclature. The nomenclature of botanical organisms is codified in the International Code of Nomenclature for algae, fungi, and plants (ICN) and administered by the International Botanical Congress.
Kingdom Plantae belongs to Domain Eukarya and is broken down recursively until each species is separately classified. The order is: Kingdom; Phylum (or Division); Class; Order; Family; Genus (plural "genera"); Species. The scientific name of a plant represents its genus and its species within the genus, resulting in a single world-wide name for each organism. For example, the tiger lily is "Lilium columbianum". "Lilium" is the genus, and "columbianum" the specific epithet. The combination is the name of the species. When writing the scientific name of an organism, it is proper to capitalise the first letter in the genus and put all of the specific epithet in lowercase. Additionally, the entire term is ordinarily italicised (or underlined when italics are not available).
The evolutionary relationships and heredity of a group of organisms is called its phylogeny. Phylogenetic studies attempt to discover phylogenies. The basic approach is to use similarities based on shared inheritance to determine relationships. As an example, species of "Pereskia" are trees or bushes with prominent leaves. They do not obviously resemble a typical leafless cactus such as an "Echinocactus". However, both "Pereskia" and "Echinocactus" have spines produced from areoles (highly specialised pad-like structures) suggesting that the two genera are indeed related.
Judging relationships based on shared characters requires care, since plants may resemble one another through convergent evolution in which characters have arisen independently. Some euphorbias have leafless, rounded bodies adapted to water conservation similar to those of globular cacti, but characters such as the structure of their flowers make it clear that the two groups are not closely related. The cladistic method takes a systematic approach to characters, distinguishing between those that carry no information about shared evolutionary history – such as those evolved separately in different groups (homoplasies) or those left over from ancestors (plesiomorphies) – and derived characters, which have been passed down from innovations in a shared ancestor (apomorphies). Only derived characters, such as the spine-producing areoles of cacti, provide evidence for descent from a common ancestor. The results of cladistic analyses are expressed as cladograms: tree-like diagrams showing the pattern of evolutionary branching and descent.
From the 1990s onwards, the predominant approach to constructing phylogenies for living plants has been molecular phylogenetics, which uses molecular characters, particularly DNA sequences, rather than morphological characters like the presence or absence of spines and areoles. The difference is that the genetic code itself is used to decide evolutionary relationships, instead of being used indirectly via the characters it gives rise to. Clive Stace describes this as having "direct access to the genetic basis of evolution." As a simple example, prior to the use of genetic evidence, fungi were thought either to be plants or to be more closely related to plants than animals. Genetic evidence suggests that the true evolutionary relationship of multicelled organisms is as shown in the cladogram below – fungi are more closely related to animals than to plants.
In 1998 the Angiosperm Phylogeny Group published a phylogeny for flowering plants based on an analysis of DNA sequences from most families of flowering plants. As a result of this work, many questions, such as which families represent the earliest branches of angiosperms, have now been answered. Investigating how plant species are related to each other allows botanists to better understand the process of evolution in plants. Despite the study of model plants and increasing use of DNA evidence, there is ongoing work and discussion among taxonomists about how best to classify plants into various taxa. Technological developments such as computers and electron microscopes have greatly increased the level of detail studied and speed at which data can be analysed.

</doc>
<doc id="4184" url="http://en.wikipedia.org/wiki?curid=4184" title="Bacillus thuringiensis">
Bacillus thuringiensis

Bacillus thuringiensis (or Bt) is a Gram-positive, soil-dwelling bacterium, commonly used as a biological pesticide. "B. thuringiensis" also occurs naturally in the gut of caterpillars of various types of moths and butterflies, as well on leaf surfaces, aquatic environments, animal feces, insect rich environments, flour mills and grain storage facilities.
During sporulation, many Bt strains produce crystal proteins (proteinaceous inclusions), called δ-endotoxins, that have Insecticide action. This has led to their use as insecticides, and more recently to genetically modified crops using Bt genes. Many crystal-producing Bt strains, though, do not have insecticidal properties.
Discovery and mechanism of insecticidal action.
"B. thuringiensis" was first discovered in 1901 by Japanese biologist Ishiwata Shigetane. In 1911, "B. thuringiensis" was rediscovered in Germany by Ernst Berliner, who isolated it as the cause of a disease called "Schlaffsucht" in flour moth caterpillars. In 1976, Robert A. Zakharyan reported the presence of a plasmid in a strain of "B. thuringiensis" and suggested the plasmid's involvement in endospore and crystal formation. "B. thuringiensis" is closely related to "B.cereus", a soil bacterium, and "B.anthracis", the cause of anthrax: the three organisms differ mainly in their plasmids. Like other members of the genus, all three are aerobes capable of producing endospores. Upon sporulation, "B. thuringiensis" forms crystals of proteinaceous insecticidal δ-endotoxins (called crystal proteins or Cry proteins), which are encoded by "cry" genes. In most strains of "B. thuringiensis", the "cry" genes are located on a plasmid (in other words, "cry" is not a chromosomal gene in most strains).
Cry toxins have specific activities against insect species of the orders Lepidoptera (moths and butterflies), Diptera (flies and mosquitoes), Coleoptera (beetles), Hymenoptera (wasps, bees, ants and sawflies) and nematodes. Thus, "B. thuringiensis" serves as an important reservoir of Cry toxins for production of biological insecticides and insect-resistant genetically modified crops. When insects ingest toxin crystals, the alkaline pH of their digestive tract denatures the insoluble crystals, making them soluble and thus amenable to being cut with proteases found in the insect gut, which liberate the cry toxin from the crystal. The Cry toxin is then inserted into the insect gut cell membrane, paralyzing the digestive tract and forming a pore. The insect stops eating and starves to death; live Bt bacteria may also colonize the insect which can contribute to death. Research published in 2006 has suggested the midgut bacteria of susceptible larvae are required for "B. thuringiensis" insecticidal activity.
In 1996 another class of insecticidal proteins in Bt was discovered; the vegetative insecticidal proteins (Vip). Vip proteins do not share sequence homology with Cry proteins, in general do not compete for the same receptors, and some kill different insects than do Cry proteins.
In 2000, a novel functional group of Cry protein, designated parasporin, was discovered from non-insecticidal "B. thuringiensis" isolates. The proteins of parasporin group are defined as "Bacillus thuringiensis" and related bacterial parasporal proteins that are non-hemolytic but capable of preferentially killing cancer cells. As of January 2013, parasporins comprise six subfamilies (PS1 to PS6).
Use of spores and proteins in pest control.
Spores and crystalline insecticidal proteins produced by "B. thuringiensis" have been used to control insect pests since the 1920s and are often applied as liquid sprays. They are now used as specific insecticides under trade names such as DiPel and Thuricide. Because of their specificity, these pesticides are regarded as environmentally friendly, with little or no effect on humans, wildlife, pollinators, and most other beneficial insects and are used in Organic farming, however the manuals for these products do contain many environmental and human health warnings, and a 2012 European regulatory peer review of 5 approved strains found that while there is data to support some claims of low toxicity to humans and the environment, there is insufficient data to justify many of these claims.
"Bacillus thuringiensis" serovar "israelensis", a strain of "B. thuringiensis" is widely used as a larvicide against mosquito larvae, where it is also considered an environmentally friendly method of mosquito control.
As, for example, insects develop resistance to Bt, or there is desire to force mutations to modify organism characteristics or to use homologous recombinant genetic engineering to improve crystal size and increase pesticidal activity or broaden the host range of Bt and obtain more effective formulations, etc., new strains of Bt are developed and introduced over time. Each new strain is given a unique number and registered with the U.S. EPA and allowances may be given for genetic modification depending on "its parental strains, the proposed pesticide use pattern, and the manner and extent to which the organism has been genetically modified". Formulations of Bt that are approved for organic farming in the US are listed at the website of the Organic Materials Review Institute (OMRI) and several university extension websites offer advice on how to use Bt spore or protein preparations in organic farming.
Use of Bt genes in genetic engineering of plants for pest control.
The Belgian company Plant Genetic Systems (now part of Bayer CropScience) was the first company (in 1985) to develop genetically modified crops (tobacco) with insect tolerance by expressing "cry" genes from "B. thuringiensis". The Bt tobacco was never commercialized; tobacco plants are used to test genetic modifications since they are easy to manipulate genetically and are not part of the food supply.
Usage.
In 1995, potato plants producing CRY 3A Bt toxin were approved safe by the Environmental Protection Agency, making it the first human-modified pesticide-producing crop to be approved in the USA, though many plants produce pesticides naturally, including tobacco, coffee plants, cocoa, and black walnut. This was the "New Leaf" potato, and it was removed from the market in 2001 due to lack of interest. For current crops and their acreage under cultivation, see genetically modified crops.
In 1996, genetically modified maize producing Bt cry protein was approved, which killed the European corn borer and related species; subsequent Bt genes were introduced that killed corn rootworm larvae.
The Bt genes that have been engineered into crops and approved for release include the following, singly and stacked: Cry1A.105, CryIAb, CryIF, Cry2Ab, Cry3Bb1, Cry34Ab1, Cry35Ab1, mCry3A, and VIP, and the engineered crops include corn and cotton. Corn genetically modified to produce VIP was first approved in the US in 2010. Monsanto developed a soybean expressing Cry1Ac and the glyphosate-resistance gene for the Brazilian market, which completed the Brazilian regulatory process in 2010.
Insect resistance.
In November 2009, Monsanto scientists found the pink bollworm had become resistant to the first generation Bt cotton in parts of Gujarat, India - that generation expresses one Bt gene, "Cry1Ac". This was the first instance of Bt resistance confirmed by Monsanto anywhere in the world. Monsanto immediately responded by introducing a second generation cotton with multiple Bt proteins, which was rapidly adopted. Bollworm resistance to first generation Bt cotton was also identified in Australia, China, Spain and the United States.
Secondary pests.
Several studies have documented surges in "sucking pests" (which are not affected by Bt toxins) within a few years of adoption of Bt cotton. In China, the main problem has been with mirids, which have in some cases "completely eroded all benefits from Bt cotton cultivation”. A 2009 study in China concluded that the increase in sucking pests depended on local temperature and rainfall conditions and increased in half the villages studied. The increase in insecticide use for the control of these secondary insects was far smaller than the reduction in total insecticide use due to Bt cotton adoption. Another study published in 2011 was based on a survey of 1,000 randomly selected farm households in five provinces in China and found that the reduction in pesticide use in Bt cotton cultivars is significantly lower than that reported in research elsewhere, consistent with the hypothesis suggested by recent studies that more pesticide sprayings are needed over time to control emerging secondary pests, such as aphids, spider mites, and lygus bugs.
Similar problems have been reported in India, with both mealy bugs and aphids although a survey of small Indian farms between 2002 and 2008 concluded that Bt cotton adoption has led to higher yields and lower pesticide use, decreasing over time.
Controversies.
There are controversies around GMOs on several levels, including whether making them is ethical, whether food produced with them is safe, whether such food should be labeled and if so how, whether agricultural biotech is needed to address world hunger now or in the future, and more specifically to GM crops—intellectual property and market dynamics; environmental effects of GM crops; and GM crops' role in industrial agricultural more generally. There are also issues specific to Bt transgenic crops.
Lepidopteran toxicity.
The most publicised problem associated with Bt crops is the claim that pollen from Bt maize could kill the monarch butterfly. The paper produced a public uproar and demonstrations against Bt maize; however by 2001 several follow-up studies coordinated by the USDA had proven that "the most common types of Bt maize pollen are not toxic to monarch larvae in concentrations the insects would encounter in the fields."
Wild maize genetic mixing.
A study published in "Nature" in 2001 reported that Bt-containing maize genes were found in maize in its center of origin, Oaxaca, Mexico. In 2002 "Nature" "concluded that the evidence available is not sufficient to justify the publication of the original paper." A significant controversy happened over the paper and "Nature"s unprecedented notice.
A subsequent large-scale study, in 2005, failed to find any evidence of genetic mixing in Oaxaca. A 2007 study found that "transgenic proteins expressed in maize were found in two (0.96%) of 208 samples from farmers' fields, located in two (8%) of 25 sampled communities. Mexico imports a substantial amount of maize from the US, and due to formal and informal seed networks among rural farmers, there are many potential routes of entrance for transgenic maize into food and feed webs." A study published in 2008 showed some small-scale (about 1%) introduction of transgenic sequences in sampled fields in Mexico; it did not find evidence for or against this introduced genetic material being inherited by the next generation of plants. That study was immediately criticized, with the reviewer writing that "Genetically any given plant should be either non-transgenic or transgenic, therefore for leaf tissue of a single transgenic plant, a GMO level close to 100% is expected. In their study, the authors chose to classify leaf samples as transgenic despite GMO levels of ∼0.1%. We contend that results such as these are incorrectly interpreted as positive and are more likely to be indicative of contamination in the laboratory."
Colony collapse disorder.
As of 2007, a new phenomenon called colony collapse disorder (CCD) began affecting bee hives all over North America. Initial speculation on possible causes ranged from new parasites to pesticide use to the use of Bt transgenic crops. The Mid-Atlantic Apiculture Research and Extension Consortium published a report in March 2007 that found no evidence that pollen from Bt crops is adversely affecting bees. According to the USDA, "Genetically modified (GM) crops, most commonly Bt corn, have been offered up as the cause of CCD. But there is no correlation between where GM crops are planted and the pattern of CCD incidents. Also, GM crops have been widely planted since the late 1990s, but CCD did not appear until 2006. In addition, CCD has been reported in countries that do not allow GM crops to be planted, such as Switzerland. German researchers have noted in one study a possible correlation between exposure to Bt pollen and compromised immunity to Nosema." The actual cause of CCD was unknown in 2007, and scientists believe that it may have multiple exacerbating causes.
Beta-exotoxins.
Some isolates of "B. thuringiensis" produce a class of insecticidal small molecules called beta-exotoxin, the common name for which is thuringiensin. A consensus document produced by the OECD says: "Beta-exotoxin and the other Bacillus toxins may contribute to the insecticidal toxicity of the bacterium to lepidopteran, dipteran, and coleopteran insects. Beta-exotoxin is known to be toxic to humans and almost all other forms of life and its presence is prohibited in B. thuringiensis microbial products. Engineering of plants to contain and express only the genes for δ-endotoxins avoids the problem of assessing the risks posed by these other toxins that may be produced in microbial preparations."

</doc>
<doc id="4185" url="http://en.wikipedia.org/wiki?curid=4185" title="Bacteriophage">
Bacteriophage

A bacteriophage (informally, "phage" ) is a virus that infects and replicates within a bacterium. The term is derived from 'bacteria' and the Greek φαγεῖν "phagein" "to devour". Bacteriophages are composed of proteins that encapsulate a DNA or RNA genome, and may have relatively simple or elaborate structures. Their genomes may encode as few as four genes, and as many as hundreds of genes. Phage replicate within the bacterium following the injection of their genome into its cytoplasm. Bacteriophage are among the most common and diverse entities in the biosphere.
Phages are widely distributed in locations populated by bacterial hosts, such as soil or the intestines of animals. One of the densest natural sources for phages and other viruses is sea water, where up to 9×108 virions per milliliter have been found in microbial mats at the surface, and up to 70% of marine bacteria may be infected by phages.
They have been used for over 90 years as an alternative to antibiotics in the former Soviet Union and Central Europe, as well as in France. They are seen as a possible therapy against multi-drug-resistant strains of many bacteria.
Classification.
Bacteriophages occur abundantly in the biosphere, with different virions, genomes and lifestyles. Phages are classified by the International Committee on Taxonomy of Viruses (ICTV) according to morphology and nucleic acid.
Nineteen families are currently recognised that infect bacteria and archaea. Of these, only two families have RNA genomes and only five families are enveloped. Of the viral families with DNA genomes, only two have single-stranded genomes. Eight of the viral families with DNA genomes have circular genomes, while nine have linear genomes. Nine families infect bacteria only, nine infect archaea only, and one ("Tectiviridae") infects both bacteria and archaea.
History.
Since ancient times, reports of river waters having the ability to cure infectious diseases, such as leprosy, have been documented. In 1896, Ernest Hanbury Hankin reported that something in the waters of the Ganges and Yamuna rivers in India had marked antibacterial action against cholera and could pass through a very fine porcelain filter. In 1915, British bacteriologist Frederick Twort, superintendent of the Brown Institution of London, discovered a small agent that infected and killed bacteria. He believed the agent must be one of the following:
Twort's work was interrupted by the onset of World War I and shortage of funding. Independently, French-Canadian microbiologist Félix d'Hérelle, working at the Pasteur Institute in Paris, announced on 3 September 1917, that he had discovered "an invisible, antagonistic microbe of the dysentery bacillus". For d’Hérelle, there was no question as to the nature of his discovery: "In a flash I had understood: what caused my clear spots was in fact an invisible microbe ... a virus parasitic on bacteria." D'Hérelle called the virus a bacteriophage or bacteria-eater (from the Greek "phagein" meaning to eat). He also recorded a dramatic account of a man suffering from dysentery who was restored to good health by the bacteriophages. It was D'Herelle who conducted much research into bacteriophages and introduced the concept of phage therapy.
In 1969, Max Delbrück, Alfred Hershey and Salvador Luria were awarded the Nobel Prize in Physiology and Medicine for their discoveries of the replication of viruses and their genetic structure.
Phage therapy.
Phages were discovered to be antibacterial agents and were used in Georgia and the United States during the 1920s and 1930s for treating bacterial infections. They had widespread use, including treatment of soldiers in the Red Army. However, they were abandoned for general use in the West for several reasons:
Their use has continued since the end of the Cold War in Georgia and elsewhere in Central and Eastern Europe. Globalyz Biotech is an international joint venture that commercializes bacteriophage treatment and its various applications across the globe. The company has successfully used bacteriophages in administering Phage therapy to patients suffering from bacterial infections, including: Staphylococcus (including MRSA), Streptococcus, Pseudomonas, Salmonella, skin and soft tissue, gastrointestinal, respiratory, and orthopedic infections. In 1923, the Eliava Institute was opened in Tbilisi, Georgia, to research this new science and put it into practice.
The first regulated randomized, double blind clinical trial was reported in the Journal of Wound Care in June 2009, which evaluated the safety and efficacy of a bacteriophage cocktail to treat infected venous leg ulcers in human patients. The study was approved by the FDA as a Phase I clinical trial. Study results satisfactorily demonstrated safety of therapeutic application of bacteriophages, however it did not show efficacy. The authors explain that the use of certain chemicals that are part of standard wound care (e.g. lactoferrin, silver) may have interfered with bacteriophage viability. Another regulated clinical trial in Western Europe (treatment of ear infections caused by "Pseudomonas aeruginosa") was reported shortly after in the journal Clinical Otolaryngology in August 2009. The study concludes that bacteriophage preparations were safe and effective for treatment of chronic ear infections in humans. Additionally, there have been numerous animal and other experimental clinical trials evaluating the efficacy of bacteriophages for various diseases, such as infected burns and wounds, and cystic fibrosis associated lung infections, among others. Meanwhile, Western scientists are developing engineered viruses to overcome antibiotic resistance, and engineering the phage genes responsible for coding enzymes which degrade the biofilm matrix, phage structural proteins and also enzymes responsible for lysis of bacterial cell wall.
The water within some rivers traditionally thought to have healing powers, including India's Ganges River, may provide sources of naturally-occurring viral candidates for phage therapy.
Replication.
Bacteriophages may have a lytic cycle or a lysogenic cycle, and a few viruses are capable of carrying out both. With "lytic phages" such as the T4 phage, bacterial cells are broken open (lysed) and destroyed after immediate replication of the virion. As soon as the cell is destroyed, the phage progeny can find new hosts to infect. Lytic phages are more suitable for phage therapy. Some lytic phages undergo a phenomenon known as lysis inhibition, where completed phage progeny will not immediately lyse out of the cell if extracellular phage concentrations are high. This mechanism is not identical to that of temperate phage going dormant and is usually temporary.
In contrast, the "lysogenic cycle" does not result in immediate lysing of the host cell. Those phages able to undergo lysogeny are known as temperate phages. Their viral genome will integrate with host DNA and replicate along with it fairly harmlessly, or may even become established as a plasmid. The virus remains dormant until host conditions deteriorate, perhaps due to depletion of nutrients; then, the endogenous phages (known as prophages) become active. At this point they initiate the reproductive cycle, resulting in lysis of the host cell. As the lysogenic cycle allows the host cell to continue to survive and reproduce, the virus is reproduced in all of the cell’s offspring.
An example of a bacteriophage known to follow the lysogenic cycle and the lytic cycle is the phage lambda of "E. coli."
Sometimes prophages may provide benefits to the host bacterium while they are dormant by adding new functions to the bacterial genome in a phenomenon called lysogenic conversion. Examples are the conversion of harmless strains of "Corynebacterium diphtheriae" or "Vibrio cholerae" by bacteriophages to a highly virulent ones, which cause Diphtheria or cholera, respectively. Strategies to combat certain bacterial infections by targeting these toxin-encoding prophages have been proposed.
Attachment and penetration.
To enter a host cell, bacteriophages attach to specific receptors on the surface of bacteria, including lipopolysaccharides, teichoic acids, proteins, or even flagella. This specificity means a bacteriophage can infect only certain bacteria bearing receptors to which they can bind, which in turn determines the phage's host range. Host growth conditions also influence the ability of the phage to attach and invade them. As phage virions do not move independently, they must rely on random encounters with the right receptors when in solution (blood, lymphatic circulation, irrigation, soil water, etc.).
Myovirus bacteriophages use a hypodermic syringe-like motion to inject their genetic material into the cell. After making contact with the appropriate receptor, the tail fibers flex to bring the base plate closer to the surface of the cell; this is known as reversible binding. Once attached completely, irreversible binding is initiated and the tail contracts, possibly with the help of ATP present in the tail, injecting genetic material through the bacterial membrane.
Podoviruses lack an elongated tail sheath similar to that of a myovirus, so they instead use their small, tooth-like tail fibers to enzymatically degrade a portion of the cell membrane before inserting their genetic material.
Synthesis of proteins and nucleic acid.
Within minutes, bacterial ribosomes start translating viral mRNA into protein. For RNA-based phages, RNA replicase is synthesized early in the process. Proteins modify the bacterial RNA polymerase so it preferentially transcribes viral mRNA. The host’s normal synthesis of proteins and nucleic acids is disrupted, and it is forced to manufacture viral products, instead. These products go on to become part of new virions within the cell, helper proteins that help assemble the new virions, or proteins involved in cell lysis. Walter Fiers (University of Ghent, Belgium) was the first to establish the complete nucleotide sequence of a gene (1972) and of the viral genome of bacteriophage MS2 (1976).
Virion assembly.
In the case of the T4 phage, the construction of new virus particles involves the assistance of helper proteins. The base plates are assembled first, with the tails being built upon them afterwards. The head capsids, constructed separately, will spontaneously assemble with the tails. The DNA is packed efficiently within the heads. The whole process takes about 15 minutes.
Release of virions.
Phages may be released via cell lysis, by extrusion, or, in a few cases, by budding. Lysis, by tailed phages, is achieved by an enzyme called endolysin, which attacks and breaks down the cell wall peptidoglycan. An altogether different phage type, the filamentous phages, make the host cell continually secrete new virus particles. Released virions are described as free, and, unless defective, are capable of infecting a new bacterium. Budding is associated with certain "Mycoplasma" phages. In contrast to virion release, phages displaying a lysogenic cycle do not kill the host but, rather, become long-term residents as prophage.
Genome structure.
Bacteriophage genomes are especially mosaic: the genome of any one phage species appears to be composed of numerous individual modules. These modules may be found in other phage species in different arrangements. Mycobacteriophages - bacteriophages with mycobacterial hosts - have provided excellent examples of this mosaicism. In these mycobacteriophages, genetic assortment may be the result of repeated instances of site-specific recombination and illegitimate recombination (the result of phage genome acquisition of bacterial host genetic sequences). It should be noted, however, that evolutionary mechanisms shaping the genomes of bacterial viruses vary between different families and depend on the type of the nucleic acid, characteristics of the virion structure, as well as the mode of the viral life cycle.
In the environment.
Metagenomics has allowed the in-water detection of bacteriophages that was not possible previously.
Bacteriophages have also been used in hydrological tracing and modelling in river systems, especially where surface water and groundwater interactions occur. The use of phages is preferred to the more conventional dye marker because they are significantly less absorbed when passing through ground waters and they are readily detected at very low concentrations.
Other areas of use.
Since 2006, the United States Food and Drug Administration (FDA) and USDA have approved several bacteriophage products. Intralytix introduced LMP-102, also called ListShield as a food additive to target and kill "Listeria monocytogenes". LMP-102 (ListShield by Intralytix) was approved for treating ready-to-eat (RTE) poultry and meat products. In that same year, the FDA approved LISTEX by Micreos (formerly EBI Food Safety) using bacteriophages on cheese to kill the "L. monocytogenes" bacteria, giving them generally recognized as safe (GRAS) status. In July 2007, the same bacteriophage were approved for use on all food products. In 2011 USDA confirmed that LISTEX is a clean label processing-aid and is included in USDA. Research in the field of food safety is continuing to see if lytic phages are a viable option to control other food-borne pathogens in various food products.
Government agencies in the West have for several years been looking to Georgia and the former Soviet Union for help with exploiting phages for counteracting bioweapons and toxins, such as anthrax and botulism. Developments are continuing among research groups in the US. Other uses include spray application in horticulture for protecting plants and vegetable produce from decay and the spread of bacterial disease. Other applications for bacteriophages are as biocides for environmental surfaces, e.g., in hospitals, and as preventative treatments for catheters and medical devices prior to use in clinical settings. The technology for phages to be applied to dry surfaces, e.g., uniforms, curtains, or even sutures for surgery now exists. Clinical trials reported in the "Lancet" show success in veterinary treatment of pet dogs with otitis.
Phage display is a different use of phages involving a library of phages with a variable peptide linked to a surface protein. Each phage's genome encodes the variant of the protein displayed on its surface (hence the name), providing a link between the peptide variant and its encoding gene. Variant phages from the library can be selected through their binding affinity to an immobilized molecule (e.g., botulism toxin) to neutralize it. The bound, selected phages can be multiplied by reinfecting a susceptible bacterial strain, thus allowing them to retrieve the peptides encoded in them for further study.
The SEPTIC bacterium sensing and identification method uses the ion emission and its dynamics during phage infection and offers high specificity and speed for detection.
Phage-ligand technology makes use of proteins, which are identified from bacteriophages, characterized and recombinantly expressed for various applications such as binding of bacteria and bacterial components (e.g. endotoxin) and lysis of bacteria.
Bacteriophages are also important model organisms for studying principles of evolution and ecology.
Model bacteriophages.
The following bacteriophages are extensively studied:

</doc>
<doc id="4187" url="http://en.wikipedia.org/wiki?curid=4187" title="Bactericide">
Bactericide

A bactericide or bacteriocide, sometimes abbreviated Bcidal, is a substance that kills bacteria. Bactericides are disinfectants, antiseptics, or antibiotics.
Bactericidal disinfectants.
The most used disinfectants are those applying
Bactericidal antiseptics.
As antiseptics (i.e., germicide agents that can be used on human or animal body, skin, mucoses, wounds and the like), few of the above mentioned disinfectants can be used, under proper conditions (mainly concentration, pH, temperature and toxicity toward humans and animals). Among them, some important are
Others are generally not applicable as safe antiseptics, either because of their corrosive or toxic nature.
Bactericidal antibiotics.
Bactericidal antibiotics kill bacteria; bacteriostatic antibiotics slow their growth or reproduction.
Antibiotics that inhibit cell wall synthesis: the Beta-lactam antibiotics (penicillin derivatives (penams), cephalosporins (cephems), monobactams, and carbapenems) and vancomycin.
Also bactericidal are daptomycin, fluoroquinolones, metronidazole, nitrofurantoin, co-trimoxazole, telithromycin.
Aminoglycosidic antibiotics are usually considered bactericidal, although they may be bacteriostatic with some organisms

</doc>
<doc id="4188" url="http://en.wikipedia.org/wiki?curid=4188" title="Brion Gysin">
Brion Gysin

Brion Gysin (19 January 1916 – 13 July 1986) was a painter, writer, sound poet, and performance artist born in Taplow, Buckinghamshire.
He is best known for his discovery of the cut-up technique, used by his friend, the novelist William S. Burroughs. With the engineer Ian Sommerville he invented the Dreamachine, a flicker device designed as an art object to be viewed with the eyes closed. It was in painting and drawing, however, that Gysin devoted his greatest efforts, creating calligraphic works inspired by the cursive Japanese "grass" script and Arabic script. Burroughs later stated that "Brion Gysin was the only man I ever respected."
Biography.
Early years.
John Clifford Brian Gysin was born at Taplow House, England, a Canadian military hospital. His mother, Stella Margaret Martin, was a Canadian from Deseronto, Ontario. His father, Leonard Gysin, a captain with the Canadian Expeditionary Force, was killed in action eight months after his son's birth. Stella returned to Canada and settled in Edmonton, Alberta where her son became "the only Catholic day-boy at an Anglican boarding school". Graduating at fifteen, Gysin was sent to Downside School in Stratton-on-the-Fosse, near Bath, Somerset in England, a prestigious college run by the Benedictines and known as "the Eton of Catholic public schools". Despite attending a Catholic school, Gysin became an atheist.
Surrealism.
In 1934, he moved to Paris to study "La Civilisation Française", an open course given at the Sorbonne where he made literary and artistic contacts through Marie Berthe Aurenche, Max Ernst's second wife. He joined the Surrealist Group and began frequenting Valentine Hugo, Leonor Fini, Salvador Dalí, Picasso and Dora Maar. A year later, he had his first exhibition at the "Galerie Quatre Chemins" in Paris with Ernst, Picasso, Hans Arp, Hans Bellmer, Victor Brauner, Giorgio de Chirico, Dalí, Marcel Duchamp, René Magritte, Man Ray and Yves Tanguy. On the day of the preview, however, he was expelled from the Surrealist Group by André Breton, who ordered the poet Paul Éluard to take down his pictures. Gysin was 19 years old. His biographer, John Geiger, suggests the arbitrary expulsion "had the effect of a curse. Years later, he blamed other failures on the Breton incident. It gave rise to conspiracy theories about the powerful interests who seek control of the art world. He gave various explanations for the expulsion, the more elaborate involving 'insubordination' or "lèse majesté" towards Breton".
After World War II.
After serving in the U.S. army during World War II, Gysin published a biography of Josiah "Uncle Tom" Henson titled, "To Master, a Long Goodnight: The History of Slavery in Canada" (1946). A gifted draughtsman, he took an 18-month course learning the Japanese language (including calligraphy) that would greatly influence his artwork. In 1949, he was among the first Fulbright Fellows. His goal: to research the history of slavery at the University of Bordeaux and in the Archivo de Indias in Seville, Spain, a project that he later abandoned. He moved to Tangier, Morocco after visiting the city with novelist and composer Paul Bowles in 1950.
Morocco and the Beat Hotel.
In 1954 in Tangier, Gysin opened a restaurant called The 1001 Nights, with his friend Mohamed Hamri, who was the cook. Gysin hired the Master Musicians of Jajouka from the village of Jajouka to perform alongside entertainment that included acrobats, a dancing boy and fire eaters. The musicians performed there for an international clientele that included William S. Burroughs. Gysin lost the business in 1958, and the restaurant closed permanently. That same year, Gysin returned to Paris, taking lodgings in a flophouse located at 9 rue Gît-le-Coeur that would become famous as the Beat Hotel. Working on a drawing, he discovered a Dada technique by accident:
William Burroughs and I first went into techniques of writing, together, back in room No. 15 of the Beat Hotel during the cold Paris spring of 1958... Burroughs was more intent on Scotch-taping his photos together into one great continuum on the wall, where scenes faded and slipped into one another, than occupied with editing the monster manuscript... "Naked Lunch" appeared and Burroughs disappeared. He kicked his habit with apomorphine and flew off to London to see Dr Dent, who had first turned him on to the cure. While cutting a mount for a drawing in room No. 15, I sliced through a pile of newspapers with my Stanley blade and thought of what I had said to Burroughs some six months earlier about the necessity for turning painters' techniques directly into writing. I picked up the raw words and began to piece together texts that later appeared as "First Cut-Ups" in "Minutes to Go" (Two Cities, Paris 1960).
When Burroughs returned from London in September 1959, Gysin not only shared his discovery with his friend but the new techniques he had developed for it. Burroughs then put the techniques to use while completing "Naked Lunch" and the experiment dramatically changed the landscape of American literature. Gysin helped Burroughs with the editing of several of his novels including "Interzone", and wrote a script for a film version of "Naked Lunch", which was never produced. The pair collaborated on a large manuscript for Grove Press titled "The Third Mind" but it was determined that it would be impractical to publish it as originally envisioned. The book later published under that title incorporates little of this material. Interviewed for "The Guardian" in 1997, Burroughs explained that Gysin was "the only man that I've ever respected in my life. I've admired people, I've liked them, but he's the only man I've ever respected." In 1969, Gysin completed his finest novel, "The Process", a work judged by critic Robert Palmer as "a classic of 20th century modernism".
A consummate innovator, Gysin altered the cut-up technique to produce what he called permutation poems in which a single phrase was repeated several times with the words rearranged in a different order with each reiteration. An example of this is "I don't dig work, man/Man, work I don't dig." Many of these permutations were derived using a random sequence generator in an early computer program written by Ian Sommerville. Commissioned by the BBC in 1960 to produce material for broadcast, Gysin's results included "Pistol Poem", which was created by recording a gun firing at different distances and then splicing the sounds. That year, the piece was subsequently used as a theme for the Paris performance of Le Domaine Poetique, a showcase for experimental works by people like Gysin, François Dufrêne, Bernard Heidsieck, and Henri Chopin.
With Sommerville, he built the Dreamachine in 1961. Described as "the first art object to be seen with the eyes closed", the flicker device uses alpha waves in the 8-16 Hz range to produce a change of consciousness in receptive viewers.
Later years.
He also worked extensively with noted jazz soprano saxophonist Steve Lacy.
He recorded an album in 1986 with French musician Ramuntcho Matta, featuring himself singing/rapping his own texts, with performances by Don Cherry, Elli Medeiros, Steve Lacy, Lizzy Mercier Descloux and more. The album was reissued on CD in 1993 by Crammed Discs, under the title "Self-Portrait Jumping".
As a joke, Gysin contributed a recipe for marijuana fudge to a cookbook by Alice B. Toklas; it was unintentionally included for publication, becoming famous under the name Alice B. Toklas brownies.
A heavily edited version of his novel, "The Last Museum", was published posthumously in 1986 by Faber & Faber (London) and by Grove Press (New York).
Made an American Commander of the French Ordre des Arts et des Lettres in 1985, Gysin died of lung cancer a year later, on July 13, 1986. An obituary by Robert Palmer published in "The New York Times" fittingly described him as a man who "threw off the sort of ideas that ordinary artists would parlay into a lifetime career, great clumps of ideas, as casually as a locomotive throws off sparks".
Burroughs on the Gysin cut-up.
In a 1966 interview by Conrad Knickerbocker for The Paris Review, William S. Burroughs explained that Brion Gysin was, to his knowledge, "the first to create cut-ups".
INTERVIEWER: How did you become interested in the cut-up technique?
BURROUGHS: A friend, Brion Gysin, an American poet and painter, who has lived in Europe for thirty years, was, as far as I know, the first to create cut-ups. His cut-up poem, "Minutes to Go", was broadcast by the BBC and later published in a pamphlet. I was in Paris in the summer of 1960; this was after the publication there of "Naked Lunch". I became interested in the possibilities of this technique, and I began experimenting myself. Of course, when you think of it, "The Waste Land" was the first great cut-up collage, and Tristan Tzara had done a bit along the same lines. Dos Passos used the same idea in 'The Camera Eye' sequences in "USA". I felt I had been working toward the same goal; thus it was a major revelation to me when I actually saw it being done.
Influence.
According to José Férez Kuri, author of "Brion Gysin: Tuning in to the Multimedia Age" (2003) and co-curator of a major retrospective of the artist's work at The Edmonton Art Gallery in 1998, Gysin's wide range of "radical ideas would become a source of inspiration for artists of the Beat Generation, as well as for their successors (among them David Bowie, Mick Jagger, Keith Haring, and Laurie Anderson)". Other artists include Genesis P-Orridge, John Zorn (as displayed on the 2013's Dreamachines album) and Brian Jones.
Selected bibliography.
Gysin is the subject of John Geiger's biography, "Nothing Is True Everything Is Permitted: The Life of Brion Gysin", and features in "Chapel of Extreme Experience: A Short History of Stroboscopic Light and the Dream Machine", also by Geiger. "Man From Nowhere: Storming the Citadels of Enlightenment with William Burroughs and Brion Gysin", a biographical study of Burroughs and Gysin with a collection of homages to Gysin, was authored by Joe Ambrose, Frank Rynne, and Terry Wilson with contributions by Marianne Faithfull, John Cale, William S. Burroughs, John Giorno, Stanley Booth, Bill Laswell, Mohamed Hamri, Keith Haring and Paul Bowles. A monograph on Gysin was published in 2003 by Thames and Hudson.
Works.
Prose
Radio
Cinema
Music
Painting

</doc>
<doc id="4190" url="http://en.wikipedia.org/wiki?curid=4190" title="Bulgarian">
Bulgarian

Bulgarian refers to anything of or relating to Bulgaria and may refer directly to:
or 

</doc>
<doc id="4191" url="http://en.wikipedia.org/wiki?curid=4191" title="BCG vaccine">
BCG vaccine

Bacillus Calmette–Guérin (historically Vaccin Bilié de Calmette et Guérin commonly referred to as Bacille de Calmette et Guérin or BCG) is a vaccine against tuberculosis that is prepared from a strain of the attenuated (virulence-reduced) live bovine tuberculosis bacillus, "Mycobacterium bovis", that has lost its virulence in humans by being specially subcultured in a culture medium, usually Middlebrook 7H9. Because the living bacilli evolve to make the best use of available nutrients, they become less well-adapted to human blood and can no longer induce disease when introduced into a human host. Still, they are similar enough to their wild ancestors to provide some degree of immunity against human tuberculosis. The BCG vaccine can be anywhere from 0 to 80% effective in preventing tuberculosis for a duration of 15 years; however, its protective effect appears to vary according to geography and the lab in which the vaccine strain was grown.
It is on the World Health Organization's List of Essential Medicines, a list of the most important medication needed in a basic health system.
Medical uses.
Tuberculosis: The main use of BCG is for vaccination against tuberculosis. BCG vaccine can be implemented after the birth intradermally. BCG vaccination is recommended to be given intradermally by a nurse skilled in the technique. A previous BCG vaccination can cause a false positive Mantoux test, although a very high-grade reading is usually due to active disease.
The age of the patient and the frequency with which BCG is given has always varied from country to country.
Method of administration.
Except in neonates, a tuberculin skin test should always be done before administering BCG. A reactive tuberculin skin test is a contraindication to BCG. Someone with a positive tuberculin reaction is not given BCG, because the risk of severe local inflammation and scarring is high, not because of the common misconception that tuberculin reactors "are already immune" and therefore do not need BCG. People found to have reactive tuberculin skin tests should be screened for active tuberculosis.
BCG is given as a single intradermal injection at the insertion of the deltoid. If BCG is accidentally given subcutaneously, then a local abscess may form (a "BCG-oma") that can sometimes ulcerate, and may require treatment with antibiotics immediately, otherwise without treatment it could spread the infection causing severe damage to vital organs. However, it is important to note an abscess is not always associated with incorrect administration, and it is one of the more common complications that can occur with the vaccination. Numerous medical studies on treatment of these abscesses with antibiotics have been done with varying results, but the consensus is once pus is aspirated and analysed, provided no unusual bacilli are present, the abscess will generally heal on its own in a matter of weeks.
The characteristic raised scar BCG immunization leaves is often used as proof of prior immunization. This scar must be distinguished from that of small pox vaccination, which it may resemble.
Efficacy.
The most controversial aspect of BCG is the variable efficacy found in different clinical trials, which appears to depend on geography. Trials conducted in the UK have consistently shown a protective effect of 60 to 80%, but those conducted elsewhere have shown no protective effect, and efficacy appears to fall the closer one gets to the equator.
A 1994 systematic review found that the BCG reduces the risk of getting TB by about 50%. There are differences in effectiveness, depending on region due to factors such as genetic differences in the populations, changes in environment, exposure to other bacterial infections, and conditions in the lab where the vaccine is grown, including genetic differences between the strains being cultured and the choice of growth medium.
The duration of protection of BCG is not clearly known. In those studies showing a protective effect, the data are inconsistent. The MRC study showed protection waned to 59% after 15 years and to zero after 20 years; however, a study looking at native Americans immunized in the 1930s found evidence of protection even 60 years after immunization, with only a slight waning in efficacy.
BCG seems to have its greatest effect in preventing miliary TB or TB meningitis, so it is still extensively used even in countries where efficacy against pulmonary tuberculosis is negligible.
Reasons.
A number of possible reasons for the variable efficacy of BCG in different countries have been proposed, but none have been proven, and none can explain the lack of efficacy in both low-TB burden countries (US) and high-TB burden countries (India). The reasons for variable efficacy have been discussed at length in a WHO document on BCG.
Adverse effects.
BCG is one of the most widely used vaccines in the world, with an unparalleled safety record. BCG immunization generally causes some pain and scarring at the site of injection. The main adverse effects are keloids—large, raised scars. The insertion of deltoid is most frequently used because the local complication rate is smallest when that site is used. Nonetheless, the buttock is an alternative site of administration because it provides better cosmetic outcomes.
BCG vaccine should be given intradermally. If given subcutaneously, it may induce local infection and spread to the regional lymph nodes, causing either suppurative and nonsuppurative lymphadenitis. Conservative management is usually adequate for nonsuppurative lymphadenitis. If suppuration occurs, it may need needle aspiration. For nonresolving suppuration, surgical excision is required, but not incision. Uncommonly, breast and gluteal abscesses can occur due to haematogenous and lymphangiomatous spread. Regional bone infection (BCG osteomyelitis or osteitis) and disseminated BCG infection are rare complications of BCG vaccination, but potentially life-threatening. Systemic antituberculous therapy may be helpful in severe complications.
If BCG is accidentally given to an immunocompromised patient (e.g., an infant with SCID), it can cause disseminated or life-threatening infection. The documented incidence of this happening is less than one per million immunizations given. In 2007, The WHO stopped recommending BCG for infants with HIV, even if there is a high risk of exposure to TB, because of the risk of disseminated BCG infection (which is approximately 400 per 100,000).
Manufacturers.
A number of different companies make BCG, sometimes using different genetic strains of the bacterium. This may result in different product characteristics. OncoTICE, used for bladder instillation for bladder cancer, was developed by Organon Laboratories (since acquired by Schering-Plough, and in turn acquired by Merck, Inc.). Pacis® BCG, made from the Montréal (Institut Armand-Frappier) strain, was first marketed by Urocor in about 2002. Urocor was since acquired by Dianon Systems. Evans Vaccines (a subsidiary of PowderJect Pharmaceuticals Plc, London: PJP). Statens Serum Institut in Denmark markets BCG vaccine prepared using Danish strain 1331. Japan BCG Laboratory markets its vaccine, based on the Tokyo 172 substrain of Pasteur BCG, in 50 countries worldwide. Sanofi Pasteur's BCG vaccine products, made with the Glaxo 1077 strain, were recalled in July 2012 due to noncompliance in the manufacturing process.
History.
The history of BCG is tied to that of smallpox. Jean Antoine Villemin first recognized bovine tuberculosis in 1854 and transmitted it, and Robert Koch first distinguished "Mycobacterium bovis" from "Mycobacterium tuberculosis". Following the success of vaccination in preventing smallpox, established during the 18th century, scientists thought to find a corollary in tuberculosis by drawing a parallel between bovine tuberculosis and cowpox: it was hypothesized that infection with bovine tuberculosis might protect against infection with human tuberculosis. In the late 19th century, clinical trials using "M. bovis" were conducted in Italy with disastrous results, because "M. bovis" was found to be just as virulent as "M. tuberculosis".
Albert Calmette, a French physician and bacteriologist, and his assistant and later colleague, Camille Guérin, a veterinarian, were working at the Institut Pasteur de Lille (Lille, France) in 1908. Their work included subculturing virulent strains of the tubercle bacillus and testing different culture media. They noted a glycerin-bile-potato mixture grew bacilli that seemed less virulent, and changed the course of their research to see if repeated subculturing would produce a strain that was attenuated enough to be considered for use as a vaccine. The research continued throughout World War I until 1919, when the now avirulent bacilli were unable to cause tuberculosis disease in research animals. They transferred to the Paris Pasteur Institute in 1919. The BCG vaccine was first used in humans in 1921.
Public acceptance was slow, and one disaster, in particular, did much to harm public acceptance of the vaccine. In the summer of 1930 in Lübeck, 240 infants were vaccinated in the first 10 days of life; almost all developed tuberculosis and 72 infants died. It was subsequently discovered that the BCG administered had been contaminated with a virulent strain that was being stored in the same incubator, and led to legal action being taken against the manufacturers of BCG.
Dr. R.G. Ferguson, working at the Fort Qu'Appelle Sanatorium in Saskatchewan, was among the pioneers in developing the practice of vaccination against tuberculosis. In 1928, BCG was adopted by the Health Committee of the League of Nations (predecessor to the WHO). Because of opposition, however, it did not become widely used until after World War II. From 1945 to 1948, relief organizations (International Tuberculosis Campaign or Joint Enterprises) vaccinated over 8 million babies in eastern Europe and prevented the predicted typical increase of TB after a major war.
BCG is very efficacious against tuberculous meningitis in the pediatric age group, but its efficacy against pulmonary tuberculosis appears to be variable. As of 2006, only a few countries do not use BCG for routine vaccination. The USA and the Netherlands have never used it routinely. In both countries, BCG vaccination is not routinely given to adults because it is felt that having a reliable Mantoux test and being able to accurately detect active disease is more beneficial to society than vaccinating against a condition that is now relatively rare in those countries. Recent research by the Imperial College London has focused instead on finding new cell-wall proteins that trigger an immune response and are suitable for use in a vaccine to provide long-term protection against "M. tuberculosis". The study has revealed a few such proteins, the most promising of which has been dubbed EspC; it elicits a very strong immune reaction, and is specific to "M. tuberculosis".

</doc>
<doc id="4192" url="http://en.wikipedia.org/wiki?curid=4192" title="Bunsen">
Bunsen

Bunsen may refer to:

</doc>
<doc id="4193" url="http://en.wikipedia.org/wiki?curid=4193" title="Common buzzard">
Common buzzard

The common buzzard ("Buteo buteo") is a medium-to-large bird of prey, whose range covers most of Europe and extends into Asia. It is usually resident year-round, except in the coldest parts of its range, and in the case of one subspecies.
Description.
The common buzzard measures between in length with a wingspan and a body mass of , making it a medium-sized raptor.
This broad-winged raptor has a wide variety of plumages, and in Europe can be confused with the similar rough-legged buzzard ("Buteo lagopus") and the only distantly related European honey buzzard ("Pernis apivorus"), which mimics the common buzzard's plumage for a degree of protection from northern goshawks . The plumage can vary in Britain from almost pure white to black, but is usually shades of brown, with a pale 'necklace' of feathers.
Systematics.
The common buzzard was first described by Linnaeus in his "Systema naturae" in 1758 as "Falco buteo". Buzzard subspecies fall into two groups.
The western "Buteo" group is mainly resident or short-distance migrants. They are:
The eastern "vulpinus" group includes
Two resident forms on islands close to Africa are often assigned to the first group, but appear to be distinct species, more closely related to the African long-legged buzzard, based on biogeography and preliminary mtDNA cytochrome "b" sequence data (Clouet & Wink 2000):
Behaviour.
The common buzzard breeds in woodlands, usually on the fringes, but favours hunting over open land. It eats mainly small mammals, and will come to carrion. A great opportunist, it adapts well to a varied diet of pheasant, rabbit, other small mammals to medium mammals, snakes and lizards, and can often be seen walking over recently ploughed fields looking for worms and insects.
Buzzards do not normally form flocks, but several may be seen together on migration or in good habitat. The Victorian writer on Dartmoor, William Crossing, noted he had on occasions seen flocks of 15 or more at some places. Though a rare occurrence, as many as 20 buzzards can be spotted in one field area, approximately 30 metres apart, so cannot be classed as a flock in the general sense, consisting of birds without a mate or territory. They are fiercely territorial, and, though rare, fights do break out if one strays onto another pair's territory, but dominant displays of aggression will normally see off the interloper. Pairs mate for life. To attract a mate (or impress his existing mate) the male performs a ritual aerial display before the beginning of spring. This spectacular display is known as 'the roller coaster'. He will rise high up in the sky, to turn and plummet downward, in a spiral, twisting and turning as he comes down. He then rises immediately upward to repeat the exercise.
The call is a plaintive "peea-ay", similar to a cat's meow.
Steppe buzzard.
The steppe buzzard, "B. (b.) vulpinus" breeds from east Europe eastward to the Far East, excluding Japan. It is a long-distance migrant, excepting some north Himalayan birds, and winters in Africa, India and southeastern Asia. In the open country favoured on the wintering grounds, steppe buzzards are often seen perched on roadside telephone poles.
The steppe buzzard is some times split off as a separate species, "B. vulpinus". Compared to the nominate form, it is slightly smaller (45–50 cm long), longer winged and longer tailed. There are two colour morphs: the rufous form which gives this subspecies its scientific name ("vulpes" is Latin for "fox"), and a dark grey form.
The tail of "vulpinus" is paler than the nominate form, and often quite rufous, recalling North American red-tailed hawk. The upper wings have pale primary patches, and the primary flight feathers are also paler when viewed from below. Adults have a black trailing edge to the wings, and both morphs often have plain underparts, lacking the breast band frequently seen in "B. b. buteo".
Forest buzzard.
The forest buzzard, "B. (b.) trizonatus", is another form sometimes upgraded to a full species, though most recent authorities have placed it as a subspecies of another species, the mountain buzzard, "B. oreophilus". This is a resident breeding species in woodlands in southern and eastern South Africa.
It is very similar to the abundant summer migrant steppe buzzard, but the adult can be distinguished with a good view by its whiter underparts and unbarred flanks. The juvenile differs from the same-age steppe buzzard by its white front and tear-shaped flank streaks.
The forest buzzard, as its name implies, inhabits evergreen woodlands, including introduced eucalyptus and pines, whereas the steppe buzzard prefers more open habitats. However, habitat alone is not a good indicator for these forms.

</doc>
