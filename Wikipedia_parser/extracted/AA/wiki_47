<doc id="3864" url="http://en.wikipedia.org/wiki?curid=3864" title="2001 World Series">
2001 World Series

The 2001 World Series, the 97th edition of Major League Baseball's championship series, took place between the Arizona Diamondbacks of the National League and the New York Yankees of the American League. The Diamondbacks won the best-of-seven series four games to three. The series was deemed by the dramatics as one of the greatest of all time and was one of the most memorable since it featured two extra-inning games and three late-inning comebacks. It ended on a Game 7 walk-off hit in the form of a bases loaded bloop single off the bat of Luis Gonzalez. This was the third World Series to end in this way after and .
This was the first World Series ever played in the state of Arizona and the Mountain Time Zone. With the All-Star Game format change in 2003, the World Series would not open in the city of the National League champion again until . This was the last World Series not to feature a wild card team until . This was also the first World Series to end in November.
With the win by the Diamondbacks, the franchise became the first World Series champion from a Far West state other than California.
Randy Johnson and Curt Schilling were the co-MVPs of the 2001 World Series, combining for a 4–0 record and a 1.40 ERA and striking out 45 Yankees in innings.
Background.
The Arizona Diamondbacks reached the Series in just their fourth season, breaking a record previously held by the Florida Marlins, and took on the three-time defending champion New York Yankees, who had won the World Series in four of the last five years and tried to become the first team to win four straight titles since the Yankees' five consecutive titles from to . Arizona captured the best of seven games Series, four games to three, thereby dethroning the defending World Champions and earning their first title.
Arizona won the first two games at home handily, but New York won the next three in close contests at the Yankee Stadium, including two dramatic ninth-inning comebacks against Arizona closer Byung-Hyun Kim. Arizona won the sixth game handily with Randy Johnson pitching a masterful game. Randy pitched in relief of Curt Schilling in Game 7. The Diamondbacks won that game by the score of 3–2, ending when Jay Bell scored the winning run on a bloop single by Luis Gonzalez, in the bottom of the ninth inning off the Yankees' ace closer, Mariano Rivera. Johnson, credited with the Game 7 win, became the first pitcher ever to win three games in the same World Series since Detroit Tigers' Mickey Lolich in .
The home team won every game in the Series. This had only happened twice before, in and also in domed ballparks; in the two earlier championships, the Minnesota Twins won the Series. This Series was the subject of an HBO documentary "Nine Innings from Ground Zero" in 2004.
Though the series was played to the maximum seven games, the Diamondbacks outscored the Yankees 37–14 as a result of large margins of victory achieved by Arizona in Bank One Ballpark relative to the one run margins the Yankees achieved at Yankee Stadium. Arizona held powerhouse New York to an .183 batting average, the lowest ever in a seven-game World Series. The previous record was .185 by the St. Louis Cardinals in the 1985 World Series when they lost to the Kansas City Royals.
September 11 and the month of November.
Due to the postponement of MLB games as a result of the September 11 attacks, the World Series began Saturday, October 27, 2001, the latest start date ever for a World Series until the 2009 World Series, which started on October 28. The last three games were the first major-league games (other than exhibitions) played in the month of November. This was just the fourth time that no World Series champion was decided within the traditional month of October. The previous three occurrences were in (no series), (series held in September due to World War I), and (no series due to work stoppage). Additionally, the Series took place in New York City only seven weeks after the attacks, representing a remarkable boost in morale for the fatigued city.
Matchups.
Game 1.
Saturday, October 27, 2001 at Bank One Ballpark in Phoenix, Arizona
The Arizona hitters chased Yankees starter Mike Mussina after three innings. The Yankees gave up five runs and the Diamondbacks rode Curt Schilling's seven strong innings to a 9–1 rout. Craig Counsell homered off Mussina in the first and Luis Gonzalez hit a two-run home run in the third and scored twice. The Yankees scored one run on one hit in the first, and were able to get two other hits before being held hitless after the fourth inning.
Game 2.
Sunday, October 28, 2001 at Bank One Ballpark in Phoenix, Arizona
Arizona continued to take control of the Series with the strong pitching performance of Randy Johnson. The Big Unit pitched a complete game shutout, allowing only four baserunners and three hits while striking out eleven Yankees. Matt Williams hit a three-run homer in the seventh off Yankee starter Andy Pettitte as Arizona won Game 2, 4–0 and led the series two games to none lead as the Series moved to New York City.
Game 3.
Tuesday, October 30, 2001 at Yankee Stadium (I) in Bronx, New York
The game was opened in New York by United States President George W. Bush, who threw the ceremonial first pitch, a strike to Yankees backup catcher Todd Greene. Bush became the first sitting US President to throw a World Series first pitch since Dwight D. Eisenhower in . He also threw the baseball from the mound where the pitcher would be set (unlike most ceremonial first pitches which are from in front of the mound) and threw it for a strike. Chants of ""U-S-A, U-S-A"" rang throughout Yankee Stadium. Yankees starter Roger Clemens allowed only three hits and struck out nine in seven innings of work. Yankees closer Mariano Rivera pitched two innings for the save. Scott Brosius broke a sixth inning tie with a run scoring RBI single to left field.
Game 4.
Wednesday, October 31, 2001 at Yankee Stadium (I) in Bronx, New York
Arizona manager Bob Brenly gambled and started Curt Schilling on three days' rest. It was a good decision as Schilling pitched seven strong innings, allowing just one run, Shane Spencer's solo homer in the third, and three hits. Yankees' Orlando Hernandez pitched solid innings, but gave up a game-tying upper deck home run to Mark Grace in the fourth. The Diamondbacks took a 3–1 lead in the top of the eighth on an Erubiel Durazo double and a fielder's choice, which prompted Brenly to bring in closer Byung-Hyun Kim for a two inning save. Kim, at 22, became the first Korean-born player ever to play in the MLB World Series. Kim struck out the side in the eighth, but the Yankees began their comeback in the bottom of the ninth inning. First, Jeter tried bunting, but was thrown out by one step. Then Paul O'Neill lined an opposite-field single in front of left fielder Luis Gonzalez. After Bernie Williams struck out, Tino Martinez hit a two-run home run on the first pitch he saw from Kim over the right-center field wall, tying the game 3–3. Brenly stuck with his closer as the game headed into extra innings. When the scoreboard clock in Yankee Stadium passed midnight, World Series play in November began, with the message on the scoreboard "Welcome to November Baseball". Derek Jeter
hit an opposite field walk-off home run on a 3–2 pitch count from Kim. This walk-off home run gave the Yankees a 4–3 victory and tied the Series at two games apiece, making Jeter the first player to hit a November home run and earning him the tongue-in-cheek nickname of "Mr. November". 
Game 5.
Thursday, November 1, 2001 at Yankee Stadium (I) in Bronx, New York
For Game 5, Brenly started Miguel Batista, who pitched a strong scoreless innings. Mussina bounced back from his poor Game 1 start, but allowed solo home runs to Steve Finley and Rod Barajas in the fifth. With the Diamondbacks leading 2–0 in the ninth, Brenly again went to his closer, and for the second night in a row Byung-Hyun Kim failed to hold the lead. Jorge Posada doubled to open the inning, but Kim retired the next two batters. Then, with two outs in the ninth Scott Brosius hit a 1–0 pitch over the left field wall to tie the game at two. Yankee Stadium erupted after the Brosius home run. For the second straight night, the game went into extra innings following a ninth-inning home run and the Yankees won it in the twelfth when Alfonso Soriano knocked in Chuck Knoblauch with a base hit off Albie Lopez. New York went ahead three games to two in the series as the teams headed back to Arizona. In the top of the ninth inning, with the Yankees down 2–0, Paul O'Neill (retiring after the series) was serenaded by Yankees fans chanting his name in unison.
Game 6.
Saturday, November 3, 2001 at Bank One Ballpark in Phoenix, Arizona
With Arizona in a must-win situation, Johnson pitched seven innings and struck out seven, giving up just two runs. The Diamondbacks rocked Yankees starter Andy Pettitte for six runs after two innings and nine more runs against reliever Jay Witasick in one and a third innings before Randy Choate and Mike Stanton kept them scoreless for the rest of the game. The Diamondbacks hit six doubles and Danny Bautista batted 3-for-4 with five RBIs. The team set a World Series record with 22 hits and defeated the New York Yankees in its most lopsided postseason loss in 293 postseason games. The 15–2 win evened the series at three games apiece and set up a Game 7 for the ages between Roger Clemens and Curt Schilling, again pitching on three days' rest.
Game 7.
Sunday, November 4, 2001 at Bank One Ballpark in Phoenix, Arizona
It was a matchup of two twenty-game winners in the Series finale that would crown a new champion. Clemens at 39 years old became the oldest Game 7 starter ever. Schilling had already started two games of the Series and pitched his 300th inning of the season on just three days' rest. The two aces matched each other inning by inning and after seven full innings, the game was tied at 1–1. The Diamondbacks scored first in the sixth inning with a Steve Finley single and a Danny Bautista double (Bautista would be called out at third base). The Yankees responded with an RBI single from Tino Martinez, which drove in Derek Jeter. Brenly stayed with Schilling into the eighth, and the move backfired as Alfonso Soriano hit a solo home run on an 0–2 pitch. After Schilling got one out, he gave up a single to David Justice, and he left the game trailing 2–1. Brenly brought in Miguel Batista to get out Derek Jeter and then in an unconventional move, brought in the previous night's starter Randy Johnson, who had thrown 104 pitches, in relief to keep it a one-run game. It proved to be a smart move, as Johnson retired all four Yankees he faced.
With the Yankees ahead 2–1 in the bottom of the eighth, manager Joe Torre turned the game over to his ace closer Mariano Rivera for a two-inning save. Rivera struck out the side in the eighth, including Arizona's Luis Gonzalez, Matt Williams, and Danny Bautista, which lowered his ERA in the postseason to a major league-best of 0.70 . Although he was effective in the eighth, this game would end in the third ninth-inning comeback of the Series.
Mark Grace led off the inning with a single to center on a 1–0 pitch. Rivera's errant throw to second base on a bunt attempt by Damian Miller on an 0–1 pitch put runners on first and second. Derek Jeter tried to reach for the ball, but got tangled in the legs of pinch-runner David Dellucci, who was sliding in an attempt to break up the double play. Rivera appeared to regain control when he fielded Jay Bell's bunt and threw out Dellucci at third base, but third baseman Scott Brosius decided to hold onto the baseball instead of throwing to first to complete the double play. Midre Cummings was sent in to pinch-run for Damien Miller. With Cummings at second and Bell at first, the next batter, Tony Womack, hit a double down the right-field line on a 2–2 pitch that tied the game and earned Rivera a blown save. Bell advanced to third and the Yankees pulled the infield and outfield in as the potential winning run stood at third with fewer than two outs. After Rivera hit Craig Counsell with an 0–1 pitch, the bases were loaded. On an 0–1 pitch, Luis Gonzalez lofted a soft single over the drawn-in Derek Jeter that barely reached the outfield grass, plating Jay Bell with the winning run. This ended New York's bid for a fourth consecutive title and brought Arizona its first championship within its fourth year of existence, making the Diamondbacks the fastest expansion team to win a World Series, as well as the first major professional sports championship for the state of Arizona.
In 2009, Game 7 was chosen by "Sports Illustrated" as the Best Postseason Game of the Decade (2000–2009).
Composite box.
2001 World Series (4–3): Arizona Diamondbacks (N.L.) over New York Yankees (A.L.)
Media coverage.
For the second consecutive year, Fox carried the World Series over its network with its top broadcast team, Joe Buck and Tim McCarver (himself a Yankees broadcaster). This was the first year of Fox's exclusive rights to the World Series (in the previous contract, Fox only broadcast the World Series in even numbered years while NBC broadcast it in odd numbered years), which it has held ever since (this particular contract also had given Fox exclusive rights to the entire baseball postseason, which aired over its family of networks; the contract was modified following Disney's purchase of Fox Family Channel shortly after the World Series ended, as ESPN regained their postseason rights following a year of postseason games on ABC Family, Fox Family's successor). ESPN Radio provided national radio coverage for the fourth consecutive year, with Jon Miller and Joe Morgan calling the action.
Locally, the Series was carried over KTAR in the Phoenix area and WABC in New York. Greg Schulte called play-by-play for the Diamondbacks while John Sterling and Michael Kay alternated duties on the Yankees coverage. This would be Sterling and Kay's last World Series working together, and Game 7 would be the last Yankee broadcast on WABC. Kay moved to television and the new YES Network the following season and WCBS picked up radio rights to the Yankees. It was Kay who announced Derek Jeter's game-winning home run in Game 4 of the series and subsequently anointed him as "Mr. November".
Aftermath.
After the Yankees lost the World Series, several players moved onto other teams or retired, the most notable changes being the signing of Jason Giambi to replace Martinez, and the retirements of Brosius and O'Neil. Martinez would later finish his career with the Yankees in 2005 after spending the previous three years in St. Louis and Tampa Bay. The Yankees would lose the 2003 World Series to the Florida Marlins and wouldn't win another World Series until 2009, when they defeated the defending champions, the Philadelphia Phillies, in six games.
After winning the NL West again in 2002 the Diamondbacks were swept 3–0 by St. Louis in the NLDS. From here they declined, losing 111 games in 2004 as Bob Brenly was fired during that season. Arizona would not win another NL West title until 2007. Schilling was traded to the Boston Red Sox after the 2003 season and in 2004 helped lead them to their first world championship since 1918. He helped them win another championship in 2007 and retired after four years with Boston, missing the entire 2008 season with a shoulder injury. Johnson was traded to the Yankees after the 2004 season, a season that saw him throw a perfect game against the Atlanta Braves, though he would be traded back to the Diamondbacks two years later and finish his career with the San Francisco Giants in 2009. Three Diamondbacks from 2001 are still active, Rod Barajas (now with the Pittsburgh Pirates), Miguel Batista (who last pitched with the New York Mets in 2012), and Lyle Overbay (rejoined the Diamondbacks in August 2011). All these players have since played with the Toronto Blue Jays; Barajas and Overbay at the same time (2008 and 2009). Only Derek Jeter and Alfonso Soriano remain from the 2001 AL champion Yankees.
From 2004 through 2007, the Yankees' misfortune in the postseason continued, with the team losing the ALCS to the Boston Red Sox in 2004, the ALDS to Anaheim in 2005, the ALDS to Detroit in 2006, and the ALDS to Cleveland in 2007. Joe Torre's contract was allowed to expire and he was replaced by Joe Girardi in 2008, a season in which the Yankees would miss the playoffs for the first time since 1993.
Buster Olney, who covered the Yankees for the "New York Times" before joining ESPN, would write a book titled "The Last Night of the Yankee Dynasty". The book is a play by play account of Game 7 in addition to stories about key players, executives, and moments from the 1996–2001 dynasty. In a 2005 reprinting, Olney included a new epilogue covering the aftermath of the 2001 World Series up to the Boston Red Sox epic comeback from down 3–0 in the 2004 ALCS.
, this is the state of Arizona's only world championship among the four major professional sports.
DVD.
On October 11, 2005 A&E Home Video released the New York Yankees Fall Classic Collectors Edition (1996–2001) DVD set. Game 4 of the 2001 World Series is included in the set. On April 29, 2008 The Arizona Diamondbacks 2001 World Series DVD set was released. All seven games are included.

</doc>
<doc id="3865" url="http://en.wikipedia.org/wiki?curid=3865" title="1903 World Series">
1903 World Series

The 1903 World Series was the first modern World Series to be played in Major League Baseball. It matched the Boston Americans of the American League against the Pittsburgh Pirates of the National League in a best-of-nine series, with Boston prevailing five games to three, winning the last four.
Pittsburgh pitcher Sam Leever injured his shoulder while trap-shooting, so his teammate Deacon Phillippe pitched five complete games for Pittsburgh. Phillippe won three of his games, but it was not enough to overcome the club from the new American League. Boston pitchers Bill Dinneen and Cy Young led Boston to victory.
Due to overflow crowds at the Exposition Park games, if a batted ball rolled under a rope in the outfield that held spectators back, a "ground-rule triple" would be scored. Seventeen ground-rule triples were hit in the four games played at the Exposition Park.
In Game 1, Phillippe set a World Series record by striking out ten Boston batters. That record lasted barely one day, as Dinneen struck out eleven Pittsburgh batters in Game 2.
Honus Wagner, bothered by injuries, batted only 6 for 27 (.222) in the Series and committed six errors. The shortstop was deeply distraught by his performance. The following spring, Wagner (who led the league in 1903 in batting average) refused to send his portrait to a "Hall of Fame" for batting champions. "I was too bum last year," he wrote. "I was a joke in that Boston-Pittsburgh Series. What does it profit a man to hammer along and make a few hits when they are not needed only to fall down when it comes to a pinch? I would be ashamed to have my picture up now."
In this World Series, the Boston Americans came back from a three games to one deficit, winning the final four games (in a best-of-nine Series rather than the now standard best-of-seven). Such a comeback would not happen again until the Pirates came back to defeat the Washington Senators in the 1925 World Series, and has happened only ten times in baseball history. The Pirates repeated this feat in against the Baltimore Orioles.
Much was made of the influence of Boston's "Royal Rooters", who traveled to Pittsburgh and sang their theme song "Tessie" to distract the opposing players (especially Honus Wagner). Boston would end up winning three out of the four games at Pittsburgh.
The Pirates' owner Barney Dreyfuss added his share of the gate receipts to the players' share, so the losing team's players actually finished with a larger individual share than the winning team's.
The Series brought the new American League prestige and proved its best could beat the best of the National League, thus strengthening the demand for future World Series competitions.
Background.
A new league.
In 1901, Ban Johnson, president of the Western League, a minor league organization, formed the American League to take advantage of the National League's 1900 contraction from twelve teams to eight. Johnson and fellow owners raided the National League and signed away many star players, including Cy Young and Jimmy Collins. Johnson had a list of 46 National Leaguers he targeted for the American League; by 1902, all but one had made the jump. The constant raiding, however, scotched the idea of a championship between the two leagues. Pirates owner Barney Dreyfuss, whose team ran away with the 1902 National League pennant, was open to a post-season contest and even said he would allow the American League champion to stock its roster with all-stars. However, Johnson had spoken of putting a team in Pittsburgh and even attempted to raid the Pirates' roster in August 1902, which soured Dreyfuss. At the end of the season, however, the Pirates played a group of American League All-Stars in a four-game exhibition series, winning two games to one, with one tie.
The leagues finally called a truce in the winter of 1902–03 and formed the National Commission to preside over organized baseball. The following season, the Boston Americans and Pittsburgh Pirates had secured their respective championship pennants by September. That August, Dreyfuss challenged the American League to an eleven game championship series. Encouraged by Johnson and National League President Harry Pulliam, Americans owner Henry J. Killilea met with Dreyfuss in Pittsburgh in September and instead agreed to a best-of-nine championship, with the first three games played in Boston, the next four in Pittsburgh, and the remaining two (if necessary) in Boston.
One significant point about this agreement was that it was an arrangement primarily between the two clubs rather than a formal arrangement between the leagues. In short, it was a voluntary event, a fact which would result in no Series at all for , and eventually to the formal establishment of the Series as a compulsory event starting in .
The teams.
The Pirates won their third straight pennant in 1903 thanks to a powerful line-up that included legendary shortstop Honus Wagner, who hit .355 and drove in 101 runs, player-manager Fred Clarke, who hit .351, and Ginger Beaumont, who hit .341 and led the league in hits and runs. The Pirates' pitching was weaker than it had been in previous years but boasted 24-game winner Deacon Phillippe and 25-game winner Sam Leever.
The Americans had a strong pitching staff, led by Cy Young, who went 28–9 in 1903 and became the all-time wins leader that year. Bill Dinneen and Long Tom Hughes, right-handers like Young, had won 21 games and 20 games each. The Boston outfield, featuring Chick Stahl (.274), Buck Freeman (.287, 104 RBIs) and Patsy Dougherty (.331, 101 runs scored) was considered excellent.
Although the Pirates had dominated their league for the previous three years, they went into the series riddled with injuries and plagued by bizarre misfortunes. Otto Krueger, the team's only utility player, was beaned on September 19 and never fully played in the series. 16-game winner Ed Doheny left the team three days later, exhibiting signs of paranoia; he was committed to an insane asylum the following month. Leever had been battling an injury to his pitching arm (which he made worse by entering a trapshooting competition). Worst of all, Wagner, who had a sore thumb throughout the season, injured his right leg in September and was never 100 percent for the post-season. 
Some sources say Boston were heavy underdogs. Boston bookies actually gave even odds to the teams (and only because Dreyfuss and other "sports" were alleged to have bet on Pittsburgh to bring down the odds). The teams were generally thought to be evenly matched, with the Americans credited with stronger pitching and the Pirates with superior offense and fielding. The outcome, many believed, hinged on Wagner's health. "If Wagner does not play, bet your money at two to one on Boston," said the Sporting News, "but if he does play, place your money at two to one on Pittsburgh."
Matchups.
Game 1.
Thursday, October 1, 1903 at Huntington Avenue Baseball Grounds in Boston, Massachusetts
The Pirates started Game 1 strong, scoring six runs in the first four innings. They extended their lead to 7–0 on a solo home run by Jimmy Sebring in the seventh, the first home run in World Series history. Boston tried to mount a comeback in the last three innings, but it was too little too late, and they ended up losing by a score of 7–3 in the first ever World Series game. Both Phillippe and Young threw complete games, with Phillippe striking out ten and Young fanning five, but Young also gave up twice as many hits and allowed three earned runs to Phillippe's two.
Game 2.
Friday, October 2, 1903 at Huntington Avenue Baseball Grounds in Boston, Massachusetts
After starting out strong in Game 1, the Pirates simply shut down offensively, eking out a mere three hits, all singles. Pittsburgh starter Sam Leever went only one inning and gave up three hits and two runs, before his ailing arm forced him to leave in favor of Bucky Veil, who finished the game. Bill Dinneen struck out eleven and pitched a complete game for the Americans, while Patsy Dougherty hit home runs in the first and sixth innings for two of the Boston's three runs.
Game 3.
Saturday, October 3, 1903 at Huntington Avenue Baseball Grounds in Boston, Massachusetts
Phillippe, pitching after only a single day of rest, started Game 3 for the Pirates and didn't let them down, hurling his second complete game victory of the Series to put Pittsburgh up two games to one.
Game 4.
Tuesday, October 6, 1903 at Exposition Park (III) in Allegheny, Pennsylvania
After two days of rest, Phillippe was ready to pitch a second straight game. He threw his third complete game victory of the series against Bill Dinneen, who was making his second start of the series. But Phillippe's second straight win was almost not to be, as the Americans, down 5–1 in the top of the ninth, rallied to narrow the deficit to one run. The comeback attempt failed, as Phillippe managed to put an end to it and give the Pirates a commanding 3–1 Series lead.
Game 5.
Wednesday, October 7, 1903 at Exposition Park (III) in Allegheny, Pennsylvania
Game 5 was a pitcher's duel for the first five innings, with Boston's Cy Young and Pittsburgh's Brickyard Kennedy giving up no runs. That changed in the top of the sixth, however, when the Americans scored a then-record six runs before being retired. Young, on the other hand, managed to keep his shutout intact before finally giving up a pair of runs in the bottom of the eighth. He went the distance and struck out four for his first World Series win.
Game 6.
Thursday, October 8, 1903 at Exposition Park (III) in Allegheny, Pennsylvania
Game 6 was a rematch between the starters of Game 2, Boston's Dinneen and Pittsburgh's Leever. Leever pitched a complete game this time but so did Dinneen, who outmatched him to earn his second complete game victory of the series. After losing three of the first four games of the World Series, the underdog Americans had tied the series at three games apiece.
Game 7.
Saturday, October 10, 1903 at Exposition Park (III) in Allegheny, Pennsylvania
The fourth and final game in Pittsburgh saw Phillippe start his fourth game of the Series for the Pirates. This time, however, he wouldn't fare as well as he did in his first three starts. Cy Young, in his third start of the Series, held the Pirates to three runs and put the Americans ahead for the first time as the Series moved back to Boston.
Game 8.
Tuesday, October 13, 1903 at Huntington Avenue Baseball Grounds in Boston, Massachusetts
The final game of this inaugural World Series started out as an intense pitcher's duel, scoreless until the bottom of the fourth when Hobe Ferris hit a two-run single. Phillippe started his fifth and final game of the series and Dinneen his fourth. As he did in Game 2, Dinneen threw a complete game shutout, striking out seven and leading his Americans to victory, while Phillippe pitched respectably but just couldn't match Dinneen because his arm had been worn out with five starts in the eight games, giving up three runs to give the first 20th-century World Championship to the Boston Americans, Honus Wagner striking out to end the Series.
Composite line score.
1903 World Series (5–3): Boston Americans (A.L.) over Pittsburgh Pirates (N.L.)
Series statistics.
Boston Americans.
Batting.
"Note: GP=Games played; AB=At Bats; H=Hits; Avg.=Batting Average; HR=Home Runs; RBI=Runs Batted In"

</doc>
<doc id="3866" url="http://en.wikipedia.org/wiki?curid=3866" title="Bluetongue disease">
Bluetongue disease

Bluetongue disease or catarrhal fever is a non-contagious, insect-borne, viral disease of ruminants, mainly sheep and less frequently cattle, goats, buffalo, deer, dromedaries and antelope. It is caused by the Bluetongue virus (BTV). The virus is transmitted by the midge "Culicoides imicola", "Culicoides variipennis" and other culicoids.
Signs and symptoms.
In sheep, BTV causes an acute disease with high morbidity and mortality. BTV also infects goats, cattle and other domestic animals as well as wild ruminants (for example, blesbuck, white-tailed deer, elk, and pronghorn antelope).
Major signs are high fever, excessive salivation, swelling of the face and tongue and cyanosis of the tongue. Swelling of the lips and tongue gives the tongue its typical blue appearance, though this sign is confined to a minority of the animals. Nasal symptoms may be prominent, with nasal discharge and stertorous respiration. 
Some animals also develop foot lesions, beginning with coronitis, with consequent lameness. In sheep, this can lead to knee-walking. In cattle, constant changing of position of the feet gives bluetongue the nickname The Dancing Disease. Torsion of the neck (opisthotonos or torticollis) is observed in severely affected animals.
Not all animals develop symptoms, but all those that do lose condition rapidly, and the sickest die within a week. For affected animals which do not die, recovery is very slow, lasting several months.
The incubation period is 5–20 days, and all symptoms usually develop within a month. The mortality rate is normally low, but it is high in susceptible breeds of sheep. In Africa, local breeds of sheep may have no mortality, but in imported breeds it may be up to 90 percent.
In cattle, goats and wild ruminants infection is usually asymptomatic despite high virus levels in blood. Red deer are an exception, and in them the disease may be as acute as in sheep.
Microbiology.
Bluetongue is caused by the pathogenic virus, Bluetongue virus (BTV), of the genus "Orbivirus", of the Reoviridae family. Twenty-six serotypes are now recognised for this virus.
The virus particle consists of ten strands of double-stranded RNA surrounded by two protein shells. Unlike other arboviruses, BTV lacks a lipid envelope. The particle has a diameter of 86 nm. The structure of the 70 nm core was determined in 1998 and was at the time the largest atomic structure to be solved.
The two outer capsid proteins, VP2 and VP5, mediate attachment and penetration of BTV into the target cell. The virus makes initial contact with the cell with VP2, triggering receptor-mediated endocytosis of the virus. The low pH within the endosome then triggers BTV's membrane penetration protein VP5 to undergo a conformational change that disrupts the endosomal membrane. Uncoating yields a transcriptionally active 470S core particle which is composed of two major proteins VP7 and VP3, and the three minor proteins VP1, VP4 and VP6 in addition to the dsRNA genome. There is no evidence that any trace of the outer capsid remains associated with these cores, as has been described for reovirus. The cores may be further uncoated to form 390S subcore particles that lack VP7, also in contrast to reovirus. Subviral particles are probably akin to cores derived "in vitro" from virions by physical or proteolytic treatments that remove the outer capsid and causes activation of the BTV transcriptase. In addition to the seven structural proteins, three non-structural (NS) proteins, NS1, NS2, NS3 (and a related NS3A) are synthesised in BTV-infected cells. Of these, NS3/NS3A is involved in the egress of the progeny virus. The two remaining non-structural proteins, NS1 and NS2, are produced at high levels in the cytoplasm and are believed to be involved in virus replication, assembly and morphogenesis.
Epidemiology.
Bluetongue has been observed in Australia, the USA, Africa, the Middle East, Asia and Europe. Its occurrence is seasonal in the affected Mediterranean countries, subsiding when temperatures drop and hard frosts kill the adult midge vectors. which may promote viral survival and vector longevity during milder winters. A significant contribution to the northward spread of Bluetongue disease has been the ability of "Culicoides obsoletus" and "C.pulicaris" to acquire and transmit the disease, both of which are spread widely throughout Europe. This is in contrast to the original "C.imicola" vector which is limited to North Africa and the Mediterranean. The relatively recent novel vector has facilitated a far more rapid spread than the simple expansion of habitats North through global warming. In August 2006, cases of bluetongue were found in the Netherlands, then Belgium, Germany, and Luxembourg. In 2007, the first case of bluetongue in the Czech Republic was detected in one bull near Cheb at the Czech-German border. In September 2007, the UK reported its first ever suspected case of the disease, in a Highland cow on a rare breeds farm near Ipswich, Suffolk. Since then the virus has spread from cattle to sheep in Britain. By October 2007 bluetongue had become a serious threat in Scandinavia and Switzerland and the first outbreak in Denmark was reported. In autumn 2008, several cases were reported in the southern Swedish provinces of Småland, Halland, and Skåne,
as well as in areas of the Netherlands bordering Germany, prompting veterinary authorities in Germany to intensify controls.
Norway saw its first finding in February 2009, when cows at two farms in Vest-Agder in the south of Norway showed an immune response to bluetongue. Norway have since been declared free of the disease in 2011.
Although the disease is not a threat to humans the most vulnerable common domestic ruminants in the UK are cattle, goats and, especially, sheep.
Overwintering.
A puzzling aspect of BTV is its survival between midge seasons in temperate regions. Adult "Culicoides" are killed by cold winter temperatures, and BTV infections typically do not last for more than 60 days, which is not long enough for BTV to last until the next spring. It is believed that the virus somehow survives in overwintering midges or animals. Multiple mechanisms have been proposed. A few adult "Culicoides" midges infected with BTV may survive the mild winters of the temperate zone. Some midges may even move indoors to avoid the cold temperature of the winter. Additionally, BTV could cause a chronic or latent infection in some animals, providing another means for BTV to survive the winter. BTV can also be transmitted from mother to fetus. The outcome is abortion or stillbirth if fetal infection occurs early in gestation and survival if infection occurs late. However infection at an intermediate stage, before the fetal immune system is fully developed, may result in a chronic infection that lingers until the first months after birth of the lamb. Midges will then spread the disease from the calves to other animals, starting a new season of infection.
Treatment and prevention.
There is no efficient treatment. Prevention is effected via quarantine, inoculation with live modified virus vaccine and control of the midge vector, including inspection of aircraft.
Livestock management and insect control.
However, simple husbandry changes and practical midge control measures may help break the livestock infection cycle. Housing livestock during times of maximum midge activity (from dusk to dawn) may lead to significantly reduced biting rates. Similarly, protecting livestock shelters with fine mesh netting or coarser material impregnated with insecticide will reduce contact with the midges. The "Culicoides" midges that carry the virus usually breed on animal dung and moist soils, either bare or covered in short grass. Identifying breeding grounds and breaking the breeding cycle will significantly reduce the local midge population. Turning off taps, mending leaks and filling in or draining damp areas will also help dry up breeding sites. Control by trapping midges and removing their breeding grounds may reduce vector numbers. Dung heaps or slurry pits should be covered or removed, and their perimeters (where most larvae are found) regularly scraped.
Vaccines.
Outbreaks in southern Europe have been caused by serotypes 2 and 4, and vaccines are available against these serotypes (ATCvet codes: for sheep, for cattle). However, the disease found in northern Europe (including the UK) in 2006 and 2007 has been caused by serotype 8. Vaccine companies Fort Dodge Animal Health (Wyeth), Merial and Intervet were developing vaccines against serotype 8 (Fort Dodge Animal Health has serotype 4 for sheep, serotype 1 for sheep and cattle and serotype 8 for sheep and cattle) and the associated production facilities. A vaccine for this is now available in the UK, produced by Intervet. Fort Dodge Animal Health has their vaccines available for multiple European Countries (vaccination will start in 2008 in Germany, Belgium, Switzerland, Spain and Italy). However, immunization with any of the available vaccines preclude later serological monitoring of affected cattle populations, a problem which could be resolved using next-generation subunit vaccines currently in development. 
History.
Although bluetongue disease was already recognized in South Africa in the early 19th century, a comprehensive description of the disease was not published until the first decade of the 20th century. In 1906 Arnold Theiler showed that bluetongue was caused by a filterable agent. He also created the first bluetongue vaccine, which was developed from an attenuated BTV strain. For many decades bluetongue was thought to be confined to Africa. The first confirmed outbreak outside of Africa occurred in Cyprus in 1943.
Related diseases.
African horse sickness is related to Bluetongue and is spread by the same midges ("Culicoides" species). It can kill the horses it infects and mortality may go as high as 90% of the infected horses during an epidemic.
The Epizootic Hemorrhagic Disease (EHD) virus is closely related and crossreacts with Bluetongue virus on many blood tests.

</doc>
<doc id="3869" url="http://en.wikipedia.org/wiki?curid=3869" title="Bruce Perens">
Bruce Perens

Bruce Perens (born 1958) is an American computer programmer and advocate in the open source community. He created the Open Source Definition and published the first formal announcement and manifesto of open source. He co-founded the Open Source Initiative (OSI) with Eric S. Raymond.
In 2005, Perens represented Open Source at the United Nations World Summit on the Information Society, at the invitation of the United Nations Development Program. He has appeared before national legislatures and is often quoted in the press, advocating for open source and the reform of national and international technology policy.
Perens is also an amateur radio operator, with callsign K6BP. He is well known in the amateur radio community for his efforts towards open radio communications standards.
Early life.
Perens grew up in Long Island, New York. He was born with cerebral palsy, which caused him to have slurred speech and difficulty reading as a child, a condition that led to a misdiagnosis of him as mentally disabled in school. He developed an interest in technology at an early age: besides his interest in amateur radio, he ran a pirate radio station in the town of Lido Beach, and briefly engaged in phone phreaking.
Career.
Computer graphics.
Perens worked for seven years at the New York Institute of Technology Computer Graphics Lab. After that, he worked at Pixar for 12 years, from 1987 to 1999. He is credited as a studio tools engineer on the Pixar films "A Bug's Life" (1998) and "Toy Story 2" (1999).
BusyBox.
In 1995, Perens created BusyBox, a package of UNIX-style utilities for operating systems including Linux and FreeBSD. He stopped working on it in 1996, after which it was taken over by other developers.
Starting in 2007, several lawsuits were filed for infringement of BusyBox copyright and licensing. These lawsuits were filed by the Software Freedom Law Center (SFLC), and some of the later managing developers of BusyBox.
In 2009, Bruce Perens released a statement about the lawsuits and those filing them. In it, he claims that he maintains a significant or even majority ownership of the software in the litigation, but was not contacted nor represented by the plaintiffs; and that some of the plaintiffs had themselves modified BusyBox and its distribution package in such a way as to violate applicable licensing terms and copyright owned by Perens and additional BusyBox developers. Perens supports enforcement of the GPL license used on Busybox. Because he was denied participation in the Busybox cases on the side of the prosecution, Perens started a consulting business to assist the defendants in coming into compliance with the GPL and arriving at an amicable settlement with the Software Freedom Law Center.
Debian Project Leader.
From April 1996 to December 1997, while still working at Pixar, Perens served as Debian Project Leader, the person who coordinates development of the Debian open source operating system. He replaced Ian Murdock, the creator of Debian, who had been the first project leader.
Software in the Public Interest.
In 1997, Perens was a co-founder of Software in the Public Interest, a non-profit organization intended to serve as an umbrella organization to aid open-source software and hardware projects. It was originally created to allow the Debian Project to accept donations.
Debian Social Contract.
In 1997, Debian developer Ean Schuessler proposed to create a "social contract" for Debian, guaranteeing to its users that it was committed to the principles of open source software and organizational transparency. The end result of this was the Debian Social Contract, the writing of which was headed by Perens. (It was based in part on the Free Software Definition, written by Richard Stallman in 1986.) Perens proposed a draft of the Debian Social Contract to the Debian developers on the debian-private mailing list early in June 1997. Debian developers contributed discussion and changes for the rest of the month while Perens edited, and the completed document was then announced as Debian project policy. Part of the Debian Social Contract was the Debian Free Software Guidelines, a set of 10 guidelines for determining whether a set of software can be described as "free software", and thus whether it could be included in Debian.
Open Source Definition and the Open Source Initiative.
On February 3, 1998, a group of people (not including Perens) met at VA Linux Systems to discuss the promotion of Free Software to business in pragmatic terms, rather than the moral terms preferred by Richard Stallman. Christine Petersen of the nanotechnology organization Foresight Institute, who was present because Foresight took an early interest in Free Software, suggested the term "Open Source". The next day, Eric Raymond recruited Perens to work with him on the formation of Open Source. Perens modified the Debian Free Software Guidelines into the Open Source Definition by removing Debian references and replacing them with "Open Source".
The original announcement of the Open Source Definition was made on February 9, 1998 on Slashdot and elsewhere; the definition was given in Linux Gazette on February 10, 1998.
Concurrently, Perens and Raymond established the Open Source Initiative, an organization intended to promote open source software.
Perens left OSI in 1999, a year after co-founding it. In an email to the Debian developers mailing list explaining his decision, he stated that, though "most hackers know that Free Software and Open Source are just two words for the same thing", the success of "open source" as a marketing term had "de-emphasized the importance of the freedoms involved in Free Software"; he added, "It's time for us to fix that." He also stated his regret that OSI co-founder Eric Raymond "seems to be losing his free software focus."
Linux Capital Group.
In 1999, Perens left Pixar and became the president of Linux Capital Group, a business incubator and venture capital firm focusing on Linux-based businesses. Their major investment was in Progeny Linux Systems, a company headed by Debian founder Ian Murdock. In 2000, as a result of the economic downturn, Perens shut down Linux Capital Group. (Progeny Linux Systems would end operations in 2007.)
Hewlett-Packard.
From December 2000 to September 2002, Perens served as "Senior Global Strategist for Linux and Open Source" at Hewlett-Packard, internally evangelizing for the use of Linux and other open-source software. He was fired as a result of his anti-Microsoft statements, which especially became an issue after HP acquired Compaq, a major manufacturer of Microsoft Windows-based PCs, in 2002.
Linux Standard Base.
In 2001, Perens founded, and became the first project leader, of the Linux Standard Base project, a joint project by several Linux distributions under the organizational structure of the Linux Foundation to standardize the Linux software system structure.
UserLinux.
In 2003 Perens created UserLinux, a Debian-based distribution whose stated goal was, "Provide businesses with freely available, high quality Linux operating systems accompanied by certifications, service, and support options designed to encourage productivity and security while reducing overall costs." UserLinux was eventually overtaken in popularity by Ubuntu, another Debian-based distribution, which was started in 2004, and UserLinux became unmaintained in 2006.
SourceLabs.
Perens was an employee of SourceLabs, a Seattle-based open source software and services company, from June 2005 until December 2007. He produced a video commercial, "Impending Security Breach", for SourceLabs in 2007. (SourceLabs went out of business in 2009.)
Kiloboot.
Perens is currently CEO of Kiloboot, a Berkeley, California-based company founded in 2007, which is working on a yet-unannounced product.
Other activities.
In 2002, Perens worked remotely as Senior Scientist for Open Source with the Cyber Security Policy Research Institute of George Washington University. In 2006, he received a three-year grant from the Competence Fund of Southern Norway. With this funding, he spent part of the summer as a visiting lecturer and researcher at University of Agder in 2006 and 2007. During this time he consulted the Norwegian Government and other entities on government policy issues related to computers and software.
In 2007 some of his government advisory roles included a meeting with the President of the Chamber of Deputies (the lower house of parliament) in Italy and testimony to the Culture Committee of the Chamber of Deputies; a keynote speech at the foundation of Norway's Open Source Center, following Norway's Minister of Governmental Reform (Perens is on the advisory board of the center); he provided input on the revision of the European Interoperability Framework; and he was keynote speaker at a European Commission conference on "Digital Business Ecosystems at the Centre Borschette, Brussels, on November 7.
In 2009, Perens acted as an expert witness on open source in the Jacobsen v. Katzer U.S. Federal lawsuit. His report, which was made publicly available by Jacobsen, presented the culture and impact of open source software development to the federal courts.
Perens delivered one of the keynote addresses at the 2012 linux.conf.au conference in Ballarat, Australia. He discussed the need for open source software to market itself better to non-technical users. He also discussed some of the latest developments in open source hardware, such as Papilio and Bus Pirate.
Views.
Perens poses Open Source as a means of marketing the free software philosophy of Richard Stallman to business people who are more concerned with profit than freedom, and states that open source and free software are only two ways of talking about the same phenomenon. This differs from Stallman and Raymond. Perens postulates an economic theory for business use of Open Source in his paper "The Emerging Economic Paradigm of Open Source" and his speech "Innovation Goes Public". This differs from Raymond's theory in "The Cathedral and the Bazaar", which having been written before there was much business involvement in open source, explains open source as a consequence of programmer motivation and leisure.
In February 2008, for the 10th anniversary of the phrase "open source", Perens published a message to the community called "State of Open Source Message: A New Decade For Open Source". Around the same time the ezine RegDeveloper published an interview with Perens where he spoke of the successes of open source, but also warned of dangers, including a proliferation of OSI-approved licenses which had not undergone legal scrutiny. He advocated the use of the GPLv3 license, especially noting Linus Torvalds' refusal to switch away from GPLv2 for the Linux kernel.
Amateur radio and other activities.
Perens is an avid amateur radio enthusiast (callsign K6BP) and maintained technocrat.net, which he closed in late 2008 because its revenues did not cover its costs. Technocrat tentatively re-opened in Feb 2014 using new software. He is also the founder of No Code International, an organization whose primary purpose was to eliminate morse code proficiency as a requirement to obtain an amateur radio license. This goal has been reached with the removal of code requirements from international law (International Telecommunications Union treaty provision S25.5), the new "code-free" rules introduced on 2007-02-23, and similar legal changes in almost all nations worldwide.
Media appearances.
Perens is featured in the 2001 documentary film "Revolution OS" and the 2006 BBC television documentary "The Code-Breakers".
From 2002 to 2006, Prentice Hall PTR published the Bruce Perens' Open Source Series, a set of 24 books covering various open source software tools, for which Perens served as the series editor. It was the first book series to be published under an open license.
Personal life.
Perens lives in Berkeley, California with his wife, Valerie, and son, Stanley, born in 2000.

</doc>
<doc id="3870" url="http://en.wikipedia.org/wiki?curid=3870" title="Bundle theory">
Bundle theory

Bundle theory, originated by the 18th century Scottish philosopher David Hume, is the ontological theory about objecthood in which an object consists only of a collection ("bundle") of properties, relations or tropes.
According to bundle theory, an object consists of its properties and nothing more: thus neither can there be an object without properties nor can one even "conceive" of such an object; for example, bundle theory claims that thinking of an apple compels one also to think of its color, its shape, the fact that it is a kind of fruit, its cells, its taste, or at least one other of its properties. Thus, the theory asserts that the apple is no more than the collection of its properties. In particular, there is no "substance" in which the properties "inhere".
Arguments for the bundle theory.
The difficulty in conceiving of or describing an object without also conceiving of or describing its properties is a common justification for bundle theory, especially among current philosophers in the Anglo-American tradition.
The inability to comprehend any aspect of the thing other than its properties implies, this argument maintains, that one cannot conceive of a "bare particular" (a "substance" without properties), an implication that directly opposes substance theory. The conceptual difficulty of "bare particulars" was illustrated by John Locke when he described a "substance" by itself, apart from its properties, as "something, I know not what."
Whether a "relation" of an object is one of its properties may complicate such an argument. However, the argument concludes that the conceptual challenge of "bare particulars" leaves a bundle of properties and nothing more as the only possible conception of an object, thus justifying bundle theory.
Objections to the bundle theory.
Objections to bundle theory concern the nature of the "bundle of properties", the properties' "compresence" relation (the "togetherness" relation between those constituent properties), and the impact of language on understanding reality.
"Compresence" objection.
Bundle theory maintains that properties are "bundled" together in a collection without describing how they are tied together. For example, bundle theory regards an apple as red, four inches (100 mm) wide, and juicy but lacking an underlying "substance". The apple is said to be a "bundle of properties" including redness, being four inches (100 mm) wide, and juiciness.
Critics question how bundle theory accounts for the properties' "compresence" (the "togetherness" relation between those properties) without an underlying "substance". Critics also question how any two given properties are determined to be properties of the same object if there is no "substance" in which they both "inhere".
Traditional bundle theory explains the "compresence" of properties by defining an object as a collection of properties "bound" together. Thus, different combinations of properties and relations produce different objects. Redness and juiciness, for example, may be found together on top of the table because they are part of a bundle of properties located on the table, one of which is the "looks like an apple" property.
By contrast, substance theory explains the "compresence" of properties by asserting that the properties are found together because it is the "substance" that has those properties. In substance theory, a "substance" is the thing in which properties "inhere". For example, redness and juiciness are found on top of the table because redness and juiciness "inhere" in an apple, making the apple red and juicy.
The "bundle theory of substance" explains "compresence". Specifically, it maintains that properties' compresence itself engenders a "substance". Thus, it determines "substancehood" empirically by the "togetherness" of properties rather than by a "bare particular" or by any other non-empirical underlying strata. The "bundle theory of substance" thus rejects the substance theories of Aristotle, Descartes, and more recently, J.P. Moreland, Jia Hou, Joseph Bridgman, Quentin Smith, and others.
"Language-reality" objection.
The "language-reality" objection to bundle theory relates to the impact language has on understanding reality. The objection maintains that language causes confusion that supports bundle theory.
Per the objection, properties are synthetic constructions of language and thinking alone provides reality to the properties of any object. An apple, it claims, does not have the properties "red" or "juicy", but rather observers who already believe in a concept called "Red" use that concept to experience an apple as red. Further, the objection maintains that "Red" cannot be distilled from an apple because "Red" is an abstraction from other experiences and not an innate property an apple might contain. Per the objection, expressions such as, "An apple is red and juicy," includes at least six concepts and would best be left as dead-end logical propositions. Since the objection regards the words "Red" and "Juicy" as simply abstractions of previous experiences, it contends that they contain only a personal summary concept of one individual. Thus, the experience of an apple is as close to the "Apple" concept that one can get. The objection regards any additional analytic work of the mind as a synthesis of other experiences that is incapable of logically revealing any true essence of "Apple".
The "language-reality" objection asserts that language encourages the belief that "synthetic exercises" distill experiences, yet it rejects the results of such exercises by maintaining that observers actually combine experiences to create each concept of any particular property. It holds that language is a complicated belief system whose only connection to reality is an abstraction of experience. The "language-reality" objection may even suggest that "reality/non-reality" or "objective/subjective" distinctions themselves are merely artifacts of language and therefore are also solely abstractions of experience.
Bundle theory and Buddhism.
The Buddhist Madhyamaka philosopher, Chandrakirti, used the aggregate nature of objects to demonstrate the lack of essence in what is known as the sevenfold reasoning. In his work, "Guide to the Middle Way" (Skt. Madhyamakāvatāra), he says:
He goes on to explain what is meant by each of these seven assertions, but briefly in a subsequent commentary he explains that the conventions of the world do not exist essentially when closely analyzed, but exist only through being taken for granted, without being subject to scrutiny that searches for an essence within them.
Another view of the Buddhist theory of the self, especially in early Buddhism, is that the Buddhist theory is essentially an eliminativist theory. According to this understanding, the self can not be reduced to a bundle because there is nothing that answers to the concept of a self. Consequently, the idea of a self must be eliminated.

</doc>
<doc id="3873" url="http://en.wikipedia.org/wiki?curid=3873" title="Bernard Montgomery, 1st Viscount Montgomery of Alamein">
Bernard Montgomery, 1st Viscount Montgomery of Alamein

Field Marshal Bernard Law Montgomery, 1st Viscount Montgomery of Alamein, KG, GCB, DSO, PC (; 17 November 1887 – 24 March 1976), nicknamed "Monty" and the "Spartan General", was a British Army officer. He saw action in the First World War, where he was seriously wounded. During the Second World War he commanded the Eighth Army from August 1942 in the Western Desert until the final Allied victory in Tunisia. This command included the Battle of El Alamein, a turning point in the Western Desert Campaign. He subsequently commanded the Eighth Army in Sicily and Italy.
He was in command of all Allied ground forces during Operation Overlord from the initial landings until after the Battle of Normandy. He then continued in command of the 21st Army Group for the rest of the campaign in North West Europe. As such he was the principal field commander for the failed airborne attempt to bridge the Rhine at Arnhem and the Allied Rhine crossing. On 4 May 1945 he took the German surrender at Lüneburg Heath in northern Germany. After the war he became Commander-in-Chief of the British Army of the Rhine (BAOR) in Germany and then Chief of the Imperial General Staff.
Early life.
Montgomery was born in Kennington, London, in 1887, the fourth child of nine, to an Anglo-Irish Anglican priest, the Reverend Henry Montgomery, and his wife, Maud (née Farrar). Henry Montgomery, Vicar of St Mark's, Kennington, at that time, was the second son of the noted Indian civilian Sir Robert Montgomery, who died a month after his grandson's birth. He was probably a descendant of Colonel Alexander Montgomery (1686–1729). Bernard's mother, Maud, was the daughter of the preacher Frederic William Farrar and was eighteen years younger than her husband. After the death of Sir Robert Montgomery, Henry inherited the Montgomery ancestral estate of New Park at Moville, County Donegal. However, there was still £13,000 to pay on a mortgage, a large debt in the 1880s, and Henry was at the time still only a parish priest. Despite selling off all the farms that were at Ballynally, "there was barely enough to keep up New Park and pay for the blasted summer holiday" (i.e., at New Park).
It was a financial relief of some magnitude when, in 1889, Henry was made Bishop of Tasmania, then still a British colony, and Bernard spent his formative years here. The bishop considered it his duty to spend as much time as possible in the rural areas of Tasmania and was away for up to six months at a time. While he was away, his wife, still in her mid-twenties, gave her children "constant" beatings, then ignored them most of the time as she performed the public duties of the bishop's wife. Of Bernard's siblings, Sibyl died prematurely in Tasmania, and Harold, Donald and Una all emigrated. Maud Montgomery took little active interest in the education of her young children other than to have them taught by tutors brought from England. The loveless environment made Bernard something of a bully, as he himself recalled, "I was a dreadful little boy. I don't suppose anybody would put up with my sort of behaviour these days." Later in life Montgomery refused to allow his son David to have anything to do with his grandmother, and refused to attend her funeral in 1949.
The family returned to England once for a Lambeth Conference in 1897, and Bernard and his brother Harold were educated for a term at The King's School, Canterbury. In 1901, Bishop Montgomery became secretary of the Society for the Propagation of the Gospel, and the family returned to London. Montgomery attended St Paul's School and then the Royal Military College, Sandhurst, from which he was almost expelled for rowdiness and violence. On graduation in September 1908 he was commissioned into the 1st Battalion The Royal Warwickshire Regiment as a second lieutenant, and first saw overseas service later that year in India. He was promoted to lieutenant in 1910, and in 1912 became adjutant of the 1st Battalion of his regiment at Shorncliffe Army Camp.
First World War.
The First World War began in August 1914 and Montgomery moved to France with his regiment that month. He saw action at the Battle of Le Cateau that month and during the retreat from Mons. At Méteren, near the Belgian border at Bailleul on 13 October 1914, during an Allied counter-offensive, he was shot through the right lung by a sniper. Montgomery was hit once more though, in the knee. He was awarded the Distinguished Service Order for gallant leadership: the citation for this award, published in the "London Gazette" in December 1914 reads:
After recovering in early 1915, he was appointed to be brigade major first of 112th Brigade and then with 104th Brigade under training in Lancashire. He returned to the Western Front in early 1916 as a general staff officer in the 33rd Division and took part in the Battle of Arras in April/May 1917. He became a general staff officer with IX Corps, part of General Sir Herbert Plumer's Second Army, in July 1917.
Montgomery served at the Battle of Passchendaele in Autumn 1917 before finishing the war as General Staff Officer 1 and effectively chief of staff of the 47th (2nd London) Division, with the temporary rank of lieutenant-colonel. A photograph from October 1918, reproduced in many biographies, shows the then unknown Lt.-Col. Montgomery standing in front of Winston Churchill (Minister of Munitions) at the parade following the liberation of Lille.
Between the world wars.
After the First World War Montgomery commanded the 17th Battalion the Royal Fusiliers, a battalion in the British Army of the Rhine, before reverting to his substantive rank of captain (brevet major) in November 1919. He then attended the army's Staff College, Camberley, before being appointed Brigade Major in the 17th Infantry Brigade in January 1921. The brigade was stationed in County Cork carrying out counter-insurgency operations during the final stages of the Irish War of Independence.
Montgomery came to the conclusion that the conflict could not be won without harsh measures, and that self-government was the only feasible solution; in 1923, after the establishment of the Irish Free State and during the Irish Civil War, Montgomery wrote to Colonel Arthur Percival of the Essex Regiment: 
In May 1923, Montgomery was posted to the Territorial 49th Division. He returned to the 1st Royal Warwickshire Regiment in 1925 as a company commander. In January 1926, having been promoted to major in July 1925, he was appointed Deputy Assistant Adjutant General at the Staff College, Camberley in the temporary rank of lieutenant-colonel, a position he held until January 1929 by which time he had been made a (brevet lieutenant-colonel).
In 1927, he met and married Elizabeth Carver, née Hobart, widow of Oswald Carver, Olympic rowing medalist who was killed in the First World War. Their son, David, was born in August 1928. Elizabeth Carver was the sister of the Second World War commander Percy Hobart.
He returned to 1st Royal Warwickshire Regiment again, as Commander of Headquarters Company in January 1929 and went to the War Office to help write the Infantry Training Manual in Summer 1929. In 1931 Montgomery was promoted to lieutenant-colonel commanding the 1st Battalion of The Royal Warwickshire Regiment and saw service in Palestine and India. He was promoted to colonel in June 1934 (seniority from January 1932). He attended and was then recommended to become an instructor at the Indian Army Staff College (now the Pakistan Army Staff College) in Quetta, British India.
On completion of his tour of duty in India, Montgomery returned to Britain in June 1937 where he became commanding officer of the 9th Infantry Brigade with the temporary rank of brigadier, but that year saw great tragedy when his wife died. While on holiday in Burnham-on-Sea, she had suffered an insect bite which became infected, and she died in his arms from septicaemia following an amputation. The loss devastated Montgomery, but he insisted on throwing himself back into his work immediately after the funeral."
In 1938, he organised an amphibious combined operations landing exercise that impressed the new commander-in-chief, Southern Command, General Wavell. He was promoted to major-general in October 1938 and took command of the 8th Infantry Division in Palestine. There he quashed an Arab revolt before returning in July 1939 to Britain, suffering a serious illness on the way, to command the 3rd (Iron) Infantry Division. On hearing of the rebel defeat in April 1939, Montgomery said, "I shall be sorry to leave Palestine in many ways, as I have enjoyed the war out here".
Second World War.
British Expeditionary Force.
Retreat to Dunkirk and evacuation.
Britain declared war on Germany on 3 September 1939. The 3rd Division was deployed to Belgium as part of the British Expeditionary Force (BEF). During this time, Montgomery faced serious trouble from his military superiors and the clergy for his frank attitude regarding the sexual health of his soldiers, but was defended from dismissal by his superior Alan Brooke, commander of II Corps. Montgomery's training paid off when the Germans began their invasion of the Low Countries on 10 May 1940 and the 3rd Division advanced to the River Dijle and then withdrew to Dunkirk with great professionalism, entering the Dunkirk perimeter in a famous night-time march which placed his forces on the left flank which had been left exposed by the Belgian surrender. The 3rd Division returned to Britain intact with minimal casualties. During Operation Dynamo — the evacuation of 330,000 BEF and French troops to Britain — Montgomery assumed command of the II Corps.
On his return Montgomery antagonised the War Office with trenchant criticisms of the command of the BEF and was briefly relegated to divisional command. He was however made a Companion of the Order of the Bath. In July 1940, he was appointed acting lieutenant-general, placed in command of V Corps, responsible for the defence of Hampshire and Dorset, and started a long-running feud with the new commander-in-chief, Southern Command, Claude Auchinleck.
In April 1941, he became commander of XII Corps responsible for the defence of Kent. During this period he instituted a regime of continuous training and insisted on high levels of physical fitness for both officers and other ranks. He was ruthless in sacking officers he considered would be unfit for command in action. Promoted to temporary lieutenant-general in July, in December Montgomery was given command of South-Eastern Command overseeing the defence of Kent, Sussex and Surrey.
He renamed his command the South-Eastern Army to promote offensive spirit. During this time he further developed and rehearsed his ideas and trained his soldiers, culminating in Exercise Tiger in May 1942, a combined forces exercise involving 100,000 troops.
North Africa and Italy.
Montgomery's early command.
In 1942, a new field commander was required in the Middle East, where Auchinleck was fulfilling both the role of commander-in-chief Middle East Command and commander Eighth Army. He had stabilised the Allied position at the First Battle of El Alamein, but after a visit in August 1942, the Prime Minister, Winston Churchill, replaced him as C-in-C with Alexander and William Gott as commander of the Eighth Army in the Western Desert. After Gott was killed flying back to Cairo Churchill was persuaded by Brooke, who by this time was Chief of the Imperial General Staff, to appoint Montgomery, who had only just been nominated to replace Alexander as commander of the British ground forces for Operation Torch.
A story, probably apocryphal but popular at the time, is that the appointment caused Montgomery to remark that "After having an easy war, things have now got much more difficult." A colleague is supposed to have told him to cheer up – at which point Montgomery is supposed to have said "I'm not talking about me, I'm talking about Rommel!" 
Montgomery's assumption of command transformed the fighting spirit and abilities of the Eighth Army. Taking command on 13 August 1942, he immediately became a whirlwind of activity. He ordered the creation of the X Corps, which contained all armoured divisions to fight alongside his XXX Corps which was all infantry divisions. This was in no way similar to a German Panzer Corps. One of Rommel's Panzer Corps combined infantry, armour and artillery units under one corps commander. The only common commander for Montgomery's all infantry and all armour corps was the Eighth Army Commander himself. Correlli Barnett commented that Montgomery's solution "... was in every way opposite to Auchinleck's and in every way wrong, for it carried the existing dangerous separatism still further." Montgomery reinforced the long front line at El Alamein, something that would take two months to accomplish. He asked Alexander to send him two new British divisions (51st Highland and 44th) that were then arriving in Egypt and were scheduled to be deployed in defence of the Nile Delta. He moved his field HQ to Burg al Arab, close to the Air Force command post in order better to coordinate combined operations.
Montgomery was determined that the Army, Navy and Air Forces should fight their battles in a unified, focused manner according to a detailed plan. He ordered immediate reinforcement of the vital heights of Alam Halfa, just behind his own lines, expecting the German commander, Erwin Rommel, to attack with the heights as his objective, something that Rommel soon did. Montgomery ordered all contingency plans for retreat to be destroyed. "I have cancelled the plan for withdrawal", he told his officers at the first meeting he held with them in the desert. "If we are attacked, then there will be no retreat. If we cannot stay here alive, then we will stay here dead."
Montgomery made a great effort to appear before troops as often as possible, frequently visiting various units and making himself known to the men, often arranging for cigarettes to be distributed. Although he still wore a standard British officer's cap on arrival in the desert, he briefly wore an Australian broad-brimmed hat before switching to wearing the black beret (with the badge of the Royal Tank Regiment next to the British General Officer's badge) for which he became notable. The black beret was offered to him by Jim Fraser whilst the latter was driving him on an inspection tour. Both Brooke and Alexander were astonished by the transformation in atmosphere when they visited on 19 August, less than a week after Montgomery had taken command.
First battles with Rommel.
Rommel attempted to turn the left flank of the Eighth Army at the Battle of Alam Halfa from 31 August 1942. The German/Italian armoured Corps infantry attack was stopped in very heavy fighting. Rommel's forces had to withdraw urgently lest their retreat through the British minefields be cut off. Montgomery was criticised for not counter-attacking the retreating forces immediately, but he felt strongly that his methodical build-up of British forces was not yet ready. A hasty counter-attack risked ruining his strategy for an offensive on his own terms in late October, planning for which had begun soon after he took command. He was confirmed in the permanent rank of lieutenant-general in mid October.
The conquest of Libya was essential for airfields to support Malta and to threaten the rear of Axis forces opposing Operation Torch. Montgomery prepared meticulously for the new offensive after convincing Churchill that the time was not being wasted. (Churchill sent a telegram to Alexander on 23 September 1942 which began, "We are in your hands and of course a victorious battle makes amends for much delay.") He was determined not to fight until he thought there had been sufficient preparation for a decisive victory, and put into action his beliefs with the gathering of resources, detailed planning, the training of troops—especially in clearing minefields and fighting at night—and in the use of 252 of the latest American-built Sherman tanks, 90 M7 Priest self-propelled howitzers, and making a personal visit to every unit involved in the offensive. By the time the offensive was ready in late October, Eighth Army had 231,000 men on its ration strength.
El Alamein.
The Second Battle of El Alamein began on 23 October 1942, and ended 12 days later with the first large-scale, decisive Allied land victory of the war. Montgomery correctly predicted both the length of the battle and the number of casualties (13,500). However, soon after Allied armoured units and infantry broke through the German and Italian lines and were pursuing the enemy forces at speed along the coast road, a violent rainstorm burst over the region, bogging down the tanks and support trucks in the desert mud. Montgomery, standing before his officers at headquarters and close to tears, announced that he was forced to call off the pursuit. Corelli Barnett has pointed out that the rain also fell on the Germans, and that the weather is therefore an inadequate explanation for the failure to exploit the breakthrough, but nevertheless the Battle of El Alamein had been a great success. Over 30,000 prisoners were taken, including the German second in command, General von Thoma, as well as eight other general officers. Rommel, having been in a hospital in Germany at the start of the battle, was forced to return on 25 October 1942 after General Stumme – his replacement as German commander – died of a heart attack in the early hours of the battle.
Tunisia.
Montgomery was advanced to KCB and promoted to full general. He kept the initiative, applying superior strength when it suited him, forcing Rommel out of each successive defensive position. On 6 March 1943, Rommel's attack on the over-extended Eighth Army at Medenine (Operation Capri) with the largest concentration of German armour in North Africa was successfully repulsed. At the Mareth Line, 20 to 27 March, when Montgomery encountered fiercer frontal opposition than he had anticipated, he switched his major effort into an outflanking inland pincer, backed by low-flying RAF fighter-bomber support. For his role in North Africa he was awarded the Legion of Merit by the United States government in the rank of Chief Commander.
Sicily.
The next major Allied attack was the Allied invasion of Sicily (Operation Husky). Montgomery considered the initial plans for the Allied invasion, which had been agreed in principle by Eisenhower and Alexander, to be unworkable because of the dispersion of effort. He managed to have the plans recast to concentrate the Allied forces, having Patton's Seventh US Army land in the Gulf of Gela (on the left flank of Eighth Army, which landed around Syracuse in the south-east of Sicily) rather than near Palermo in the west and north of Sicily. Inter-Allied tensions grew as the American commanders Patton and Bradley (then commanding II US Corps under Patton), took umbrage at what they perceived as Montgomery's attitudes and boastfulness.
Italian Campaign.
During the autumn of 1943, Montgomery continued to command the Eighth Army during the landings on the mainland of Italy itself. In conjunction with the Anglo-American landings at Salerno (near Naples) by Mark Clark's Fifth Army and seaborne landings by British paratroops in the heel of Italy (including the key port of Taranto, where they disembarked without resistance directly into the port), Montgomery led the Eighth Army up the toe of Italy. Montgomery abhorred the lack of coordination, the dispersion of effort, and the strategic muddle and opportunism he perceived in the Allied effort in Italy and was glad to leave the "dog's breakfast" on 23 December 1943.
Normandy.
Montgomery returned to Britain in January 1944. He was assigned to command the 21st Army Group which consisted of all Allied ground forces that would take part in Operation Overlord, the invasion of Normandy under overall direction of the Supreme Commander, Allied Expeditionary Forces, American General Dwight D. Eisenhower. At St Paul's School on 7 April and 15 May he presented his strategy for the invasion. He envisaged a ninety day battle, ending when all the forces reached the Seine, pivoting on an Allied-held Caen, with British and Canadian armies forming a shoulder to attract and defeat the main German counter-attacks, while the US armies took the Cherbourg peninsula and Brittany, wheeling south and then east on the right.
During the hard fought two and a half month Battle of Normandy that followed, the impact of a series of unfavourable autumnal weather conditions disrupted the Normandy landing areas. Montgomery's initial plan was to break out immediately towards Caen. Depending on the historical interpretation he was unable or unwilling to do so. As the campaign progressed Montgomery altered his initial plan for the invasion and switched to a strategy of attracting and holding German counter-attacks in the area north of Caen, which was designed to allow the United States Army in the west to take Cherbourg. Hampered by stormy weather and the bocage terrain, Montgomery had to ensure Rommel focused on the British in the east rather than the Americans in the west, who had to take the Cotentin Peninsula and Brittany before the Germans could be trapped by a general swing east. By the middle of July Caen had been taken, as Rommel continued to prioritise prevention of the break-out by British forces rather than the western territories being taken by the Americans. This was broadly as Montgomery had planned, albeit not with the same speed as he outlined at St Paul's. An American break-out was achieved with Operation Cobra and the encirclement of German forces in the Falaise pocket at the cost of British sacrifice with the diversionary Operation Goodwood.
Advance to the Rhine.
General Eisenhower took over Ground Forces Command on 1 September, while continuing as Supreme Commander, with Montgomery continuing to command the 21st Army Group, now consisting mainly of British and Canadian units. Montgomery bitterly resented this change, although it had been agreed before the D-Day invasion.
Winston Churchill had Montgomery promoted to field marshal by way of compensation. Montgomery was able to persuade Eisenhower to adopt his strategy of a single thrust to the Ruhr with Operation Market Garden in September 1944. It was uncharacteristic of Montgomery's battles: the offensive was strategically bold but poorly planned. Montgomery either did not receive or ignored ULTRA intelligence which warned of the presence of German armoured units near the site of the attack.
When the surprise attack on the Ardennes took place on 16 December 1944, starting the Battle of the Bulge, the front of the U.S. 12th Army Group was split, with the bulk of the U.S. First Army being on the northern shoulder of the German 'bulge'. The Army Group commander, General Omar Bradley, was located south of the penetration at Luxembourg and command of the U.S. First Army became problematic. Montgomery was the nearest commander on the ground and on 20 December, Eisenhower (who was in Versailles) transferred Courtney Hodges' U.S. First Army and William Simpson's U.S. Ninth Army to his 21st Army Group, despite Bradley's vehement objections on national grounds. Montgomery grasped the situation quickly, visiting all divisional, corps, and army field commanders himself and instituting his 'Phantom' network of liaison officers. He grouped the British XXX Corps as a strategic reserve behind the Meuse and reorganised the US defence of the northern shoulder, shortening and strengthening the line and ordering the evacuation of St Vith. The German commander of the 5th Panzer Army, Hasso von Manteuffel said:
The operations of the American 1st Army had developed into a series of individual holding actions. Montgomery's contribution to restoring the situation was that he turned a series of isolated actions into a coherent battle fought according to a clear and definite plan. It was his refusal to engage in premature and piecemeal counter-attacks which enabled the Americans to gather their reserves and frustrate the German attempts to extend their breakthrough.
Montgomery's 21st Army Group advanced to the Rhine with operations Veritable and Grenade in February 1945. A meticulously planned Rhine crossing occurred on 24 March. While successful it was weeks after the Americans had unexpectedly captured the Ludendorff Bridge and crossed the river. Montgomery's river crossing was followed by the encirclement of the German Army Group B in the Ruhr. Initially Montgomery's role was to guard the flank of the American advance. This was altered, however, to forestall any chance of a Red Army advance into Denmark, and the 21st Army Group occupied Hamburg and Rostock and sealed off the Danish peninsula. On 4 May 1945, on Lüneburg Heath, Montgomery accepted the Surrender of German forces in north-west Germany, Denmark and the Netherlands.
Later life.
After the war Montgomery became the C-in-C of the British Army of the Rhine (BAOR), the name given to the British Occupation Forces, and was the British member of the Allied Control Council. He was created 1st Viscount Montgomery of Alamein in 1946. He was Chief of the Imperial General Staff from 1946–48, succeeding Alanbrooke, but was largely a failure as the role required strategic and political skills he did not possess. He was barely on speaking terms with his fellow chiefs, sending his VCIGS to attend their meetings and he clashed particularly with Arthur Tedder, who as Deputy Supreme Commander had intrigued for Montgomery's dismissal during the Battle of Normandy, and who was by now Chief of the Air Staff. When Montgomery's term of office expired, Prime Minister Clement Attlee appointed General (later Field-Marshal) William Slim as his successor; when Montgomery protested that he had told his protégé John Crocker, a former corps commander from the 1944-45 campaign, that the job was to be his, Attlee is said to have given the memorable retort "Untell him".
He was then appointed Chairman of the Western European Union's commanders-in-chief committee. Volume 3 of Nigel Hamilton's "Life of Montgomery of Alamein" gives a good account of the bickering between Montgomery and his land forces chief, a French general, which created splits through the Union headquarters. He was thus pleased to become Eisenhower's deputy in creating the North Atlantic Treaty Organisation's European forces in 1951. He was an effective inspector-general and mounted good exercises, but out of his depth politically. He continued to serve under Eisenhower's successors, Matthew Ridgway and Al Gruenther, until his retirement, aged nearly 71, in 1958. His mother died in 1949; Montgomery did not attend the funeral, claiming he was "too busy".
He was chairman of the governing body of St. John's School, Leatherhead from 1951–66, and a generous supporter. Montgomery was an Honorary Member of the Winkle Club, a noted charity in Hastings, East Sussex, and introduced Winston Churchill to the club in 1955.
In 1953, the Hamilton Board of Education in Hamilton, Ontario, Canada, wrote to Montgomery and asked permission to name a new school in the city's east end after him. Viscount Montgomery Elementary was billed as "the most modern school in North America" and the largest single-storey school in Hamilton, when the sod was turned on 14 March 1951. The school officially opened on 18 April 1953, with Montgomery in attendance among almost 10,000 well-wishers. At the opening, he gave the motto "Gardez Bien" from his own family's coat of arms. Montgomery referred to the school as his "beloved school" and visited on five separate occasions, the last being in 1960. On his last visit, he said to "his" students:
Montgomery's memoirs (1958) criticised many of his wartime comrades in harsh terms, including Eisenhower, whom he accused, among other things, of prolonging the war by a year through poor leadership — allegations which ended their friendship, not least as Eisenhower was still US President at the time. He was threatened with legal action by Field-Marshal Auchinleck for suggesting that Auchinleck had intended to retreat from the Alamein position if attacked again, and had to give a radio broadcast (20 November 1958) expressing his gratitude to Auchinleck for having stabilised the front at the First Battle of Alamein. The 1960 paperback edition of his memoirs contains a publisher's note drawing attention to that broadcast, and stating that in the publisher's view the reader might reasonably assume from Montgomery's text that Auchinleck had been planning to retreat "into the Nile Delta or beyond" and pointing out that it had been Auchinleck's intention to launch an offensive as soon as Eighth Army was "rested and regrouped". Montgomery was stripped of his honorary citizenship of Montgomery, Alabama, and was challenged to a duel by an Italian officer.
In retirement he publicly supported apartheid after a visit to South Africa in 1962, outraging much British liberal opinion, and after a visit to China declared himself impressed by the Chinese leadership. He spoke out against the legalisation of homosexuality in the United Kingdom, arguing that the "Sexual Offences Act 1967" was a "charter for buggery" and that "this sort of thing may be tolerated by the French, but we're British – thank God." Biographer Nigel Hamilton has suggested Montgomery may have been a repressed homosexual; in the late 1940s Montgomery maintained an affectionate friendship with a 12-year-old Swiss boy. One biographer called the friendship "bizarre", although not "improper", and a sign of "pitiful loneliness."
He twice met with Israeli general Moshe Dayan. After an initial meeting in the early 1950s, Montgomery met Dayan again in the 1960s to discuss the Vietnam War, which Dayan was studying. Montgomery was harshly critical of US strategy in Vietnam, which involved deploying large numbers of combat troops, aggressive bombing attacks, and uprooting entire village populations and forcing them into strategic hamlets. Montgomery said that the Americans' most important problem was that they had no clear-cut objective, and allowed local commanders to set military policy. At the end of their meeting, Montgomery asked Dayan to tell the Americans, in his name, that they were "insane".
Death.
Montgomery died from unspecified causes in 1976 at his home Isington Mill, Isington near Alton, Hampshire, aged 88. After his funeral at St George's Chapel, Windsor, Montgomery was interred in Holy Cross churchyard, Binsted.
Legacy.
His portrait (by Frank O. Salisbury, 1945) hangs in the National Portrait Gallery.
A statue of Montgomery can be found outside the Ministry of Defence in Whitehall, alongside those of Field Marshal Lord Slim and Field Marshal Lord Alanbrooke.
Montgomery gave his name to the French commune Colleville-Montgomery, Normandy.
The Imperial War Museum holds a variety of material relating to Montgomery in its collections. These include Montgomery's Grant command tank (on display in the atrium at the Museum's London branch), his command caravans as used in North West Europe (on display at IWM Duxford), and his papers are held by the Museum's Department of Documents. The Museum maintains a permanent exhibition about Montgomery, entitled "Monty: Master of the Battlefield".
The Field Marshal Montgomery Pipe Band from Northern Ireland is named after him.
His Rolls-Royce staff car is on display at the Royal Logistic Corps Museum, Deepcut, Surrey.
The Montgomery cocktail is a martini mixed at a ratio of 15:1, facetiously named that because Montgomery supposedly refused to go into battle unless his numerical advantage was at least that high. Ironically, following severe internal injuries received in the First World War, Montgomery himself could neither smoke nor drink.
In the 1998 documentary "Live At Aspen" during the US Comedy Arts Festival, the British comedy troupe "Monty Python" explained how they came up with their name, saying that the name Monty "... made us laugh because Monty to us means Lord Montgomery, our great general of the Second World War".
Honours and awards.
Viscount Montgomery's ribbons as they would appear today, not including campaign or other awards.

</doc>
<doc id="3874" url="http://en.wikipedia.org/wiki?curid=3874" title="Herman Boerhaave">
Herman Boerhaave

Herman Boerhaave (, 31 December 1668 – 23 September 1738) was a Dutch botanist, Christian humanist and physician of European fame. He is regarded as the founder of clinical teaching and of the modern academic hospital and is sometimes referred to as "the father of physiology," along with his pupil Albrecht von Haller.
His best known for demonstrating the relation of symptoms to lesions and, in addition, he was the first to isolate the chemical urea from urine. His motto was "Simplex sigillum veri"; "Simplicity is the sign of truth".
From 1950 to 1970, Boerhaave's image was printed on Dutch 20-guilder banknotes. The Leiden University Medical Centre organises medical trainings called "Boerhaave-courses".
Biography.
Boerhaave was born at Voorhout near Leiden. The son of a Protestant pastor, in his youth Boeerhave studied for a divinity degree and wanted to become a preacher. After the death of his father, however, he was offered a scholarship and he entered the University of Leiden, where he took his degree in philosophy in 1689, with a dissertation "De distinctione mentis a corpore" (on the difference of the mind from the body). There he attacked the doctrines of Epicurus, Thomas Hobbes and Spinoza. He then turned to the study of medicine, in which he graduated in 1693 at Harderwijk in present-day Gelderland.
In 1701 he was appointed lecturer on the institutes of medicine at Leiden; in his inaugural discourse, "De commendando Hippocratis studio", he recommended to his pupils that great physician as their model. In 1709 he became professor of botany and medicine, and in that capacity he did good service, not only to his own university, but also to botanical science, by his improvements and additions to the botanic garden of Leiden, and by the publication of numerous works descriptive of new species of plants.
On 14 September 1710, Boerhaave married Maria Drolenvaux, the daughter of the rich merchant, Alderman Abraham Drolenvaux. They had four children, of whom one daughter, Maria Joanna, lived to adulthood [http://www.whonamedit.com/doctor.cfm/2404.html]. In 1722, he began to suffer from an extreme case of gout, recovering the next year.
In 1714, when he was appointed rector of the university, he succeeded Govert Bidloo in the chair of practical medicine, and in this capacity he introduced the modern system of clinical instruction. Four years later he was appointed to the chair of chemistry as well. In 1728 he was elected into the French Academy of Sciences, and two years later into the Royal Society of London. In 1729 declining health obliged him to resign the chairs of chemistry and botany; and he died, after a lingering and painful illness, at Leiden.
Legacy.
His reputation so increased the fame of the University of Leiden, especially as a school of medicine, that it became popular with visitors from every part of Europe. All the princes of Europe sent him pupils, who found in this skillful professor not only an indefatigable teacher, but an affectionate guardian. When Peter the Great went to Holland in 1716 (he was in Holland before in 1697 to instruct himself in maritime affairs), he also took lessons from Boerhaave. Voltaire traveled to see him, as did Carl Linnaeus, who became a close friend. His reputation was not confined to Europe; a Chinese mandarin sent him a letter addressed to "the illustrious Boerhaave, physician in Europe," and it reached him in due course. The operating theatre of the University of Leiden in which he once worked as an anatomist is now at the center of a museum named after him; the Boerhaave Museum. The near-Earth minor planet (8176) 1991 WA in the Apollo group is nicknamed Booerhaave in his honor.
Boerhaave first described Boerhaave syndrome, which involves tearing of the esophagus, usually a consequence of vigorous vomiting. He notoriously described in 1724 the case of Baron Jan von Wassenaer, a Dutch admiral who died of this condition following a gluttonous feast and subsequent regurgitation. This condition was uniformly fatal prior to modern surgical techniques allowing repair of the esophagus.
Boerhaave was critical of his Dutch contemporary, Baruch Spinoza, attacking him in his dissertation in 1689. At the same time, he admired Isaac Newton and was a devout Christian who often wrote about God in his works. A collection of his religious thoughts on medicine, translated from Latin to English, has been compiled by the "Sir Thomas Browne Instituut Leiden" under the name "Boerhaaveìs Orations" (meaning "Boherhaavian Prayers"). Among other things, he considered nature as God's Creation and he used to say that the poor were his best patients because God was their paymaster.

</doc>
<doc id="3875" url="http://en.wikipedia.org/wiki?curid=3875" title="Benjamin Disraeli">
Benjamin Disraeli

Benjamin Disraeli, 1st Earl of Beaconsfield, KG, PC, FRS, (21 December 1804 – 19 April 1881) was a British Conservative politician, writer and aristocrat who twice served as Prime Minister. He played a central role in the creation of the modern Conservative Party, defining its policies and its broad outreach. Disraeli is remembered for his influential voice in world affairs, his political battles with the Liberal leader William Ewart Gladstone, and his one-nation conservatism or "Tory democracy". He made the Conservatives the party most identified with the glory and power of the British Empire. He is as of 2014 the only British Prime Minister of Jewish birth.
Disraeli was born in London. His father left Judaism after a dispute at his synagogue; young Benjamin became an Anglican at age 12. After several unsuccessful attempts, Disraeli entered the House of Commons in 1837. When the Conservatives gained power in 1841, Disraeli was given no office by the Prime Minister, Sir Robert Peel. In 1846, Peel split the party over his proposal to repeal the Corn Laws, which imposed a tariff on imported grain. Disraeli clashed with Peel in the Commons. The Conservatives who split from Peel had few who were adept in Parliament, and Disraeli became a major figure in the party, though many in it did not favour him. When Lord Derby, the party leader, thrice formed governments in the 1850s and 1860s, Disraeli served as Chancellor of the Exchequer and Leader of the House of Commons. He also forged a bitter rivalry with the Liberal Party's William Ewart Gladstone.
Upon Derby's retirement due to ill health in 1868, Disraeli became Prime Minister briefly before losing that year's election. He returned to opposition, before leading the party to a majority in the 1874 election. He maintained a close friendship with Queen Victoria, who in 1876 created him Earl of Beaconsfield. Disraeli's second term was dominated by the Eastern Question—the slow decay of the Ottoman Empire and the desire of other countries, such as Russia, to gain at its expense. Disraeli arranged for the British to purchase a major interest in the Suez Canal Company (in Ottoman-controlled Egypt). In 1878, faced with Russian victories against the Ottomans, he worked at the Congress of Berlin to maintain peace in the Balkans and made terms favourable to Britain which weakened Russia, its longstanding enemy. This diplomatic victory over Russia established Disraeli as one of Europe's leading statesmen.
World events thereafter moved against the Conservatives. Controversial wars in Afghanistan and South Africa undermined his public support. He angered British farmers by refusing to reinstitute the Corn Laws in response to poor harvests and cheap American grain. With Gladstone conducting a massive speaking campaign, his Liberals bested Disraeli's Conservatives in the 1880 election. In his final months, Disraeli led the Conservatives in opposition. He had throughout his career written novels, beginning in 1826, and he published his last completed novel, "Endymion", shortly before he died at the age of 76.
Early life.
Childhood.
Disraeli was born on 21 December 1804 at 6 King's Road, Bedford Row, Bloomsbury, London, the second child and eldest son of Isaac D'Israeli, a literary critic and historian, and Maria (Miriam), "née" Basevi. The family was of Sephardic Jewish Italian mercantile background. All Disraeli's grandparents and great grandparents were born in Italy; Isaac's father, Benjamin, moved to England from Venice in 1748. Disraeli later romanticised his origins, claiming that his father's family was of grand Spanish and Venetian descent; in fact Isaac's family was of no great distinction, but on Disraeli's mother's side, in which he took no interest, there were some highly distinguished forebears. Historians differ on Disraeli's motives for rewriting his family history: Bernard Glassman argues that it was intended to give him status comparable to that of England's ruling élite; Sarah Bradford believes "his dislike of the commonplace would not allow him to accept the facts of his birth as being as middle class and undramatic as they really were".
Disraeli's siblings were Sarah (1802–1859), Naphtali (born and died 1807), Ralph (1809–1898), and James ("Jem") (1813–1868). He was close to his sister, and on affectionate but more distant terms with his surviving brothers. Details of his schooling are sketchy. From the age of about six he was a day boy at a dame school in Islington that one of his biographers later described as "for those days a very high-class establishment." Two years later or so—the exact date has not been ascertained—he was sent as a boarder to the Rev John Potticary's school at Blackheath. While he was there events at the family home changed the course of Disraeli's education and of his whole life: his father renounced Judaism and had the four children baptised into the Church of England in July and August 1817.
Isaac D'Israeli had never taken religion very seriously, but had remained a conforming member of the Bevis Marks Synagogue. His father, the elder Benjamin, was a prominent and devout member; it was probably from respect for him that Isaac did not leave when he fell out with the synagogue authorities in 1813. After Benjamin senior died in 1816 Isaac felt free to leave the congregation following a second dispute. His friend Sharon Turner, a solicitor, convinced him that although he could comfortably remain unattached to any formal religion it would be disadvantageous to the children if they did so. Turner stood as godfather when Benjamin was baptised, aged twelve, on 31 July 1817.
Conversion to Christianity enabled Disraeli to contemplate a career in politics. Britain in the early 19th century was not a greatly anti-Semitic society, and there had been Members of Parliament (MPs) from Jewish families since Samson Gideon in 1770. But until 1858 MPs were required to take the oath of allegiance "on the true faith of a Christian", necessitating at least nominal conversion. It is not known whether Disraeli formed any ambition for a parliamentary career at the time of his baptism, but there is no doubt that he bitterly regretted his parents' decision not to send him to Winchester College. As one of the great public schools of England, Winchester consistently provided recruits to the political élite. His two younger brothers were sent there, and it is not clear why Isaac D'Israeli chose to send his eldest son to a much less prestigious school. The boy evidently held his mother responsible for the decision; Bradford speculates that "Benjamin's delicate health and his obviously Jewish appearance may have had something to do with it." The school chosen for him was run by Eliezer Cogan at Higham Hill in Walthamstow. He began there in the autumn term of 1817; he later recalled his education:
1820s.
In November 1821, shortly before his seventeenth birthday, Disraeli was articled as a clerk to a firm of solicitors—Swain, Stevens, Maples, Pearse and Hunt—in the City of London. T F Maples was not only the young Disraeli's employer and friend of his father's, but also his prospective father-in-law: Isaac and Maples entertained the possibility that the latter's only daughter might be a suitable match for Benjamin. A friendship developed, but there was no romance. The firm had a large and profitable business, and as the biographer R W Davis observes, the clerkship was "the kind of secure, respectable position that many fathers dream of for their children". Although biographers including Robert Blake and Bradford comment that such a post was incompatible with Disraeli's romantic and ambitious nature, he reportedly gave his employers satisfactory service, and later professed to have learned a good deal from his time with the firm. He recalled, "I had some scruples, for even then I dreamed of Parliament. My father's refrain always was 'Philip Carteret Webb', who was the most eminent solicitor of his boyhood and who was an MP. It would be a mistake to suppose that the two years and more that I was in the office of our friend were wasted. I have often thought, though I have often regretted the University, that it was much the reverse."
The year after joining Maples's firm, Benjamin changed his surname from D'Israeli to Disraeli. His reasons for doing so are unknown, but the biographer Bernard Glassman surmises that it was to avoid being confused with his father. Disraeli's sister and brothers adopted the new version of the name; Isaac and his wife retained the older form.
Disraeli toured Belgium and the Rhine Valley with his father in the summer of 1824; he later wrote that it was while travelling on the Rhine that he decided to abandon his position: "I determined when descending those magical waters that I would not be a lawyer." On their return to England he left the solicitors, at the suggestion of Maples, with the aim of qualifying as a barrister. He enrolled as a student at Lincoln's Inn and joined the chambers of his uncle, Nathaniel Basevy, and then those of Benjamin Austen, who persuaded Isaac that Disraeli would never make a barrister and should be allowed to pursue a literary career. He had made a tentative start: in May 1824 he submitted a manuscript to his father's friend, the publisher John Murray, but withdrew it before Murray could decide whether to publish it. Released from the law, Disraeli did some work for Murray, but turned most of his attention not to literature but to speculative dealing on the stock exchange.
There was at the time a boom in shares in South American mining companies. Spain was losing its South American colonies in the face of rebellions. At the urging of George Canning the British government recognised the new independent governments of Argentina (1824), Colombia and Mexico (both 1825). With no money of his own, Disraeli borrowed money to invest. He became involved with the financier J D Powles, who was prominent among those encouraging the mining boom. In the course of 1825, Disraeli wrote three anonymous pamphlets for Powles, promoting the companies. The pamphlets were published by John Murray, who invested heavily in the boom.
Murray had for some time had ambitions to establish a new morning paper to compete with "The Times". In 1825 Disraeli convinced him that he should proceed. The new paper, "The Representative", promoted the mines and those politicians who supported them, particularly Canning. Disraeli impressed Murray with his energy and commitment to the project, but he failed in his key task of persuading the eminent writer John Gibson Lockhart to edit the paper. After that, Disraeli's influence on Murray waned, and to his resentment he was sidelined in
the affairs of "The Representative". The paper survived for only six months, partly because the mining bubble burst in late 1825, and partly because, according to Blake, the paper was "atrociously edited", and would have failed regardless.
The bursting of the mining bubble was ruinous for Disraeli. By June 1825 he and his business partners had lost £7,000. Disraeli could not pay off the last of his debts from this debacle until 1849. He turned to writing, motivated partly by his desperate need for money, and partly by a wish for revenge on Murray and others by whom he felt slighted. There was a vogue for what was called "silver-fork fiction"—novels depicting aristocratic life, usually by anonymous authors, read avidly by the aspirational middle classes. Disraeli's first novel, "Vivian Grey", published anonymously in four volumes in 1826–27, was a thinly veiled re-telling of the affair of "The Representative". It sold well, but caused much offence in influential circles when the authorship was discovered. Disraeli, then just twenty-three, did not move in high society, as the numerous solecisms in his book made obvious. Reviewers were sharply critical on these grounds of both the author and the book. Furthermore, Murray and Lockhart, men of great influence in literary circles, believed that Disraeli had caricatured them and abused their confidence—an accusation denied by the author but repeated by many of his biographers. In later editions Disraeli made many changes, softening his satire, but the damage to his reputation proved long-lasting.
Disraeli's biographer Jonathan Parry writes that the financial failure and personal criticism that Disraeli suffered in 1825 and 1826 were probably the trigger for a serious nervous crisis affecting him over the next four years: "He had always been moody, sensitive, and solitary by nature, but now became seriously depressed and lethargic." He was still living with his parents in London, but in search of the "change of air" recommended by the family's doctors Isaac took a succession of houses in the country and on the coast, before Disraeli sought wider horizons.
1830s.
Together with his sister's fiancé, William Meredith, Disraeli travelled widely in southern Europe and beyond in 1830–31. The trip was financed partly by another high society novel, "The Young Duke", written in 1829–30. The tour was cut short suddenly by Meredith's death from smallpox in Cairo in July 1831. Despite this tragedy, and the need for treatment for a sexually transmitted disease on his return, Disraeli felt enriched by his experiences. He became, in Parry's words, "aware of values that seemed denied to his insular countrymen. The journey encouraged his self-consciousness .. and his interest in Eastern attitudes." Blake regards the tour as one of the formative experiences of Disraeli's whole career: "he impressions that it made on him were life-lasting. They conditioned his attitude toward some of the most important political problems which faced him in his later years—especially the Eastern Question; they also coloured many of his novels."
Disraeli wrote two novels in the aftermath of the tour. "Contarini Fleming" (1832) was avowedly a self-portrait. It is subtitled "a psychological autobiography", and depicts the conflicting elements of its hero's character: the duality of northern and Mediterranean ancestry, the dreaming artist and the bold man of action. As Parry observes, the book ends on a political note, setting out Europe's progress "from feudal to federal principles." "The Wondrous Tale of Alroy" the following year portrayed the problems of a medieval Jew in deciding between a small, exclusively Jewish state and a large empire embracing all.
After the two novels were published, Disraeli declared that he would "write no more about myself". He had already turned his attention to politics in 1832, during the great crisis over the Reform Bill. He contributed to an anti-Whig pamphlet edited by John Wilson Croker and published by Murray entitled "England and France: or a cure for Ministerial Gallomania". The choice of a Tory publication was regarded as strange by Disraeli's friends and relatives, who thought him more of a Radical. Indeed, he had objected to Murray about Croker's inserting "high Tory" sentiment: Disraeli remarked, "it is quite impossible that anything adverse to the general measure of Reform can issue from my pen." Moreover, at the time "Gallomania" was published, Disraeli was electioneering in High Wycombe in the Radical interest.
Disraeli's politics at the time were influenced both by his rebellious streak and by his desire to make his mark. At that time, the politics of the nation were dominated by members of the aristocracy, together with a few powerful commoners. The Whigs derived from the coalition of lords who had forced through the Bill of Rights in 1689 and in some cases were their actual descendants, not merely spiritual. The Tories tended to support King and Church, and sought to thwart political change. A small number of Radicals, generally from northern constituencies, were the strongest advocates of continuing reform. In the early 1830s the Tories and the interests they represented appeared to be a lost cause. The other great party, the Whigs, were anathema to Disraeli: "Toryism is worn out & I cannot condescend to be a Whig." There were two general elections in 1832; Disraeli unsuccessfully stood as a Radical at High Wycombe in each.
Disraeli's political views embraced certain Radical policies, particularly democratic reform of the electoral system, and also some Tory ones, including protectionism. He began to move in Tory circles. In 1834 he was introduced to the former Lord Chancellor, Lord Lyndhurst, by Henrietta Sykes, wife of Sir Francis Sykes. She was having an affair with Lyndhurst, and began another with Disraeli. Disraeli and Lyndhurst took an immediate liking to each other. Lyndhurst was an indiscreet gossip with a fondness for intrigue; this appealed greatly to Disraeli, who became his secretary and go-between. In 1835 Disraeli stood for the last time as a Radical, unsuccessfully contesting High Wycombe once again.
In April 1835 Disraeli fought a by-election at Taunton as a Tory. The Irish MP Daniel O'Connell, misled by inaccurate press reports, thought Disraeli had slandered him while electioneering at Taunton; he launched an outspoken attack, referring to Disraeli as:
Disraeli's public exchanges with O'Connell, extensively reproduced in "The Times", included a demand for a duel with the 60-year-old O'Connell's son (which resulted in Disraeli's temporary detention by the authorities), a reference to "the inextinguishable hatred with which shall pursue [O'Connell's existence", and the accusation that O'Connell's supporters had a "princely revenue wrung from a starving race of fanatical slaves". Disraeli was highly gratified by the dispute, which propelled him to general public notice for the first time. He did not defeat the incumbent Whig member, Henry Labouchere, but the Taunton constituency was regarded as unwinnable by the Tories. Disraeli kept Labouchere's majority down to 170, a good showing that put him in line for a winnable seat in the near future.
With Lyndhurst's encouragement Disraeli turned to writing propaganda for his newly adopted party. His "Vindication of the English Constitution", was published in December 1835. It was couched in the form of an open letter to Lyndhurst, and in Bradford's view encapsulates a political philosophy that Disraeli adhered to for the rest of his life. Its themes were the value of benevolent aristocratic government, a loathing of political dogma, and the modernisation of Tory policies. The following year he wrote a series of satires on politicians of the day, which he published in "The Times" under the pen-name "Runnymede". His targets included the Whigs, collectively and individually, Irish nationalists, and political corruption. One essay ended:
Disraeli was now firmly in the Tory camp. He was elected to the exclusively Tory Carlton Club in 1836, and was also taken up by the party's leading hostess, Lady Londonderry. In June 1837 WilliamIV died, the young Queen Victoria, his niece, succeeded him, and parliament was dissolved. On the recommendation of the Carlton Club, Disraeli was adopted as a Tory parliamentary candidate at the ensuing General Election.
Parliament.
Back-bencher.
In the election in July 1837 Disraeli won a seat in the House of Commons as one of two members, both Tory, for the constituency of Maidstone. The other was Wyndham Lewis, who helped finance Disraeli's election campaign, and who died the following year. In the same year Disraeli published a novel, "Henrietta Temple", which was a love story and social comedy, drawing on his affair with Henrietta Sykes. He had broken off the relationship in late 1836, distraught that she had taken yet another lover. His other novel of this period is "Venetia", a romance based on the characters of Shelley and Byron, written quickly to raise much-needed money.
Disraeli made his maiden speech in Parliament on 7 December 1837. He followed O'Connell, whom he sharply criticised for the latter's "long, rambling, jumbling, speech". He was shouted down by O'Connell's supporters. After this unpromising start Disraeli kept a low profile for the rest of the parliamentary session. He was a loyal supporter of the party leader Sir Robert Peel and his policies, with the exception of a personal sympathy for the Chartist movement that most Tories did not share.
In 1839 Disraeli married Mary Anne Lewis, the widow of Wyndham Lewis. Twelve years Disraeli's senior, Mary Lewis had a substantial income of £5,000 a year. His motives were generally assumed to be mercenary, but the couple came to cherish one another, remaining close until she died more than three decades later. "Dizzy married me for my money," his wife said later, "But, if he had the chance again, he would marry me for love."
Finding the financial demands of his Maidstone seat too much, Disraeli secured a Tory nomination for Shrewsbury, winning one of the constituency's two seats at the 1841 general election, despite serious opposition, and heavy debts which opponents seized on. The election was a massive defeat for the Whigs across the country, and Peel became Prime Minister. Disraeli hoped, unrealistically, for ministerial office. Though disappointed at being left on the back benches, he continued his support for Peel in 1842 and 1843, seeking to establish himself as an expert on foreign affairs and international trade.
Although a Tory (or Conservative, as some in the party now called themselves) Disraeli was sympathetic to some of the aims of Chartism, and argued for an alliance between the landed aristocracy and the working class against the increasing power of the merchants and new industrialists in the middle class. After Disraeli won widespread acclaim in March 1842 for worsting the formidable Lord Palmerston in debate, he was taken up by a small group of idealistic new Tory MPs, with whom he formed the Young England group. They held that the landed interests should use their power to protect the poor from exploitation by middle-class businessmen.
For many years in his parliamentary career Disraeli hoped to forge a paternalistic Tory-Radical alliance, but he was unsuccessful. Before the Reform Act 1867, the working class did not possess the vote and therefore had little political power. Although Disraeli forged a personal friendship with John Bright, a Lancashire manufacturer and leading Radical, Disraeli was unable to persuade Bright to sacrifice his distinct position for parliamentary advancement. When Disraeli attempted to secure a Tory-Radical cabinet in 1852, Bright refused.
Disraeli gradually became a sharp critic of Peel's government, often deliberately taking positions contrary to those of his nominal chief. The best known of these stances were over the Maynooth grant in 1845 and the repeal of the Corn Laws in 1846. The President of the Board of Trade, William Gladstone, resigned from the cabinet over the Maynooth grant. The Corn Laws imposed a tariff on imported wheat, protecting British farmers from foreign competition, but making the cost of bread artificially high. Peel hoped that the repeal of the Corn Laws and the resultant influx of cheaper wheat into Britain would relieve the condition of the poor, and in particular the suffering caused by successive failure of potato crops in Ireland—the Great Famine.
The first months of 1846 were dominated by a battle in Parliament between the free traders and the protectionists over the repeal of the Corn Laws, with the latter rallying around Disraeli and Lord George Bentinck. An alliance of free-trade Conservatives (the "Peelites"), Radicals, and Whigs carried repeal, and the Conservative Party split: the Peelites moved towards the Whigs, while a "new" Conservative Party formed around the protectionists, led by Disraeli, Bentinck, and Lord Stanley (later Lord Derby).
The split in the Tory party over the repeal of the Corn Laws had profound implications for Disraeli's political career: almost every Tory politician with experience of office followed Peel, leaving the rump bereft of leadership. In Blake's words, " found himself almost the only figure on his side capable of putting up the oratorical display essential for a parliamentary leader." Looking on from the House of Lords, the Duke of Argyll wrote that Disraeli "was like a subaltern in a great battle where every superior officer was killed or wounded." If the Tory Party could muster the electoral support necessary to form a government, then Disraeli now seemed to be guaranteed high office. However, he would take office with a group of men who possessed little or no official experience, who had rarely felt moved to speak in the House of Commons, and who, as a group, remained hostile to Disraeli on a personal level. In the event the matter was not put to the test, as the Tory split soon had the party out of office, not regaining power until 1852. The Conservatives would not again have a majority in the House of Commons until 1874.
Bentinck and the leadership.
Peel successfully steered the repeal of the Corn Laws through Parliament, and was then defeated by an alliance of all his enemies on the issue of Irish law and order; he resigned in June 1846. The Tories remained split and the Queen sent for Lord John Russell, the Whig leader. In the 1847 general election, Disraeli stood, successfully, for the Buckinghamshire constituency. The new House of Commons had more Conservative than Whig members, but the depth of the Tory schism enabled Russell to continue to govern. The Conservatives were led by Bentinck in the Commons and Stanley in the Lords.
In 1847 a small political crisis occurred which removed Bentinck from the leadership and highlighted Disraeli's differences with his own party. In that year's general election, Lionel de Rothschild had been returned for the City of London. As a practising Jew he could not take the oath of allegiance in the prescribed Christian form, and therefore could not take his seat. Lord John Russell, the Whig leader who had succeeded Peel as Prime Minister and like Rothschild was a member for the City of London, proposed in the Commons that the oath should be amended to permit Jews to enter Parliament.
Disraeli spoke in favour of the measure, arguing that Christianity was "completed Judaism," and asking the House of Commons "Where is your Christianity if you do not believe in their Judaism?" Russell and Disraeli's future rival Gladstone thought it brave of him to speak as he did; the speech was badly received by his own party. The Tories and the Anglican establishment were hostile to the bill. Samuel Wilberforce, Bishop of Oxford, spoke strongly against the measure and implied that Russell was paying off the Jews for helping elect him. With the exception of Disraeli, every member of the future protectionist cabinet then in Parliament voted against the measure. One who was not yet an MP, Lord John Manners, stood against Rothschild when the latter re-submitted himself for election in 1849. Bentinck joined Disraeli in speaking and voting for the bill, although his own speech was a standard one of toleration. The measure was voted down.
In the aftermath of the debate Bentinck resigned the leadership and was succeeded by Lord Granby; Disraeli's own speech, thought by many of his own party to be blasphemous, ruled him out for the time being. While these intrigues played out, Disraeli was working with the Bentinck family to secure the necessary financing to purchase Hughenden Manor, in Buckinghamshire. The possession of a country house, and incumbency of a county constituency were regarded as essential for a Tory with ambitions to lead the party. Disraeli and his wife alternated between Hughenden and several homes in London for the rest of their marriage. The negotiations were complicated by Bentinck's sudden death on 21 September 1848, but Disraeli obtained a loan of £25,000 from Bentinck's brothers Lord Henry Bentinck and Lord Titchfield.
Within a month of his appointment Granby resigned the leadership in the Commons, feeling himself inadequate to the post, and the party functioned without a leader in the Commons for the rest of the parliamentary session. At the start of the next session, affairs were handled by a triumvirate of Granby, Disraeli, and John Charles Herries—indicative of the tension between Disraeli and the rest of the party, who needed his talents but mistrusted him. This confused arrangement ended with Granby's resignation in 1851; Disraeli effectively ignored the two men regardless.
Office.
First Derby government.
In March 1851 Lord John Russell's government was defeated over a bill to equalise the county and borough franchises, mostly because of divisions among his supporters. He resigned, and the Queen sent for Stanley, who felt that a minority government could do little and would not last long, so Russell remained in office. Disraeli regretted this, hoping for an opportunity, however brief, to show himself capable in office. Stanley, on the other hand, deprecated his inexperienced followers as a reason for not assuming office, "These are not names I can put before the Queen."
At the end of June 1851, Stanley's father died, and he succeeded to his title as Earl of Derby. The Whigs were wracked by internal dissensions during the second half of 1851, much of which Parliament spent in recess. Russell dismissed Lord Palmerston from the cabinet, leaving the latter determined to deprive the Prime Minister of office as well. Palmerston did so within weeks of Parliament's reassembly on 4 February 1852, with his followers combining with Disraeli's Tories to defeat the government on a Militia Bill, and Russell resigned. Derby had either to take office or risk damage to his reputation and he accepted the Queen's commission as Prime Minister. Palmerston declined any office; Derby had hoped to have him as Chancellor of the Exchequer. Disraeli was his second choice and accepted, though disclaiming any great knowledge in the financial field. Gladstone refused to join the government. Disraeli may have been attracted to the office by the £5,000 per year salary, which would help pay his debts. Few of the new cabinet had held office before; when Derby tried to inform the Duke of Wellington of the names of the Queen's new ministers, the old Duke, who was somewhat deaf, inadvertently branded the new government by incredulously repeating "Who? Who?"
In the following weeks, Disraeli served as Leader of the House (with Derby as Prime Minister in the Lords) and as Chancellor. He wrote regular reports on proceedings in the Commons to Victoria, who described them as "very curious" and "much in the style of his books". Parliament was prorogued on 1 July 1852 as the Tories could not govern for long as a minority; Disraeli hoped that they would gain a majority of about 40. Instead, the election later that month had no clear winner, and the Derby government held to power pending the meeting of Parliament.
Disraeli's task as Chancellor was to devise a budget which would satisfy the protectionist elements who supported the Tories, without uniting the free-traders against it. His proposed budget, which he presented to the Commons on 3 December, lowered the taxes on malt and tea, provisions designed to appeal to the working class. To make his budget revenue-neutral, as funds were needed to provide defences against the French, he doubled the house tax and continued the income tax. Disraeli's overall purpose was to enact policies which would benefit the working classes, making his party more attractive to them. Although the budget did not contain protectionist features, the opposition was prepared to destroy it—and Disraeli's career as Chancellor—in part out of revenge for his actions against Peel in 1846. MP Sidney Herbert predicted that the budget would fail because "Jews make no converts".
Disraeli delivered the budget on 3 December 1852, and prepared to wind up the debate for the government on 16 December—it was customary for the Chancellor to have the last word. A massive defeat for the government was predicted. Disraeli attacked his opponents individually, and then as a force, "I face a Coalition ... This, too, I know, that England does not love coalitions." His speech of three hours was quickly seen as a parliamentary masterpiece. As MPs prepared to divide, Gladstone rose to his feet and began an angry speech, despite the efforts of Tory MPs to shout him down. The interruptions were fewer, as Gladstone gained control of the House, and in the next two hours painted a picture of Disraeli as frivolous and his budget as subversive. The government was defeated by 19 votes, and Derby resigned four days later. He was replaced by the Peelite Earl of Aberdeen, with Gladstone as his Chancellor. Because of Disraeli's unpopularity among the Peelites, no party reconciliation was possible while he remained Tory leader in the House of Commons.
Opposition.
With the fall of the government, Disraeli and the Conservatives returned to the opposition benches. Disraeli would spend three-quarters of his 44-year parliamentary career in opposition. Derby was reluctant to seek to unseat the government, fearing a repetition of the Who? Who? Ministry and knowing that despite his lieutenant's strengths, shared dislike of Disraeli was part of what had formed the governing coalition. Disraeli, on the other hand, was anxious to return to office. In the interim, Disraeli, as Conservative leader in the Commons, opposed the government on all major measures.
In June 1853 Disraeli was awarded an honorary degree by Oxford University. He had been recommended for it by Lord Derby, the university's Chancellor. The start of the Crimean War in 1854 caused a lull in party politics; Disraeli spoke patriotically in support. The British military efforts were marked by bungling, and in 1855 a restive Parliament considered a resolution to establish a committee on the conduct of the war. The Aberdeen government chose to make this a motion of confidence; Disraeli led the opposition to defeat the government, 305 to 148. Aberdeen resigned, and the Queen sent for Derby, who to Disraeli's frustration refused to take office. Palmerston was deemed essential to any Whig ministry, and he would not join any he did not head. The Queen reluctantly asked Palmerston to form a government. Under Palmerston, the war went better, and was ended by the Treaty of Paris in early 1856. Disraeli was early to call for peace, but had little influence on events.
When a rebellion broke out in India in 1857, Disraeli took a keen interest in affairs, having been a member of a select committee in 1852 which considered how best to rule the subcontinent, and had proposed eliminating the governing role of the British East India Company. After peace was restored, and Palmerston in early 1858 brought in legislation for direct rule of India by the Crown, Disraeli opposed it. Many Conservative MPs refused to follow him and the bill passed the Commons easily.
Palmerston's grip on the premiership was weakened by his response to the Orsini affair, in which an attempt was made to assassinate the French Emperor Napoleon III by an Italian revolutionary with a bomb made in Birmingham. At the request of the French ambassador, Palmerston put forward amendments to the conspiracy to murder statute, proposing to make creating an infernal device a felony rather than a misdemeanour. He was defeated by 19 votes on the second reading, with many Liberals crossing the aisle against him. He immediately resigned, and Lord Derby returned to office.
Second Derby government.
Derby took office at the head of a purely "Conservative" administration, not in coalition with any other faction. He again offered a place to Gladstone, who declined. Disraeli was once more leader of the House of Commons and returned to the Exchequer. As in 1852, Derby led a minority government, dependent on the division of its opponents for survival. As Leader of the House, Disraeli resumed his regular reports to Queen Victoria, who had requested that he include what she "could not meet in newspapers".
During its brief life of just over a year, the Derby government proved moderately progressive. The Government of India Act 1858 ended the role of the East India Company in governing the subcontinent. Disraeli had supported efforts to allow Jews to sit in Parliament—the oaths required of new members could only be made in good faith by a Christian. Disraeli had a bill passed through the Commons allowing each house of Parliament to determine what oaths its members should take. This was grudgingly agreed to by the House of Lords, with a minority of Conservatives joining with the opposition to pass it. In 1858, Baron Lionel de Rothschild became the first MP to profess the Jewish faith.
Faced with a vacancy, Disraeli and Derby tried yet again to bring Gladstone, still nominally a Conservative MP, into the government, hoping to strengthen it. Disraeli wrote a personal letter to Gladstone, asking him to place the good of the party above personal animosity: "Every man performs his office, and there is a Power, greater than ourselves, that disposes of all this." In responding to Disraeli, Gladstone denied that personal feelings played any role in his decisions then and previously whether to accept office, while acknowledging that there were differences between him and Derby "broader than you may have supposed".
The Tories pursued a Reform Bill in 1859, which would have resulted in a modest increase to the franchise. The Liberals were healing the breaches between those who favoured Russell and the Palmerston loyalists, and in late March 1859, the government was defeated on a Russell-sponsored amendment. Derby dissolved Parliament, and the ensuing general election resulted in modest Tory gains, but not enough to control the Commons. When Parliament assembled, Derby's government was defeated by 13 votes on an amendment to the Address from the Throne. He resigned, and the Queen reluctantly sent for Palmerston again.
Opposition and third term as Chancellor.
After Derby's second ejection from office, Disraeli faced dissension within Conservative ranks from those who blamed him for the defeat, or who felt he was disloyal to Derby—the former Prime Minister warned Disraeli of some MPs seeking his removal from the front bench. Among the conspirators were Lord Robert Cecil, a young Conservative MP who would a quarter century later become Prime Minister as Lord Salisbury; he wrote that having Disraeli as leader in the Commons decreased the Conservatives' chance of holding office. When Cecil's father objected, Lord Robert stated, "I have merely put into print what all the country gentlemen were saying in private."
Disraeli led a toothless opposition in the Commons—seeing no way of unseating Palmerston, Derby had privately agreed not to seek the government's defeat. Disraeli kept himself informed on foreign affairs, and on what was going on in cabinet, thanks to a source within it. When the American Civil War began in 1861, Disraeli said little publicly, but like most Englishmen expected the South to win. Less reticent were Palmerston, Gladstone (again Chancellor) and Russell, whose statements in support of the South contributed to years of hard feelings in the United States. In 1862, Disraeli met Prussian Count Otto von Bismarck for the first time and said of him, "be careful about that man, he means what he says."
The party truce ended in 1864, with Tories outraged over Palmerston's handling of the territorial dispute between the German Confederation and Denmark known as the Schleswig-Holstein Question. Disraeli had little help from Derby, who was ill, but he united the party enough on a no-confidence vote to limit the government to a majority of 18—Tory defections and absentees kept Palmerston in office. Despite rumours about Palmerston's health as he passed his eightieth birthday, he remained personally popular, and the Liberals increased their margin in the July 1865 general election. In the wake of the poor election results, Derby predicted to Disraeli that neither of them would ever hold office again.
Political plans were thrown into disarray by Palmerston's death on 18 October 1865. Russell became Prime Minister again, with Gladstone clearly the Liberal Party's leader-in-waiting, and as Leader of the House Disraeli's direct opponent. One of Russell's early priorities was a Reform Bill, but the proposed legislation that Gladstone announced on 12 March 1866 divided his party. The Conservatives and the dissident Liberals repeatedly attacked Gladstone's bill, and in June finally defeated the government; Russell resigned on 26 June. The dissidents were unwilling to serve under Disraeli in the House of Commons, and Derby formed a third Conservative minority government, with Disraeli again as Chancellor. In 1867, the Conservatives introduced a Reform Bill. Without a majority in the Commons, the Conservatives had little choice but to accept amendments that considerably liberalised the legislation, though Disraeli refused to accept any from Gladstone.
The Reform Act 1867 passed that August, extending the franchise by 938,427—an increase of 88%—by giving the vote to male householders and male lodgers paying at least £10 for rooms. It eliminated rotten boroughs with fewer than 10,000 inhabitants, and granted constituencies to 15 unrepresented towns, with extra representation to large municipalities such as Liverpool and Manchester. This act was unpopular with the right wing of the Conservative Party, most notably Lord Cranborne (as Robert Cecil was by then known), who resigned from the government and spoke against the bill, accusing Disraeli of "a political betrayal which has no parallel in our Parliamentary annals." Cranborne, however, was unable to lead an effective rebellion against Derby and Disraeli. Disraeli gained wide acclaim and became a hero to his party for the "marvellous parliamentary skill" with which he secured the passage of Reform in the Commons.
Derby had long suffered from attacks of gout which sent him to his bed, unable to deal with politics. As the new session of Parliament approached in February 1868, he was bedridden at his home, Knowsley Hall, near Liverpool. He was reluctant to resign, reasoning that he was only 68, much younger than either Palmerston or Russell at the end of their premierships. Derby knew that his "attacks of illness would, at no distant period, incapacitate me from the discharge of my public duties"; doctors had warned him that his health required his resignation from office. In late February, with Parliament in session and Derby absent, he wrote to Disraeli asking for confirmation that "you will not shrink from the additional heavy responsibility". Reassured, he wrote to the Queen, resigning and recommending Disraeli as "only he could command the cordial support, en masse, of his present colleagues". Disraeli went to Osborne House on the Isle of Wight, where the Queen asked him to form a government. The monarch wrote to her daughter, Prussian Crown Princess Victoria, "Mr. Disraeli is Prime Minister! A proud thing for a man 'risen from the people' to have obtained!" The new Prime Minister told those who came to congratulate him, "I have climbed to the top of the greasy pole."
First term as Prime Minister; opposition leader.
First government (February–December 1868).
The Conservatives remained a minority in the House of Commons and the passage of the Reform Bill required the calling of a new election once the new voting register had been compiled. Disraeli's term as Prime Minister, which began in February 1868, would therefore be short unless the Conservatives won the general election. He made only two major changes in the cabinet: he replaced Lord Chelmsford as Lord Chancellor with Lord Cairns, and brought in George Ward Hunt as Chancellor of the Exchequer. Derby had intended to replace Chelmsford once a vacancy in a suitable sinecure developed. Disraeli was unwilling to wait, and Cairns, in his view, was a far stronger minister.
Disraeli's first premiership was dominated by the heated debate over the Church of Ireland. Although Ireland was overwhelmingly Roman Catholic, the Protestant Church remained the established church and was funded by direct taxation, which was greatly resented by the Catholic majority. An initial attempt by Disraeli to negotiate with Archbishop Manning the establishment of a Roman Catholic university in Dublin foundered in March when Gladstone moved resolutions to disestablish the Irish Church altogether. The proposal united the Liberals under Gladstone's leadership, while causing divisions among the Conservatives.
The Conservatives remained in office because the new electoral register was not yet ready; neither party wished a poll under the old roll. Gladstone began using the Liberal majority in the House of Commons to push through resolutions and legislation. Disraeli's government survived until the December general election, at which the Liberals were returned to power with a majority of about 110.
Despite its short life, the first Disraeli government succeeded in passing a number of pieces of legislation of a politically noncontentious sort. It ended public executions, and the Corrupt Practices Act did much to end electoral bribery. It authorised an early version of nationalisation, having the Post Office buy up the telegraph companies. Amendments to the school law, the Scottish legal system, and the railway laws were passed. Disraeli sent the successful expedition against Tewodros II of Ethiopia under Sir Robert Napier.
Opposition leader; 1874 election.
With Gladstone's Liberal majority dominant in the Commons, Disraeli could do little but protest as the government advanced legislation. Accordingly, he chose to await Liberal mistakes. Having leisure time as he was not in office, he wrote a new novel, "Lothair" (1870). A work of fiction by a former Prime Minister was a new thing for Britain, and the book became a best seller.
By 1872 there was dissent in the Conservative ranks over the failure to challenge Gladstone and his Liberals. This was quieted as Disraeli took steps to assert his leadership of the party, and as divisions among the Liberals became clear. Public support for Disraeli was shown by cheering at a thanksgiving service in 1872 on the recovery of the Prince of Wales from illness, while Gladstone was met with silence. Disraeli had supported the efforts of party manager John Eldon Gorst to put the administration of the Conservative Party on a modern basis. On Gorst's advice, Disraeli gave a speech to a mass meeting in Manchester that year. To roaring approval, he compared the Liberal front bench to "a range of exhausted volcanoes. Not a flame flickers on a single pallid crest. But the situation is still dangerous. There are occasional earthquakes and ever and again the dark rumbling of the sea." Gladstone, Disraeli stated, dominated the scene and "alternated between a menace and a sigh".
At his first departure from 10 Downing Street in 1868, Disraeli had had Victoria create Mary Anne Viscountess of Beaconsfield in her own right in lieu of a peerage for himself. Through 1872 the eighty-year-old peeress was suffering from stomach cancer. She died on 15 December. Urged by a clergyman to turn her thoughts to Jesus Christ in her final days, she said she could not: "You know Dizzy is my J.C." After she died, Gladstone, who always had a liking for Mary Anne, sent her widower a letter of condolence.
In 1873 Gladstone brought forward legislation to establish a Catholic university in Dublin. This divided the Liberals, and on 12 March an alliance of Conservatives and Irish Catholics defeated the government by three votes. Gladstone resigned, and the Queen sent for Disraeli, who refused to take office. Without a general election, a Conservative government would be another minority, dependent for survival on the division of its opponents. Disraeli wanted the power a majority would bring, and felt he could gain it later by leaving the Liberals in office now. Gladstone's government struggled on, beset by scandal and unimproved by a reshuffle. As part of that change, Gladstone took on the office of Chancellor, leading to questions as to whether he had to stand for re-election on taking on a second ministry—until the 1920s, MPs becoming ministers, thus taking an office of profit under the Crown, had to seek re-election.
In January 1874 Gladstone called a general election, convinced that if he waited longer, he would do worse at the polls. Balloting was spread over two weeks, beginning on 1 February. Disraeli devoted much of his campaign to decrying the Liberal programme of the past five years. As the constituencies voted, it became clear that the result would be a Conservative majority, the first since 1841. In Scotland, where the Conservatives were perennially weak, they increased from seven seats to nineteen. Overall, they won 350 seats to 245 for the Liberals and 57 for the Irish Home Rule League. The Queen sent for Disraeli, and he became Prime Minister for the second time.
Second government (1874–80).
Disraeli's cabinet of twelve, with six peers and six commoners, was the smallest since Reform. Of the peers, five of them had been in Disraeli's 1868 cabinet; the sixth, Lord Salisbury, was reconciled to Disraeli after negotiation and became Secretary of State for India. Lord Stanley (who had succeeded his father, the former Prime Minister, as Earl of Derby) became Foreign Secretary and Sir Stafford Northcote the Chancellor.
In August 1876, Disraeli was elevated to the House of Lords as Earl of Beaconsfield and Viscount Hughenden. The Queen had offered to ennoble him as early as 1868; he had then declined. She did so again in 1874, when he fell ill at Balmoral, but he was reluctant to leave the Commons for a house in which he had no experience. Continued ill health during his second premiership caused him to contemplate resignation, but his lieutenant, Derby, was unwilling, feeling that he could not manage the Queen. For Disraeli, the Lords, where the debate was less intense, was the alternative to resignation from office. Five days before the end of the 1876 session of Parliament, on 11 August, Disraeli was seen to linger and look around the chamber before departing the Commons. Newspapers reported his ennoblement the following morning.
In addition to the viscounty bestowed on Mary Anne Disraeli; the earldom of Beaconsfield was to have been bestowed on Edmund Burke in 1797, but he had died before receiving it. The name Beaconsfield, a town near Hughenden, also was given to a minor character in "Vivian Grey". Disraeli made various statements about his elevation, writing to Selina, Lady Bradford on 8 August 1876, "I am quite tired of that place Commons" but when asked by a friend how he liked the Lords, replied, "I am dead; dead but in the Elysian fields."
Domestic policy.
Reforming legislation.
Under the stewardship of Richard Assheton Cross, the Home Secretary, Disraeli's new government enacted many reforms, including the Artisan's and Labourers' Dwellings Improvement Act 1875, which made inexpensive loans available to towns and cities to construct working-class housing. Also enacted were the Public Health Act 1875, modernising sanitary codes through the nation, the Sale of Food and Drugs Act (1875), and the Education Act (1876).
Disraeli's government also introduced a new Factory Act meant to protect workers, the Conspiracy and Protection of Property Act 1875, which allowed peaceful picketing, and the Employers and Workmen Act (1875) to enable workers to sue employers in the civil courts if they broke legal contracts. As a result of these social reforms the Liberal-Labour MP Alexander Macdonald told his constituents in 1879, "The Conservative party have done more for the working classes in five years than the Liberals have in fifty."
Patronage and Civil Service reform.
Gladstone in 1870 had sponsored an Order in Council, introducing competitive examination into the Civil Service, diminishing the political aspects of government hiring. Disraeli did not agree, and while he did not seek to reverse the order, his actions often frustrated its intent. For example, Disraeli made political appointments to positions previously given to career civil servants. In this, he was backed by his party, hungry for office and its emoluments after almost thirty years with only brief spells in government. Disraeli gave positions to hard-up Conservative leaders, even—to Gladstone's outrage—creating one office at £2,000 per year. Nevertheless, Disraeli made fewer peers (only 22, and one of those one of Victoria's sons) than had Gladstone—the Liberal leader had arranged for the bestowal of 37 peerages during his just over five years in office.
As he had in government posts, Disraeli rewarded old friends with clerical positions, making Sydney Turner, son of a good friend of Isaac D'Israeli, Dean of Ripon. He favoured Low church clergymen in promotion, disliking other movements in Anglicanism for political reasons. In this, he came into disagreement with the Queen, who out of loyalty to her late husband, Albert, Prince Consort, preferred Broad church teachings. One controversial appointment had occurred shortly before the 1868 election. When the position of Archbishop of Canterbury fell vacant, Disraeli reluctantly agreed to the Queen's preferred candidate, Archibald Tait, the Bishop of London. To fill Tait's vacant see, Disraeli was urged by many people to appoint Samuel Wilberforce, the former Bishop of Winchester and leading figure in London society. Disraeli disliked Wilberforce and instead appointed John Jackson, the Bishop of Lincoln. Blake suggested that, on balance, these appointments cost Disraeli more votes than they gained him.
Foreign policy.
Disraeli always considered foreign affairs to be the most critical and most interesting part of statesmanship. Nevertheless, his biographer Robert Blake doubts that his subject had specific ideas about foreign policy when he took office in 1874. He had rarely travelled abroad; since his youthful tour of the Middle East in 1830–1831, he had left Britain only for his honeymoon and three visits to Paris, the last of which was in 1856. As he had criticised Gladstone for a do-nothing foreign policy, he most probably contemplated what actions would reassert Britain's place in Europe. His brief first premiership, and the first year of his second, gave him little opportunity to make his mark in foreign affairs.
Suez.
The Suez Canal, opened in 1869, cut weeks and thousands of miles off the journey between Britain and India; in 1875, approximately 80% of the ships using the canal were British. In the event of another rebellion in India, or of a Russian invasion, the time saved at Suez might be crucial. Built by French interests, much of the ownership and bonds in the canal remained in their hands, though some of the stock belonged to Isma'il Pasha, the Khedive of Egypt, who was noted for his profligate spending. The canal was losing money, and an attempt by Ferdinand de Lesseps, builder of the canal, to raise the tolls had fallen through when the Khedive had threatened to use military force to prevent it, and had also attracted Disraeli's attention. The Khedive governed Egypt under the Ottoman Empire; as in the Crimea, the issue of the Canal raised the Eastern Question of what to do about the decaying empire governed from Constantinople. With much of the pre-canal trade and communications between Britain and India passing through the Ottoman Empire, Britain had done its best to prop up the Ottomans against the threat that Russia would take Constantinople, cutting those communications, and giving Russian ships unfettered access to the Mediterranean. The French might also threaten those lines from colonies in Syria. Britain had had the opportunity to purchase shares in the canal but had declined to do so.
Disraeli had passed near Suez in his tour of the Middle East in his youth, and on taking office, recognising the British interest in the canal as a gateway to India, he sent the Liberal MP Nathan Rothschild to Paris to enquire about buying de Lesseps's shares. On 14 November 1875, the editor of the "Pall Mall Gazette", Frederick Greenwood, learned from London banker Henry Oppenheim that the Khedive was seeking to sell his shares in the Suez Canal Company to a French firm. Greenwood quickly told Lord Derby, the Foreign Secretary, who notified Disraeli. The Prime Minister moved immediately to secure the shares. On 23 November, the Khedive offered to sell the shares for 100,000,000 francs. Rather than seek the aid of the Bank of England, Disraeli asked Lionel de Rothschild to loan funds. Rothschild did so and controversially took a commission on the deal. The banker's capital was at risk as Parliament could have refused to ratify the transaction. The contract for purchase was signed at Cairo on 25 November and the shares deposited at the British consulate the following day.
Disraeli told the Queen, "it is settled; you have it, madam!" The public saw the venture as a daring British statement of its dominance of the seas. Sir Ian Malcolm described the Suez Canal share purchase as "the greatest romance of Mr. Disraeli's romantic career." In the following decades, the security of the Suez Canal, as the pathway to India, became a major focus of British foreign policy. A later Foreign Secretary, Lord Curzon, described the canal in 1909 as "the determining influence of every considerable movement of British power to the east and south of the Mediterranean".
Royal Titles Act.
Although initially curious about Disraeli when he entered Parliament in 1837, Victoria came to detest him over his treatment of Peel. Over time, her dislike softened, especially as Disraeli took pains to cultivate her. He told Matthew Arnold, "Everybody likes flattery; and, when you come to royalty, you should lay it on with a trowel". Disraeli's biographer, Adam Kirsch, suggests that Disraeli's obsequious treatment of his queen was part flattery, part belief that this was how a queen should be addressed by a loyal subject, and part awe that a middle-class man of Jewish birth should be the companion of a monarch. By the time of his second premiership, Disraeli had built a strong relationship with Victoria, probably closer to her than any of her Prime Ministers except her first, Lord Melbourne. When Disraeli returned as Prime Minister in 1874 and went to kiss hands, he did so literally, on one knee, and according to Richard Aldous on his book on the Disraeli/Gladstone rivalry, "for the next six years Victoria and Disraeli would exploit their closeness for mutual advantage."
Victoria had long wished to have an imperial title, reflecting Britain's expanding domain. She was irked when Czar Alexander II held a higher rank than her as an emperor, and was appalled that her daughter, the Prussian Crown Princess, would outrank her when her husband came to the throne. She also saw an imperial title as proclaiming Britain's increased stature in the world. The title "Empress of India" had been used informally with respect to Victoria for some time and she wished to have that title formally bestowed on her. The Queen prevailed upon Disraeli to introduce a Royal Titles Bill, and also told of her intent to open Parliament in person, which during this time she did only when she wanted something from legislators. Disraeli was cautious in response, as careful soundings of MPs brought a negative reaction, and declined to place such a proposal in the Queen's Speech.
Once the desired bill was prepared, Disraeli's handling of it was not adept. He neglected to notify either the Prince of Wales or the opposition, and was met by irritation from the prince and a full-scale attack from the Liberals. An old enemy of Disraeli, former Liberal Chancellor Robert Lowe, alleged during the debate in the Commons that two previous Prime Ministers had refused to introduce such legislation for the Queen. Gladstone immediately stated that he was not one of them, and the Queen gave Disraeli leave to quote her saying she had never approached a Prime Minister with such a proposal. According to Blake, Disraeli "in a brilliant oration of withering invective proceeded to destroy Lowe", who apologised and never held office again. Disraeli said of Lowe that he was the only person in London with whom he would not shake hands and, "he is in the mud and there I leave him."
Fearful of losing, Disraeli was reluctant to bring the bill to a vote in the Commons, but when he eventually did, it passed with a majority of 75. Once the bill was formally enacted, Victoria began signing her letters "Victoria R & I" (Regina et Imperatrix, that is, Queen and Empress). According to Aldous, "the unpopular Royal Titles Act, however, shattered Disraeli's authority in the House of Commons".
Balkans and Bulgaria.
In July 1875 Christian populations in Bosnia and Herzegovina, then provinces of the Ottoman Empire, rose in revolt against their Turkish masters, alleging religious persecution and poor administration. The following January, Sultan Abdülaziz, who ruled the empire, agreed to reforms proposed by Hungarian statesman Julius Andrássy, but the rebels, suspecting they might win their freedom, continued their uprising, joined by militants in Serbia and Bulgaria. The Turks suppressed the Bulgarian uprising harshly, and when reports of these actions escaped, Disraeli and Derby stated in Parliament that they did not believe them. Disraeli called them "coffee-house babble" and dismissed allegations of torture by the Ottomans since "Oriental people usually terminate their connections with culprits in a more expeditious fashion".
Gladstone, who had left the Liberal leadership and retired from public life, was appalled by reports of atrocities in Bulgaria, and in August 1876, penned a hastily-written pamphlet arguing that the Turks should be deprived of Bulgaria because of what they had done there. He sent a copy to Disraeli, who called it "vindictive and ill-written ... of all the Bulgarian horrors perhaps the greatest". Gladstone's pamphlet became an immense best-seller and rallied the Liberals to urge that the Ottoman Empire should no longer be a British ally. Disraeli wrote to Lord Salisbury on 3 September, "Had it not been for these unhappy 'atrocities', we should have settled a peace very honourable to England and satisfactory to Europe. Now we are obliged to work from a new point of departure, and dictate to Turkey, who has forfeited all sympathy." In spite of this, Disraeli's policy favoured Constantinople and the territorial integrity of its empire.
Disraeli and the cabinet sent Salisbury as lead British representative to the Constantinople Conference, which met in December 1876 and January 1877. In advance of the conference, Disraeli sent Salisbury private word to seek British military occupation of Bulgaria and Bosnia, and British control of the Turkish Army. Salisbury ignored these instructions, which his biographer, Andrew Roberts deemed "ludicrous". Nevertheless, the conference failed to reach agreement with the Turks.
Parliament opened in February 1877, with Disraeli now in the Lords as Earl of Beaconsfield. He spoke only once there in the 1877 session on the Eastern Question, stating on 20 February that there was a need for stability in the Balkans, and that forcing Turkey into territorial concessions would do nothing to secure it. The Prime Minister wanted a deal with the Ottomans whereby Britain would temporarily occupy strategic areas to deter the Russians from war, to be returned on the signing of a peace treaty, but found little support in his cabinet, which favoured partition of the Ottoman Empire. As Disraeli, by then in poor health, continued to battle within the cabinet, Russia invaded Turkey on 21 April, beginning the Russo-Turkish War.
Congress of Berlin.
The Russians pushed through Ottoman territory and by December 1877 had captured the strategic Bulgarian town of Plevna; their march on Constantinople seemed inevitable. The war divided the British, but the Russian success caused some to forget the atrocities and call for intervention on the Turkish side. Others hoped for further Russian successes. The fall of Plevna was a major story for weeks in the newspapers, and Disraeli's warnings that Russia was a threat to British interests in the eastern Mediterranean were deemed prophetic. The jingoistic attitude of many Britons increased Disraeli's political support, and the Queen acted to help him as well, showing her favour by visiting him at Hughenden—the first time she had visited the country home of her Prime Minister since the Melbourne ministry. At the end of January 1878, the Ottoman Emperor appealed to Britain to save Constantinople. Amid war fever in Britain, the government asked Parliament to vote £6,000,000 to prepare the Army and Navy for war. Gladstone, who had involved himself again in politics, opposed the measure, but less than half his party voted with him. Popular opinion was with Disraeli, though some thought him too soft for not immediately declaring war on Russia.
With the Russians close to Constantinople, the Turks yielded and in March 1878, signed the Treaty of San Stefano, conceding a state which though dubbed Bulgaria would in fact cover most of the Balkans. It would be initially Russian-occupied and would give them a client state deep in Europe. Other Ottoman possessions in Europe would become independent; additional territory was to be ceded directly to Russia. This was unacceptable to the British, who protested, hoping to get the Russians to agree to attend an international conference which Prussian Chancellor Bismarck proposed to hold at Berlin. The cabinet discussed Disraeli's proposal to position Indian troops at Malta for possible transit to the Balkans and call out reserves. Derby resigned in protest, and Disraeli appointed Salisbury as Foreign Secretary. Amid British preparations for war, the Russians and Turks agreed to discussions at Berlin.
In advance of the meeting, confidential negotiations took place between Britain and Russia in April and May 1878. The Russians were willing to make changes to the big Bulgaria, but were determined to retain its new possessions Bessarabia in Europe and Batum and Kars on the east coast of the Black Sea. To counterbalance this, Britain required a possession in the Eastern Mediterranean where it might base ships and troops, and negotiated with the Ottomans for the cession of Cyprus. Once this was secretly agreed, Disraeli was prepared to allow Russia's territorial gains.
The Congress of Berlin was held in June and July 1878, the central relationship in it that between Disraeli and Bismarck. In later years, the Prussian chancellor would show visitors to his office three pictures on the wall: "the portrait of my Sovereign, there on the right that of my wife, and on the left, there, that of Lord Beaconsfield". Disraeli caused an uproar in the congress by making his opening address in English, rather than in French, hitherto accepted as the international language of diplomacy. By one account, the British ambassador in Berlin, Lord Odo Russell, hoping to spare the delegates Disraeli's awful French accent, told Disraeli that the congress was hoping to hear a speech in the English tongue by one of its masters.
Disraeli left much of the detailed work to Salisbury, concentrating his efforts on making it as difficult as possible for the broken-up big Bulgaria to reunite. Disraeli did not have things all his own way: he intended that Batum be demilitarised, but the Russians obtained their preferred language, and in 1886, fortified the town. Nevertheless, the Cyprus Convention ceding the island to Britain was announced during the congress, and again made Disraeli a sensation.
Disraeli gained agreement that Turkey should retain enough of its European possessions to safeguard the Dardanelles. By one account, when met with Russian intransigence, Disraeli told his secretary to order a special train to return them home to begin the war. Although Russia yielded, Czar Alexander II later described the congress as "a European coalition against Russia, under Bismarck".
The Treaty of Berlin was signed on 13 July 1878 at the Radziwill Palace in Berlin. For the first time, the title of Britain's lead signatory was given as "Prime Minister". Disraeli and Salisbury returned home to heroes' receptions at Dover and in London. At the door of 10 Downing Street, he received flowers sent by the Queen. There, he told the gathered crowd, "Lord Salisbury and I have brought you back peace—but a peace I hope with honour." The Queen offered him a dukedom, which he declined, though accepting the Garter, as long as Salisbury also received it. In Berlin, word spread of Bismarck's admiring description of Disraeli, ""Der alte Jude, das ist der Mann!" "
Afghanistan to Zululand.
In the weeks after Berlin, Disraeli and the cabinet considered calling a general election to capitalise on the public applause he and Salisbury had received. Parliaments were then for a seven-year term, and it was the custom not to go to the country until the sixth year unless forced to by events. Only four and a half years had passed since the last general election. Additionally, they did not see any clouds on the horizon that might forecast Conservative defeat if they waited. This decision not to seek re-election has often been cited as a great mistake by Disraeli. Blake, however, pointed out that results in local elections had been moving against the Conservatives, and doubted if Disraeli missed any great opportunity by waiting.
As successful invasions of India generally came through Afghanistan, the British had observed and sometimes intervened there since the 1830s, hoping to keep the Russians out. In 1878 the Russians sent a mission to Kabul; it was not rejected by the Afghans, as the British had hoped. The British then proposed to send their own mission, insisting that the Russians be sent away. The Viceroy, Lord Lytton, concealed his plans to issue this ultimatum from Disraeli, and when the Prime Minister insisted he take no action, went ahead anyway. When the Afghans made no answer, the British advanced against them in the Second Anglo-Afghan War, and under Lord Roberts easily defeated them. The British installed a new ruler, and left a mission and garrison in Kabul.
British policy in South Africa was to encourage federation between the British-run Cape Colony and Natal, and the Boer republics, the Transvaal (annexed by Britain in 1877) and the Orange Free State. The governor of Cape Colony, Sir Bartle Frere, believing that the federation could not be accomplished until the native tribes acknowledged British rule, made demands on the Zulu and their king, Cetewayo, which they were certain to reject. As Zulu troops could not marry until they had washed their spears in blood, they were eager for combat. Frere did not send word to the cabinet of what he had done until the ultimatum was about to expire. Disraeli and the cabinet reluctantly backed him, and in early January 1879 resolved to send reinforcements. Before they could arrive, on 22 January, a Zulu "impi", or army, moving with great speed and stealth, ambushed and destroyed a British encampment in South Africa in the Battle of Isandlwana. Over a thousand British and colonial troops were killed. Word of the defeat did not reach London until 12 February. Disraeli wrote the next day, "the terrible disaster has shaken me to the centre". He reprimanded Frere, but left him in charge, attracting fire from all sides. Disraeli sent General Sir Garnet Wolseley as High Commissioner and Commander in Chief, and Cetewayo and the Zulus were crushed at the Battle of Ulundi on 4 July 1879.
On 8 September 1879 Sir Louis Cavagnari, in charge of the mission in Kabul, was killed with his entire staff by rebelling Afghan soldiers. Roberts undertook a successful punitive expedition against the Afghans over the next six weeks.
1880 election.
Gladstone, in the 1874 election, had been returned for Greenwich, finishing second behind a Conservative in the two-member constituency, a result he termed more like a defeat than a victory. In December 1878, he was offered the Liberal nomination at the next election for Edinburghshire, a constituency popularly known as Midlothian. The small Scottish electorate was dominated by two noblemen, the Conservative Duke of Buccleuch and the Liberal Earl of Rosebery. The Earl, a friend of both Disraeli and Gladstone who would succeed the latter after his final term as Prime Minister, had journeyed to the United States to view politics there, and was convinced that aspects of American electioneering could be translated to the United Kingdom. On his advice, Gladstone accepted the offer in January 1879, and later that year began his Midlothian campaign, speaking not only in Edinburgh, but across Britain, attacking Disraeli, to huge crowds.
Conservative chances of re-election were damaged by the poor weather, and consequent effects on agriculture. Four consecutive wet summers through 1879 had led to poor harvests in the United Kingdom. In the past, the farmer had the consolation of higher prices at such times, but with bumper crops cheaply transported from the United States, grain prices remained low. Other European nations, faced with similar circumstances, opted for protection, and Disraeli was urged to reinstitute the Corn Laws. He declined, stating that he regarded the matter as settled. Protection would have been highly unpopular among the newly enfranchised urban working classes, as it would raise their cost of living. Amid an economic slump generally, the Conservatives lost support among farmers.
Disraeli's health continued to fail through 1879. Owing to his infirmities, Disraeli was three-quarters of an hour late for the Lord Mayor's Dinner at the Guildhall in November, at which it is customary that the Prime Minister speaks. Though many commented on how healthy he looked, it took him great effort to appear so, and when he told the audience he expected to speak to the dinner again the following year, attendees chuckled—Gladstone was then in the midst of his campaign. Despite his public confidence, Disraeli recognised that the Conservatives would probably lose the next election, and was already contemplating his resignation honours.
Despite this pessimism, Conservatives hopes were buoyed in early 1880 with successes in by-elections the Liberals had expected to win, concluding with victory in Southwark, normally a Liberal stronghold. The cabinet had resolved to wait before dissolving Parliament; in early March they reconsidered, agreeing to go to the country as soon as possible. Parliament was dissolved on 24 March; the first borough constituencies began voting a week later.
Disraeli took no public part in the electioneering, it being deemed improper for peers to make speeches to influence Commons elections. This meant that the chief Conservatives—Disraeli, Salisbury, and India Secretary Lord Cranbrook—would not be heard from. The election was thought likely to be close. Once returns began to be announced, it became clear that the Conservatives were being decisively beaten. The final result gave the Liberals an absolute majority of about 50.
Final months, death, and memorials.
Disraeli refused to cast blame for the defeat, which he understood was likely to be final for him. He wrote to Lady Bradford that it was just as much work to end a government as to form one, without any of the fun. Victoria was bitter at his departure as Prime Minister. Among the honours he arranged before resigning as Prime Minister on 21 April 1880 was one for his private secretary, Montagu Corry, who became Baron Rowton.
Returning to Hughenden, Disraeli brooded over his electoral dismissal, but also resumed work on "Endymion", which he had begun in 1872 and laid aside before the 1874 election. The work was rapidly completed and published by November 1880. He carried on a correspondence with Victoria, with letters passed through intermediaries. When Parliament met in January 1881, he served as Conservative leader in the Lords, attempting to serve as a moderating influence on Gladstone's legislation.
Suffering from asthma and gout, Disraeli went out as little as possible, fearing more serious episodes of illness. In March, he fell ill with bronchitis, and emerged from bed only for a meeting with Salisbury and other Conservative leaders on the 26th. As it became clear that this might be his final sickness, friends and opponents alike came to call. Disraeli declined a visit from the Queen, "She would only ask me to take a message to Albert." Almost blind, when he received the last letter from Victoria of which he was aware on 5 April, he held it momentarily, then had it read to him by Lord Barrington, a Privy Councillor. One card, signed "A Workman", delighted its recipient, "Don't die yet, we can't do without you."
Despite the gravity of Disraeli's condition, the doctors concocted optimistic bulletins, for public consumption. The Prime Minister, Gladstone, called several times to enquire about his rival's condition, and wrote in his diary, "May the Almighty be near his pillow." There was intense public interest in the former Prime Minister's struggles for life. Disraeli had customarily taken the sacrament at Easter; when this day was observed on 17 April, there was discussion among his friends and family if he should be given the opportunity, but those against, fearing that he would lose hope, prevailed. On the morning of the following day, Easter Monday, he became incoherent, then comatose. Disraeli's last confirmed words before dying in the early morning of 19 April were "I had rather live but I am not afraid to die" though there were rumours that his final utterance was the "Shema", the Jewish declaration of faith in a unitary god.
Disraeli's executors decided against a public procession and funeral, fearing that too large crowds would gather to do him honour. The chief mourners at the service at Hughenden on 26 April were his brother Ralph and nephew Coningsby, to whom Hughenden would eventually pass. The Queen was prostrated with grief, and considered ennobling Ralph or Coningsby as a memorial to Disraeli (without children, his titles became extinct with his death) but decided against it on the ground that their means were too small for a peerage. Protocol forbade her attending Disraeli's funeral (this would not be changed until 1965, when Elizabeth II attended the rites for the former Prime Minister Sir Winston Churchill) but she sent primroses ("his favourite flowers") to the funeral, and visited the burial vault to place a wreath of china blooms four days later.
Disraeli is buried with his wife in a vault beneath the Church of St Michael and All Angels which stands in the grounds of his home, Hughenden Manor, accessed from the churchyard. There is also a memorial to him in the chancel in the church, erected in his honour by Queen Victoria. His literary executor was his private secretary, Lord Rowton. The Disraeli vault also contains the body of Sarah Brydges Willyams, the wife of James Brydges Willyams of St Mawgan in Cornwall. Disraeli carried on a long correspondence with Mrs. Williams, writing frankly about political affairs. At her death in 1865, she left him a large legacy, which helped clear up his debts. His will was proved at £84,000.
Disraeli has a memorial in Westminster Abbey. This monument was erected by the nation on the motion of Gladstone in his memorial speech on Disraeli in the House of Commons. Gladstone had absented himself from the funeral, with his plea of the press of public business met with public mockery. His speech was widely anticipated, if only because his dislike for Disraeli was well known, and caused the Prime Minister much worry. In the event, the speech was a model of its kind, in which he avoided comment on Disraeli's politics, while praising his personal qualities.
Legacy.
Literary.
Blake comments that Disraeli "produced an epic poem, unbelievably bad, and a five-act blank verse tragedy, if possible worse. Further he wrote a discourse on political theory and a political biography, the "Life of Lord George Bentinck", which is excellent ... remarkably fair and accurate." But it is on his novels that Disraeli's literary achievements are generally judged. They have from the outset divided critical opinion. The writer R W Stewart observed that there have always been two criteria for judging Disraeli's novels—one political and the other artistic. The critic Robert O'Kell, concurring, writes, "It is after all, even if you are a Tory of the staunchest blue, impossible to make Disraeli into a first-rate novelist. And it is equally impossible, no matter how much you deplore the extravagances and improprieties of his works, to make him into an insignificant one."
Disraeli's early "silver fork" novels "Vivian Grey" (1826) and "The Young Duke" (1831) featured romanticised depictions of aristocratic life (despite his ignorance of it) with character sketches of well-known public figures lightly disguised. In some of his early fiction Disraeli also portrayed himself and what he felt to be his Byronic dual nature: the poet and the man of action. His most autobiographical novel was "Contarini Fleming" (1832), an avowedly serious work that did not sell well. The critic William Kuhn suggests that Disraeli's fiction can be read as "the memoirs he never wrote", revealing the inner life of a politician for whom the norms of Victorian public life appeared to represent a social straitjacket—particularly with regard to what Kuhn sees as the author's "ambiguous sexuality."
Of the other novels of the early 1830s, "Alroy" is described by Blake as "profitable but unreadable", and "The Rise of Iskander" (1833), "The Infernal Marriage" and "Ixion in Heaven" (1834) made little impact. "Henrietta Temple" (1837) was Disraeli's next major success. It draws on the events of his affair with Henrietta Sykes to tell the story of a debt-ridden young man torn between a mercenary loveless marriage and a passionate love-at-first-sight for the eponymous heroine. "Venetia" (1837) was a minor work, written to raise much-needed cash.
In the 1840s Disraeli wrote a trilogy of novels with political themes. With "Coningsby; or, The New Generation" (1844), Disraeli, in Blake's view, "infused the novel genre with political sensibility, espousing the belief that England's future as a world power depended not on the complacent old guard, but on youthful, idealistic politicians." "Coningsby" was followed by "Sybil; or, The Two Nations" (1845), another political novel, which was less idealistic and more clear-eyed than "Coningsby"; the "two nations" of its sub-title referred to the huge economic and social gap between the privileged few and the deprived working classes. The last in Disraeli's political novel trilogy was "Tancred; or, The New Crusade" (1847), promoting the Church of England's role in reviving Britain's flagging spirituality.
Disraeli's last completed novels were "Lothair" (1870) and "Endymion" (1880). The first, described by Daniel R Schwarz as "Disraeli's ideological "Pilgrim's Progress"", is a story of political life with particular regard to the roles of the Anglican and Roman Catholic churches. "Endymion", despite having a Whig as hero, is a last exposition of the author's economic policies and political beliefs. Disraeli continued to the last to pillory his enemies in barely disguised caricatures: the character St Barbe in "Endymion" is widely seen as a parody of Thackeray, who had offended Disraeli more than thirty years earlier by lampooning him in "Punch" as "Codlingsby". Disraeli left an unfinished novel in which the priggish central character, Falconet, is unmistakably a caricature of Gladstone.
Political.
In the years after Disraeli's death, as Salisbury began his reign of more than twenty years over the Conservatives, the party emphasised the late leader's "One Nation" views, that the Conservatives at root shared the beliefs of the working classes, with the Liberals the party of the urban élite. Disraeli had, for example, stressed the need to improve the lot of the urban labourer. The memory of Disraeli was used by the Conservatives to appeal to the working classes, with whom he was said to have had a rapport. This aspect of his policies has been re-evaluated by historians in the 20th and 21st centuries. In 1972 BHAbbott stressed that it was not Disraeli but Lord Randolph Churchill who invented the term "Tory democracy", though it was Disraeli who made it an essential part of Conservative policy and philosophy. In 2007 Parry wrote, "The tory democrat myth did not survive detailed scrutiny by professional historical writing of the 1960s demonstrated that Disraeli had very little interest in a programme of social legislation and was very flexible in handling parliamentary reform in 1867." Despite this, Parry sees Disraeli, rather than Peel, as the founder of the modern Conservative party. The Conservative politician and writer Douglas Hurd wrote in 2013, "[Disraeli was not a one-nation Conservative—and this was not simply because he never used the phrase. He rejected the concept in its entirety."
Disraeli's enthusiastic propagation of the British Empire has also been seen as appealing to working class voters. Before his leadership of the Conservative Party, imperialism was the province of the Liberals, most notably Palmerston, with the Conservatives murmuring dissent across the aisle. Disraeli made the Conservatives the party that most loudly supported both the Empire and military action to assert its primacy. This came about in part because Disraeli's own views stemmed that way, in part because he saw advantage for the Conservatives, and partially in reaction against Gladstone, who disliked the expense of empire. Blake argued that Disraeli's imperialism "decisively orientated the Conservative party for many years to come, and the tradition which he started was probably a bigger electoral asset in winning working-class support during the last quarter of the century than anything else". Some historians have commented on a romantic impulse behind Disraeli's approach to Empire and foreign affairs: Abbott writes, "To the mystical Tory concepts of Throne, Church, Aristocracy and People, Disraeli added Empire." Others have identified a strongly pragmatic aspect to his policies. Gladstone's biographer Philip Magnus contrasted Disraeli's grasp of foreign affairs with that of Gladstone, who "never understood that high moral principles, in their application to foreign policy, are more often destructive of political stability than motives of national self-interest." In Parry's view, Disraeli's foreign policy "can be seen as a gigantic castle in the air (as it was by Gladstone), or as an overdue attempt to force the British commercial classes to awaken to the realities of European politics."
During his lifetime Disraeli's opponents, and sometimes even his friends and allies, questioned whether he sincerely held the views he propounded, or whether they were adopted by him as essential to one who sought to spend his life in politics, and were mouthed by him without conviction. Lord John Manners, in 1843 at the time of Young England, wrote, "could I only satisfy myself that D'Israeli believed all that he said, I should be more happy: his historical views are quite mine, but does he believe them?" Blake (writing in 1966) suggested that it is no more possible to answer that question now than it was then. Nevertheless, Paul Smith, in his journal article on Disraeli's politics, argues that Disraeli's ideas were coherently argued over a political career of nearly half a century, and "it is impossible to sweep them aside as a mere bag of burglar's tools for effecting felonious entry to the British political pantheon."
Stanley Weintraub, in his biography of Disraeli, points out that his subject did much to advance Britain towards the 20th century, carrying one of the two great Reform Acts of the 19th despite the opposition of his Liberal rival, Gladstone. "He helped preserve constitutional monarchy by drawing the Queen out of mourning into a new symbolic national role and created the climate for what became 'Tory democracy'. He articulated an imperial role for Britain that would last into World War II and brought an intermittently self-isolated Britain into the concert of Europe."
Frances Walsh comments on Disraeli's multifaceted public life:
The debate about his place in the Conservative pantheon has continued since his death. Disraeli fascinated and divided contemporary opinion; he was seen by many, including some members of his own party, as an adventurer and a charlatan and by others as a far-sighted and patriotic statesman. As an actor on the political stage he played many roles: Byronic hero, man of letters, social critic, parliamentary virtuoso, squire of Hughenden, royal companion, European statesman. His singular and complex personality has provided historians and biographers with a particularly stiff challenge.

</doc>
<doc id="3876" url="http://en.wikipedia.org/wiki?curid=3876" title="Binomial distribution">
Binomial distribution

</math>
In probability theory and statistics, the binomial distribution is the discrete probability distribution of the number of successes in a sequence of "n" independent yes/no experiments, each of which yields success with probability "p". Therewith the probability of an event is defined by its binomial distribution.
A success/failure experiment is also called a Bernoulli experiment or Bernoulli trial; when "n" = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular binomial test of statistical significance.
The binomial distribution is frequently used to model the number of successes in a sample of size "n" drawn with replacement from a population of size "N." If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a hypergeometric distribution, not a binomial one. However, for "N" much larger than "n", the binomial distribution is a good approximation, and widely used.
Specification.
Probability mass function.
In general, if the random variable "X" follows the binomial distribution with parameters "n" and "p", we write "X" ~ B("n", "p"). The probability of getting exactly "k" successes in "n" trials is given by the probability mass function:
for "k" = 0, 1, 2, ..., "n", where
is the binomial coefficient, hence the name of the distribution. The formula can be understood as follows: we want "k" successes ("p""k") and "n" − "k" failures (1 − "p")"n" − "k". However, the "k" successes can occur anywhere among the "n" trials, and there are formula_9 different ways of distributing "k" successes in a sequence of "n" trials.
In creating reference tables for binomial distribution probability, usually the table is filled in up to "n"/2 values. This is because for "k" > "n"/2, the probability can be calculated by its complement as
Looking at the expression "ƒ"("k", "n", "p") as a function of "k", there is a "k" value that maximizes it. This "k" value can be found by calculating
and comparing it to 1. There is always an integer "M" that satisfies
"ƒ"("k", "n", "p") is monotone increasing for "k" < "M" and monotone decreasing for "k" > "M", with the exception of the case where ("n" + 1)"p" is an integer. In this case, there are two values for which "ƒ" is maximal: ("n" + 1)"p" and ("n" + 1)"p" − 1. "M" is the "most probable" ("most likely") outcome of the Bernoulli trials and is called the mode. Note that the probability of it occurring can be fairly small.
Recurrence relation
formula_13
Cumulative distribution function.
The cumulative distribution function can be expressed as:
where formula_15 is the "floor" under "k", i.e. the greatest integer less than or equal to "k".
It can also be represented in terms of the regularized incomplete beta function, as follows:
Some closed-form bounds for the cumulative distribution function are given below.
Example.
Suppose a biased coin comes up heads with probability 0.3 when tossed. What is the probability of achieving 0, 1..., 6 heads after six tosses?
Mean and variance.
If "X" ~ "B"("n", "p"), that is, "X" is a binomially distributed random variable, n being the total number of experiments and p the probability of each experiment yielding a successful result, then the expected value of "X" is
<br>
"(For example, if n=100, and p=25/100, then 25% of the results are likely to be successful. It is expected that 25 results are successful even though it is not certain.)"
and the variance 
Mode and median.
Usually the mode of a binomial "B"("n", "p") distribution is equal to formula_26, where formula_27 is the floor function. However when ("n" + 1)"p" is an integer and "p" is neither 0 nor 1, then the distribution has two modes: ("n" + 1)"p" and ("n" + 1)"p" − 1. When "p" is equal to 0 or 1, the mode will be 0 and "n" correspondingly. These cases can be summarized as follows:
In general, there is no single formula to find the median for a binomial distribution, and it may even be non-unique. However several special results have been established:
Covariance between two binomials.
If two binomially distributed random variables "X" and "Y" are observed together, estimating their covariance can be useful. Using the definition of covariance, in the case "n" = 1 (thus being Bernoulli trials) we have
The first term is non-zero only when both "X" and "Y" are one, and "μ""X" and "μ""Y" are equal to the two probabilities. Defining "p""B" as the probability of both happening at the same time, this gives
and for "n" independent pairwise trials
If "X" and "Y" are the same variable, this reduces to the variance formula given above.
Related distributions.
Sums of binomials.
If "X" ~ B("n", "p") and "Y" ~ B("m", "p") are independent binomial variables with the same probability "p", then "X" + "Y" is again a binomial variable; its distribution is
Conditional binomials.
If "X" ~ B("n", "p") and, conditional on "X", "Y" ~ B("X", "q"), then "Y" is a simple binomial variable with distribution
For example imagine throwing "n" balls to a basket "UX" and taking the balls that hit and throwing them to another basket "UY". If "p" is the probability to hit "UX" then "X" ~ B("n", "p") is the number of balls that hit "UX". If "q" is the probability to hit "UY" then the number of balls that hit "UY" is "Y" ~ B("X", "q") and therefore "Y" ~ B("n", "pq").
Bernoulli distribution.
The Bernoulli distribution is a special case of the binomial distribution, where "n" = 1. Symbolically, "X" ~ B(1, "p") has the same meaning as "X" ~ Bern("p"). Conversely, any binomial distribution, B("n", "p"), is the distribution of the sum of "n" Bernoulli trials, Bern("p"), each with the same probability "p".
Poisson binomial distribution.
The binomial distribution is a special case of the Poisson binomial distribution, which is a sum of "n" independent non-identical Bernoulli trials Bern("pi"). If "X" has the Poisson binomial distribution with "p1" = … = "pn" ="p" then "X" ~ B("n", "p").
Normal approximation.
If "n" is large enough, then the skew of the distribution is not too great. In this case a reasonable approximation to B("n", "p") is given by the normal distribution
and this basic approximation can be improved in a simple way by using a suitable continuity correction.
The basic approximation generally improves as "n" increases (at least 20) and is better when "p" is not near to 0 or 1. Various rules of thumb may be used to decide whether "n" is large enough, and "p" is far enough from the extremes of zero or one:
The following is an example of applying a continuity correction. Suppose one wishes to calculate Pr("X" ≤ 8) for a binomial random variable "X". If "Y" has a distribution given by the normal approximation, then Pr("X" ≤ 8) is approximated by Pr("Y" ≤ 8.5). The addition of 0.5 is the continuity correction; the uncorrected normal approximation gives considerably less accurate results.
This approximation, known as de Moivre–Laplace theorem, is a huge time-saver when undertaking calculations by hand (exact calculations with large "n" are very onerous); historically, it was the first use of the normal distribution, introduced in Abraham de Moivre's book "The Doctrine of Chances" in 1738. Nowadays, it can be seen as a consequence of the central limit theorem since B("n", "p") is a sum of "n" independent, identically distributed Bernoulli variables with parameter "p". This fact is the basis of a hypothesis test, a "proportion z-test", for the value of "p" using "x/n", the sample proportion and estimator of "p", in a common test statistic.
For example, suppose one randomly samples "n" people out of a large population and ask them whether they agree with a certain statement. The proportion of people who agree will of course depend on the sample. If groups of "n" people were sampled repeatedly and truly randomly, the proportions would follow an approximate normal distribution with mean equal to the true proportion "p" of agreement in the population and with standard deviation σ = ("p"(1 − "p")/"n")1/2. Large sample sizes "n" are good because the standard deviation, as a proportion of the expected value, gets smaller, which allows a more precise estimate of the unknown parameter "p".
Poisson approximation.
The binomial distribution converges towards the Poisson distribution as the number of trials goes to infinity while the product "np" remains fixed. Therefore the Poisson distribution with parameter "λ" = "np" can be used as an approximation to B("n", "p") of the binomial distribution if "n" is sufficiently large and "p" is sufficiently small. According to two rules of thumb, this approximation is good if "n" ≥ 20 and "p" ≤ 0.05, or if "n" ≥ 100 and "np" ≤ 10.
Beta distribution.
Beta distributions provide a family of conjugate prior probability distributions for binomial distributions in Bayesian inference. The domain of the beta distribution can be viewed as a probability, and in fact the beta distribution is often used to describe the distribution of a probability value "p": 
Confidence intervals.
Even for quite large values of "n", the actual distribution of the mean is significantly nonnormal. Because of this problem several methods to estimate confidence intervals have been proposed.
Let "n"1 be the number of successes out of "n", the total number of trials, and let 
be the proportion of successes. Let "z"α/2 be the 100(1 − α/2)th percentile of the standard normal distribution.
The exact (Clopper-Pearson) method is the most conservative. The Wald method although commonly recommended in the text books is the most biased.
Generating binomial random variates.
Methods for random number generation where the marginal distribution is a binomial distribution are well-established.
One way to generate random samples from a binomial distribution is to use an inversion algorithm. To do so, one must calculate the probability that P(X=k) for all values "k" from 0 through "n". (These probabilities should sum to a value close to one, in order to encompass the entire sample space.) Then by using a Linear congruential generator to generate samples uniform between 0 and 1, one can transform the calculated samples U[0,1] into discrete numbers by using the probabilities calculated in step one.
Bounds for the cumulative distribution function.
For "k" ≤ "np", upper bounds for the lower tail of the distribution function can be derived. In particular, Hoeffding's inequality yields the bound
and Chernoff's inequality can be used to derive the bound
Moreover, these bounds are reasonably tight when "p = 1/2", since the following expression holds for all "k" ≥ "3n/8"
However, the bounds do not work well for extreme values of "p". In particular, as "p" formula_48 "1", value "F(k;n,p)" goes to zero (for fixed "k", "n" with "k<n")
while the upper bound above goes to a positive constant. In this case a better bound is given by
Asymptotically, this bound is reasonably tight; see
Both these bounds are derived by directly minimising the Chernoff bound without any approximation in.

</doc>
<doc id="3878" url="http://en.wikipedia.org/wiki?curid=3878" title="Biostatistics">
Biostatistics

Biostatistics (or biometry) is the application of statistics to a wide range of topics in biology. The science of biostatistics encompasses the design of biological experiments, especially in medicine, pharmacy, agriculture and fishery; the collection, summarization, and analysis of data from those experiments; and the interpretation of, and inference from, the results. A major branch of this is medical biostatistics, which is exclusively concerned with medicine and health.
Biostatistics and the history of biological thought.
Biostatistical reasoning and modeling were of critical importance to the foundation theories of modern biology. In the early 1900s, after the rediscovery of Mendel's work, the gaps in understanding between genetics and evolutionary Darwinism led to vigorous debate among biometricians, such as Walter Weldon and Karl Pearson, and Mendelians, such as Charles Davenport, William Bateson and Wilhelm Johannsen. By the 1930s, statisticians and models built on statistical reasoning had helped to resolve these differences and to produce the neo-Darwinian modern evolutionary synthesis.
The leading figures in the establishment of this synthesis all relied on statistics and developed its use in biology.
These individuals and the work of other biostatisticians, mathematical biologists, and statistically inclined geneticists helped bring together evolutionary biology and genetics into a consistent, coherent whole that could begin to be quantitatively modeled.
In parallel to this overall development, the pioneering work of D'Arcy Thompson in "On Growth and Form" also helped to add quantitative discipline to biological study.
Despite the fundamental importance and frequent necessity of statistical reasoning, there may nonetheless have been a tendency among biologists to distrust or deprecate results which are not qualitatively apparent. One anecdote describes Thomas Hunt Morgan banning the Friden calculator from his department at Caltech, saying "Well, I am like a guy who is prospecting for gold along the banks of the Sacramento River in 1849. With a little intelligence, I can reach down and pick up big nuggets of gold. And as long as I can do that, I'm not going to let any people in my department waste scarce resources in placer mining."
Scope and training programs.
Almost all educational programmes in biostatistics are at postgraduate level. They are most often found in schools of public health, affiliated with schools of medicine, forestry, or agriculture, or as a focus of application in departments of statistics.
In the United States, where several universities have dedicated biostatistics departments, many other top-tier universities integrate biostatistics faculty into statistics or other departments, such as epidemiology. Thus, departments carrying the name "biostatistics" may exist under quite different structures. For instance, relatively new biostatistics departments have been founded with a focus on bioinformatics and computational biology, whereas older departments, typically affiliated with schools of public health, will have more traditional lines of research involving epidemiological studies and clinical trials as well as bioinformatics. In larger universities where both a statistics and a biostatistics department exist, the degree of integration between the two departments may range from the bare minimum to very close collaboration. In general, the difference between a statistics program and a biostatistics program is twofold: (i) statistics departments will often host theoretical/methodological research which are less common in biostatistics programs and (ii) statistics departments have lines of research that may include biomedical applications but also other areas such as industry (quality control), business and economics and biological areas other than medicine.
Recent developments in modern biostatistics.
The advent of modern computer technology and relatively cheap computing rescources have enabled computer-intensive biostatistical methods like bootstrapping and resampling methods. 
Furthermore new biomedical technologies like microarrays, next generation sequencers (for genomics) and mass spectrometry (for proteomics) generate enormous amounts of (redundant) data that can only be analyzed with biostatistical methods. For example, a microarray can measure all the genes of the human genome simultaneously, but only a fraction of them will be differentially expressed in diseased vs. non-diseased states. One might encounter the problem of multicolinearity: Due to high intercorelation between the predictors (in this case say genes), the information of one predictor might be contained in another one. It could be that only 5% of the predictors are responsible for 90% of the variability of the response. In such a case, one would apply the biostatistical technique of dimension reduction (for example via principal component analysis). Classical statistical techniques like linear or logistic regression and linear discrimanant analysis do not work well for high dimensional data (i.e. when the number of observations n is smaller than the number of features or predictors p: n 2-values despite very low predictive power of the statistical model. These classical statistical techniques (esp. least squares linear regression) were developed for low dimensional data (i.e. where the number of observations n is much larger than the number of predictors p: n Â» p). In cases of high dimensionality, one should always consider an independent validation test set and the corresponding residual sum of squares (RSS) and R2 of the validation test set, not those of the training set.
In recent times, random forests have gained popularity. This technique, invented by the statistican Leo Breiman, generates a lot of decision trees randomly and uses them for classification (In classification the response is on a nominal or ordinal scale, as opposed to regression where the response is on a ratio scale). Decision trees have of course the advantage that you can draw them and interpret them (even with a very basic understanding of mathematics and statistics). Random Forrests have thus been used for clinical decision support systems.
Gene Set Enirchment Analysis (GSEA) is a new method for analyzing biological high throughput experiments. With this method, one does not consider the perturbation of single genes but of whole (functionally related) gene sets. These gene sets might be known biochemical pathways or otherwiese functionally related genes. The advantage of this approach is that it is more robust: It is more likely that a single gene is found to be falsely perturbed than it is that a whole pathway is falsely perturbed. Furthermore, one can integrate the accumulated knowledge about biochemical pathways (like the JAK-STAT signaling pathway) using this approach.

</doc>
<doc id="3879" url="http://en.wikipedia.org/wiki?curid=3879" title="Business statistics">
Business statistics

Business statistics is the science of good decision making in the face of uncertainty and is used in many disciplines such as financial analysis, econometrics, auditing, production and operations including services improvement, and marketing research. 
These sources feature regular repetitive publication of series of data. This makes the topic of time series especially important for business statistics. It is also a branch of applied statistics working mostly on data collected as a by-product of doing business or by government agencies. It provides knowledge and skills to interpret and use statistical techniques in a variety of business applications. A typical business statistics course is intended for business majors, and 
covers statistical study, descriptive statistics (collection, description, analysis, and summary of data), probability, and the binomial and normal distributions, test of hypotheses and confidence intervals, linear regression, and correlation. 
References.
Darlene Basilio

</doc>
<doc id="3883" url="http://en.wikipedia.org/wiki?curid=3883" title="Lists of people">
Lists of people

People denotes a group of humans, either with unspecified traits, or specific characteristics (e. g. the people of Spain or the people of the Plains). Lists of people include the following (fictional characters are excluded):

</doc>
<doc id="3912" url="http://en.wikipedia.org/wiki?curid=3912" title="List of major biblical figures">
List of major biblical figures

The Bible is a canonical collection of texts considered sacred in Judaism or Christianity. Different religious groups include different books within their canons, in different orders, and sometimes divide or combine books, or incorporate additional material into canonical books. Christian Bibles range from the sixty-six books of the Protestant canon to the eighty-one books of the Ethiopian Orthodox Church canon.
Hebrew Bible.
Tribes of Israel.
According to the Book of Genesis, the Israelites were descendants of the sons of Jacob, who was renamed Israel after wrestling with an angel. His twelve male children become the ancestors of the Twelve Tribes of Israel.
New Testament.
Jesus and his relatives.
Jesus
Christian Apostles of Jesus.
The Twelve:
Others:

</doc>
<doc id="3914" url="http://en.wikipedia.org/wiki?curid=3914" title="British and Irish Lions">
British and Irish Lions

The British and Irish Lions, formerly known as the British Lions, is a rugby union team selected from players eligible for any of the Home Unions – the national sides of England, Ireland, Scotland and Wales. The "Lions" are a Test side, and generally select international players, but they can pick uncapped players available to any one of the four unions. The side tours every four years, with these rotating among Australia, New Zealand, and South Africa. The 2009 Test series was lost 2–1 to South Africa, while the 2013 Test series was won 2–1 over Australia.
From 1888 onwards combined rugby sides from the United Kingdom of Great Britain and Ireland toured the Southern Hemisphere. The first tour was a commercial venture, and was undertaken without official backing. The six subsequent visits enjoyed a growing degree of support from the authorities, before the 1910 South Africa tour, which was the first tour representative of the four Home Unions. In 1949 the four Home Unions formally created a Tours Committee and for the first time, every player of the 1950 Lions squad had played internationally before the tour. The 1950s tours saw high win rates in provincial games, but the Test series were typically lost or drawn. The winning series in 1971 (New Zealand) and 1974 (South Africa) changed this pattern. The last tour of the amateur age took place in 1993.
Naming and symbols.
Team name.
The multi-nation team that is today named the British and Irish Lions first came into existence in 1888 as the Shaw & Shrewsbury Team. It was then primarily English in composition but also contained players from Scotland and Wales. Later the name British Isles became associated with the team. On their 1950 tour of New Zealand and Australia they officially adopted the name British Lions, the nickname first used by British and South African journalists on the 1924 South African tour after the lion emblem on their ties, the emblem on their jerseys having been dropped in favour of the four-quartered badge with the symbols of the four represented unions.
When the team first emerged in the nineteenth century, it represented the United Kingdom of Great Britain and Ireland, then one single state. The team continued to exist after the Irish War of Independence and the subsequent division of the island of Ireland in 1922 into the Irish Free State (later the Republic of Ireland) and Northern Ireland. To avoid ambiguity and possible offence to Irish players, it was later decided to define the team's identity as representing the two sovereign states – Ireland and the United Kingdom – with the team members being either "British" or "Irish". From the 2001 tour of Australia, the official name British and Irish Lions has been used. The team is often referred to simply as the Lions.
Team anthem.
As the Lions represent two nation-states, they do not have a national anthem. For the 2005 tour to New Zealand, the Lions management commissioned a song, "The Power of Four", although it met with little support amongst Lions fans at the matches and was not used on the 2009 or 2013 Tours.
Team colours and strip.
For more than half a century, the Lions have been synonymous with the red jersey that sports the amalgamated crests of the four unions. However, prior to 1950 the strip went through a number of significantly different formats.
Unsanctioned tours.
In 1888, the promoter of the first expedition to Australia and New Zealand, Arthur Shrewsbury, demanded "something that would be good material and yet take them by storm out here". The result was a jersey in thick red, white and blue hoops, worn above white shorts and dark socks. The tours to South Africa in 1891 and 1896 retained the red, white and blue theme but this time as red and white hooped jerseys and dark blue shorts and socks. The 1899 trip to Australia saw a reversion to red, white and blue jerseys, but with the blue used in thick hoops and the red and white in thin bands. The shorts remained blue, as did the socks although a white flash was added to the latter. The one-off test in 1999 between England and Australia that was played to commemorate Australia's first test against Reverend Matthew Mullineux's British side saw England wear an updated version of this jersey. In 1903, the South Africa tour followed on from the 1896 tour, with red and white hooped jerseys. The slight differences were that the red hoops were slightly thicker than the white (the opposite was true in 1896), and the white flash on the socks introduced in 1899 was partially retained. The Australia of 1904 saw exactly the same kit as in 1899, and it seemed that the British touring sides had settled on kits particular to the host destination. However, in 1908 with the Scottish and Irish unions refusing to be involved, the Anglo-Welsh side only sported red jerseys with a thick white band on their jerseys on tour to Australia and New Zealand. Blue shorts were retained, but the socks were for the first time red, with a white flash.
Blue jerseys, the Lions named and the crest adopted.
The Scots were once again involved in Dr Tom Smyth's 1910 team to South Africa. Thus, dark blue jerseys, were introduced with white shorts and the red socks of 1908. The jerseys also had a single lion-rampant crest. The 1924 tour returned to South Africa, retaining the blue jerseys but now with shorts to match. It is the 1924 tour that is credited as being the first in which the team were referred to as "the Lions", the irony being that it was on this tour that the single lion-rampant crest was replaced with the forerunner of the four-quartered badge with the symbols of the four represented unions, that is still worn today. Although the lion had been dropped from the jersey, the players had worn the lion motif on their ties as they arrived in South Africa, which led the press and public referring to them as "the Lions".
The unofficial 1927 Argentina tour used the same kit and badge. So powerful was the attribution of "the Lions" nickname that three heraldic versions of the animal returned as the jersey badge in 1930. This was the tour to New Zealand where the tourists now standard blue jerseys caused some controversy. The convention in rugby is for the home side to accommodate its guests when there is a clash of kit. The New Zealand side, by then already synonymous with the appellation "All Blacks", had an all black kit that clashed with the Lions' blue. After much reluctance and debate New Zealand agreed to change for the Tests and the All Blacks became the All Whites for the first time. On the 1930 tour a delegation led by the Irish lock George Beamish expressed their displeasure at the fact that whilst the blue of Scotland, white of England and red of Wales were represented in the strip there was no green for Ireland. A green flash was added to the socks, which from 1938 became a green turnover (although on blue socks thus eliminating red from the kit), and that has remained a feature of the strip ever since. In 1936, the four-quartered badge returned for the tour to Argentina and has remained on the kits ever since, but other than that the strip remained the same.
Red jerseys.
The adoption of the red jersey happened in the 1950 tour. A return to New Zealand was accompanied by a desire to avoid the controversy of 1930 and so red replaced blue for the jersey with the resultant kit being that which is still worn today, the combination of red jersey, white shorts and green and blue socks, representing the four unions. The only additions to the strip since 1950 began appearing in 1993, with the addition of kit suppliers logos in prominent positions. Umbro had in 1989 asked for "maximum brand exposure whenever possible" but this did not affect the kit's appearance. Since then, Nike then Adidas have had more overt branding on the shirts, with sponsors Scottish Provident (1997), (2001), Zurich (2005) and HSBC (2009 & 2013).
History.
1888–1909.
The earliest tours date back to 1888, when a 21-man squad visited Australia and New Zealand. The squad drew players from England, Scotland and Wales, though English players predominated. The 35-match tour of two host nations included no tests, but the side played provincial, city and academic sides, winning 27 matches. They played 19 games of Australian rules football, against prominent clubs in Victoria and South Australia, winning six and drawing one of these (see Australian rules football in England).
The first tour, although unsanctioned by rugby bodies, established the concept of Northern Hemisphere sporting sides touring to the Southern Hemisphere. Three years after the first tour, the Western Province union invited rugby bodies in Britain to tour South Africa. Some saw the 1891 team — the first sanctioned by the Rugby Football Union — as the English national team, though others referred to it as "the British Isles". The tourists played a total of twenty matches, three of them tests. The team also played the regional side of South Africa (South Africa did not exist as a political unit in 1891), winning all three matches. In a notable event of the tour, the touring side presented the Currie Cup to Griqualand West, the province they thought produced the best performance on the tour.
Five years later a British Isles side returned to South Africa. They played one extra match on this tour, making the total of 21 games, including four tests against South Africa, with the British Isles winning three of them. The squad had a notable Irish orientation, with the Irish national team contributing six players to the 21-man squad.
In 1899 the British Isles touring side returned to Australia for the first time since the unofficial tour of 1888. The squad of 23 for the first time ever had players from each of the home nations. The team again participated in 21 matches, playing state teams as well as northern Queensland sides and Victorian teams. A four-test series took place against Australia, the tourists winning three out of the four. The team returned via Hawaii and Canada playing additional games on route.
Four years later, in 1903, the British and Irish team returned to South Africa. The opening performance of the side proved disappointing from the tourists' point of view, with defeats in its opening three matches by Western Province sides in Cape Town. From then on the team experienced mixed results, though more wins than losses. The side lost the test series to South Africa, drawing twice, but with the South Africans winning the decider 8 to nil.
No more than twelve months passed before the British and Irish team ventured to Australia and New Zealand in 1904. The tourists devastated the Australian teams, winning every single game. Australia also lost all three tests to the visitors, even getting held to a standstill in two of the three games. Though the New Zealand leg of the tour did not take long in comparison to the number of Australian games, the British and Irish experienced considerable difficulty across the Tasman after whitewashing the Australians. The team managed two early wins before losing the test to New Zealand and only winning one more game as well as drawing once. Despite their difficulties in New Zealand, the tour proved a raging success on-field for the British and Irish.
In 1908, another tour took place to Australia and New Zealand. In a reversal of previous practice, the planners allocated more matches in New Zealand rather than in Australia: perhaps the strength of the New Zealand teams and the heavy defeats of all Australian teams on the previous tour influenced this decision. Some commentators thought that this tour hoped to reach out to rugby communities in Australia, as rugby league (infamously) started in Australia in 1908. The Anglo-Welsh side (Irish and Scottish unions did not participate) performed well in all the non-test matches, but drew a test against New Zealand and lost the other two.
1910–1949.
Visits that took place before the 1910 South Africa tour (the first selected by a committee from the four Home Unions) had enjoyed a growing degree of support from the authorities, although only one of these included representatives of all four nations. The 1910 tour to South Africa marked the official beginning of British and Irish rugby tours: the inaugural tour operating under all four unions. The team performed moderately against the non-test parties, claiming victories in just over half their matches. The test series, however, went to South Africa, who won two of the three games. A side managed by Oxford University — supposedly the England rugby team, but actually including three Scottish players — toured Argentina at the time: the people of Argentina termed it the "Combined British".
The next British Isles team tour did not take place until 1924, again in South Africa. The team, led by Ronald Cove-Smith, struggled with injuries and lost three of the four test matches, drawing the other 3–3. In total, 21 games were played, with the touring side winning 9, drawing 3 and losing 9. This tour may have marked the occasion when the team first became known as "the Lions".
In 1927 a short, nine-game series took place in Argentina, with the Lions winning all nine encounters; the tour did however become a financial success for Argentine rugby. After a seemingly long absence from New Zealand, the Lions returned in 1930 to some success. The Lions won all of their games that did not have test status except for the matches against Auckland, Wellington and Canterbury; they did however lose three of their four test matches against New Zealand, winning the first test 6–3. The side also visited Australia, losing a test but winning five out of the six non-test games.
In 1936 the Lions visited Argentina for the second time, winning all ten of their matches and only conceding nine points in the whole tour. Two years later the Lions toured in South Africa, winning more than half of their normal matches. Despite having lost the test series to South Africa by game three, the Lions won the final test.
1950–1969.
The first post-war tour went to New Zealand and Australia in 1950. The Lions, sporting newly redesigned jerseys and displaying a fresh style of play, managed to win 22 and draw one of 29 matches over the two nations. The Lions won the opening four fixtures before losing to Otago and Southland, but succeeded in holding the All Blacks to a 9–9 draw. The Lions performed well in the remaining All Black tests though they lost all three, the team did not lose another non-test in the New Zealand leg of the tour. The Lions won all their games in Australia except for their final fixture against a New South Wales XV in Newcastle. They won both tests against Australia, in Brisbane, Queensland and in Sydney, New South Wales.
In 1955 the Lions toured South Africa and left with another imposing record, one draw and 19 wins from the 25 fixtures. The four-test series against South Africa, a thrilling affair, ended in a drawn series.
The 1959 tour to Australia and New Zealand marked once again a very successful tour for the Lions, who only lost six of their 35 fixtures. The Lions easily won both tests against Australia and lost the first three tests against the All Blacks, but did find victory (9–6) in the final test.
After the glittering decade of the 1950s, the first tour of the 1960s proved not nearly as successful as previous ones. The 1962 tour to South Africa saw the Lions still win 16 of their 25 games, but did not fare well against the Springboks, losing three of the four tests. For the 1966 tour to Australia and New Zealand John Robins became the first Lions Coach, and the trip started off very well for the Lions, who stormed through Australia, winning five non-tests and drawing one; and most notably defeating Australia in two tests as well. The Lions however experienced mixed results during the New Zealand leg of the tour, as well as losing all of the tests against the All Blacks. The Lions also played a test against Canada on their way home, winning 19 to 8 in Toronto. The 1968 tour of South Africa saw the Lions win 15 of their 16 provincial matches, but the team actually lost three tests against the Springboks and drew one.
1970–1979.
The 1970s saw a renaissance for the Lions. The 1971 team, centred around the skilled Welsh half-back pairing of Gareth Edwards and Barry John, secured a series win over the All Blacks. The tour started with a loss to Queensland but proceeded to storm through the next provincial fixtures, winning 11 games in a row. The Lions then went on to defeat the All Blacks in Dunedin. The Lions would only lose a single match on the rest of the tour, and won the test series against New Zealand, winning and drawing the last two games, to take the series two wins to one.
One of the best-known and most successful Lions team toured South Africa in 1974 under the esteemed Irish forward Willie John McBride. It went through 22 games unbeaten, and triumphed 3–0 (with one drawn) in the test open series. The test series featured a lot of violence. The management of the Lions concluded that the Springboks dominated their opponents with physical aggression. At that time, test match referees came from the home nation, substitutions took place only if a doctor found a player unable to continue and there were no video cameras or sideline officials to prevent violent play. The Lions decided "to get their retaliation in first" with the infamous "99 call". The Lions postulated that a South African referee would probably not send off all of the Lions if they all retaliated against "blatant thuggery". Famous video footage of the 'battle of Boet Erasmus Stadium' shows JPR Williams running over half of the pitch and launching himself at Van Heerden after such a call.
The 1977 tour to New Zealand saw the Lions drop only one non-test out of 21 games, a loss to a Universities side. The team did not win the test series though, winning one game but losing the other three.
In August 1977 the British Lions made a stopover in Fiji on the way home from their tour of New Zealand. Fiji beat them 25–21 at Buckhurst Park, Suva.
1980–2005.
The Lions toured South Africa in 1980. The team completed a flawless non-test record, winning 14 out of 14 non-test matches on the tour. The Lions did however lose the first three tests to South Africa, winning the last one, though the series had already been won by the Springboks.
The 1983 tour to New Zealand saw the team successful on the non-test front, winning all but two games, but getting white-washed in the test-series against the All Blacks. A tour to South Africa by the Lions was anticipated in 1986. However, the invitation for the Lions to tour South Africa was never accepted because of controversy surrounding Apartheid. As a result the anticipated tour never occurred in 1986. The Lions did not return to South Africa until 1997, after the Apartheid era. A Lions team was selected in 1986 for the International Rugby Board centenary match against a Rest of the World XV in April of that year; the team was organised by the Four Home Unions Committee and the players were given the status of official British Lions. The Lions tour to Australia in 1989 was a short affair, being only 12 matches in total. The tour was very successful for the Lions, who won all eight non-tests and won the test series against Australia, two to one.
The Lions tour to New Zealand in 1993 was the last of the amateur era. The tourists won six and lost four non-test matches, and lost the test series 2–1.
The tour to South Africa in 1997 was a success for the Lions, who completed the tour with only two losses. The Lions won the test series 2–1.
In 2001, the ten game tour to Australia, saw the Wallabies win the test series 2–1. This series saw the first award of the Tom Richards Trophy. The Lions' 2005 tour to New Zealand, coached by 2003 England world cup winning coach Clive Woodward, won all seven games against provincial teams however suffered heavy defeats in all three tests and were narrowly defeated by the New Zealand Maori team.
2009.
The Lions faced the World Cup winners South Africa, with Ian McGeechan leading a coaching team including Warren Gatland, Shaun Edwards and Rob Howley. The Lions were captained by Irish lock Paul O'Connell. The initial Lions selection consisted of fourteen Irish players, thirteen Welsh, eight English and two Scots in the 37-man squad.
In the first Test on 20 June, they lost 26–21, and lost the series in the second 28–25 in a tightly-fought game at Loftus Versfeld on 27 June. The Lions won the third Test 28–9 at Ellis Park, and the series finished 2–1 to South Africa.
2013.
During June 2013 the British and Irish Lions toured Australia.
Former Scotland and Lions full-back Andy Irvine was appointed as tour manager in 2010.
The tour started in Hong Kong with a match against the Barbarians before moving on to Australia for the main tour featuring six provincial matches and three tests.
2017 & Beyond.
The next British and Irish Lions tour will be to New Zealand in 2017. The current agreement with the SANZAR Nations runs out after the New Zealand tour and negotiations will begin in 2014 on a new one which promises to be markedly different because of the explosion of interest in the Lions. It has been stated that everything will be up for discussion, from the financial side to scheduling, itineraries, the strength of opposition in warm-up matches and the number of matches played.
Following the performances of the Canadian, American and Argentine teams at the 2011 Rugby World Cup, some commentators have suggested the Lions conduct a shortened tour of the Americas in the future.
Overall.
Overall test matches
Updated after the 2013 Tour
Overall tour results
Tours.
Format.
The Lions tour three southern hemisphere nations; Australia, South Africa and New Zealand. They also routinely toured in Argentina before World War II. Tours currently take place every four years. The most recent tour visited Australia in June–July 2013, and before that the Lions toured South Africa in 2009.
In a break with tradition, a "home" fixture against Argentina took place at Millennium Stadium in Cardiff on 23 May 2005, before the Lions went to New Zealand. It finished in a draw, 25–25.
On tour, games take place against local provinces, clubs or representative sides as well as the full tests against the host's national team.
The Lions, and their predecessor teams, have often played games against other nearby countries on tour. For example, they played Rhodesia (the future Zimbabwe) in 1910, 1924, 1938, 1955, 1962, 1968 & 1974 during their tours to South Africa. They also were beaten by Fiji on their 1977 tour to New Zealand. In addition, they toured pre-independence Namibia (then South West Africa), in 1955, 1962, 1968, and 1974.
There have also been games in other countries on the way home. These include games in in 1959 and 1966, East Africa (then mostly Kenya, and held in Nairobi), and an unofficial game against Ceylon (future Sri Lanka) in 1950.
Previous tours have seen some non-Test players become demotivated, but more recently this issue has reduced because of high injury rates, increased use of replacements and greater selection flexibility.
In recent tours a common issue has been weak opposition in many non-Test games, partly as opposition countries have their top players in national training camps, partly as sides protect top players for domestic games which are seen as more commercially important than Lions games, and possibly partly to prevent the Lions having high standard preparatory games.
Lions non-tour and home matches.
The Lions have played a number of "home matches" against international opposition. With the exception of the 2005 home match against Argentina (which was played as a warm-up to the 2005 British and Irish Lions tour to New Zealand), these matches have been one-offs to mark special occasions:
Notes.
a. Name of the Lions in the languages of Britain and Ireland:

</doc>
<doc id="3916" url="http://en.wikipedia.org/wiki?curid=3916" title="Bass guitar">
Bass guitar

The bass guitar (also called electric bass, or simply bass; ) is a stringed instrument played primarily with the fingers or thumb, by plucking, slapping, popping, tapping, thumping, or picking with a plectrum, often known as a pick.
The bass guitar is similar in appearance and construction to an electric guitar, but with a longer neck and scale length, and four to six strings or courses. The four-string bass—by far the most common—is usually tuned the same as the double bass, which corresponds to pitches an octave lower than the four lowest pitched strings of a guitar (E, A, D, and G). The bass guitar is a transposing instrument, as it is notated in bass clef an octave higher than it sounds (as is the double bass) to avoid excessive ledger lines. Like the electric guitar, the bass guitar is plugged into an amplifier and speaker for live performances.
Since the 1960s, the bass guitar has largely replaced the double bass in popular music as the bass instrument in the rhythm section. While types of bass lines vary widely from one style of music to another, the bassist usually fulfills a similar role: anchoring the harmonic framework and establishing the beat. Many styles of music utilise the bass guitar, including rock, metal, pop, punk rock, country, reggae, gospel, blues, and jazz. It is often a soloing instrument in jazz, jazz fusion, Latin, funk, progressive rock and other rock and metal styles.
History.
1930s–1940s.
In the 1930s, musician and inventor Paul Tutmarc from Seattle, Washington, who was manufacturing lap steel guitars, developed the first electric string bass in its modern form, a fretted instrument designed to be played horizontally. The 1935 sales catalog for Tutmarc's electronic musical instrument company, Audiovox, featured his "Model 736 Bass Fiddle", a four-stringed, solid-bodied, fretted electric bass instrument with a 30½-inch scale length. The adoption of a "guitar" form made the instrument easier to hold and transport, than any of the existing stringed bass instruments. The addition of frets enabled bassists to play in tune more easily than on acoustic or electric upright basses. Around 100 of these instruments were made during this period.
Around 1947, Tutmarc's son, Bud, began marketing a similar bass under the Serenader brand name, prominently advertised in the nationally distributed L. D. Heater Music Company wholesale jobber catalogue of '48. However, the Tutmarc family inventions did not achieve market success.
1950s.
In the 1950s, Leo Fender, with the help of his employee George Fullerton, developed the first mass-produced electric bass. His Fender Precision Bass, introduced in 1951, became a widely copied industry standard. The Precision Bass (or "P-bass") evolved from a simple, uncontoured "slab" body design similar to that of a Telecaster with a single coil pickup, to a contoured body design with beveled edges for comfort and a single four-pole "single coil pickup." This "split pickup", introduced in 1957, appears to have been two mandolin pickups (Fender was marketing a four string solid body electric mandolin at the time). The pole pieces and leads of the coils were reversed with respect to each other, producing a humbucking effect.
The "Fender Bass" was a revolutionary new instrument, which could be easily transported to a gig, and amplified to just about any volume without feeding back". Monk Montgomery was the first bass player to tour with the Fender bass guitar, with Lionel Hampton's postwar big band. Roy Johnson, and Shifty Henry with Louis Jordan & His Tympany Five, were other early Fender bass pioneers. Bill Black, playing with Elvis Presley, adopted the Fender Precision Bass around 1957. The bass guitar was intended to appeal to guitarists as well as upright bass players, and many early pioneers of the instrument, such as Carol Kaye and Joe Osborn, were originally guitarists.
Following Fender's lead, in 1953, Gibson released the first short scale violin-shaped electric bass with extendable end pin, allowing it to be played upright or horizontally. Gibson renamed the Electric Bass in 1958 to the EB-1 (The EB-1 was reissued around 1970, but this time without the end pin.) Also in 1958 Gibson released the maple arched top EB-2 described in the Gibson catalogue as "A hollow-body electric bass that features a Bass/Baritone pushbutton for two different tonal characteristics". In 1959 these were followed by the more conventional-looking EB-0 Bass. The EB-0 was very similar to a Gibson SG in appearance (although the earliest examples have a slab-sided body shape closer to that of the double-cutaway Les Paul Special).
Whereas Fender basses had pickups mounted in positions in between the base of the neck and the top of the bridge, many of Gibson's early basses featured one humbucking pickup mounted directly against the neck pocket. The EB-3, introduced in 1961, also had a "mini-humbucker" at the bridge position. Gibson basses also tended to be smaller, sleeker instruments; Gibson did not produce a 34" scale bass until 1963 with the release of the Thunderbird, which was also the first Gibson bass to use dual-humbucking pickups in a more traditional position, about halfway between the neck and bridge. A small number of other companies also began manufacturing bass guitars during the 1950s: Kay in 1952, and Danelectro in 1956;
1956 saw the appearance at the German trade fair "Musikmesse Frankfurt" of the distinctive Höfner 500/1 violin bass made using violin construction techniques by Walter Höfner, a second generation violin luthier. The instrument is often known as the "Beatle Bass", due to its endorsement by Paul McCartney. In 1957 Rickenbacker introduced the model 4000 bass, the first bass to feature a neck-through-body design; the Fender and Gibson versions used bolt-on and glued-on necks.
1960s.
With the explosion of the popularity of rock music in the 1960s, many more manufacturers began making electric basses. First introduced in 1960, the Fender Jazz Bass was known as the Deluxe Bass and was meant to accompany the Jazzmaster guitar. The Jazz Bass (often referred to as a "J-bass") featured two single-coil pickups, one close to the bridge and one in the Precision bass' split coil pickup position. The earliest production basses had a 'stacked' volume and tone control for each pickup. This was soon changed to the familiar configuration of a volume control for each pickup, and a single, passive tone control. The Jazz Bass' neck was narrower at the nut than the Precision bass (1½" versus 1¾").
Another visual difference that set the Jazz Bass apart from the Precision is its "offset-waist" body. Pickup shapes on electric basses are often referred to as "P" or "J" pickups in reference to the visual and electrical differences between the Precision Bass and Jazz Bass pickups.
Fender also began production of the Mustang Bass; a 30" scale length instrument used by bassists such as Tina Weymouth of Talking Heads and Bill Wyman of The Rolling Stones ("P" and "J" basses have a scale length of 34", a design echoed on most current production electric basses of all makes). In the 1950s and 1960s, the instrument was often called the "Fender bass", due to Fender's early dominance in the market.
Gibson introduced the short-scale (30.5") bass the Gibson EB-3 in 1961, favoured by Jack Bruce of Cream.
1970s.
The 1970s saw the founding of Music Man Instruments by Tom Walker, Forrest White and Leo Fender, which produced the StingRay, the first widely produced bass with active (powered) electronics. This amounts to an impedance buffering pre-amplifier on board the instrument to lower the output impedance of the bass's pickup circuit, increasing low-end output, and overall frequency response (more lows and highs). Specific models became identified with particular styles of music, such as the Rickenbacker 4001 series, which became identified with progressive rock bassists like Chris Squire of Yes, and Geddy Lee of Rush, while the StingRay was used by Louis Johnson of the funk band The Brothers Johnson.
In 1971, Alembic established the template for what became known as "boutique" or "high-end" electric bass guitars. These expensive, custom-tailored instruments, as used by Phil Lesh, Jack Casady, and Stanley Clarke, featured unique designs, premium hand-finished wood bodies, onboard electronics for preamplification and equalization, and innovative construction techniques such as multi-laminate neck-through-body construction and graphite necks. In the mid-1970s, Alembic and other boutique bass manufacturers, such as Tobias, produced four-string and five-string basses with a low "B" string. In 1975, bassist Anthony Jackson commissioned luthier Carl Thompson to build a six-string bass tuned (low to high) B0, E1, A1, D2, G2, C3.
1980s–Present.
In the 1980s, bass designers continued to explore new approaches. Ned Steinberger introduced a headless bass in 1979 and continued his innovations in the 1980s, using graphite and other new materials and (in 1984) introducing the TransTrem tremolo bar. In 1987, the Guild Guitar Corporation launched the fretless Ashbory bass, which used silicone rubber strings and a piezoelectric pickup to achieve a "double bass" sound with a short 18" scale length. In the late 1980s, MTV's "Unplugged" show, which featured bands performing with acoustic instruments, helped to popularize hollow-bodied acoustic bass guitars amplified with pickups.
During the 1990s, as five-string basses became more widely available and more affordable, an increasing number of bassists in genres ranging from metal to gospel began using five-string instruments for added lower range—a low "B". As well, onboard battery-powered electronics such as preamplifiers and equalizer circuits, which were previously only available on expensive "boutique" instruments, became increasingly available on modestly priced basses.
In the 2000s (decade), some bass manufacturers included digital modelling circuits inside the instrument to recreate tones and sounds from many models of basses (e.g., Line 6's Variax bass). Traditional bass designs such as the Fender Precision Bass and Fender Jazz Bass remained popular in the 2000s (decade); in 2011, a 60th Anniversary P-bass was introduced by Fender, along with the re-introduction of the short-scale Fender Jaguar Bass.
Design considerations.
Bass bodies are typically made of wood, although other materials such as graphite (for example, some of the Steinberger designs) have also been used. While a wide variety of woods are suitable for use in the body, neck, and fretboard of the bass guitar, the most common type of wood used for the body is alder, for the neck is maple, and for the fretboard is rosewood. Other commonly used woods include mahogany, maple, ash, walnut, and poplar for bodies, mahogany for necks, and maple and ebony for fretboards.
Other design options include finishes, such as lacquer, wax and oil; flat and carved designs; Luthier-produced custom-designed instruments; headless basses, which have tuning machines in the bridge of the instrument (e.g., Steinberger and Hohner designs) and several artificial materials such as luthite. The use of artificial materials (e.g., BassLab) allows for unique production techniques such as die-casting, to produce complex body shapes. While most basses have solid bodies, they can also include hollow chambers to increase the resonance or reduce the weight of the instrument. Some basses are built with entirely hollow bodies, which change the tone and resonance of the instrument. Acoustic bass guitars are typically equipped with piezoelectric or magnetic pickups and amplified.
Instruments handmade by highly skilled luthiers are becoming increasingly available. Exotic materials include woods such as bubinga, wenge, ovangkol, ebony and goncalo alves. Graphite composite is used to make lightweight necks Exotic woods are used on more expensive instruments: for example, Alembic uses cocobolo as a body or top layer material because of its attractive grain. Warwick bass guitars are also well known for exotic hardwoods: most of the necks are made of ovangkol, and the fingerboards wenge or ebony. Solid bubinga bodies are also used for tonal and aesthetic qualities.
A common feature of more expensive basses is "neck-through" construction. Instead of milling the body from a single piece of wood (or "bookmatched" halves) and then attaching the neck into a pocket (so-called "bolt-on" design), neck-through bases are constructed first by assembling the neck, which may comprise one, three, five or more layers of wood in vertical stripes, which are longer than the length of the fretboard. To this elongated neck, the body is attached as two "wings," which may also be made up of several layers. The entire bass is then milled and shaped. Many players believe "neck-through" construction provides better sustain and a mellower tone than "bolt-on" neck construction. While neck-through construction is most common in handmade "boutique" basses, some models of mass-produced basses such as Ibanez's BTB series also have neck-through construction. Bolt-on neck construction doesn't necessarily imply a cheaply made instrument; virtually all traditional Fender designs still use bolt-on necks for instruments costing thousands of dollars, and many boutique luthiers build bolt-on basses as well as neck-through.
The number of frets installed on a bass guitar neck may vary. The original Fender basses had 20 frets, and most bass guitars have between 20 and 24 frets or fret positions. Instruments with between 24 and 36 frets (2 and 3 octaves) also exist.
The long scale necks on Leo Fender's basses—with a scale length (distance between nut and bridge) of 34 inches—set the standard for electric basses, although 30 inch "short scale" instruments, such as the Höfner 500/1 "violin bass" played by Paul McCartney, and the Fender Mustang Bass are also common. While 35", 35.5" and 36" scale lengths were once only available in "boutique" instruments, in the 2000s (decade), many manufacturers began offering these "extra long" scale lengths. This extra long scale provides a higher string tension, which may yield a more defined tone on the low "B" string of five- and six-stringed instruments (or detuned four-string basses).
Fretted and fretless basses.
Another design consideration for the bass is whether to use frets on the fingerboard. On a fretted bass, the frets divide the fingerboard into semitone divisions (as on a guitar). Fretless basses have a distinct sound, because the absence of frets means that the string must be pressed down directly onto the wood of the fingerboard as with the double bass. The string buzzes against the wood and is somewhat muted because the sounding portion of the string is in direct contact with the flesh of the player's finger. The fretless bass allows players to use the expressive devices of glissando, vibrato and microtonal intonations such as quarter tones and just intonation.
While fretless basses are often associated with jazz and jazz fusion, bassists from other genres have always used fretless basses, such as Freebo (country), Rick Danko (rock/blues), Rod Clements (folk), Steve DiGiorgio (metal), Colin Edwin (modern/progressive rock). Some bassists use both fretted and fretless basses in performances, according to the type of material they are performing, e.g. Pino Palladino or Tony Levin.
The first fretless bass guitar was made by Bill Wyman in 1961 when he converted an inexpensive Japanese fretted bass by removing the frets. The first production fretless bass was the Ampeg AUB-1 introduced in 1966, and Fender introduced a fretless Precision Bass in 1970. Around 1970, Rick Danko from The Band began to use an Ampeg fretless, which he modified with Fender pickups—as heard on the 1971 "Cahoots" studio album and the "Rock of Ages" album recorded live in 1971. Danko said, "It's a challenge to play fretless because you have to really use your ear."
In the early 1970s, fusion-jazz bassist Jaco Pastorius created his own fretless bass by removing the frets from a Fender Jazz Bass, filling the holes with wood putty, and coating the fretboard with epoxy resin. Some fretless basses have "fret line" markers inlaid in the fingerboard as a guide, while others only use guide marks on the side of the neck.
Tapewound (double bass type) and flatwound strings are sometimes used with the fretless bass so the metal string windings do not wear down the fingerboard. Some fretless basses have epoxy coated fingerboards to increase the fingerboard's durability, enhance sustain, and give a brighter tone.
Strings and tuning.
The standard design for the electric bass guitar has four strings, tuned E, A, D and G, in fourths such that the open highest string, G, is an eleventh (an octave and a fourth) below middle C, making the tuning of all four strings the same as that of the double bass (E1, A1, D2, G2). This tuning is also the same as the standard tuning on the lower four strings on a six-string guitar, only an octave lower. String types include all-metal strings (roundwound, flatwound, halfwound, ground wound, and pressure wound); as well as metal strings with different coverings, such as tapewound and plastic-coatings. The variety of materials used in the strings gives bass players a range of tonal options. In the 1950s and early 1960s, bassists mostly used flatwound strings with a smooth surface, which had a smooth, damped sound reminiscent of a double bass. In the late 1960s and 1970s, roundwound bass strings similar to guitar strings became popular, though flatwounds also remain popular. Roundwounds have a brighter timbre with longer sustain than flatwounds.
A variety of tuning options and number of string courses have been used to extend the range of the instrument, or facilitate different modes of playing. The most common are four, five, or six strings:
Alternative range approaches.
Some bassists use other types of tuning to extended the range or get other benefits, such as providing multiple octaves of notes at any given position, or a larger tonal range. Instrument types or tunings used for this purpose include basses with fewer than four strings (one-string bass guitars, and alternative tunings e.g., tenor bass. 
Extended Range Basses (ERBs) are basses with six to twelve strings—with the additional strings used for range rather than unison or octave pairs. A seven-string bass (B0-E1-A1-D2-G2-C3-F3) was built by luthier Michael Tobias in 1987. This instrument, commissioned by bassist Garry Goodman, was an early example of a bass with more than six single course strings.
In 1999 South American ERB player Igor Saavedra designed one of the first 8 string ERBs known, and asked Luthier Alfonso Iturra to build it for him.
In 2011 Warwick released a new Thumb NT 7 bass for Jeroen Paul Thesseling, featuring a 34" scale with sub-contra tuning F#-B-E-A-D-G-C. Yves Carbonne developed 10 and 12 string fretless sub-bass guitars.
Piccolo Basses are cosmetically similar to a four-stringed electric bass guitar, but usually tuned one whole octave higher than a normal bass. The first electric piccolo bass was constructed by luthier Carl Thompson for Stanley Clarke. To allow for the raised tuning, the strings will be thinner, and the length of the neck (the scale) may be shorter. Several companies manufacture piccolo sets that can be put on any regular bass, thereby converting any bass into a piccolo bass. Because of the thinner strings, a new nut may be required to hold the strings. Some people prefer a slightly shorter scale, such as 30" or 28".
The tuning varies with the personal tastes of the artist, as does the number of strings. Joey DeMaio from the heavy metal band Manowar plays with four strings on his piccolo bass. Jazz bassist John Patitucci used a six-string piccolo bass, unaccompanied, on his song "Sachi's Eyes" on his album "One More Angel". Michael Manring has used a five-string piccolo bass in several altered tunings. Michael uses D'Addario EXL 280 piccolo bass strings on his four-string hyperbass, made by Zon Guitars.
Pickups and amplification.
Magnetic pickups.
Most electric bass guitars use magnetic pickups. The vibrations of the instrument's ferrous metal strings within the magnetic field of the permanent magnets in magnetic pickups produce small variations in the magnetic flux threading the coils of the pickups. This in turn produces small electrical voltages in the coils. These low-level signals are then amplified and played through a speaker. Since the 1980s, basses are often available with battery-powered "active" electronics that boost the signal, provide equalization controls to boost or cut bass and treble frequencies, or both.
Many basses have just one pickup, typically a "P" or soapbar pickup. Multiple pickups are also quite common, two of the most common configurations being a "P" near the neck and a "J" near the bridge (e.g., Fender Precision Bass Special, Fender Precision Bass Plus), or two "J" pickups (e.g., Fender Jazz). A two-"soapbar" configuration is also very common, especially on basses by makes such as Ibanez and Yamaha. A combination of a J or other single-coil pickup at the neck and a Music Man-style humbucker in the bridge has become popular among boutique builders, giving a very bright, focused tone that is good for jazz, funk and thumbstyle.
Some basses use more unusual pickup configurations, such as a soapbar and a "P" pickup (found on some Fenders), Stu Hamm's "Urge" basses, which have a "P" pickup sandwiched between two "J" pickups, and some of Bootsy Collins' custom basses, which had as many as 5 J pickups. Another unusual pickup configuration is found on some of the custom basses that Billy Sheehan uses, in which there is one humbucker at the neck and a split-coil pickup at the middle position.
The placement of the pickup greatly affects the sound. A pickup near the neck joint emphasizes the fundamental and low-order harmonics and thus produces a deeper, bassier sound, while a pickup near the bridge emphasizes higher-order harmonics and makes a "tighter" or "sharper" sound. Usually basses with multiple pickups allow blending of the output from the pickups, with electrical and acoustical interactions between the two pickups (such as partial phase cancellations) allowing a range of tonal effects.
Non-magnetic pickups.
The use of non-magnetic pickups allows bassists to use non-ferrous strings such as nylon, brass or even silicone rubber, which create different tones.
Amplification and effects.
Like the electric guitar, the electric bass guitar is often connected to an amplifier and a speaker with a patch cord for live performances. Electric bassists use either a "combo" amplifier, which combines an amplifier and a speaker in a single cabinet, or an amplifier and a separate speaker cabinet (or cabinets). In some cases, when the bass is used with large-scale PA amplification, it is plugged into a "DI" or "direct box", which routes the signal directly into a mixing console, and thence to the main and monitor speakers. Recording may use a microphone setup in front of the amplifier speaker for the amplified signal, a direct box that feeds the recording console, or a mix of both.
Various electronic bass effects such as preamplifiers, "stomp box"-style pedals and signal processors and the configuration of the amplifier and speaker can be used to alter the basic sound of the instrument. In the 1990s and early 2000s (decade), signal processors such as equalizers, overdrive devices (sometimes referred to as "fuzz bass"), and compressors or limiters became increasingly popular. Modulation effects like chorus, flanging, phase shifting, and time effects such as delay and looping are less commonly used with bass than with electric guitar, but they are used in some styles of music.
Playing techniques.
Sitting or standing.
Most bass players stand while playing, although sitting is also accepted, particularly in large ensemble settings, such as jazz big bands or in acoustic genres such as folk music. Some bassists, such as Jah Wobble, alternate between standing or seated playing. It is a matter of the player's preference as to which position gives the greatest ease of playing and what a bandleader expects. When sitting, right-handed players can balance the instrument on the right thigh or like classical guitar players, the left. Balancing the bass on the left thigh usually positions it in such a way that it mimics the standing position, allowing for less difference between the standing and sitting positions. Balancing the bass on the right thigh provides better access to the neck and fretboard in its entirety, especially lower frets.
Performing techniques.
In contrast to the upright bass (or double bass), the electric bass guitar is played horizontally across the body, like an electric guitar. When the strings are plucked with the fingers (pizzicato), the index and middle fingers (and sometimes with the thumb, ring, and little fingers as well) are used. James Jamerson, an influential bassist from the Motown era, played intricate bass lines using only his index finger, which he called "The Hook." There are also variations in how a bassist chooses to rest the right-hand thumb (or left thumb in the case of left-handed players). A player may rest his or her thumb on the top edge of one of the pickups or on the side of the fretboard, which is especially common among bassists who have an upright bass influence. Some bassists anchor their thumbs on the lowest string and move it off to play on the low string. Alternatively, the thumb can be rested loosely on the strings to mute the unused strings.
The string can be plucked at any point between the bridge and the point where the fretting hand is holding down the string; different timbres are produced depending on where along the string it is plucked. When plucked closer to the bridge, the string produces more pronounced harmonics, giving a brighter tone. Closer to the middle of the string that harmonics are less pronounced, giving a more mellow tone.
Bassists trying to emulate the sound of a double bass sometimes pluck the strings with their thumb and use palm-muting to create a short, "thumpy" tone. The late Monk Montgomery (who played in Lionel Hampton's band) and Bruce Palmer (who performed with Buffalo Springfield) use thumb downstrokes. The use of the thumb was acknowledged by early Fender models, which came with a "thumbrest" or "Tug Bar" attached to the pickguard below the strings. Contrary to its name, this was not used to rest the thumb, but to provide leverage while using the thumb to pluck the strings. The thumbrest was moved above the strings in 1970s models (as a true thumbrest) and eliminated in the 1980s.
"Slap and pop".
The slap and pop method, or "thumbstyle", most associated with funk, uses tones and percussive sounds achieved by striking, thumping, or "slapping" a string with the thumb and snapping (or "popping") a string or strings with the index or middle fingers. Bassists often interpolate left hand-muted "dead notes" between the slaps and pops to achieve a rapid percussive effect, and after a note is slapped or popped, the fretting hand may cause other notes to sound by using "hammer ons", "pull offs", or a left-hand glissando (slide). Larry Graham of Sly and the Family Stone and Graham Central Station was an early innovator of the slap style, and Louis Johnson of The Brothers Johnson is also credited as an early slap bass player.
Slap and pop style is also used by many bassists in other genres, such as rock (e.g., J J Burnel and Les Claypool), metal (e.g., Eric Langlois, Martin Mendez, Fieldy and Ryan Martinie), and fusion (e.g., Marcus Miller, Victor Wooten and Alain Caron). Slap style playing was popularized throughout the 1980s and early 1990s by pop bass players such as Mark King (from Level 42) and rock bassists such as with Pino Palladino (currently a member of the John Mayer Trio and bassist for The Who),
Flea (from the Red Hot Chili Peppers) and Alex Katunich (from Incubus). Spank bass developed from the slap and pop style and treats the electric bass as a percussion instrument, striking the strings above the pickups with an open palmed hand. Wooten popularized the "double thump," in which the string is slapped twice, on the upstroke and a downstroke (for more information, see Classical Thump). A rarely used playing technique related to slapping is the use of wooden dowel "funk fingers", an approach popularized by Tony Levin.
Picking techniques.
The pick (or plectrum) is used to obtain a more articulate attack, for speed, or just personal preference. Although the use of a pick is primarily associated with rock and punk rock, picks are also used in other styles. Jazz bassist Steve Swallow often plays with a pick, while Pink Floyd bassist Roger Waters uses one for a heavier tone. Picks can be used with alternating downstrokes and upstrokes, or with all downstrokes for a more consistent attack. The pick is usually held with the index and thumb, with the up-and-down plucking motion supplied by the wrist.
There are many varieties of picks available, but due to the thicker, heavier strings of the electric bass, bassists tend to use heavier picks than those used for electric guitar, typically ranging from 1.14 mm–3.00 mm (3.00 is unusual). Different materials are used for picks, including plastic, nylon, and felt, all of which produce different tones. Felt picks are used to emulate a fingerstyle tone.
Palm-muting techniques.
Palm-muting is a widely used bass technique. The outer edge of the palm of the picking hand is rested on the bridge while picking, and "mutes" the strings, shortening the sustain time. The harder the palm presses, or the more string area that is contacted by the palm, the shorter the string’s sustain. The sustain of the picked note can be varied for each note or phrase. The shorter sustain of a muted note on an electric bass can be used to imitate the shorter sustain and character of an upright bass. Palm-muting is commonly done while using a pick, but can also be done without a pick, as when doing down-strokes with the thumb.
One prominent example of the pick/palm-muting combination is Paul McCartney, who has consistently used this technique for decades. Sting also uses palm-muting; but often does so without a pick, using the thumb and first finger to pluck.
Fretting techniques.
The fretting hand, the left hand for right-handed bass players and the right hand for left-handed bass players, is used to press down the strings to play different notes and shape the tone or timbre of a plucked or picked note. The fundamental technique used in the fretting hand is known as "a finger per fret", where each finger in the fretting hand plays one fret in a given position. Also, the double bass technique can be used for fretting. This technique involves the use of four fingers in the space of three frets, especially in the lower positions. When considering the spacing between notes, this is a comfortable distance for the average person's hand size. The main advantage of the "four fingers in three frets" technique is less tendon strain, leading to a diminished likelihood of Repetitive Strain Injury (RSI). The "four-in-three" technique is demonstrated in the image below (A bassist performing tapping).
The fretting hand can be used to change a sounded note, either by fully muting it after it is plucked or picked to shorten its duration or by partially muting it near the bridge to reduce the volume of the note, or make the note die away faster. The fretting hand is often used to mute strings that are not being played and stop the sympathetic vibrations, particularly when the player wants a "dry" or "focused" sound. On the other hand, the sympathetic resonance of harmonically related strings may be desired for some songs, such as ballads. In these cases, a bassist can fret harmonically related notes. For example, while fretting a sustained "F" (on the third fret of the "D" string), underneath an F major chord being played by a piano player, a bassist might hold down the "C" and low "F" below this note so their harmonics sound sympathetically.
The fretting hand can add vibrato to a plucked or picked note, either a gentle, narrow vibrato or a more exaggerated, wide vibrato with bigger pitch variations. For fretted basses, vibrato is always an alternation between the pitch of the note and a slightly higher pitch. For fretless basses, the player can use this style of vibrato, or they can alternate between the note and a slightly lower pitch. While vibrato is mostly done on "stopped" notes—that is, notes that are pressed down on the fingerboard—open strings can also be vibratoed by pressing down on the string behind the nut. As well, the fretting hand can be used to "bend" a plucked or picked note up in pitch. To create the opposite effect, a "bend down", the string is pushed to a higher pitch before being plucked or picked and then allowed to fall to the lower, regular pitch after it is sounded. Though rare, some bassists may use a tremolo bar-equipped bass to produce the same effect.
In addition to pressing down one note at a time, bassists can also press down several notes at one time with their fretting hand to perform a chord. While chords are used less often by bassists than by electric guitarists, a variety of chords can be performed on the electric bass, especially with instruments with higher ranges such as six-string basses. Another variation to fully pressing down a string is to gently graze the string with the finger at the harmonic node points on the string, which creates chime-like upper partials. Glissando is an effect in which the fretting hand slides up or down the neck. A subtle glissando can be performed by moving the fretting hand without plucking or picking the string; for a more pronounced effect, the string is plucked or picked first, or, in a metal or hardcore punk context, a pick may be scraped along the sides of the strings.
Two-handed tapping.
In the two-handed tapping styles, bassists use both hands to play notes on the fretboard by rapidly pressing and holding the string to the fret. Instead of plucking or picking the string to create a sound, in this technique, the action of striking the string against the fret or the fretboard creates the sound. Since two hands can be used to play on the fretboard, this makes it possible to play interweaving contrapuntal lines, to simultaneously play a bass line and a simple chord, or play chords and arpeggios. Bassist John Entwistle of The Who tapped percussively on the strings, causing them to strike the fretboard with a twangy sound to create drum-style fills. Players noted for this technique include Cliff Burton, Billy Sheehan, Stuart Hamm, John Myung, Victor Wooten, Les Claypool, Mark King and Michael Manring. The Chapman Stick and Warr Guitars are string instruments specifically designed to be played using two-handed tapping.
Uses.
Popular music.
Popular music bands and rock groups use the bass guitar as a member of the rhythm section, which provides the chord sequence or "progression" and sets out the "beat" for the song. The rhythm section typically consists of a rhythm guitarist or electric keyboard player, or both, a bass guitarist and a drummer; larger groups may add additional guitarists, keyboardists, or percussionists.
Bassists often play a bass line composed by an arranger or composer of a song—or, in the case of a cover song, the bass line from the original. In other bands—e.g., jazz-rock bands that play from lead sheets and country bands using the Nashville number system—bassists are expected to improvise or prepare their own part to fit the song's chord progression and rhythmic style.
Types of bass lines vary widely, depending on musical style. However, the bass guitarist generally fulfills a similar role: anchoring the harmonic framework (often by emphasizing the roots of the chord progression) and laying down the beat in collaboration with the drummer. The importance of the bass guitarist and the bass line varies in different styles of music. In some pop styles, such as 1980s-era pop and musical theater, the bass sometimes plays a relatively simple part as the music emphasizes vocals and melody instruments. In contrast, in reggae, funk, or hip-hop, entire songs may center on the bass groove, and the bass line is usually prominent in the mix.
In traditional country music, folk rock, and related styles, the bass often plays the roots and fifth of each chord in alternation. In Chicago blues, the electric bass often performs a walking bassline made up of scales and arpeggios. In blues rock bands, the bassist often plays blues scale-based riffs and chugging boogie-style lines. In metal, the bass guitar may perform complex riffs along with the rhythm guitarist or play a low, rumbling pedal point to anchor the group's sound.
The bass guitarist sometimes breaks out of the strict rhythm section role to perform bass breaks or bass solos. The types of bass lines used for bass breaks or bass solos vary by style. In a rock band, a bass break may consist of the bassist playing a riff or lick during a pause in the song. In some styles of metal, a bass break may consist of "shred guitar"-style tapping on the bass. In a funk or funk rock band, a bass solo may showcase the bassist's percussive slap and pop playing. In genres such as progressive rock, art rock, or progressive metal, the bass guitar player may play melody lines along with the lead guitar (or vocalist) and perform extended guitar solos.
Chords are not used that often by electric bass players. However, in some styles, bassists may sound "double stops", such as octaves with open strings and powerchords. In Latin music, double stops with fifths are used. Robert Trujillo of Metallica is known for playing "massive chords" and "chord-based harmonics" on the bass. Lemmy of Motörhead often plays powerchords in his bass lines. When asked about whether he had begun as a rhythm guitarist, he stated:
No, I play a lot of notes, but I also play a lot of chords. And I play a lot of open strings. I just don't play like a bass player. There are complaints about me from time to time. It's not like having a bass player; it's like having a deep guitarist.
Jazz and jazz fusion.
The electric bass is a relative newcomer to the world of jazz. The big bands of the 1930s and 1940s Swing era and the small combos of the 1950s Bebop and Hard Bop movements all used the double bass. The electric bass was introduced in some bands in the 1950s and it became prominent during the late 1960s and early 1970s, when rock influences were blended with jazz to create jazz-rock fusion.
The introduction of the electric bass in jazz fusion, as in the rock world, helped bassists play in high-volume stadium concerts with powerful amplifiers, because it is easier to amplify the electric bass than the double bass (the latter is prone to feedback in high-volume settings). The electric bass has both an accompaniment and a soloing role in jazz. In accompaniment, the bassist may perform walking basslines for traditional tunes and jazz standards, playing smooth quarter note lines that imitate the double bass. For latin or salsa tunes and rock-infused jazz fusion tunes, the electric bass may play rapid, syncopated rhythmic figures in coordination with the drummer, or lay down a low, heavy groove.
In a jazz setting, the electric bass tends to have a much more expansive solo role than in most popular styles. In most rock settings, the bass guitarist may only have a few short bass breaks or brief solos during a concert. During a jazz concert, a jazz bassist may have a number of lengthy improvised solos, which are called "blowing" in jazz parlance. Whether a jazz bassist is comping (accompanying) or soloing, they usually aim to create a rhythmic drive and "timefeel" that creates a sense of "swing" and "groove". For information on notable jazz bassists, see the List of jazz bassists article.
Contemporary classical music.
Contemporary classical music uses both the standard instruments of Western Art music (piano, violin, double bass, etc.) and newer instruments or sound producing devices, ranging from electrically amplified instruments to tape players and radios. The electric bass guitar has occasionally been used in contemporary classical music (art music) since the late 1960s.
Contemporary composers often obtained unusual sounds or instrumental timbres through the use of non-traditional (or unconventional) instruments or playing techniques. As such, bass guitarists playing contemporary classical music may be instructed to pluck or strum the instrument in unusual ways.
American composers using electric bass in the 1960s included experimental classical music composer Christian Wolff (born 1934) ("Electric Spring 1", 1966; "Electric Spring 2", 1966/70; "Electric Spring 3", 1967; and "Untitled", 1996); Francis Thorne, a student of Paul Hindemith at Yale University (born 1922), who wrote ("Liebesrock" 1968–69); and Krzysztof Penderecki (Cello Concerto no. 1, 1966/67, rev. 1971/72), "The Devils of Loudun", 1969; "Kosmogonia", 1970; and "Partita", 1971), Louis Andriessen ("Spektakel", 1970; "De Staat", 1972–76; "Hoketus", 1976; "De Tijd", 1980–81 and "De Materie", 1984–1988). European composers who began scoring for the bass guitar in the 1960s included Danish composer Pelle Gudmundsen-Holmgreen (born 1932) ("Symfoni på Rygmarven", 1966; "Rerepriser", 1967; and "Piece by Piece", 1968); Irwin Bazelon ("Churchill Downs", 1970).
In the 1970s, electric bass was used by the American conductor-composer Leonard Bernstein (1918–1990) for his "MASS" (1971). American jazz pianist Dave Brubeck used bass guitar for his 1971 piece "Truth Has Fallen". Russian and Soviet composer Alfred Schnittke used the instrument for his Symphony no. 1, 1972. In 1977, David Amram (born 1930) scored for electric bass in "En memoria de Chano Pozo". Amram is an American composer known for his eclectic use of jazz, ethnic and folk music.
In the 1980s and 1990s, electric bass was used in works by Hans Werner Henze ("El Rey de Harlem", 1980; and "Il ritorno d'Ulisse in patria", 1981), Harold Shapero, "On Green Mountain (Chaconne after Monteverdi)", 1957, orchestrated 1981; Steve Reich's "Electric Counterpoint" (1987), Wolfgang Rihm ("Die Eroberung von Mexico", 1987–91), Arvo Pärt ("Miserere", 1989/92), Steve Martland ("Danceworks", 1993; and "Horses of Instruction", 1994), Sofia Gubaidulina ("Aus dem Stundenbuch", 1991), Giya Kancheli ("Wingless", 1993), John Adams ("I Was Looking at the Ceiling and Then I Saw the Sky", 1995; and "Scratchband", 1996/97), and Michael Nyman (various works for the Michael Nyman Band).
Pedagogy and training.
The pedagogy and training for the electric bass varies widely by genre and country. Rock and pop bass has a history of pedagogy dating back to the 1950s and 1960s, when method books were developed to help students learn the instrument. One notable method book was Carol Kaye's "How to Play the Electric Bass".
In the jazz scene, since the bass guitar takes on much of the same role as the double bass—laying down the rhythm, and outlining the harmonic foundation—electric bass players have long used both bass guitar methods and jazz double bass method books. The use of jazz double bass method books by electric bass players in jazz is facilitated in that jazz methods tend to emphasize improvisation techniques (e.g., how to improvise walking basslines) and rhythmic exercises rather than specific ways of holding or plucking the instrument.
Formal training.
Of all of the genres, jazz and the mainstream commercial genres (rock, R&B, etc.) have the most established and comprehensive systems of instruction and training for electric bass. In the jazz scene, teens can begin taking private lessons on the instrument and performing in amateur big bands at high schools or run by the community. Young adults who aspire to becoming professional jazz bassists or studio rock bassists can continue their studies in a variety of formal training settings, including colleges and some universities.
Several colleges offer electric bass training in the US. The Bass Institute of Technology (BIT) in Los Angeles was founded in 1978, as part of the Musician's Institute. Chuck Rainey (electric bassist for Aretha Franklin and Marvin Gaye) was BIT's first director. BIT was one of the earliest professional training program for electric bassists. The program teaches a range of modern styles, including funk, rock, jazz, Latin, and R&B.
The Berklee College of Music in Boston offers training for electric bass players. Electric bass students get private lessons and there is a choice of over 270 ensembles to play in. Specific electric bass courses include funk/fusion styles for bass; slap techniques for electric bass; fingerstyle R&B; five- and six-string electric bass playing (including performing chords); and how to read bass sheet music. Berklee College alumni include Jeff Andrews, Victor Bailey, Jeff Berlin, Michael Manring, and Neil Stubenhaus. The Bass Department has two rooms with bass amps for classes and ten private lesson studios equipped with audio recording gear. Berklee offers instruction for the four-, five-, and six-string electric bass, the fretless bass, and double bass. "Students learn concepts in Latin, funk, Motown, and hip-hop...jazz, rock, and fusion."
In Canada, the Humber College Institute of Technology & Advanced Learning offers an Advanced Diploma (a three-year program) in jazz and commercial music. The program accepts performers who play bass, guitar, keyboard, drums, melody instruments (e.g., saxophone, flute, violin) and who sing. Students get private lessons and perform in 40 student ensembles.
Although there are far fewer university programs that offer electric bass instruction in jazz and popular music, some universities offer Bachelor's degrees (B.Mus.) and Master of Music (M.Mus.) degrees in jazz performance or "commercial music", where electric bass can be the main instrument. In the US, the Manhattan School of Music has a jazz program leading to B.Mus. and M.Mus degrees that accepts students who play bass (double bass and electric bass), guitar, piano, drums, and melody instruments (e.g., saxophone, trumpet, etc.).
In the Australian state of Victoria, the Victorian Curriculum and Assessment Authority has set out minimum standards for its electric bass students doing their end-of-year Solo performance recital. To graduate, students must perform pieces and songs from a set list that includes Baroque suite movements that were originally written for cello, 1960s Motown tunes, 1970s fusion jazz solos, and 1980s slap bass tunes. A typical program may include a Prelude by J.S. Bach; "Portrait of Tracy" by Jaco Pastorius; "Twisted" by Wardell Gray and Annie Ross; "What’s Going On" by James Jamerson; and the funky Disco hit "Le Freak" by Chic.
In addition to college and university diplomas and degrees, there are a variety of other training programs such as jazz or funk summer camps and festivals, which give students the opportunity to play a wide range of contemporary music, from 1970s-style jazz-rock fusion to 2000s-style R&B.
Informal training.
In other less mainstream genres, such as hardcore punk or metal, the pedagogical systems and training sequences are typically not formalized and institutionalized. As such, many players learn "by ear", by copying bass lines from records and CDs, and by playing in a number of bands. Even in non-mainstream styles, though, students may be able to take lessons from experts in these or other styles, adapting learned techniques to their own style. As well, there are a range of books, playing methods, and, since the 1990s, instructional DVDs (e.g., how to play metal bass).

</doc>
<doc id="3921" url="http://en.wikipedia.org/wiki?curid=3921" title="Basketball">
Basketball

Basketball is a sport played by two teams of five players on a rectangular court. The objective is to shoot a ball through a hoop in diameter and high mounted to a backboard at each end. Basketball is one of the world's most popular and widely viewed sports.
A team can score a field goal by shooting the ball through the basket during regular play. A field goal scores two points for the shooting team if a player is touching or closer to the basket than the three-point line, and three points (known commonly as a "3 pointer" or "three") if the player is behind the three-point line. The team with the most points at the end of the game wins, but additional time (overtime) may be issued when the game ends with a draw. The ball can be advanced on the court by bouncing it while walking or running or throwing it to a team mate. It is a violation to move without dribbling the ball, to carry it, or to hold the ball with both hands then resume dribbling.
Violations are called "fouls". A personal foul is penalized, and a free throw is usually awarded to an offensive player if he is fouled while shooting the ball. A technical foul may also be issued when certain infractions occur, most commonly for unsportsmanlike conduct on the part of a player or coach. A technical foul gives the opposing team a free throw, and the opposing team also retains possession of the ball.
As well as many techniques for shooting, passing, dribbling and rebounding, basketball has specialized player positions and offensive and defensive structures (player positioning). Typically, the tallest and strongest members of a team will play the center or power forward positions, while slightly shorter and more agile players will play small forward, and the shortest players or those who possess the best ball handling skills and speed play point guard or shooting guard.
History.
Creation.
In early December 1891, Canadian Dr. James Naismith, a physical education professor and instructor at the International Young Men's Christian Association Training School (YMCA) (today, Springfield College) in Springfield, Massachusetts was trying to keep his gym class active on a rainy day. He sought a vigorous indoor game to keep his students occupied and at proper levels of fitness during the long New England winters. After rejecting other ideas as either too rough or poorly suited to walled-in gymnasiums, he wrote the basic rules and nailed a peach basket onto a 10-foot (3.05 m) elevated track. In contrast with modern basketball nets, this peach basket retained its bottom, and balls had to be retrieved manually after each "basket" or point scored; this proved inefficient, however, so the bottom of the basket was removed, allowing the balls to be poked out with a long dowel each time.
Basketball was originally played with a soccer ball. The first balls made specifically for basketball were brown, and it was only in the late 1950s that Tony Hinkle, searching for a ball that would be more visible to players and spectators alike, introduced the orange ball that is now in common use. Dribbling was not part of the original game except for the "bounce pass" to teammates. Passing the ball was the primary means of ball movement. Dribbling was eventually introduced but limited by the asymmetric shape of early balls. Dribbling only became a major part of the game around the 1950s, as manufacturing improved the ball shape.
The peach baskets were used until 1906 when they were finally replaced by metal hoops with backboards. A further change was soon made, so the ball merely passed through. Whenever a person got the ball in the basket, his team would gain a point. Whichever team got the most points won the game. The baskets were originally nailed to the mezzanine balcony of the playing court, but this proved impractical when spectators on the balcony began to interfere with shots. The backboard was introduced to prevent this interference; it had the additional effect of allowing rebound shots. Naismith's handwritten diaries, discovered by his granddaughter in early 2006, indicate that he was nervous about the new game he had invented, which incorporated rules from a children's game called "Duck on a Rock", as many had failed before it. Naismith called the new game "Basket Ball". The first official game was played in the YMCA gymnasium in Albany, New York on January 20, 1892 with nine players. The game ended at 1–0; the shot was made from , on a court just half the size of a present-day Streetball or National Basketball Association (NBA) court. By 1897–1898 teams of five became standard.
College basketball.
Basketball's early adherents were dispatched to YMCAs throughout the United States, and it quickly spread through the USA and Canada. By 1895, it was well established at several women's high schools. While the YMCA was responsible for initially developing and spreading the game, within a decade it discouraged the new sport, as rough play and rowdy crowds began to detract from the YMCA's primary mission. However, other amateur sports clubs, colleges, and professional clubs quickly filled the void. In the years before World War I, the Amateur Athletic Union and the Intercollegiate Athletic Association of the United States (forerunner of the NCAA) vied for control over the rules for the game. The first pro league, the National Basketball League, was formed in 1898 to protect players from exploitation and to promote a less rough game. This league only lasted five years.
Dr. James Naismith was instrumental in establishing college basketball. His colleague C.O. Beamis fielded the first college basketball team just a year after the Springfield YMCA game at the suburban Pittsburgh Geneva College. Naismith himself later coached at the University of Kansas for six years, before handing the reins to renowned coach Forrest "Phog" Allen. Naismith's disciple Amos Alonzo Stagg brought basketball to the University of Chicago, while Adolph Rupp, a student of Naismith's at Kansas, enjoyed great success as coach at the University of Kentucky. On February 9, 1895, the first intercollegiate 5-on-5 game was played at Hamline University between Hamline and the School of Agriculture, which was affiliated with the University of Minnesota. The School of Agriculture won in a 9–3 game.
In 1901, colleges, including the University of Chicago, Columbia University, Dartmouth College, the University of Minnesota, the U.S. Naval Academy, the University of Colorado and Yale University began sponsoring men's games. In 1905, frequent injuries on the football field prompted President Theodore Roosevelt to suggest that colleges form a governing body, resulting in the creation of the Intercollegiate Athletic Association of the United States (IAAUS). In 1910, that body would change its name to the National Collegiate Athletic Association (NCAA). The first Canadian interuniversity basketball game was played at the YMCA in Kingston, Ontario on February 6, 1904, when McGill University visited Queen's University. McGill won 9–7 in overtime; the score was 7–7 at the end of regulation play, and a ten-minute overtime period settled the outcome. A good turnout of spectators watched the game.
The first men's national championship tournament, the National Association of Intercollegiate Basketball tournament, which still exists as the National Association of Intercollegiate Athletics (NAIA) tournament, was organized in 1937. The first national championship for NCAA teams, the National Invitation Tournament (NIT) in New York, was organized in 1938; the NCAA national tournament would begin one year later. College basketball was rocked by gambling scandals from 1948 to 1951, when dozens of players from top teams were implicated in match fixing and point shaving. Partially spurred by an association with cheating, the NIT lost support to the NCAA tournament.
High school basketball.
Before widespread school district consolidation, most American high schools were far smaller than their present-day counterparts. During the first decades of the 20th century, basketball quickly became the ideal interscholastic sport due to its modest equipment and personnel requirements. In the days before widespread television coverage of professional and college sports, the popularity of high school basketball was unrivaled in many parts of America. Perhaps the most legendary of high school teams was Indiana's Franklin Wonder Five, which took the nation by storm during the 1920s, dominating Indiana basketball and earning national recognition.
Today virtually every high school in the United States fields a basketball team in varsity competition. Basketball's popularity remains high, both in rural areas where they carry the identification of the entire community, as well as at some larger schools known for their basketball teams where many players go on to participate at higher levels of competition after graduation. In the 2003–04 season, 1,002,797 boys and girls represented their schools in interscholastic basketball competition, according to the National Federation of State High School Associations. The states of Illinois, Indiana and Kentucky are particularly well known for their residents' devotion to high school basketball, commonly called Hoosier Hysteria in Indiana; the critically acclaimed film "Hoosiers" shows high school basketball's depth of meaning to these communities.
There is currently no national tournament to determine a national high school champion. The most serious effort was the National Interscholastic Basketball Tournament at the University of Chicago from 1917 to 1930. The event was organized by Amos Alonzo Stagg and sent invitations to state champion teams. The tournament started out as a mostly Midwest affair but grew. In 1929 it had 29 state champions. Faced with opposition from the National Federation of State High School Associations and North Central Association of Colleges and Schools that bore a threat of the schools losing their accreditation the last tournament was in 1930. The organizations said they were concerned that the tournament was being used to recruit professional players from the prep ranks. The tournament did not invite minority schools or private/parochial schools.
The National Catholic Interscholastic Basketball Tournament ran from 1924 to 1941 at Loyola University. The National Catholic Invitational Basketball Tournament from 1954 to 1978 played at a series of venues, including Catholic University, Georgetown and George Mason. The National Interscholastic Basketball Tournament for Black High Schools was held from 1929 to 1942 at Hampton Institute. The National Invitational Interscholastic Basketball Tournament was held from 1941 to 1967 starting out at Tuskegee Institute. Following a pause during World War II it resumed at Tennessee State College in Nashville. The basis for the champion dwindled after 1954 when "Brown v. Board of Education" began an integration of schools. The last tournaments were held at Alabama State College from 1964 to 1967.
Professional basketball.
Teams abounded throughout the 1920s. There were hundreds of men's professional basketball teams in towns and cities all over the United States, and little organization of the professional game. Players jumped from team to team and teams played in armories and smoky dance halls. Leagues came and went. Barnstorming squads such as the Original Celtics and two all-African American teams, the New York Renaissance Five ("Rens") and the (still existing) Harlem Globetrotters played up to two hundred games a year on their national tours.
In 1946, the Basketball Association of America (BAA) was formed. The first game was played in Toronto, Ontario, Canada between the Toronto Huskies and New York Knickerbockers on November 1, 1946. Three seasons later, in 1949, the BAA merged with the National Basketball League to form the National Basketball Association (NBA). By the 1950s, basketball had become a major college sport, thus paving the way for a growth of interest in professional basketball. In 1959, a basketball hall of fame was founded in Springfield, Massachusetts, site of the first game. Its rosters include the names of great players, coaches, referees and people who have contributed significantly to the development of the game. The hall of fame has people who have accomplished many goals in their career in basketball. An upstart organization, the American Basketball Association, emerged in 1967 and briefly threatened the NBA's dominance until the ABA-NBA merger in 1976. Today the NBA is the top professional basketball league in the world in terms of popularity, salaries, talent, and level of competition.
The NBA has featured many famous players, including George Mikan, the first dominating "big man"; ball-handling wizard Bob Cousy and defensive genius Bill Russell of the Boston Celtics; Wilt Chamberlain, who originally played for the barnstorming Harlem Globetrotters; all-around stars Oscar Robertson and Jerry West; more recent big men Kareem Abdul-Jabbar, Shaquille O'Neal and Karl Malone; playmaker John Stockton; crowd-pleasing forward Julius Erving; European stars Dirk Nowitzki and Dražen Petrović and the three players who many credit with ushering the professional game to its highest level of popularity: Larry Bird, Earvin "Magic" Johnson, and Michael Jordan. In 2001, the NBA formed a developmental league, the NBDL. As of 2012, the league has 16 teams.
International basketball.
The International Basketball Federation was formed in 1932 by eight founding nations: Argentina, Czechoslovakia, Greece, Italy, Latvia, Portugal, Romania and Switzerland. At this time, the organization only oversaw amateur players. Its acronym, derived from the French "Fédération Internationale de Basketball Amateur", was thus "FIBA". Men's Basketball was first included at the Berlin 1936 Summer Olympics, although a demonstration tournament was held in 1904. The United States defeated Canada in the first final, played outdoors. This competition has usually been dominated by the United States, whose team has won all but three titles, the first loss in a controversial final game in Munich in 1972 against the Soviet Union. In 1950 the first FIBA World Championship for men was held in Argentina. Three years later, the first FIBA World Championship for Women was held in Chile. Women's basketball was added to the Olympics in 1976, which were held in Montreal, Canada with teams such as the Soviet Union, Brazil and Australia rivaling the American squads.
FIBA dropped the distinction between amateur and professional players in 1989, and in 1992, professional players played for the first time in the Olympic Games. The United States' dominance continued with the introduction of their Dream Team. However, with developing programs elsewhere, other national teams started to beat the United States. A team made entirely of NBA players finished sixth in the 2002 World Championships in Indianapolis, behind Yugoslavia, Argentina, Germany, New Zealand and Spain. In the 2004 Athens Olympics, the United States suffered its first Olympic loss while using professional players, falling to Puerto Rico (in a 19-point loss) and Lithuania in group games, and being eliminated in the semifinals by Argentina. It eventually won the bronze medal defeating Lithuania, finishing behind Argentina and Italy. In 2006, in the World Championship of Japan, the United States advanced to the semifinals but were defeated by Greece by 101–95. In the bronze medal game it beat team Argentina and finished 3rd behind Greece and Spain. After the disappointments of 2002 through 2006, the U.S. regrouped, reestablishing themselves as the dominant international team behind the "Redeem Team", which won gold at the 2008 Olympics, and the so-called "B-Team", which won gold at the 2010 FIBA World Championship in Turkey despite featuring no players from the 2008 squad.
The all-tournament teams at the 2002 and 2006 FIBA World Championships, respectively held in Indianapolis and Japan, demonstrate the globalization of the game equally dramatically. Only one member of either team was American, namely Carmelo Anthony in 2006. The 2002 team featured Nowitzki, Ginobili, Yao, Peja Stojakovic of Yugoslavia (now of Serbia), and Pero Cameron of New Zealand. Ginobili also made the 2006 team; the other members were Anthony, Gasol, his Spanish teammate Jorge Garbajosa and Theodoros Papaloukas of Greece. The only players on either team to never have joined the NBA are Cameron and Papaloukas. The all-tournament team from the 2010 edition in Turkey featured four NBA players—MVP Kevin Durant of Team USA and the Oklahoma City Thunder, Linas Kleiza of Lithuania and the Toronto Raptors, Luis Scola of Argentina and the Houston Rockets, and Hedo Türkoğlu of Turkey and the Phoenix Suns. The only non-NBA player was Serbia's Miloš Teodosić. The strength of international Basketball is evident in the fact that Team USA won none of the three world championships held between 1998 and 2006, with Serbia (then known as Yugoslavia) winning in 1998 and 2002 and Spain in 2006.
Worldwide, basketball tournaments are held for boys and girls of all age levels. The global popularity of the sport is reflected in the nationalities represented in the NBA. Players from all six inhabited continents currently play in the NBA. Top international players began coming into the NBA in the mid-1990s, including Croatians Dražen Petrović and Toni Kukoč, Serbian Vlade Divac, Lithuanians Arvydas Sabonis and Šarūnas Marčiulionis and German Detlef Schrempf.
In the Philippines, the Philippine Basketball Association's first game was played on April 9, 1975 at the Araneta Coliseum in Cubao, Quezon City. Philippines. It was founded as a "rebellion" of several teams from the now-defunct Manila Industrial and Commercial Athletic Association which was tightly controlled by the Basketball Association of the Philippines (now defunct), the then-FIBA recognized national association. Nine teams from the MICAA participated in the league's first season that opened on April 9, 1975. The NBL is Australia's pre-eminent men's professional basketball league. The league commenced in 1979, playing a winter season (April–September) and did so until the completion of the 20th season in 1998. The 1998/99 season, which commenced only months later, was the first season after the shift to the current summer season format (October–April). This shift was an attempt to avoid competing directly against Australia's various football codes. It features 8 teams from around Australia and one in New Zealand. A few players including Luc Longley, Andrew Gaze, Shane Heal, Chris Anstey and Andrew Bogut made it big internationally, becoming poster figures for the sport in Australia. The Women's National Basketball League began in 1981.
Women's basketball.
Women's basketball began in 1892 at Smith College when Senda Berenson, a physical education teacher, modified Naismith's rules for women. Shortly after she was hired at Smith, she went to Naismith to learn more about the game. Fascinated by the new sport and the values it could teach, she organized the first women’s collegiate basketball game on March 21, 1893, when her Smith freshmen and sophomores played against one another. However, the first women's interinstitutional game was played in 1892 between the University of California and Miss Head's School. Berenson's rules were first published in 1899, and two years later she became the editor of A.G. Spalding’s first Women's Basketball Guide. Berenson's freshmen played the sophomore class in the first women's intercollegiate basketball game at Smith College, March 21, 1893. The same year, Mount Holyoke and Sophie Newcomb College (coached by Clara Gregory Baer) women began playing basketball. By 1895, the game had spread to colleges across the country, including Wellesley, Vassar, and Bryn Mawr. The first intercollegiate women's game was on April 4, 1896. Stanford women played Berkeley, 9-on-9, ending in a 2–1 Stanford victory.
Women's basketball development was more structured than that for men in the early years. In 1905, the Executive Committee on Basket Ball Rules (National Women's Basketball Committee) was created by the American Physical Education Association. These rules called for six to nine players per team and 11 officials. The International Women's Sports Federation (1924) included a women's basketball competition. 37 women's high school varsity basketball or state tournaments were held by 1925. And in 1926, the Amateur Athletic Union backed the first national women's basketball championship, complete with men's rules. The Edmonton Grads, a touring Canadian women's team based in Edmonton, Alberta, operated between 1915 and 1940. The Grads toured all over North America, and were exceptionally successful. They posted a record of 522 wins and only 20 losses over that span, as they met any team which wanted to challenge them, funding their tours from gate receipts. The Grads also shone on several exhibition trips to Europe, and won four consecutive exhibition Olympics tournaments, in 1924, 1928, 1932, and 1936; however, women's basketball was not an official Olympic sport until 1976. The Grads' players were unpaid, and had to remain single. The Grads' style focused on team play, without overly emphasizing skills of individual players. The first women's AAU All-America team was chosen in 1929. Women's industrial leagues sprang up throughout the United States, producing famous athletes, including Babe Didrikson of the Golden Cyclones, and the All American Red Heads Team, which competed against men's teams, using men's rules. By 1938, the women's national championship changed from a three-court game to two-court game with six players per team.
The NBA-backed Women's National Basketball Association (WNBA) began in 1997. Though it had shaky attendance figures, several marquee players (Lisa Leslie, Diana Taurasi, and Candace Parker among others) have helped the league's popularity and level of competition. Other professional women's basketball leagues in the United States, such as the American Basketball League (1996-1998), have folded in part because of the popularity of the WNBA. The WNBA has been looked at by many as a niche league. However, the league has recently taken steps forward. In June 2007, the WNBA signed a contract extension with ESPN. The new television deal runs from 2009 to 2016. Along with this deal, came the first ever rights fees to be paid to a women's professional sports league. Over the eight years of the contract, "millions and millions of dollars" will be "dispersed to the league's teams." The WNBA gets more viewers on national television broadcasts (413,000) than both Major League Soccer (253,000) and the NHL (310,732). In a March 12, 2009 article, NBA commissioner David Stern said that in the bad economy, "the NBA is far less profitable than the WNBA. We're losing a lot of money amongst a large number of teams. We're budgeting the WNBA to break even this year."
Rules and regulations.
Measurements and time limits discussed in this section often vary among tournaments and organizations; international and NBA rules are used in this section.
The object of the game is to outscore one's opponents by throwing the ball through the opponents' basket from above while preventing the opponents from doing so on their own. An attempt to score in this way is called a shot. A successful shot is worth two points, or three points if it is taken from beyond the three-point arc which is from the basket in international games and in NBA games. A one-point shot can be earned when shooting from the foul line after a foul is made.
Playing regulations.
Games are played in four quarters of 10 (FIBA) or 12 minutes (NBA). College games use two 20-minute halves, while United States high school varsity games use 8 minute quarters. 15 minutes are allowed for a half-time break under FIBA, NBA, and NCAA rules and 10 minutes in United States high schools. Overtime periods are five minutes in length except for high school which is four minutes in length. Teams exchange baskets for the second half. The time allowed is actual playing time; the clock is stopped while the play is not active. Therefore, games generally take much longer to complete than the allotted game time, typically about two hours.
Five players from each team may be on the court at one time. Substitutions are unlimited but can only be done when play is stopped. Teams also have a coach, who oversees the development and strategies of the team, and other team personnel such as assistant coaches, managers, statisticians, doctors and trainers.
For both men's and women's teams, a standard uniform consists of a pair of shorts and a jersey with a clearly visible number, unique within the team, printed on both the front and back. Players wear high-top sneakers that provide extra ankle support. Typically, team names, players' names and, outside of North America, sponsors are printed on the uniforms.
A limited number of time-outs, clock stoppages requested by a coach (or sometimes mandated in the NBA) for a short meeting with the players, are allowed. They generally last no longer than one minute (100 seconds in the NBA) unless, for televised games, a commercial break is needed.
The game is controlled by the officials consisting of the referee (referred to as crew chief in the NBA), one or two umpires (referred to as referees in the NBA) and the table officials. For college, the NBA, and many high schools, there are a total of three referees on the court. The table officials are responsible for keeping track of each teams scoring, timekeeping, individual and team fouls, player substitutions, team possession arrow, and the shot clock.
Equipment.
The only essential equipment in a basketball game is the ball and the court: a flat, rectangular surface with baskets at opposite ends. Competitive levels require the use of more equipment such as clocks, score sheets, scoreboard(s), alternating possession arrows, and whistle-operated stop-clock systems.
A regulation basketball court in international games is 91.9 feet long and 49.2 feet wide. In the NBA and NCAA the court is 94 feet by 50 feet. Most courts have wood flooring, usually constructed from maple planks running in the same direction as the longer court dimension. The name and logo of the home team is usually painted on or around the center circle.
The basket is a steel rim 18 inches diameter with an attached net affixed to a backboard that measures 6 feet by 3.5 feet and one basket is at each end of the court. The white outlined box on the backboard is 18 inches high and 2 feet wide. At almost all levels of competition, the top of the rim is exactly 10 feet above the court and 4 feet inside the baseline. While variation is possible in the dimensions of the court and backboard, it is considered important for the basket to be of the correct height – a rim that is off by just a few inches can have an adverse effect on shooting.
The size of the basketball is also regulated. For men, the official ball is 29.5 inches in circumference (size 7, or a "295 ball") and weighs 22 oz. If women are playing, the official basketball size is 28.5 inches in circumference (size 6, or a "285 ball") with a weight of 20 oz.
Violations.
The ball may be advanced toward the basket by being shot, passed between players, thrown, tapped, rolled or dribbled (bouncing the ball while running).
The ball must stay within the court; the last team to touch the ball before it travels out of bounds forfeits possession. The ball is out of bounds if it touches or crosses over a boundary line, or touches a player who is out of bounds. This is in contrast to other sports such as football, volleyball, and tennis (but not rugby or American football) where the ball (or player) is still considered in if any part of it is touching a boundary line.
The ball-handler may not step with both feet without dribbling, an infraction known as traveling, nor dribble with both hands or hold the ball and resume dribbling, a violation called double dribbling. Any part of the player's hand cannot be directly under the ball while dribbling; doing so is known as carrying the ball. A team, once having established ball control in the front half of their court, may not return the ball to the backcourt and be the first to touch it. The ball may not be kicked, nor be struck with the fist. A violation of these rules results in loss of possession, or, if committed by the defense, a reset of the shot clock (with some exceptions in the NBA).
There are limits imposed on the time taken before progressing the ball past halfway (8 seconds in FIBA and the NBA; 10 seconds in NCAA men's play and high school for both sexes, but no limit in NCAA women's play), before attempting a shot (24 seconds in FIBA and the NBA, 30 seconds in NCAA women's and Canadian Interuniversity Sport play for both sexes, and 35 seconds in NCAA men's play), holding the ball while closely guarded (5 seconds), and remaining in the restricted area known as the free-throw lane, (or the "key") (3 seconds). These rules are designed to promote more offense.
No player may touch the ball on its downward trajectory to the basket, unless it is obvious that the ball has no chance of entering the basket (goaltending). In addition, no player may touch the ball while it is on or in the basket; when any part of the ball is in the spacious cylinder above the basket (the area extended upwards from the basket); or when the ball is outside the cylinder, if the player reaches through the basket and touches it. This violation is known as "basket interference". If a defensive player goaltends or commits basket interference, the basket is awarded and the offending team gets the ball. If a teammate of the player shooting goaltends or commits interference, the basket is cancelled and play continues with the defensive team being given possession.
Fouls.
An attempt to unfairly disadvantage an opponent through physical contact is illegal and is called a foul. These are most commonly committed by defensive players; however, they can be committed by offensive players as well. Players who are fouled either receive the ball to pass inbounds again, or receive one or more free throws if they are fouled in the act of shooting, depending on whether the shot was successful. One point is awarded for making a free throw, which is attempted from a line from the basket.
The referee may use discretion in calling fouls (for example, by considering whether an unfair advantage was gained), sometimes making fouls controversial calls or no-calls. The calling of fouls can vary between games, leagues and even among referees.
A player or coach who shows poor sportsmanship, such as by arguing with a referee or by fighting with another player, can be charged with a more serious foul called a technical foul. The penalty involves free throws (where, unlike a personal foul, the other team can choose any player to shoot) and varies among leagues. Repeated incidents can result in disqualification. A blatant foul involving physical contact that is either excessive or unnecessary is called an intentional foul (flagrant foul in the NBA). In FIBA, a foul resulting in ejection is called a disqualifying foul, while in leagues other than the NBA, such a foul is referred to as flagrant.
If a team exceeds a certain limit of team fouls in a given period (quarter or half) – four for NBA and international games – the opposing team is awarded one or two free throws on all subsequent non-shooting fouls for that period, the number depending on the league. In the US college and high school games, if a team reaches 7 fouls in a half, the opposing team is awarded one free throw, along with a second shot if the first is made. This is called shooting "one-and-one". If a team exceeds 10 fouls in the half, the opposing team is awarded two free throws on all subsequent fouls for the half.
When a team shoots foul shots, the opponents may not interfere with the shooter, nor may they try to regain possession until the last or potentially last free throw is in the air.
After a team has committed a specified number of fouls, it is said to be "in the penalty". On scoreboards, this is usually signified with an indicator light reading "Bonus" or "Penalty" with an illuminated directional arrow indicating that team is to receive free throws when fouled by the opposing team. (Some scoreboards also indicate the number of fouls committed.)
If a team misses the first shot of a two-shot situation, the opposing team must wait for the completion of the second shot before attempting to reclaim possession of the ball and continuing play.
If a player is fouled while attempting a shot and the shot is unsuccessful, the player is awarded a number of free throws equal to the value of the attempted shot. A player fouled while attempting a regular two-point shot, then, receives two shots. A player fouled while attempting a three-point shot, on the other hand, receives three shots.
If a player is fouled while attempting a shot and the shot is successful, typically the player
will be awarded one additional free throw for one point. In combination with a regular
shot, this is called a "three-point play" or "four-point play" (or more colloquially, an "and one") because of the basket made at the time of the foul (2 or 3 points) and the additional free throw (1 point).
Common techniques and practices.
Positions.
Although the rules do not specify any positions whatsoever, they have evolved as part of basketball. During the first five decades of basketball's evolution, one guard, two forwards, and two centers or two guards, two forwards, and one center were used. Since the 1980s, more specific positions have evolved, namely:
Point guard (often called the "1") : usually the fastest player on the team, organizes the team's offense by controlling the ball and making sure that it gets to the right player at the right time.
Shooting guard (the "2") : creates a high volume of shots on offense, mainly long-ranged; and guards the opponent's best perimeter player on defense.
Small forward (the "3") : often primarily responsible for scoring points via cuts to the basket and dribble penetration; on defense seeks rebounds and steals, but sometimes plays more actively.
Power forward (the "4"): plays offensively often with their back to the basket; on defense, plays under the basket (in a zone defense) or against the opposing power forward (in man-to-man defense).
Center (the "5"): uses height and size to score (on offense), to protect the basket closely (on defense), or to rebound.
The above descriptions are flexible. On some occasions, teams will choose to use a "three guard offense", replacing one of the forwards or center with a third guard.
Strategy.
There are two main defensive strategies: "zone defense" and "man-to-man defense". In a zone defense, each player is assigned to guard a specific area of the court. In a man-to-man defense, each defensive player guards a specific opponent. Man-to-man defense is generally preferred at higher levels of competition, as it is intuitively easier to understand and avoid mismatches between players who play different positions. However, zone defenses are sometimes used in particular situations or simply to confuse the offense with an unexpected look.
Offensive plays are more varied, normally involving planned passes and movement by players without the ball. A quick movement by an offensive player without the ball to gain an advantageous position is known as a "cut". A legal attempt by an offensive player to stop an opponent from guarding a teammate, by standing in the defender's way such that the teammate cuts next to him, is a "screen" or "pick". The two plays are combined in the "pick and roll", in which a player sets a pick and then "rolls" away from the pick towards the basket. Screens and cuts are very important in offensive plays; these allow the quick passes and teamwork which can lead to a successful basket. Teams almost always have several offensive plays planned to ensure their movement is not predictable. On court, the point guard is usually responsible for indicating which play will occur.
Defensive and offensive structures, and positions, are more emphasized in higher levels in basketball; it is these that a coach normally requests a time-out to discuss.
Shooting.
Shooting is the act of attempting to score points by throwing the ball through the basket, methods varying with players and situations.
Typically, a player faces the basket with both feet facing the basket. A player will rest the ball on the fingertips of the dominant hand (the shooting arm) slightly above the head, with the other hand supporting the side of the ball. The ball is usually shot by jumping (though not always) and extending the shooting arm. The shooting arm, fully extended with the wrist fully bent, is held stationary for a moment following the release of the ball, known as a "follow-through". Players often try to put a steady backspin on the ball to absorb its impact with the rim. The ideal trajectory of the shot is somewhat controversial, but generally a proper arc is recommended. Players may shoot directly into the basket or may use the backboard to redirect the ball into the basket.
The two most common shots that use the above described setup are the "set-shot" and the "jump-shot". The set-shot is taken from a standing position, with neither foot leaving the floor, typically used for free throws, and in other circumstances whilst the jump-shot is taken in mid-air, the ball released near the top of the jump. This provides much greater power and range, and it also allows the player to elevate over the defender. Failure to release the ball before the feet return to the floor is considered a traveling violation.
Another common shot is called the "lay-up". This shot requires the player to be in motion toward the basket, and to "lay" the ball "up" and into the basket, typically off the backboard (the backboard-free, underhand version is called a "finger roll"). The most crowd-pleasing and typically highest-percentage accuracy shot is the "slam dunk", in which the player jumps very high and throws the ball downward, through the basket whilst touching it.
Another shot that is becoming common is the "circus shot". The circus shot is a low-percentage shot that is flipped, heaved, scooped, or flung toward the hoop while the shooter is off-balance, airborne, falling down, and/or facing away from the basket. A back-shot is a shot taken when the player is facing away from the basket, and may be shot with the dominant hand, or both; but there is a very low chance that the shot will be successful.
A shot that misses both the rim and the backboard completely is referred to as an "air-ball". A particularly bad shot, or one that only hits the backboard, is jocularly called a brick.
Rebounding.
The objective of rebounding is to successfully gain possession of the basketball after a missed field goal or free throw, as it rebounds from the hoop or backboard. This plays a major role in the game, as most possessions end when a team misses a shot. There are two categories of rebounds: offensive rebounds, in which the ball is recovered by the offensive side and does not change possession, and defensive rebounds, in which the defending team gains possession of the loose ball. The majority of rebounds are defensive, as the team on defense tends to be in better position to recover missed shots.
Passing.
A pass is a method of moving the ball between players. Most passes are accompanied by a step forward to increase power and are followed through with the hands to ensure accuracy.
A staple pass is the "chest pass". The ball is passed directly from the passer's chest to the receiver's chest. A proper chest pass involves an outward snap of the thumbs to add velocity and leaves the defence little time to react.
Another type of pass is the "bounce pass". Here, the passer bounces the ball crisply about two-thirds of the way from his own chest to the receiver. The ball strikes the court and bounces up toward the receiver. The bounce pass takes longer to complete than the chest pass, but it is also harder for the opposing team to intercept (kicking the ball deliberately is a violation). Thus, players often use the bounce pass in crowded moments, or to pass around a defender.
The "overhead pass" is used to pass the ball over a defender. The ball is released while over the passer's head.
The "outlet pass" occurs after a team gets a defensive rebound. The next pass after the rebound is the "outlet pass".
The crucial aspect of any good pass is it being difficult to intercept. Good passers can pass the ball with great accuracy and they know exactly where each of their other teammates prefers to receive the ball. A special way of doing this is passing the ball without looking at the receiving teammate. This is called a "no-look pass".
Another advanced style of passing is the "behind-the-back pass" which, as the description implies, involves throwing the ball behind the passer's back to a teammate. Although some players can perform such a pass effectively, many coaches discourage no-look or behind-the-back passes, believing them to be difficult to control and more likely to result in turnovers or violations.
Dribbling.
Dribbling is the act of bouncing the ball continuously with one hand, and is a requirement for a player to take steps with the ball. To dribble, a player pushes the ball down towards the ground with the fingertips rather than patting it; this ensures greater control.
When dribbling past an opponent, the dribbler should dribble with the hand farthest from the opponent, making it more difficult for the defensive player to get to the ball. It is therefore important for a player to be able to dribble competently with both hands.
Good dribblers (or "ball handlers") tend to bounce the ball low to the ground, reducing the distance of travel of the ball from the floor to the hand, making it more difficult for the defender to "steal" the ball. Good ball handlers frequently dribble behind their backs, between their legs, and switch directions suddenly, making a less predictable dribbling pattern that is more difficult to defend against. This is called a crossover, which is the most effective way to move past defenders while dribbling.
A skilled player can dribble without watching the ball, using the dribbling motion or peripheral vision to keep track of the ball's location. By not having to focus on the ball, a player can look for teammates or scoring opportunities, as well as avoid the danger of having someone steal the ball away from him/her.
Blocking.
A block is performed when, after a shot is attempted, a defender succeeds in altering the shot by touching the ball. In almost all variants of play, it is illegal to touch the ball after it is in the downward path of its arc; this is known as "goaltending". It is also illegal under NBA and Men's NCAA basketball to block a shot after it has touched the backboard, or when any part of the ball is directly above the rim. Under international rules it is illegal to block a shot that is in the downward path of its arc or one that has touched the backboard until the ball has hit the rim. After the ball hits the rim, it is again legal to touch it even though it is no longer considered as a block performed.
To block a shot, a player has to be able to reach a point higher than where the shot is released. Thus, height can be an advantage in blocking. Players who are taller and playing the power forward or center positions generally record more blocks than players who are shorter and playing the guard positions. However, with good timing and a sufficiently high vertical leap, even shorter players can be effective shot blockers.
Height.
At the professional level, most male players are above and most women above . Guards, for whom physical coordination and ball-handling skills are crucial, tend to be the smallest players. Almost all forwards in the men's pro leagues are or taller. Most centers are over tall. According to a survey given to all NBA teams, the average height of all NBA players is just under , with the average weight being close to . The tallest players ever in the NBA were Manute Bol and Gheorghe Mureşan, who were both tall. The tallest current NBA player is Hasheem Thabeet, who stands at . At , Margo Dydek was the tallest player in the history of the WNBA.
The shortest player ever to play in the NBA is Muggsy Bogues at . Other short players have thrived at the pro level. Anthony "Spud" Webb was just tall, but had a 42-inch (1.07 m) vertical leap, giving him significant height when jumping. While shorter players are often not very good at defending against shooting, their ability to navigate quickly through crowded areas of the court and steal the ball by reaching low are strengths.
Variations and similar games.
Variations of basketball are activities based on the game of basketball, using common basketball skills and equipment (primarily the ball and basket). Some variations are only superficial rules changes, while others are distinct games with varying degrees of basketball influences. Other variations include children's games, contests or activities meant to help players reinforce skills.
There are principal basketball sports with variations on basketball including Wheelchair basketball, Water basketball, Beach basketball, Slamball, Streetball and Unicycle basketball. An earlier version of basketball was Six-on-six basketball played until the end of the 1950s. Horseball is a game played on horseback where a ball is handled and points are scored by shooting it through a high net (approximately 1.5m×1.5m). The sport is like a combination of polo, rugby, and basketball. There is even a form played on donkeys known as Donkey basketball, but that version has come under attack from animal rights groups.
There are also other basketball sports, such as:
Beach basketball has grown to a very popular, widespread competitive sport. 15 Annual World Championships have been organized.
Spin-offs from basketball that are now separate sports include:
Social forms of basketball.
Basketball has been adopted by various social groups, which have established their own environments and sometimes their own rules. Such socialized forms of basketball include the following.
Fantasy basketball.
Fantasy basketball was inspired by fantasy baseball. Originally played by keeping track of stats by hand, it was popularized during the 1990s after the advent of the Internet. Those who play this game are sometimes referred to as General Managers, who draft actual NBA players and compute their basketball statistics. The game was popularized by ESPN Fantasy Sports, NBA.com, and Yahoo! Fantasy Sports. Other sports websites provided the same format keeping the game interesting with participants actually owning specific players.

</doc>
<doc id="3926" url="http://en.wikipedia.org/wiki?curid=3926" title="Blowfish (disambiguation)">
Blowfish (disambiguation)

The blowfish, or Tetraodontidae, is a fish in the Tetraodontidae family.
Blowfish may also refer to:

</doc>
<doc id="3928" url="http://en.wikipedia.org/wiki?curid=3928" title="Ball">
Ball

A ball is a round, usually spherical but sometimes ovoid, object with various uses. It is used in ball games, where the play of the game follows the state of the ball as it is hit, kicked or thrown by players. In the context of sports, "ball" need not refer to a spherical object, as is the case in American football. Balls can also be used for simpler activities, such as catch, marbles and juggling. Balls made from hard-wearing materials are used in engineering applications to provide very low friction bearings, known as ball bearings. Black-powder weapons use stone and metal balls as projectiles.
Although many types of balls are today made from rubber, this form was unknown outside the Americas until after the voyages of Columbus. The Spanish were the first Europeans to see bouncing rubber balls (albeit solid and not inflated) which were employed most notably in the Mesoamerican ballgame. Balls used in various sports in other parts of the world prior to Columbus were made from other materials such as animal bladders or skins, stuffed with various materials.
As balls are one of the most familiar spherical objects to humans, the word "ball" is used to refer to, or to describe, anything spherical or near-spherical.
Etymology.
The first known use of the word "ball" in English in the sense of a globular body that is played with was in 1205 in "" in the phrase, "" The word came from the Middle English "bal" (inflected as "ball-e, -es", in turn from Old Norse "böllr" (pronounced ; compare Old Swedish "baller," and Swedish "boll") from Proto-Germanic "ballu-z," (whence probably Middle High German "bal, ball-es," Middle Dutch "bal"), a cognate with Old High German "ballo, pallo," Middle High German balle from Proto-Germanic "*ballon" (weak masculine), and Old High German "ballâ, pallâ," Middle High German "balle," Proto-Germanic "*ballôn" (weak feminine). No Old English representative of any of these is known. (The answering forms in Old English would have been "beallu, -a, -e"—compare "bealluc, ballock".) If "ball-" was native in Germanic, it may have been a cognate with the Latin "foll-is" in sense of a "thing blown up or inflated." In the later Middle English spelling "balle" the word coincided graphically with the French "balle" "ball" and "bale" which has hence been erroneously assumed to be its source. French "balle" (but not "boule") is assumed to be of Germanic origin, itself, however. In Ancient Greek the word πάλλα ("palla") for "ball" is attested besides the word "σφαίρα", "sphere".
History.
A ball, as the essential feature in many forms of gameplay requiring physical exertion, must date from the very earliest times. A rolling object appeals not only to a human baby but to a kitten and a puppy. Some form of game with a ball is found portrayed on Egyptian monuments, and is played among aboriginal tribes at the present day. In Homer, Nausicaa was playing at ball with her maidens when Odysseus first saw her in the land of the Phaeacians (Od. vi. 100). And Halios and Laodamas performed before Alcinous and Odysseus with ball play, accompanied with dancing (Od. viii. 370). The Hebrews have no mention of the ball in their scriptures.
Ancient Greeks.
Among the Greeks games with balls (σφαῖραι) were regarded as a useful subsidiary to the more violent athletic exercises, as a means of keeping the body supple, and rendering it graceful, but were generally left to boys and girls. Of regular rules for the playing of ball games, little trace remains, if there were any such. The names in Greek for various forms, which have come down to us in such works as the Ὀνομαστικόν of Julius Pollux, imply little or nothing of such; thus, ἀπόρραξις ("aporraxis") only means the putting of the ball on the ground with the open hand, οὐρανία ("ourania"), the flinging of the ball in the air to be caught by two or more players; φαινίνδα ("phaininda") would seem to be a game of catch played by two or more, where feinting is used as a test of quickness and skill. Pollux (i. x. 104) mentions a game called episkyros (ἐπίσκυρος), which has often been looked on as the origin of football. It seems to have been played by two sides, arranged in lines; how far there was any form of "goal" seems uncertain.
Ancient Romans.
Among the Romans, ball games were looked upon as an adjunct to the bath, and were graduated to the age and health of the bathers, and usually a place (sphaeristerium) was set apart for them in the baths (thermae). There appear to have been three types or sizes of ball, the pila, or small ball, used in catching games, the paganica, a heavy ball stuffed with feathers, and the follis, a leather ball filled with air, the largest of the three. This was struck from player to player, who wore a kind of gauntlet on the arm. There was a game known as trigon, played by three players standing in the form of a triangle, and played with the follis, and also one known as harpastum, which seems to imply a "scrimmage" among several players for the ball. These games are known to us through the Romans, though the names are Greek.
Modern ball games.
The various modern games played with a ball or balls and subject to rules are treated under their various names, such as polo, cricket, football, etc.

</doc>
<doc id="3931" url="http://en.wikipedia.org/wiki?curid=3931" title="Binary relation">
Binary relation

In mathematics, a binary relation on a set "A" is a collection of ordered pairs of elements of "A". In other words, it is a subset of the Cartesian product "A"2 = . More generally, a binary relation between two sets "A" and "B" is a subset of . The terms correspondence, dyadic relation and 2-place relation are synonyms for binary relation.
An example is the "divides" relation between the set of prime numbers P and the set of integers Z, in which every prime "p" is associated with every integer "z" that is a multiple of "p" (and not with any integer that is not a multiple of "p"). In this relation, for instance, the prime 2 is associated with numbers that include −4, 0, 6, 10, but not 1 or 9; and the prime 3 is associated with numbers that include 0, 6, and 9, but not 4 or 13.
Binary relations are used in many branches of mathematics to model concepts like "is greater than", "is equal to", and "divides" in arithmetic, "is congruent to" in geometry, "is adjacent to" in graph theory, "is orthogonal to" in linear algebra and many more. The concept of function is defined as a special kind of binary relation. Binary relations are also heavily used in computer science.
A binary relation is the special case of an "n"-ary relation "R" ⊆ "A"1 × … × "A""n", that is, a set of "n"-tuples where the "j"th component of each "n"-tuple is taken from the "j"th domain "A""j" of the relation.
In some systems of axiomatic set theory, relations are extended to classes, which are generalizations of sets. This extension is needed for, among other things, modeling the concepts of "is an element of" or "is a subset of" in set theory, without running into logical inconsistencies such as Russell's paradox.
Formal definition.
A binary relation "R" is usually defined as an ordered triple ("X", "Y", "G") where "X" and "Y" are arbitrary sets (or classes), and "G" is a subset of the Cartesian product "X" × "Y". The sets "X" and "Y" are called the domain (or the set of departure) and codomain (or the set of destination), respectively, of the relation, and "G" is called its graph.
The statement ("x","y") ∈ "G" is read ""x" is "R"-related to "y"", and is denoted by "xRy" or "R"("x","y"). The latter notation corresponds to viewing "R" as the characteristic function on "X" × "Y" for the set of pairs of "G".
The order of the elements in each pair of "G" is important: if "a" ≠ "b", then "aRb" and "bRa" can be true or false, independently of each other. Resuming the above example, the prime 3 divides the integer 9, but 9 doesn't divide 3.
A relation as defined by the triple ("X", "Y", "G") is sometimes referred to as a correspondence instead. In this case the relation from "X" to "Y" is the subset "G" of "X"×"Y", and "from "X" to "Y"" must always be either specified or implied by the context when referring to the relation. In practice correspondence and relation tend to be used interchangeably.
Is a relation more than its graph?
According to the definition above, two relations with identical graphs but different domains or different codomains are considered different. For example, if formula_1, then formula_2, formula_3, and formula_4 are three distinct relations.
Especially in set theory, binary relations are often defined as sets of ordered pairs, identifying binary relations with their graphs. The domain of a binary relation formula_5 is then defined as the set of all formula_6 such that there exists at least one formula_7 such that formula_8, the range of formula_5 is defined as the set of all formula_7 such that there exists at least one formula_6 such that formula_8, and the field of formula_5 is the union of its domain and its range.
A special case of this difference in points of view applies to the notion of function. Many authors insist on distinguishing between a function's codomain and its range. Thus, a single "rule," like mapping every real number "x" to "x"2, can lead to distinct functions formula_14 and formula_15, depending on whether the images under that rule are understood to be reals or, more restrictively, non-negative reals. But others view functions as simply sets of ordered pairs with unique first components. This difference in perspectives does raise some nontrivial issues. As an example, the former camp considers surjectivity—or being onto—as a property of functions, while the latter sees it as a relationship that functions may bear to sets.
Either approach is adequate for most uses, provided that one attends to the necessary changes in language, notation, and the definitions of concepts like restrictions, composition, inverse relation, and so on. The choice between the two definitions usually matters only in very formal contexts, like category theory.
Example.
Example: Suppose there are four objects {ball, car, doll, gun} and four persons {John, Mary, Ian, Venus}. Suppose that John owns the ball, Mary owns the doll, and Venus owns the car. Nobody owns the gun and Ian owns nothing. Then the binary relation "is owned by" is given as
Thus the first element of R is the set of objects, the second is the set of people, and the last element is a set of ordered pairs of the form (object, owner).
The pair (ball, John), denoted by ball"R"John means that the ball is owned by John.
Two different relations could have the same graph. For example: the relation
is different from the previous one as everyone is an owner. But the graphs of the two relations are the same.
Nevertheless, "R" is usually identified or even defined as G("R") and "an ordered pair ("x", "y") ∈ G("R")" is usually denoted as "("x", "y") ∈ "R"".
Special types of binary relations.
Some important types of binary relations "R" between "X" and "Y" are listed below.
Uniqueness properties:
Totality properties:
Uniqueness and totality properties:
Relations over a set.
If "X" = "Y" then we simply say that the binary relation is over "X", or that it is an endorelation over "X". Some types of endorelations are widely studied in graph theory, where they are known as simple directed graphs permitting loops.
The set of all binary relations Rel("X") on a set "X" is the set 2"X" × "X" which is a Boolean algebra augmented with the involution of mapping of a relation to its inverse relation. For the theoretical explanation see Relation algebra.
Some important properties of a binary relation "R" over a set "X" are:
A relation that is reflexive, symmetric, and transitive is called an equivalence relation. A relation that is reflexive, antisymmetric, and transitive is called a partial order. A partial order that is total is called a total order, "simple order", linear order, or a chain. A linear order where every nonempty subset has a least element is called a well-order. A relation that is symmetric, transitive, and serial is also reflexive.
Operations on binary relations.
If "R", "S" are binary relations over "X" and "Y", then each of the following is a binary relation over "X" and "Y":
If "R" is a binary relation over "X" and "Y", and "S" is a binary relation over "Y" and "Z", then the following is a binary relation over "X" and "Z": (see main article "composition of relations")
A relation "R" on sets "X" and "Y" is said to be contained in a relation "S" on "X" and "Y" if "R" is a subset of "S", that is, if "x" "R" "y" always implies "x" "S" "y". In this case, if "R" and "S" disagree, "R" is also said to be smaller than "S". For example, > is contained in ≥.
If "R" is a binary relation over "X" and "Y", then the following is a binary relation over "Y" and "X":
If "R" is a binary relation over "X", then each of the following is a binary relation over "X":
Complement.
If "R" is a binary relation over "X" and "Y", then the following too:
The complement of the inverse is the inverse of the complement.
If "X" = "Y" the complement has the following properties:
The complement of the inverse has these same properties.
Restriction.
The restriction of a binary relation on a set "X" to a subset "S" is the set of all pairs ("x", "y") in the relation for which "x" and "y" are in "S".
If a relation is reflexive, irreflexive, symmetric, antisymmetric, asymmetric, transitive, total, trichotomous, a partial order, total order, strict weak order, total preorder (weak order), or an equivalence relation, its restrictions are too.
However, the transitive closure of a restriction is a subset of the restriction of the transitive closure, i.e., in general not equal.
For example, restricting the relation ""x" is parent of "y"" to females yields the relation ""x" is mother of the woman "y""; its transitive closure doesn't relate a woman with her paternal grandmother. On the other hand, the transitive closure of "is parent of" is "is ancestor of"; its restriction to females does relate a woman with her paternal grandmother.
Also, the various concepts of completeness (not to be confused with being "total") do not carry over to restrictions. For example, on the set of real numbers a property of the relation "≤" is that every non-empty subset "S" of R with an upper bound in R has a least upper bound (also called supremum) in R. However, for a set of rational numbers this supremum is not necessarily rational, so the same property does not hold on the restriction of the relation "≤" to the set of rational numbers.
The "left-restriction" ("right-restriction", respectively) of a binary relation between "X" and "Y" to a subset "S" of its domain (codomain) is the set of all pairs ("x", "y") in the relation for which "x" ("y") is an element of "S".
Sets versus classes.
Certain mathematical "relations", such as "equal to", "member of", and "subset of", cannot be understood to be binary relations as defined above, because their domains and codomains cannot be taken to be sets in the usual systems of axiomatic set theory.  For example, if we try to model the general concept of "equality" as a binary relation =, we must take the domain and codomain to be the "class of all sets", which is not a set in the usual set theory.
In most mathematical contexts, references to the relations of equality, membership and subset are harmless because they can be understood implicitly to be restricted to some set in the context.  The usual work-around to this problem is to select a "large enough" set "A", that contains all the objects of interest, and work with the restriction ="A" instead of =.  Similarly, the "subset of" relation ⊆ needs to be restricted to have domain and codomain "P"("A") (the power set of a specific set "A"): the resulting set relation can be denoted ⊆"A".  Also, the "member of" relation needs to be restricted to have domain "A" and codomain "P"("A") to obtain a binary relation ∈"A" that is a set. Bertrand Russell has shown that assuming ∈ to be defined on all sets leads to a contradiction in naive set theory.
Another solution to this problem is to use a set theory with proper classes, such as NBG or Morse–Kelley set theory, and allow the domain and codomain (and so the graph) to be proper classes: in such a theory, equality, membership, and subset are binary relations without special comment.  (A minor modification needs to be made to the concept of the ordered triple ("X", "Y", "G"), as normally a proper class cannot be a member of an ordered tuple; or of course one can identify the function with its graph in this context.)   With this definition one can for instance define a function relation between every set and its power set.
The number of binary relations.
The number of distinct binary relations on an "n"-element set is 2"n"2 :
Notes:
The binary relations can be grouped into pairs (relation, complement), except that for "n" = 0 the relation is its own complement. The non-symmetric ones can be grouped into quadruples (relation, complement, inverse, inverse complement).

</doc>
<doc id="3933" url="http://en.wikipedia.org/wiki?curid=3933" title="Braille">
Braille

Braille is a tactile writing system used by the blind and the visually impaired. It is traditionally written with embossed paper. Braille-users can read computer screens and other electronic supports thanks to refreshable braille displays. They can write braille with the original slate and stylus or type it on a braille writer, such as a portable braille note-taker, or on a computer that prints with a braille embosser.
Braille is named after its creator, Frenchman Louis Braille, who went blind following a childhood accident. In 1824, at the age of 15, Braille developed his code for the French alphabet as an improvement on night writing. He published his system, which subsequently included musical notation, in 1829. The second revision, published in 1837, was the first digital (binary) form of writing.
Braille characters are small rectangular blocks called "cells" that contain tiny palpable bumps called "raised dots". The number and arrangement of these dots distinguish one character from another. Since the various braille alphabets originated as transcription codes of printed writing systems, the mappings (sets of character designations) vary from language to language. Furthermore, in English Braille there are three levels of encoding: Grade 1, a letter-by-letter transcription used for basic literacy; Grade 2, an addition of abbreviations and contractions; and Grade 3, various non-standardized personal shorthands.
Braille cells are not the only thing to appear in embossed text. There may be embossed illustrations and graphs, with the lines either solid or made of series of dots, arrows, bullets that are larger than braille dots, etc.
In the face of screen-reader software, braille usage has declined. However, braille education remains important for developing reading skills among blind and visually impaired children, and braille literacy correlates with higher employment rates.
History.
Braille was based on a tactile military code called night writing, developed by Charles Barbier in response to Napoleon's demand for a means for soldiers to communicate silently at night and without light. In Barbier's system, sets of 12 embossed dots encoded 36 different sounds. It proved to be too difficult for soldiers to recognize by touch, and was rejected by the military. In 1821 Barbier visited the Royal Institute for the Blind in Paris, where he met Louis Braille. Braille identified two major defects of the code: first, by representing only sounds, the code was unable to render the orthography of the words; second, the human finger could not encompass the whole 12-dot symbol without moving, and so could not move rapidly from one symbol to another. Braille's solution was to use 6-dot cells and to assign a specific pattern to each letter of the alphabet.
At first, braille was a one-to-one transliteration of French orthography, but soon various abbreviations, contractions, and even logograms were developed, creating a system much more like shorthand. The expanded English system, called Grade-2 Braille, was complete by 1905. For the blind today, braille is an independent writing system rather than a code of printed orthography.
Derivation.
Braille is derived from the Latin alphabet, albeit indirectly. In Braille's original system, the dot patterns were assigned to letters according to their position within the alphabetic order of the French alphabet, with accented letters and "w" sorted at the end.
The first ten letters of the alphabet, "a–j," use the upper four dot positions: (black dots in the table below). These stand for the ten digits "1–9" and "0" in a system parallel to Hebrew gematria and Greek isopsephy. (Though the dots are assigned in no obvious order, the cells with the fewest dots are assigned to the first three letters (and lowest digits), "abc = 123" (), and to the three vowels in this part of the alphabet, "aei" (), whereas the even digits, "4, 6, 8, 0" (), are corners/right angles.)
The next ten letters, "k–t," are identical to "a–j," respectively, apart from the addition of a dot at position 3 (red dots in the table): :
The next ten letters (the next "decade") are the same again, but with dots at both 3 and 6 (green dots). Here "w" was left out as not being part of the basic French alphabet; the French braille order is "u v x y z ç é à è ù" (). The next ten, ending in "w", are the same again, except that for this series position 6 (purple dot) is used without position 3. These are "â ê î ô û ë ï ü ö w" (). The "a–j" series lowered in dot space () are used for punctuation. Letters "a" and "c" , which only use dots in the top row, were lowered two places for the apostrophe and hyphen: . (These are the decade diacritics, at left in the table below, of the second and third decade.) In addition, there are ten patterns that are based on the first two letters () shifted to the right; these were assigned to non-French letters ("ì ä ò" ) or serve non-letter functions: (superscript; in English the accent mark), (currency prefix), (capital, in English the decimal point), (number sign), (emphasis mark), (symbol prefix).
Originally there had been nine decades. The fifth through ninth used dashes as well as dots, but proved to be impractical and were soon abandoned. These could be replaced with what we now know as the number sign (), though that only caught on for the digits (old 5th decade → modern 1st decade). The dash occupying the top two dots of the original sixth decade was simply dropped, producing the modern fifth decade. (See 1829 braille.)
Assignment.
Historically, there have been three principles in assigning the values of a linear script (print) to braille: Using Louis Braille's original French letter values; reassigning the braille letters according to the sort order of the print alphabet being transcribed; and reassigning the letters to improve the efficiency of writing in braille. Under international consensus, most braille alphabets follow the French sorting order for the 26 letters of the basic Latin alphabet, and there have been attempts at unifying the letters beyond these 26 (see international braille), though differences remain, for example in German Braille and the contractions of English Braille. This unification avoids the chaos of each nation reordering the braille code to match the sorting order of its print alphabet, as happened in Algerian Braille, where braille codes were numerically reassigned to match the order of the Arabic alphabet and bear little relation to the values used in other countries (compare modern Arabic Braille, which uses the French sorting order), and as happened in an early American version of English Braille, where the letters "w, x, y, z" were reassigned to match English alphabetical order. A convention sometimes seen for letters beyond the basic 26 is to exploit the physical symmetry of braille patterns iconically, for example, by assigning a reversed "n" to "ñ" or an inverted "s" to "sh". (See Hungarian Braille and Bharati Braille, which do this to some extent.) A third principle was to assign braille codes according to frequency, with the simplest patterns (quickest ones to write) assigned to the most frequent letters of the alphabet. Such frequency-based alphabets were used in Germany and the United States in the 19th century (see American Braille), but none are attested in modern use. Finally, there are braille scripts which don't order the codes numerically at all, such as Japanese Braille and Korean Braille, which are based on more abstract principles of syllable composition.
Academic texts are sometimes written in a script of eight dots per cell rather than six, enabling them encode a greater number of symbols. (See Gardner–Salinas braille codes.) Luxembourgish Braille has adopted eight-dot cells for general use; for example, it adds a dot below each letter to derive its capital variant.
Form.
Braille was the first writing system with binary encoding. The system as devised by Braille consists of two parts:
Within an individual cell, the dot positions are arranged as two columns of three positions. A raised dot can appear in any of the six positions, producing sixty-four (26) possible patterns, including one in which there are no raised dots. For reference purposes, a pattern is commonly described by listing the positions where dots are raised, the positions being universally numbered, from top to bottom, as 1 to 3 on the left and 4 to 6 on the right. For example, dot pattern 1-3-4 describe a cell with three dots raised, at the top and bottom in the left column and at the top of the right column: that is, the letter "m". The lines of horizontal braille text are separated by a space, much like visible printed text, so that the dots of one line can be differentiated from the braille text above and below. Different assignments of braille codes (or code pages) are used to map the character sets of different printed scripts to the six-bit cells. Braille assignments have also been created for mathematical and musical notation. However, because the six-dot braille cell allows only 64 (26) patterns, including the space, the characters of a braille script commonly have multiple values, depending on their context. That is, character mapping between print and braille is not one-to-one. For example, the character corresponds in print to both the letter "d" and the digit "4".
In addition to simple encoding, many braille alphabets uses contractions to reduce the size of braille texts and to increase reading speed. (See Contracted braille)
Writing braille.
Braille may be produced by hand using a slate and stylus in which each dot is created from the back of the page, writing in mirror image, or it may be produced on a braille typewriter or Perkins Brailler. Because braille letters cannot be effectively erased and written over if an error is made, an error is overwritten with all six dots (). "Interpoint" refers to braille printing that is offset, so that the paper can be embossed on both sides, with the dots on one side appearing between the divots that form the dots on the other (see the photo in the box at the top of this article for an example).
Using a computer or other electronic device, braille may be produced with a braille embosser (printer) or a refreshable braille display (screen).
Braille has been extended to an 8-dot code, particularly for use with braille embossers and refreshable braille displays. In 8-dot braille the additional dots are added at the bottom of the cell, giving a matrix 4 dots high by 2 dots wide. The additional dots are given the numbers 7 (for the lower-left dot) and 8 (for the lower-right dot). Eight-dot braille has the advantages that the case of an individual letter is directly coded in the cell containing the letter and that all the printable ASCII characters can be represented in a single cell. All 256 (28) possible combinations of 8 dots are encoded by the Unicode standard. Braille with six dots is frequently stored as Braille ASCII.
Letters.
The first 25 braille letters, up through the first half of the 3rd decade, transcribe "a–z" (skipping "w"). In English Braille, the rest of that decade is rounded out with the ligatures "and, for, of, the," and "with". Omitting dot 3 from these forms the 4th decade, the ligatures "ch, gh, sh, th, wh, ed, er, ou, ow" and the letter "w".
Formatting.
Various formatting marks affect the values of the letters that follow them. They have no direct equivalent in print. The most important in English Braille are:
That is, is read as capital 'A', and as the digit '1'.
Punctuation.
Basic punctuation marks in English Braille include:
Punctuation varies from language to language. For example, French Braille uses for its question mark and swaps the quotation marks and parentheses (to and ); it uses the period () for the decimal point, as in print, and the decimal point () to mark capitalization.
Contractions.
Braille contractions are words and affixes that are shortened so that they take up fewer cells. In English Braille, for example, the word "afternoon" is written with just three letters, , much like stenoscript. There are also several abbreviation marks that create what are effectively logograms. The most common of these is dot 5, which combines with the first letter of words. With the letter "m", the resulting word is "mother". There are also ligatures ("contracted" letters), which are single letters in braille but correspond to more than one letter in print. The letter "and", for example, is used to write words with the sequence "a-n-d" in them, such as "hand".
Unicode rendering table.
The Unicode standard encodes 8-dot braille glyphs according to their binary appearance, rather than following their assigned numeric order. Unicode defines the character block "Braille Patterns" in the hex code-point range of 2800 to 28FF. Dot 1 corresponds to the least significant bit of the low byte of the Unicode scalar value, and dot 8 to the high bit of that byte.
Most braille embossers and refreshable braille displays do not support Unicode, using instead 6-dot braille ASCII. Because of this, they are unable to display this article. Some embossers have proprietary control codes for 8-dot braille or for full graphics mode, where dots may be placed anywhere on the page without leaving any space between braille cells, so that continuous lines can be drawn in diagrams, but these are rarely used and are not standard.
Page dimensions.
Most braille embossers support between 34 and 37 cells per line, and between 25 and 28 lines per page.
A manually operated Perkins braille typewriter supports a maximum of 42 cells per line (its margins are adjustable), and typical paper allows 25 lines per page.
A large interlining Stainsby has 36 cells per line and 18 lines per page.
An A4-sized Marburg braille frame, which allows interpoint braille (dots on both sides of the page, offset so they do not interfere with each other) has 30 cells per line and 27 lines per page.
Literacy.
A sighted child who is reading at a basic level should be able to understand common words and answer simple questions about the information presented. The child should also have enough fluency to get through the material in a timely manner. Over the course of a child's education, these foundations are built upon in order to teach higher levels of math, science, and comprehension skills. Children who are blind not only have the educational disadvantage of not being able to see, but they also miss out on the very fundamental parts of early and advanced education if not provided with the necessary tools.
U.S. braille literacy statistics.
In 1960, 50% of legally blind, school-age children were able to read braille in the U.S. According to the 2011 "Annual Report" from the American Printing House for the Blind, there are approximately 58,939 legally blind children in the U.S aged 0–21. Of these, about 9% prefer braille as their primary reading medium; 27% are visual readers, 8% are auditory readers, 21% are pre-readers, and 34% are non-readers.
There are numerous causes for the decline in braille usage, including school budget constraints, technology advancement, and different philosophical views over how blind children should be educated.
A key turning point for braille literacy was the passage of the Rehabilitation Act of 1973, an act of Congress that moved thousands of children from specialized schools for the blind into mainstream public schools. Because only a small percentage of public schools could afford to train and hire braille-qualified teachers, braille literacy has declined since the law took effect. Braille literacy rates have improved slightly since the bill was passed, in part because of pressure from consumers and advocacy groups that has led 27 states to pass legislation mandating that children who are legally blind be given the opportunity to learn braille.
In 1998–99, there were approximately 55,200 legally blind children in the United States, but only 5,500 of them used braille as their primary reading medium. Early Braille education is crucial to literacy for a visually impaired child. A study conducted in the state of Washington found that people who learned braille at an early age did just as well, if not better, than their sighted peers in several areas, including vocabulary and comprehension. In the preliminary adult study, while evaluating the correlation between adult literacy skills and employment, it was found that 44% of the participants who had learned to read in braille were unemployed, compared to the 77% unemployment rate of those who had learned to read using print. Currently, among the estimated 85,000 blind adults in the United States, 90% of those who are braille-literate are employed. Among adults who do not know braille, only 33% are employed. Statistically, history has proven that braille reading proficiency provides an essential skill set that allows visually impaired children not only to compete with their sighted peers in a school environment, but also later in life as they enter the workforce.
United Kingdom.
Though braille is thought to be the main way blind people read and write, in Britain (for example) out of the reported 2 million visually impaired population, it is estimated that only around 15–20 thousand people use braille. Younger people are turning to electronic text on computers with screen reader software instead, a more portable communication method that they can also use with their friends. A debate has started on how to make braille more attractive and for more teachers to be available to teach it.
Braille transcription.
Although it is possible to transcribe print by simply substituting the equivalent braille character for its printed equivalent, in English such a character-by-character transcription (known as "uncontracted braille") is only used by beginners.
Braille characters are much larger than their printed equivalents, and the standard 11" by 11.5" (28 cm × 30 cm) page has room for only 25 lines of 43 characters. To reduce space and increase reading speed, most braille alphabets and orthographies use ligatures, abbreviations, and contractions. Virtually all English Braille books are transcribed in this "contracted braille," which adds an additional layer of complexity to English orthography: The Library of Congress's "Instruction Manual for Braille Transcribing" runs to over 300 pages and braille transcribers must pass certification tests.
Fully contracted braille is known as "Grade 2 Braille". There is an intermediate form between Computer Braille—one-for-one identity with print—and Grade 2, which is called Grade 1 Braille. In Grade 1 the capital-sign and Number sign are used, and most punctuation marks are shown using their Grade 2 values.
The system of contractions in English Braille begins with a set of 23 words which are contracted to single characters. Thus the word "but" is contracted to the single letter "b," "can" to "c", "do" to "d", and so on. Even this simple rule creates issues requiring special cases; for example, "d" is, specifically, an abbreviation of the verb "do;" the noun "do" representing the note of the musical scale is a different word, and must be spelled out.
Portions of words may be contracted, and many rules govern this process. For example, the character with dots 2-3-5 (the letter "f" lowered in the braille cell) stands for "ff" when used in the middle of a word. At the beginning of a word, this same character stands for the word "to"; the character is written in braille with no space following it. (This contraction was removed in the Unified English Braille Code.) At the end of a word, the same character represents an exclamation point.
Some contractions are more similar than their print equivalents. For example, the contraction , meaning 'letter', differs from , meaning 'little', only in adding one dot to the second : "little", "letter". This causes greater confusion between the braille spellings of these words and can hinder the learning process of contracted braille.
The contraction rules take into account the linguistic structure of the word; thus, contractions are generally not to be used when their use would alter the usual braille form of a base word to which a prefix or suffix has been added. Some portions of the transcription rules are not fully codified and rely on the judgment of the transcriber. Thus, when the contraction rules permit the same word in more than one way, preference is given to "the contraction that more nearly approximates correct pronunciation."
"Grade 3 Braille" is a variety of non-standardized systems that include many additional shorthand-like contraction. They are not used for publication, but by individuals for their personal convenience.
Braille translation software.
When people produce braille, this is called braille transcription. When computer software produces braille, this is called braille
translation. Braille translation software exists to handle most of the common languages of the world, and many technical areas,
such as math, music, and tactile graphics.
Braille-reading techniques.
Since braille is one of the few writing systems where tactile perception is used, as opposed to visual perception, a braille reader must develop new skills. One skill important for braille readers is the ability to create smooth and even pressures when running one's fingers along the words. There are many different styles and techniques used for the understanding and development of braille, even though a study by B. F. Holland suggests that there is no specific technique that is superior to any other.
Another study by Lowenfield & Abel shows that braille could be read "the fastest and best... by students who read using the index fingers of both hands." Another important reading skill emphasized in this study is to finish reading the end of a line with the right hand and to find the beginning of the next line with the left hand simultaneously. One final conclusion drawn by both Lowenfield and Abel is that children have difficulty using both hands independently where the right hand is the dominant hand. But this hand preference does not correlate to other activities.
International uniformity.
When braille was first adapted to languages other than French, many schemes were adopted, including mapping the native alphabet to the alphabetical order of French – e.g. in English W, which was not in the French alphabet at the time, is mapped to braille X, X to Y, Y to Z, and Z to the first French accented letter – or completely rearranging the alphabet such that common letters are represented by the simplest braille patterns. Needless to say, mutual intelligibility was greatly hindered by this state of affairs. In 1878, the International Congress on Work for the Blind, held in Paris, proposed an international braille standard, where braille codes for different languages and scripts would be based, not on the order of a particular alphabet, but on phonetic correspondence and transliteration to Latin.
This unified braille has been applied to the languages of India and Africa, Arabic, Vietnamese, Hebrew, Russian, and Armenian, as well as nearly all Latin-script languages. Greek, for example, "gamma" is written as Latin "g", despite the fact that it has the alphabetic position of "c"; Hebrew "bet", the second letter of the alphabet and cognate with the Latin letter "b", is sometimes pronounced /b/ and sometimes /v/, and is written "b" or "v" accordingly; Russian "ts" is written as "c", which is the usual letter for /ts/ in those Slavic languages that use the Latin alphabet; and Arabic "f" is written as "f", despite being historically "p", and occurring in that part of the Arabic alphabet (between historic "o" and "q").
Other braille conventions.
Other systems for assigning values to braille patterns are also followed, beside the simple mapping of the alphabetical order onto the original French order. Some braille alphabets start with unified braille, and then diverge significantly based on the phonology of the target languages, while others diverge even further.
In the various Chinese systems, traditional braille values are used for initial consonants and the simple vowels. In both Mandarin and Cantonese Braille, however, characters have different readings depending on whether they are placed in syllable-initial (onset) or syllable-final (rime) position. For instance, the cell for Latin "k", , represents Cantonese "k" ("g" in Yale and other modern romanizations) when initial, but "aak" when final, while Latin "j", , represents Cantonese initial "j" but final "oei".
Novel systems of braille mapping include Korean, which adopts separate syllable-initial and syllable-final forms for its consonants, explicitly grouping braille cells into syllabic groups in the same way as hangul. Japanese, meanwhile, combines independent vowel dot patterns and modifier consonant dot patterns into a single braille cell – an abugida representation of each Japanese mora.
Uses.
The current series of Canadian banknotes has a tactile feature consisting of raised dots that indicate the denomination, allowing bills to be easily identified by visually impaired people. It does not use standard braille; rather, the feature uses a system developed in consultation with blind and visually impaired Canadians after research indicated that braille was not sufficiently robust and that not all potential users read braille. Mexican bank notes, Indian Rupee notes, Israeli New Shekel notes and Russian Ruble notes also have special raised symbols to make them identifiable by the visually impaired.
In India there are instances where the parliament acts have been published in braille, such as "The Right to Information Act".
In the United States, the Americans with Disabilities Act of 1990 requires various building signage to be in braille.
Unicode.
Braille was added to the Unicode Standard in September, 1999 with the release of version 3.0.
The Unicode block for braille is U+2800 ... U+28FF:
Braille Phone.
In May 2014 a Braille phone was introduced by London-based manufacturer OwnFone. Constructed using 3D printing techniques, the device has print raised text on the keypad to help those who cannot read Braille. 

</doc>
<doc id="3936" url="http://en.wikipedia.org/wiki?curid=3936" title="Bastille Day">
Bastille Day

Bastille Day is the name given in English speaking countries to the French National Day, which is celebrated on 14 July each year. In France, it is formally called La Fête Nationale (; "The National Celebration") and commonly Le quatorze juillet (; "the fourteenth of July"). 
The French National Day commemorates the beginning of the French Revolution with the Storming of the Bastille on the 14 July 1789, as well as the Fête de la Fédération on the 14 July 1790. Celebrations are held all over France. The oldest and largest regular military parade in Europe is held on the morning of 14 July, on the Champs-Élysées avenue in Paris in front of the President of the Republic, French officials and foreign guests.
Events and traditions of the day.
The Bastille Day Military Parade opens with cadets from the École polytechnique, Saint-Cyr, École Navale, and so forth, then other infantry troops, then motorized troops; aircraft of the Patrouille de France aerobatics team fly above. In recent times, it has become custom to invite units from France's allies to the parade; in 2004 during the centenary of the Entente Cordiale, British troops (the band of the Royal Marines, the Household flying overhead. In 2007 the German 26th Airborne Brigade led the march followed by British Royal Marines. In 2013, Malian soldiers opened the parade, following the Franco-Malian military Operation Serval. Members of the United Nations' MINUSMA forces also took part in the parade, including soldiers from twelve other African countries, notably Chad. United Nations Secretary General Ban Ki-moon attended the parade alongside French President François Hollande.
The president gives an interview to members of the press, discussing the situation of the country, recent events and projects for the future. Nicolas Sarkozy, elected president in 2007, chose not to give it. François Hollande, elected president in 2012, reinstated it.
History.
Storming of the Bastille.
On 19 May 1789, Louis XVI convened the Estates-General to hear their grievances. The deputies of the Third Estate representing the common people (the two others were the Catholic Church and nobility) decided to break away and form a National Assembly. On June 20 the deputies of the Third Estate took the Tennis Court Oath, swearing not to separate until a constitution had been established. They were gradually joined by delegates of the other estates; Louis XVI started to recognize their validity on 27 June. The assembly renamed itself the National Constituent Assembly on 9 July, and began to function as a legislature and to draft a constitution.
In the wake of the 11 July dismissal of Jacques Necker, the people of Paris, fearful that they and their representatives would be attacked by the royal military, and seeking to gain ammunition and gunpowder for the general populace, stormed the Bastille, a fortress-prison in Paris which had often held people jailed on the basis of "lettres de cachet", arbitrary royal indictments that could not be appealed. Besides holding a large cache of ammunition and gunpowder, the Bastille had been known for holding political prisoners whose writings had displeased the royal government, and was thus a symbol of the absolutism of the monarchy. As it happened, at the time of the siege in July 1789 there were only seven inmates, none of great political significance.
When the crowd—eventually reinforced by mutinous "gardes françaises"—proved a fair match for the fort's defenders, Governor de Launay, the commander of the Bastille, capitulated and opened the gates to avoid a mutual massacre. However, possibly because of a misunderstanding, fighting resumed. Ninety-eight attackers and just one defender died in the actual fighting, but in the aftermath, de Launay and seven other defenders were killed, as was the 'prévôt des marchands' (roughly, mayor) Jacques de Flesselles.
Shortly after the storming of the Bastille, on 4 August feudalism was abolished and on 26 August, the "Declaration of the Rights of Man and of the Citizen" was proclaimed.
"Fête de la Fédération".
The Fête de la Fédération on the 14 July 1790 was a celebration to commemorate the first anniversary of the Storming of the Bastille and the unity of the French Nation during the French Revolution. The event took place on the Champ de Mars, which was at the time far outside Paris. The place had been transformed on a voluntary basis by the population of Paris itself, in what was recalled as the Journée des brouettes ("Wheelbarrow Day").
A mass was celebrated by Talleyrand, bishop of Autun. The popular General Lafayette, as captain of the National Guard of Paris and confidant of the king, took his oath to the constitution, followed by King Louis XVI. After the end of the official celebration, the day ended in a huge four-day popular feast and people celebrated with fireworks, as well as fine wine and running naked through the streets in order to display their great freedom.
Origin of the present celebration.
On 30 June 1878, a feast had been arranged in Paris by official decision to honour the French Republic (the event was commemorated in a painting by Claude Monet). On 14 July 1879, another feast took place, with a semi-official aspect; the events of the day included a reception in the Chamber of Deputies, organised and presided over by Léon Gambetta, a military review in Longchamp, and a Republican Feast in the Pré Catelan. All through France, "Le Figaro" wrote, "people feasted much to honour the storming of the Bastille".
On 21 May 1880, Benjamin Raspail proposed a law to have "the Republic choose the 14 July as a yearly national holiday". The Assembly voted in favour of the proposal on 21 May and 8 June. The Senate approved on it 27 and 29 June, favouring 14 July against 4 August (honouring the end of the feudal system on 4 August 1789). The law was made official on 6 July 1880, and the Ministry of the Interior recommended to Prefects that the day should be "celebrated with all the brilliance that the local resources allow". Indeed, the celebrations of the new holiday in 1880 were particularly magnificent.
In the debate leading up to the adoption of the holiday, Henri Martin, chairman of the French Senate, addressed that chamber on 29 June 1880:
Bastille Day Military Parade.
The Bastille Day Military Parade is the French military parade that has been held on the morning of 14 July each year in Paris since 1880. While previously held elsewhere within or near the capital city, since 1918 it has been held on the Champs-Élysées, with the evident agreement of the Allies as represented in the Versailles Peace Conference, and with the exception of the period of German occupation from 1940 to 1944. The parade passes down the Champs-Élysées from the Arc de Triomphe to the Place de la Concorde, where the President of the French Republic, his government and foreign ambassadors to France stand. This is a popular event in France, broadcast on French TV, and is the oldest and largest regular military parade in Europe. In some years, invited detachments of foreign troops take part in the parade and foreign statesmen attend as guests.
Smaller military parades are held in French garrison towns, including Toulon and Belfort, with local troops.

</doc>
<doc id="3940" url="http://en.wikipedia.org/wiki?curid=3940" title="Blowfish (cipher)">
Blowfish (cipher)

Blowfish is a symmetric-key block cipher, designed in 1993 by Bruce Schneier and included in a large number of cipher suites and encryption products. Blowfish provides a good encryption rate in software and no effective cryptanalysis of it has been found to date. However, the Advanced Encryption Standard (AES) now receives more attention.
Schneier designed Blowfish as a general-purpose algorithm, intended as an alternative to the aging DES and free of the problems and constraints associated with other algorithms. At the time Blowfish was released, many other designs were proprietary, encumbered by patents or were commercial or government secrets. Schneier has stated that, "Blowfish is unpatented, and will remain so in all countries. The algorithm is hereby placed in the public domain, and can be freely used by anyone."
Notable features of the design include key-dependent S-boxes and a highly complex key schedule.
The algorithm.
Blowfish has a 64-bit block size and a variable key length from 32 bits up to 448 bits. It is a 16-round Feistel cipher and uses large key-dependent S-boxes. In structure it resembles CAST-128, which uses fixed S-boxes.
The diagram to the left shows the action of Blowfish. Each line represents 32 bits. The algorithm keeps two subkey arrays: the 18-entry P-array and four 256-entry S-boxes. The S-boxes accept 8-bit input and produce 32-bit output. One entry of the P-array is used every round, and after the final round, each half of the data block is XORed with one of the two remaining unused P-entries.
The diagram to the upper right shows Blowfish's F-function. The function splits the 32-bit input into four eight-bit quarters, and uses the quarters as input to the S-boxes. The outputs are added modulo 232 and XORed to produce the final 32-bit output.
Decryption is exactly the same as encryption, except that P1, P2..., P18 are used in the reverse order. This is not so obvious because xor is commutative and associative. A common misconception is to use inverse order of encryption as decryption algorithm (i.e. first XORing P17 and P18 to the ciphertext block, then using the P-entries in reverse order).
Blowfish's key schedule starts by initializing the P-array and S-boxes with values derived from the hexadecimal digits of pi, which contain no obvious pattern (see nothing up my sleeve number). The secret key is then, byte by byte, cycling the key if necessary, XORed with all the P-entries in order. A 64-bit all-zero block is then encrypted with the algorithm as it stands. The resultant ciphertext replaces P1 and P2. The same ciphertext is then encrypted again with the new subkeys, and the new ciphertext replaces P3 and P4. This continues, replacing the entire P-array and all the S-box entries. In all, the Blowfish encryption algorithm will run 521 times to generate all the subkeys - about 4KB of data is processed.
Because the P-array is 576 bits long, and the key bytes are XORed through all these 576 bits during the initialization, many implementations support key sizes up to 576 bits. While this is certainly possible, the 448 bits limit is here to ensure that every bit of every subkey depends on every bit of the key, as the last four values of the P-array don't affect every bit of the ciphertext. This point should be taken in consideration for implementations with a different number of rounds, as even though it increases security against an exhaustive attack, it weakens the security guaranteed by the algorithm. And given the slow initialization of the cipher with each change of key, it is granted a natural protection against brute-force attacks, which doesn't really justify key sizes longer than 448 bits.
Blowfish in practice.
Blowfish is a fast block cipher, except when changing keys. Each new key requires pre-processing equivalent to encrypting about 4 kilobytes of text, which is very slow compared to other block ciphers. This prevents its use in certain applications, but is not a problem in others.
In one application Blowfish's slow key changing is actually a benefit: the password-hashing method used in OpenBSD uses an algorithm derived from Blowfish that makes use of the slow key schedule; the idea is that the extra computational effort required gives protection against dictionary attacks. "See" key stretching.
Blowfish has a memory footprint of just over 4 kilobytes of RAM. This constraint is not a problem even for older desktop and laptop computers, though it does prevent use in the smallest embedded systems such as early smartcards.
Blowfish was one of the first secure block ciphers not subject to any patents and therefore freely available for anyone to use. This benefit has contributed to its popularity in cryptographic software.
Weakness and successors.
Blowfish is known to be susceptible to attacks on reflectively weak keys.

</doc>
<doc id="3942" url="http://en.wikipedia.org/wiki?curid=3942" title="Bijection">
Bijection

In mathematics, a bijection (or bijective function or one-to-one correspondence) is a function between the elements of two sets, where every element of one set is paired with exactly one element of the other set, and every element of the other set is paired with exactly one element of the first set. There are no unpaired elements. In formal mathematical terms, a bijective function "f": "X" → "Y" is a one to one and onto mapping of a set "X" to a set "Y". 
A bijection from the set "X" to the set "Y" has an inverse function from "Y" to "X". If "X" and "Y" are finite sets, then the existence of a bijection means they have the same number of elements. For infinite sets the picture is more complicated, leading to the concept of cardinal number, a way to distinguish the various sizes of infinite sets.
A bijective function from a set to itself is also called a "permutation".
Bijective functions are essential to many areas of mathematics including the definitions of isomorphism, homeomorphism, diffeomorphism, permutation group, and projective map.
Definition.
For a pairing between "X" and "Y" (where "Y" need not be different from "X") to be a bijection, four properties must hold:
Satisfying properties (1) and (2) means that a bijection is a function with domain "X". It is more common to see properties (1) and (2) written as a single statement: Every element of "X" is paired with exactly one element of "Y". Functions which satisfy property (3) are said to be "onto "Y" " and are called surjections (or surjective functions). Functions which satisfy property (4) are said to be "one-to-one functions" and are called injections (or injective functions). With this terminology, a bijection is a function which is both a surjection and an injection, or using other words, a bijection is a function which is both "one-to-one" and "onto".
Examples.
As a concrete example of a bijection, consider the batting line-up of a baseball team (or any list of all the players of any sports team). The set "X" will be the nine players on the team and the set "Y" will be the nine positions in the batting order (1st, 2nd, 3rd, etc.) The "pairing" is given by which player is in what position in this order. Property (1) is satisfied since each player is somewhere in the list. Property (2) is satisfied since no player bats in two (or more) positions in the order. Property (3) says that for each position in the order, there is some player batting in that position and property (4) states that two or more players are never batting in the same position in the list.
In a classroom there are a certain number of seats. A bunch of students enter the room and the instructor asks them all to be seated. After a quick look around the room, the instructor declares that there is a bijection between the set of students and the set of seats, where each student is paired with the seat they are sitting in. What the instructor observed in order to reach this conclusion was that:
The instructor was able to conclude that there were just as many seats as there were students, without having to count either set.
Inverses.
A bijection "f" with domain "X" ("functionally" indicated by "f": "X → Y") also defines a relation starting in "Y" and going to "X" (by turning the arrows around). The process of "turning the arrows around" for an arbitrary function does not usually yield a function, but properties (3) and (4) of a bijection say that this inverse relation is a function with domain "Y". Moreover, properties (1) and (2) then say that this inverse "function" is a surjection and an injection, that is, the inverse function exists and is also a bijection. Functions that have inverse functions are said to be invertible. A function is invertible if and only if it is a bijection. 
Stated in concise mathematical notation, a function "f": "X → Y" is bijective if and only if it satisfies the condition
Continuing with the baseball batting line-up example, the function that is being defined takes as input the name of one of the players and outputs the position of that player in the batting order. Since this function is a bijection, it has an inverse function which takes as input a position in the batting order and outputs the player who will be batting in that position.
Composition.
The composition formula_3 of two bijections "f": "X → Y" and "g": "Y → Z" is a bijection. The inverse of formula_3 is formula_5.
Conversely, if the composition formula_3 of two functions is bijective, we can only say that "f" is injective and "g" is surjective.
Bijections and cardinality.
If "X" and "Y" are finite sets, then there exists a bijection between the two sets "X" and "Y" if and only if "X" and "Y" have the same number of elements. Indeed, in axiomatic set theory, this is taken as the definition of "same number of elements" (equinumerosity), and generalising this definition to infinite sets leads to the concept of cardinal number, a way to distinguish the various sizes of infinite sets.
Bijections and category theory.
Bijections are precisely the isomorphisms in the category Set of sets and set functions. However, the bijections are not always the isomorphisms for more complex categories. For example, in the category Grp of groups, the morphisms must be homomorphisms since they must preserve the group structure, so the isomorphisms are "group isomorphisms" which are bijective homomorphisms.
References.
This topic is a basic concept in set theory and can be found in any text which includes an introduction to set theory. Almost all texts that deal with an introduction to writing proofs will include a section on set theory, so the topic may be found in any of these:

</doc>
<doc id="3943" url="http://en.wikipedia.org/wiki?curid=3943" title="Binary function">
Binary function

In mathematics, a binary function, or function of two variables, is a function which takes two inputs.
Precisely stated, a function formula_1 is binary if there exists sets formula_2 such that
where formula_4 is the Cartesian product of formula_5 and formula_6
Alternative Definitions.
Set-theoretically, one may represent a binary function as a subset of the Cartesian product "X" × "Y" × "Z", where ("x","y","z") belongs to the subset if and only if "f"("x","y") = "z".
Conversely, a subset "R" defines a binary function if and only if, for any "x" in "X" and "y" in "Y", there exists a unique "z" in "Z" such that ("x","y","z") belongs to "R".
We then define "f" ("x","y") to be this "z".
Alternatively, a binary function may be interpreted as simply a function from "X" × "Y" to "Z".
Even when thought of this way, however, one generally writes "f" ("x","y") instead of "f"(("x","y")).
Example - Division.
Division of whole numbers can be thought of as a function; if Z is the set of integers, N+ is the set of natural numbers (except for zero), and Q is the set of rational numbers, then division is a binary function from Z and N+ to Q.
Restrictions to ordinary functions.
In turn, one can also derive ordinary functions of one variable from a binary function.
Given any element "x" of "X", there is a function "f" "x", or "f" ("x",·), from "Y" to "Z", given by "f" "x"("y") := "f" ("x","y").
Similarly, given any element "y" of "Y", there is a function "f" "y", or "f" (·,"y"), from "X" to "Z", given by "f" "y"("x") := "f" ("x","y"). (In computer science, this identification between a function from "X" × "Y" to "Z" and a function from "X" to "Z""Y" is called Currying.)
NB: "Z""Y" is the set of all functions from "Y" to "Z"
Generalisations.
The various concepts relating to functions can also be generalised to binary functions.
For example, the division example above is "surjective" (or "onto") because every rational number may be expressed as a quotient of an integer and a natural number.
This example is "injective" in each input separately, because the functions "f" "x" and "f" "y" are always injective.
However, it's not injective in both variables simultaneously, because (for example) "f" (2,4) = "f" (1,2).
One can also consider "partial" binary functions, which may be defined only for certain values of the inputs.
For example, the division example above may also be interpreted as a partial binary function from Z and N to Q, where N is the set of all natural numbers, including zero.
But this function is undefined when the second input is zero.
A binary operation is a binary function where the sets "X", "Y", and "Z" are all equal; binary operations are often used to define algebraic structures.
In linear algebra, a bilinear transformation is a binary function where the sets "X", "Y", and "Z" are all vector spaces and the derived functions "f" "x" and "f""y" are all linear transformations.
A bilinear transformation, like any binary function, can be interpreted as a function from "X" × "Y" to "Z", but this function in general won't be linear.
However, the bilinear transformation can also be interpreted as a single linear transformation from the tensor product formula_7 to "Z".
Generalisations to ternary and other functions.
The concept of binary function generalises to "ternary" (or "3-ary") "function", "quaternary" (or "4-ary") "function", or more generally to "n-ary function" for any natural number "n".
A "0-ary function" to "Z" is simply given by an element of "Z".
One can also define an "A-ary function" where "A" is any set; there is one input for each element of "A".
Category theory.
In category theory, "n"-ary functions generalise to "n"-ary morphisms in a multicategory.
The interpretation of an "n"-ary morphism as an ordinary morphisms whose domain is some sort of product of the domains of the original "n"-ary morphism will work in a monoidal category.
The construction of the derived morphisms of one variable will work in a closed monoidal category.
The category of sets is closed monoidal, but so is the category of vector spaces, giving the notion of bilinear transformation above.

</doc>
<doc id="3947" url="http://en.wikipedia.org/wiki?curid=3947" title="Blue Velvet (film)">
Blue Velvet (film)

Blue Velvet is a 1986 American mystery thriller film written and directed by David Lynch. The movie exhibits elements of both film noir and surrealism. The film stars Kyle MacLachlan, Isabella Rossellini, Dennis Hopper and Laura Dern. The title is taken from The Clovers' 1955 song of the same name. Although initially detested by some mainstream critics, the film is now widely acclaimed, and earned Lynch his second Academy Award nomination for Best Director. As an example of a director casting against the norm, "Blue Velvet" is also noted for re-launching Hopper's career and for providing Rossellini with a dramatic outlet beyond the work as a fashion model and a cosmetics spokeswoman for which she had until then been known.
After the commercial and critical failure of Lynch's "Dune" (1984), he made attempts at developing a more "personal story", somewhat characteristic of the surreal style he displayed in his debut "Eraserhead" (1977). The screenplay of "Blue Velvet" had been passed around multiple times in the late 1970s and early 1980s, with many major studios declining it because of its strong sexual and violent content. The independent studio De Laurentiis Entertainment Group, owned at the time by Italian film producer Dino De Laurentiis, agreed to finance and produce the film. Since its initial theatrical release, "Blue Velvet" has achieved cult status, significant academic attention and, alongside "Eraserhead" and "Mulholland Drive", is widely regarded as one of Lynch's finest works. It is also seen by many critics as representing a modern-day version of film-noir, "neo-noir", present in many thrillers from the early 1980s to the mid-1990s. "Blue Velvet" was ranked as one of the 100 Greatest Films of All Time by "Entertainment Weekly" in 1999 and chosen by the American Film Institute as one of the greatest mystery films ever made.
The film centers on eccentric college student Jeffrey Beaumont (MacLachlan), who, returning from visiting his ill father in the hospital, comes across a human ear in a field in his hometown of Lumberton. He proceeds to investigate the ear with help from a high school student, Sandy Williams (Dern), who provides him with information and leads from her father, a local police detective. Jeffrey's investigation draws him deeper into his hometown's seedy underworld, and sees him forming a sexual relationship with the alluring torch singer Dorothy Vallens (Rossellini), and uncovering the psychotic criminal Frank Booth (Hopper), who engages in drug abuse, kidnapping, and sexual violence.
Plot.
Jeffrey Beaumont (Kyle MacLachlan) returns to his logging home town of Lumberton from Oak Lake College after his father suffers a near fatal stroke. While walking home from the hospital, he cuts through a vacant lot and discovers a severed ear. Jeffrey takes the ear to police detective John Williams (George Dickerson), through whom he reacquaints with the detective's daughter, Sandy (Laura Dern). She tells him details about the ear case and a suspicious woman, Dorothy Vallens (Isabella Rossellini), who may be connected to the case. Increasingly curious, Jeffrey enters Dorothy's apartment by posing as an exterminator, and while Dorothy is distracted by a man dressed in a yellow suit at her door (whom Jeffrey later refers to as the Yellow Man), Jeffrey steals her spare key.
Jeffrey and Sandy attend Dorothy's nightclub act, in which she sings "Blue Velvet", and leave early so Jeffrey can sneak into her apartment to snoop. He hurriedly hides in a closet when she returns home. However, Dorothy, wielding a knife, discovers him and threatens to kill him. Believing his curiosity is merely sexual and aroused by his voyeurism, Dorothy makes Jeffrey undress at knifepoint and begins to fellate him before their encounter is interrupted by a knock at the door. Dorothy hides Jeffrey in the closet. From there he witnesses the visitor, Frank Booth (Dennis Hopper), inflict his bizarre sexual proclivities—which include inhaling an unidentified gas, dry humping, and sadomasochism—upon Dorothy. Frank is an extremely foul-mouthed, violent sociopath whose orgasmic climax is a fit of both pleasure and rage. Frank has kidnapped Dorothy's husband and son to force her to perform sexual favors. When Frank leaves, a sad and desperate Dorothy tries to seduce Jeffrey again and demands that he hit her, but when he refuses, she tells him to leave. When Jeffrey moves to leave, she asks him to stay, though he leaves anyway.
Jeffrey relays his experience to Sandy, asking her why there are people like Frank. Sandy in turn tells him of a wonderful dream she had about robins that she interprets as a sign of hope for humanity. Clearly, Jeffrey and Sandy are attracted to each other, though Sandy has a boyfriend.
Jeffrey again visits Dorothy's apartment and she tells him that although she knows nothing about him, she has been yearning for him. Jeffrey attends another of Dorothy's performances at the club, where she sings the same song. At the club, Jeffrey spots Frank in the audience fondling a piece of blue velvet fabric he cut from Dorothy's robe. Jeffrey follows Frank and spends the next few days spying on him. Shortly afterwards, two men that Jeffrey calls the Well-Dressed Man and the Yellow Man exit an industrial building that Frank frequently goes to. Jeffrey concludes the men are criminal associates of Frank. Jeffrey tells his new findings to Sandy and the two briefly kiss, though she feels uncomfortable about going any further. Jeffrey immediately visits Dorothy again and the two have sex. When he refuses to hit her, though, she pressures him, becoming more emotional. In a blind rage he knocks her backwards and is instantly horrified, but Dorothy derives pleasure from it.
Afterwards, Frank catches Dorothy and Jeffrey together and forces them both to accompany him to the apartment of Ben (Dean Stockwell), his suave, dandy partner in crime who is holding Dorothy's son. Ben lip-syncs a performance of Roy Orbison's "In Dreams", sending Frank into maudlin sadness, then rage. Frank takes Jeffrey to a lumber yard and when he molests Dorothy, Jeffrey stands up to Frank by punching him. Frank's cronies drag Jeffrey out of the car and Frank kisses Jeffrey's face, intimidates him, and then savagely beats him to the overture of "In Dreams". Jeffrey wakes the next day at the same place and walks home, overcome with guilt and despair. He goes to the police station, where he notices that Sandy's father's partner is the Yellow Man—an officer named Lieutenant Detective Tom Gordon (Fred Pickler). Later at Sandy's home, her father is amazed by Jeffrey's story, but warns Jeffrey to stop his amateur sleuthing lest he endanger himself and the investigation. Jeffrey and Sandy go to a dance together and profess their love, only to be confronted by Sandy's boyfriend. A confrontation is averted when the group finds Dorothy, naked, battered, and distressed, on Jeffrey's front lawn. Barely conscious, Dorothy calls Jeffrey "my lover," thereby revealing her intimacy with Jeffrey, causing Sandy to become upset and to slap Jeffrey, although she later forgives him.
Jeffrey insists on returning to Dorothy's apartment and tells Sandy to send the police there, including her father, immediately. At Dorothy's apartment, Jeffrey finds Dorothy's husband (Don Green), who is dead from a gunshot to the head and identifiable by his missing ear, as well as the Yellow Man, on whom Frank has performed a crude lobotomy. When Jeffrey tries to leave, he sees the Well-Dressed Man coming up the stairs and recognizes him as Frank in disguise. Jeffrey talks to Detective Williams over the Yellow Man's police radio, but lies about his location inside the apartment. Frank enters the apartment and brags about hearing Jeffrey's location over his own police radio. While Frank searches for him in the wrong room, Jeffrey retrieves the Yellow Man's gun and hides in the same closet in which he hid during his first visit to the apartment. Frank fires sporadically, killing the Yellow Man, and when he opens the closet door, Jeffrey fatally shoots him through the head. Detective Williams, gun drawn, enters with Sandy a moment later. Jeffrey and Sandy now go ahead with their relationship and note the unusual appearance of robins in their town. A montage sequence ends the film, which shows Dorothy and her son reunited.
Production.
The film's story originated from three ideas that crystallized in the filmmaker's mind over a period of time starting as early as 1973. The first idea was only "a feeling" and the title "Blue Velvet", Lynch told "Cineaste" in 1987. The second idea was an image of a severed, human ear lying in a field. "I don't know why it had to be an ear. Except it needed to be an opening of a part of the body, a hole into something else...The ear sits on the head and goes right into the mind so it felt perfect", Lynch remarked in an interview. The third idea was Bobby Vinton's classic rendition of the song "Blue Velvet" and "the mood that came with that song a mood, a time, and things that were of that time." Lynch and Roth pitched the script to Warner Bros., who showed interest in the project. Lynch eventually spent two years writing two drafts, which, he stated, were not very good. The problem with them, Lynch has said, was that "there was maybe all the unpleasantness in the film but nothing else. A lot was not there. And so it went away for a while."
After completing "The Elephant Man" (1980), Lynch met producer Richard Roth over coffee. Roth had read and enjoyed Lynch's "Ronnie Rocket" script, but did not think it was something he wanted to produce. He asked Lynch if the filmmaker had any other scripts, but the director only had ideas. "I told him I had always wanted to sneak into a girl's room to watch her into the night and that, maybe, at one point or another, I would see something that would be the clue to a murder mystery. Roth loved the idea and asked me to write a treatment. I went home and thought of the ear in the field." Production was announced in August 1984. Lynch wrote two more drafts before he was satisfied with the script of the film. Conditions at this point were ideal for Lynch's film: he had cut a deal with Dino De Laurentiis that gave him complete artistic freedom and final cut privileges, with the stipulation that the filmmaker take a cut in his salary and work with a budget of only $6 million. This deal meant that "Blue Velvet" was the smallest film on the De Laurentiis' slate. Consequently, Lynch would be left mostly unsupervised during production. "After "Dune" I was down so far that anything was up! So it was just a euphoria. And when you work with that kind of feeling, you can take chances. You can experiment." Because the material was completely different from anything that would be considered mainstream at the time, Laurentiis had to start his own production company to distribute it.
The cast of "Blue Velvet" included several then-relatively unknown actors. Isabella Rossellini had gained some exposure before the film for her Lancôme ads in the early 1980s and for being the daughter of actress Ingrid Bergman and Italian film director Roberto Rossellini. Dennis Hopper was the biggest "name" in the film, having starred in "Easy Rider" (1969) and "Apocalypse Now" (1979), while Kyle MacLachlan had played the central role in Lynch's "Dune" (1984), a science fiction epic based on the novel of the same name, the film having been a critical and commercial failure. MacLachlan later became a recurring collaborator with Lynch, who remarked: "Kyle plays innocents who are interested in the mysteries of life. He's the person you trust enough to go into a strange world with." Dennis Hopper—said to be Lynch's third choice—accepted the role, reportedly having exclaimed, "I've got to play Frank! I am Frank!" as Hopper confirmed in the "Blue Velvet" "making-of" documentary "The Mysteries of Love", produced for the 2002 special edition. For the role of Dorothy Vallens, Lynch met Isabella Rossellini at a restaurant, and she accepted the role. Laura Dern, then just nineteen years old, was cast after various successful actresses at the time turned it down, including Molly Ringwald.
The scene in which Dorothy appears naked outside was inspired by a real-life experience Lynch had during childhood when he and his brother saw a naked woman walking down a neighborhood street at night. The experience was so traumatic to the young Lynch that it made him cry, and he had never forgotten it. Principal photography of "Blue Velvet" began in February 1986 and completed in April. The film was shot at EUE/Screen Gems studio in Wilmington, North Carolina, which also provided the exterior scenes of Lumberton. The scene with a raped and battered Dorothy proved to be particularly challenging. Several townspeople arrived to watch the filming with picnic baskets and rugs, against the wishes of Rossellini and Lynch. However, they continued filming as normal, and when Lynch yelled cut, the townspeople had left. As a result, police told Lynch they were no longer permitted to shoot in any public areas of Wilmington.
Lynch's original rough cut ran for approximately four hours. He was contractually obligated to deliver a two-hour movie by De Laurentiis and cut many small subplots and character scenes. He also made cuts at the request of the MPAA. For example, when Frank slaps Dorothy after the first rape scene, the audience was supposed to see Frank actually hitting her. Instead, the film cuts away to Jeffrey in the closet, wincing at what he has just seen. This cut was made to satisfy the MPAA's concerns about violence. Lynch thought that the change only made the scene more disturbing. Lynch announced in a radio interview on January 18, 2011, that footage from the deleted scenes, long thought lost, had been discovered. It later appeared on the 2011 special edition Blu-ray disc release of the film. The final cut produced by Lynch runs for just under two hours.
Interpretation.
Despite "Blue Velvet"s initial appearance as a mystery, the film operates on a number of thematic levels. The film owes a large debt to 1950s film noir, containing and exploring such conventions as the femme fatale (Dorothy Vallens), a seemingly unstoppable villain (Frank Booth), and the questionable moral outlook of the hero (Jeffrey Beaumont), as well as its unusual use of shadowy, sometimes dark cinematography. "Blue Velvet" represents and establishes Lynch's famous "askew vision," and introduces several common elements of Lynch's work, some of which would later become his trademarks, including distorted characters, a polarized world, and debilitating damage to the skull or brain. Perhaps the most significant "Lynchian" trademark in the film is the depiction of unearthing a dark underbelly in a seemingly idealized small town; Jeffrey even proclaims in the film that he is "seeing something that was always hidden," thus alluding to the film's plot central idea. Lynch's characterization of films, symbols, and motifs have become well-known, and his particular style, characterised largely in "Blue Velvet" for the first time, has been written about extensively using descriptions like "dreamlike", "ultraweird," "dark," and "oddball." Red curtains also show up in key scenes, specifically in Dorothy's apartment, which have since become a Lynch trademark. The film has been compared to Alfred Hitchcock's "Psycho" (1960) because of its stark treatment of psychotic evil. The premise of both films is curiosity, leading to an investigation that draws the lead characters into a hidden, voyeuristic underworld of crime.
The film's thematic framework hearkens back to Poe, James, and early gothic fiction, as well as films such as "Shadow of a Doubt" (1943) and "The Night of the Hunter" (1955) and the entire notion of film noir. Lynch has called it a "film about things that are hidden—within a small city and within people." Like many other Lynch films, "Blue Velvet" is immersed in pop culture imagery, both from the 1950s and the 1960s, as well as the 1980s.
Feminist psychoanalytic film theorist Laura Mulvey argues that "Blue Velvet" establishes a metaphorical Oedipal family—"the child", Jeffrey Beaumont, and his "parents", Frank Booth and Dorothy Vallens—through deliberate references to film noir and its underlying Oedipal theme. The resulting violence, she claims, can be read as symbolic of domestic violence within real families. For instance, Frank's violent acts can be seen to reflect the different types of abuse within families, and the control he has over Dorothy might represent the hold an abusive husband has over his wife. Michael Atkinson reads Jeffrey as an innocent youth who is both horrified by the violence inflicted by Frank, but also tempted by it as the means of possessing Dorothy for himself. Atkinson takes a Freudian approach to the film; considering it to be an expression of the traumatised innocence which characterises Lynch's work. He claims that "Dorothy represents the sexual force of the mother because she is forbidden and because she becomes the object of the unhealthy, infantile impulses at work in Jeffrey's subconscious".
Symbolism.
Symbolism is used very heavily in "Blue Velvet". The most consistent symbolism in the film is an insect motif introduced at the end of the first scene, when the camera zooms in on a well-kept suburban lawn until it unearths a swarming underground nest of disgusting bugs. This is generally recognized as a metaphor for the seedy underworld that Jeffrey will soon discover under the surface of his own suburban, Reaganesque paradise. The severed ear he finds is being overrun by black ants. The bug motif is recurrent throughout the film, most notably in the horrific bug-like gas mask that Frank wears, but also the excuse that Jeffrey uses to gain access to Dorothy's apartment: he claims to be an insect exterminator. One of Frank's sinister accomplices is also consistently identified through the yellow jacket he wears, possibly reminiscent of the name of a type of wasp. Finally, a robin eating a bug on a fence becomes a topic of discussion in the last scene of the film. The robin, mentioned earlier by Sandy when she recounted her dream, represents love conquering evil.
The severed ear that Jeffrey discovers is also a key symbolic element; the ear is what leads Jeffrey into danger. Indeed, just as Jeffrey's troubles begin, the audience is treated to a nightmarish sequence in which the camera zooms into the canal of the severed, decomposing ear. Notably, the camera does not reemerge from the ear canal until the end of the film. When Jeffrey finally comes through his hellish ordeal unscathed, the ear canal shot is replayed, only in reverse, zooming out through Jeffrey's own ear as he relaxes in his yard on a summer day.
Soundtrack.
The "Blue Velvet" soundtrack was supervised by Angelo Badalamenti (who makes a brief cameo appearance as the pianist at the Slow Club where Dorothy performs). The soundtrack makes heavy usage of vintage pop songs, such as Bobby Vinton's "Blue Velvet" and Roy Orbison's "In Dreams", juxtaposed with an orchestral score inspired by Shostakovich. During filming, Lynch placed speakers on set and in streets and played Shostakovich to set the mood he wanted to convey.
"Entertainment Weekly" ranked "Blue Velvet's" soundtrack on its list of the "100 Greatest Film Soundtracks", at the 100th position. Critic John Alexander wrote, "the haunting soundtrack accompanies the title credits, then weaves through the narrative, accentuating the noir mood of the film." Lynch worked with music composer Angelo Badalamenti for the first time in this film and asked him to write a score that had to be "like Shostakovich, be very Russian, but make it the most beautiful thing but make it dark and a little bit scary." Badalamenti's success with "Blue Velvet" would lead him to contribute to all of Lynch's future full-length films until "Inland Empire". Also included in the sound team was long time Lynch collaborator Alan Splet, a sound editor and designer who had won an Academy Award for his work on "The Black Stallion" (1979), and been nominated for "Never Cry Wolf" (1983).
Release and reaction.
Performance.
"Blue Velvet" premiered in competition at the Montréal World Film Festival in August 1986, and at the Toronto Film Festival on September 12, 1986, and a few days later in the United States. It debuted commercially in both countries on September 19, 1986, in 98 theatres across the United States. In its opening weekend, the film grossed a total of $789,409. It eventually expanded to another fifteen theatres, and domestically grossed a total of $8,551,228. It was also released internationally, in Australia, most of West Germany, China, Canada, Hong Kong, and Japan, followed by subsequent video releases. The film grossed $900,000 in Australia, and $450,139 in Hong Kong.
Lynch was nominated for a Best Director Oscar for the film. Isabella Rossellini won an Independent Spirit Award for the Best Female Lead in 1987. David Lynch and Dennis Hopper won a Los Angeles Film Critics Association award in 1987 for "Blue Velvet" in categories Best Director (Lynch) and Best Supporting Actor (Hopper). In 1987, National Society of Film Critics awarded Best Film, Best Director (David Lynch), Best Cinematography (Frederick Elmes), and Best Supporting Actor (Dennis Hopper) awards.
Critical reception.
The film received critical acclaim in the United States, with one critic claiming "Blue Velvet" would "cause a sensation" upon its theatrical release. The film was included in "The New York Times" "10 Best Films of 1986" upon its release. Paul Attanasio of "The Washington Post" said "the film showcases a visual stylist utterly in command of his talents" and that Angelo Badalamenti "contributes an extraordinary score, slipping seamlessly from slinky jazz to violin figures to the romantic sweep of a classic Hollywood score", but claimed that Lynch "isn't interested in communicating, he's interested in parading his personality. The movie doesn't progress or deepen, it just gets weirder, and to no good end." "The New York Times" critic Janet Maslin expressed her admiration for the film, and directed much praise toward the performances of Hopper and Rossellini: "Mr. Hopper and Miss Rossellini are so far outside the bounds of ordinary acting here that their performances are best understood in terms of sheer lack of inhibition; both give themselves entirely over to the material, which seems to be exactly what's called for." She called it "an instant cult classic." Maslin concluded by saying that "Blue Velvet" "is as fascinating as it is freakish. It confirms Mr. Lynch's stature as an innovator, a superb technician, and someone best not encountered in a dark alley." Sheila Benson of the "Los Angeles Times" called the film "the most brilliantly disturbing film ever to have its roots in small-town American life." She called it "shocking, visionary, rapturously controlled."
Looking back in his "Guardian/Observer" review, critic Philip French wrote, "The film is wearing well and has attained a classic status without becoming respectable or losing its sense of danger." Peter Travers, film critic for "Rolling Stone", named "Blue Velvet" the best film of the 1980s, and referred to the film as an "American masterpiece." Film critic Gene Siskel included "Blue Velvet" on his list of the best films of 1986, at #5. Nevertheless, "Blue Velvet" was not without its detractors. A general criticism from critics in the United States was the film's often vulgar approach to sexuality and violence that detracts from the film's serious side. One of the film's detractors, Roger Ebert, film critic of the "Chicago Sun-Times", supported that view; although he praised Isabella Rossellini's performance as being "convincing and courageous", he criticized how she was depicted in the film, even accusing David Lynch of misogyny: "degraded, slapped around, humiliated and undressed in front of the camera. And when you ask an actress to endure those experiences, you should keep your side of the bargain by putting her in an important film." During an online Q&A session in 2007, Ebert said he still had negativity regarding how Rossellini was depicted but said he should re-visit "Blue Velvet" and that David Lynch was a good director. In a tweet honoring David Lynch's birthday, Ebert later revealed though he views Lynch as a great director, his feelings remain unchanged about "Blue Velvet".
Legacy.
Although it initially gained a relatively small theatrical audience in North America and was met with controversy over its artistic merit, "Blue Velvet" soon became the center of a "national firestorm" in 1986, and over time achieved status as an American classic. In the late 1980s, and early 1990s, after its release on videotape, the film became a widely known cult film, well known for its dark depiction of a suburban America. Followed by myriad VHS, Laserdisc and DVD releases, the film became increasingly well-known among American audiences. It marked the entrance of David Lynch into the Hollywood mainstream and the comeback of Dennis Hopper after a significant hiatus from work. Hopper's performance and the character of Frank Booth itself has left an imprint on popular culture, with countless tributes, cultural references and parodies. The success of the film alone has helped propel Hollywood mainstream toward more graphic displays of previously censored themes, a similar case to "Psycho" (1960), to which "Blue Velvet" has been frequently compared. It has become one of the most significant, well-recognized films of its era, spawning countless imitations and parodies in media. The film's dark, stylish and erotic production design has served as a benchmark for a number of films, parodies and even Lynch's own later work, notably "Twin Peaks" (1990–91), and "Mulholland Drive" (2001). Peter Travers of "Rolling Stone" magazine cited it as one of the most "influential American films", as did Michael Atkinson, who dedicated a book to the film's themes and motifs.
"Blue Velvet" now frequently appears in various critical assessments of all-time great films, also ranked as one of the greatest films of the 1980s, one of the best examples of American surrealism and one of the finest examples of David Lynch's work. In a poll of two American critics ranking the "most outstanding films of the decade", "Blue Velvet" was placed third and fourth, behind "Raging Bull" (1980), "E.T. The Extra Terrestrial" (1982) and the German film "Wings of Desire" (1987). An "Entertainment Weekly" book special released in 1999 ranked "Blue Velvet" at thirty-seventh greatest films of all time. The film was ranked by "The Guardian" in its list of the 100 Greatest Films. "Film Four's" ranked it on their list of 100 Greatest Films. In a 2007 poll of the online film community held by "Variety", "Blue Velvet" came in at the ninety-fifth greatest film of all time. "Total Film" ranked "Blue Velvet" as one of the all time best films in both a critics list and a public poll, in 2006 and 2007, respectively. In December 2002, a UK film critics poll in "Sight & Sound" ranked the film #5 on their list of the 10 Best Films of the Last 25 Years. In a special "Entertainment Weekly" issue, 100 new film classics were chosen from 1983 to 2008: "Blue Velvet" was ranked at #4.
In addition to "Blue Velvet's" various "all time greatest films" rankings, the American Film Institute has awarded the film three honors in its lists: #96 on "100 Years... 100 Thrills" in 2001, selecting cinema's most thrilling moments and ranked Frank Booth #36 of the 50 greatest villains in "100 Years...100 Heroes and Villains" in 2003. In June 2008, the AFI revealed its "Ten top Ten"—the best ten films in ten "classic" American film genres—after polling over 1,500 people from the creative community. "Blue Velvet" was acknowledged as the eighth best film in the mystery genre. "Premiere" magazine listed Frank Booth, played by Dennis Hopper, as #54 on its list of The 100 Greatest Movie Characters of All Time, calling him one of "the most monstrously funny creations in cinema history". The film was ranked #84 on Bravo Television's four-hour program "100 Scariest Movie Moments" (2004). It is frequently sampled musically and an array of bands and solo artists have taken their names and inspiration from the film. In August 2012, "Sight & Sound" unveiled their latest list of the 250 greatest films of all time, with "Blue Velvet" ranking at #69.
"Blue Velvet" was also nominated for the following AFI lists:
"Blue Velvet" was released on Blu-ray on November 8, 2011 in a special 25th anniversary edition featuring never-before-seen deleted scenes. The film had previously been released on DVD in 1999 and 2002 by MGM Home Entertainment. Inspired by the film, baroque pop singer Lana Del Rey recorded a cover version of Bobby Vinton's classic rendition of the song "Blue Velvet" in 2012. Used to endorse clothing line H&M, a music video accompanied the track and aired as a television commercial. Filmed in Post-war Americana, the video drew influence from Lynch and "Blue Velvet". In the video, Del Rey plays the role of Dorothy Vallens, performing a private concert similar to the scene where Ben (Dean Stockwell) pantomimes "In Dreams" for Frank Booth. Del Rey's version, however, has her lip-synching "Blue Velvet" when a little person dressed as Frank Sinatra approaches and unplugs a hidden victrola, revealing Del Rey as a fraud. When Lynch heard of the music video, he praised it, telling "Artinfo": "Lana Del Rey, she's got some fantastic charisma and—this is a very interesting thing—it's like she's born out of another time. She's got something that's very appealing to people. And I didn't know she was influenced by me!"
References.
Notes

</doc>
<doc id="3948" url="http://en.wikipedia.org/wiki?curid=3948" title="Binary operation">
Binary operation

In mathematics, a binary operation on a set is a calculation that combines two elements of the set (called operands) to produce another element of the set (more formally, an operation whose arity is two, and whose two domains and one codomain are (subsets of) the same set).  Examples include the familiar elementary arithmetic operations of addition, subtraction, multiplication and division.  Other examples are readily found in different areas of mathematics, such as vector addition, matrix multiplication and conjugation in groups.
Terminology.
More precisely, a binary operation on a set "S" is a map which sends elements of the Cartesian product to "S":
Because the result of performing the operation on a pair of elements of "S" is again an element of "S", the operation is called a closed binary operation on "S" (or sometimes expressed as having the property of closure).  If "f" is not a function, but is instead a partial function, it is called a partial binary operation.  For instance, division of real numbers is a partial binary operation, because one can't divide by zero: "a"/0 is not defined for any real "a".  Note however that both in algebra and model theory the binary operations considered are defined on all of .
Sometimes, especially in computer science, the term is used for any binary function.
Binary operations are the keystone of algebraic structures studied in abstract algebra: they are essential in the definitions of groups, monoids, semigroups, rings, and more.  Most generally, a "magma" is a set together with some binary operation defined on it.
Properties and examples.
Typical examples of binary operations are the addition (+) and multiplication (×) of numbers and matrices as well as composition of functions on a single set.
For instance,
Many binary operations of interest in both algebra and formal logic are commutative, satisfying f("a","b") = f("b","a") for all elements "a" and "b" in "S", or associative, satisfying f(f("a","b"), "c") = f("a", f("b","c")) for all "a", "b" and "c" in "S".  Many also have identity elements and inverse elements.
The first three examples above are commutative and all of the above examples are associative.  The paper-scissors-rock binary operation is commutative but not associative.
On the set of real numbers R, subtraction, that is, f("a","b") = "a" - "b", is a binary operation which is not commutative since, in general, "a" - "b" ≠ "b" - "a".  It is also not associative, since, in general, "a" - ("b" - "c") ≠ ("a" - "b") - "c"; for instance, 1 - (2 - 3) = 2 but (1 - 2) - 3 = -4.
On the set of natural numbers N, the binary operation exponentiation, f("a","b") = "a""b", is not commutative since, in general, "a""b" ≠ "b""a" and is also not associative since f(f("a","b"),"c") ≠ f("a", f("b","c")).  For instance, with "a" = 2, "b" = 3 and "c" = 2, f(23,2) = f(8,2) = 64, but f(2,32) = f(2,9) = 512.  By changing the set N to the set of integers Z, this binary operation becomes a partial binary operation since it is now undefined when "a" = 0 and "b" is any negative integer.  For either set, this operation has a "right identity" (which is 1) since f("a", 1) = "a" for all "a" in the set, which is not an "identity" (two sided identity) since f(1, "b") ≠ "b" in general.
Division (/), a partial binary operation on the set of real or rational numbers, is not commutative or associative as well.  Tetration(↑↑), as a binary operation on the natural numbers, is not commutative nor associative and has no identity element.
Notation.
Binary operations are often written using infix notation such as "a"*"b", "a" + "b", "a·b" or (by juxtaposition with no symbol) "ab" rather than by functional notation of the form "f"("a", "b").  Powers are usually also written without operator, but with the second argument as superscript.
Binary operations sometimes use prefix or (probably more often) postfix notation, both of which dispense with parentheses.  They are also called, respectively, Polish notation and reverse Polish notation.
Pair and tuple.
A binary operation, "ab", depends on the ordered pair ("a, b") and so ("ab")"c" (where the parentheses here mean first operate on the ordered pair ("a", "b") and then operate on the result of that using the ordered pair (("ab"), "c")) depends in general on the ordered pair (("a", "b"), "c").  Thus, for the general, non-associative case, binary operations can be represented with binary trees.
However:
Binary operations as ternary relations.
A binary operation "f" on a set "S" may be viewed as a "ternary" relation on "S", that is, the set of triples ("a", "b", "f(a,b)") in "S" × "S" × "S" for all "a" and "b" in "S".
External binary operations.
An external binary operation is a binary function from "K" × "S" to "S".  This differs from a binary operation in the strict sense in that "K" need not be "S"; its elements come from "outside".
An example of an external binary operation is scalar multiplication in linear algebra.  Here "K" is a field and "S" is a vector space over that field.
An external binary operation may alternatively be viewed as an action; "K" is acting on "S".
Note that the dot product of two vectors is not a binary operation, external or otherwise, as it maps from "S"× "S" to "K", where "K" is a field and "S" is a vector space over "K".

</doc>
<doc id="3950" url="http://en.wikipedia.org/wiki?curid=3950" title="Bagpipes">
Bagpipes

Bagpipes are a class of musical instrument, aerophones, using enclosed reeds fed from a constant reservoir of air in the form of a bag. Though the Scottish and Irish Great Highland bagpipe (known in Ireland as the War pipes) and Irish Uilleann Pipes have the greatest international visibility, bagpipes have been played for centuries throughout large parts of Europe, the Caucasus, around the Persian Gulf and in Northern Africa. The term "bagpipe" is equally correct in the singular or plural, although in the English language, pipers most commonly talk of "the pipes", "a set of pipes" or "a stand of pipes".
Construction.
A set of bagpipes minimally consists of an air supply, a bag, a chanter, and, usually, at least one drone. Most bagpipes have more than one drone (and, sometimes, more than one chanter) in various combinations, held in place in stocks — sockets that fasten the various pipes to the bag.
Air supply.
The most common method of supplying air to the bag is through blowing into a blowpipe, or blowstick. In some pipes the player must cover the tip of the blowpipe with his tongue while inhaling, but most blowpipes have a non-return valve that eliminates this need.
An innovation, dating from the 16th or 17th century, is the use of a bellows to supply air. In these pipes, sometimes called "cauld wind pipes", air is not heated or moistened by the player's breathing, so bellows-driven bagpipes can use more refined or delicate reeds. Such pipes include the Irish uilleann pipes, the Scottish border pipes and Lowland pipes; Northumbrian smallpipes, pastoral pipes and English Border pipes in Britain, and the musette de cour in France.
Bag.
The bag is an airtight reservoir that can hold air and can be used to regulate its flow, enabling the player to maintain continuous sound. The player keeps the bag inflated by blowing air into it through a blowpipe or pumping air into it with a bellows. Materials used for bags vary widely, but the most common are the skins of local animals such as goats, dogs, sheep, and cows. More recently, bags made of synthetic materials including Gore-Tex have become much more common. However, a drawback of the synthetic bag is the potential for fungal spores to colonise the bag because of a reduction in necessary cleaning, with the associated danger of lung infection.
Bags cut from larger materials are usually saddle-stitched with an extra strip folded over the seam and stitched (for skin bags) or glued (for synthetic bags) to reduce leaks. Holes are then cut to accommodate the stocks. In the case of bags made from largely intact animal skins the stocks are typically tied into the points where limbs and the head joined the body of the living animal, a construction technique common in Central Europe.
Chanter.
The chanter is the melody pipe, played with two hands. Almost all bagpipes have at least one chanter; some pipes have two chanters, particularly those in North Africa, the Balkans in Southern Europe, and Southwest Asia. A chanter can be bored internally so that the inside walls are parallel (or "cylindrical") for its full length, or it can be bored in a conical shape.
The chanter is usually open-ended, so there is no easy way for the player to stop the pipe from sounding. Thus most bagpipes share a constant, legato sound where there are no rests in the music. Primarily because of this inability to stop playing, technical movements are used to break up notes and to create the illusion of articulation and accents. Because of their importance, these embellishments (or "ornaments") are often highly technical systems specific to each bagpipe, and take many years of study to master. A few bagpipes (such as the musette de cour, the uilleann pipes, the Northumbrian smallpipe, and the left chanter of the "surdulina", a type of Calabrian zampogna) have closed ends or stop the end on the player's leg, so that when the player "closes" (covers all the holes) the chanter it becomes silent.
Chanter reed.
The note from the chanter is produced by a reed installed at its top. The reed may be a single (a reed with one vibrating tongue) or double reed (of two pieces that vibrate against each other). Double reeds are used with both conical- and parallel-bored chanters while single reeds are generally (although not exclusively) limited to parallel-bored chanters. In general, double-reed chanters are found in pipes of Western Europe while single-reed chanters appear in most other regions.
Drone.
Most bagpipes have at least one drone: a pipe which is generally not fingered but rather produces a constant harmonizing note throughout play. These drones have reeds just like in the chanter. Exceptions are generally those pipes which have a double-chanter instead. A drone is most commonly a cylindrically-bored tube with a single reed, although drones with double reeds exist. The drone is generally designed in two or more parts with a sliding joint so that the pitch of the drone can be adjusted.
Depending on the type of pipes, the drones may lie over the shoulder, across the arm opposite the bag, or may run parallel to the chanter. Some drones have a tuning screw, which effectively alters the length of the drone by opening a hole, allowing the drone to be tuned to two or more distinct pitches. The tuning screw may also shut off the drone altogether. In most types of pipes, where there is one drone it is pitched two octaves below the tonic of the chanter. Additional drones often add the octave below and then a drone consonant with the fifth of the chanter.
History.
Possible ancient origins.
The evidence for Roman and pre-Roman era bagpipes is still uncertain but several textual and visual clues have been suggested. The "Oxford History of Music" says that a sculpture of bagpipes has been found on a Hittite slab at Euyuk in the Middle East, dated to 1000 BC. In the 2nd century AD, Suetonius described the Roman emperor Nero as a player of the "tibia utricularis". Dio Chrysostom wrote in the 1st century of a contemporary sovereign (possibly Nero) who could play a pipe (tibia, Roman reedpipes similar to Greek aulos) with his mouth as well as with his armpit.
Spread and development in Europe.
In the early part of the second millennium, bagpipes began to appear with frequency in European art and iconography. The Cantigas de Santa Maria, compiled in Castile in the mid-13th century, depicts several types of bagpipes. Though evidence of bagpipes in the British Isles prior to the 14th century is contested, bagpipes are explicitly mentioned in "The Canterbury Tales" (written around 1380): "A baggepype wel coude he blowe and sowne, /And ther-with-al he broghte us out of towne."
Actual examples of bagpipes from before the 18th century are extremely rare; however, a substantial number of paintings, carvings, engravings, manuscript illuminations, and so on survive. They make it clear that bagpipes varied hugely throughout Europe, and even within individual regions.Many examples of early folk bagpipes in continental Europe can be found in the paintings of Brueghel, Teniers, Jordaens and Durer.
The first clear reference to the use of the Scottish Highland bagpipes is from a French history, which mentions their use at the Battle of Pinkie Cleugh in 1547. George Buchanan (1506–82) claimed that they had replaced the trumpet on the battlefield. This period saw the creation of the "ceòl mór" (great music) of the bagpipe, which reflected its martial origins, with battle-tunes, marches, gatherings, salutes and laments. The Highlands of the early seventeenth century saw the development of piping families including the MacCrimmonds, MacArthurs, MacGregors and the Mackays of Gairloch.
Evidence of the bagpipe in Ireland occurs in 1581, when John Derrick's "The Image of Irelande" clearly depicts a bagpiper. Derrick's illustrations are considered to be reasonably faithful depictions of the attire and equipment of the English and Irish population of the 16th century. The "Battell" sequence from "My Ladye Nevells Booke" (1591) by William Byrd, which probably alludes to the Irish wars of 1578, contains a piece entitled "The bagpipe: & the drone". In 1760, the first serious study of the Scottish Highland bagpipe and its music was attempted, in Joseph MacDonald's "Compleat Theory". Further south, a manuscript from the 1730s by a William Dixon from Northumberland contains music that fits the border pipes, a nine-note bellows-blown bagpipe whose chanter is similar to that of the modern Great Highland bagpipe. However the music in Dixon's manuscript varied greatly from modern Highland bagpipe tunes, consisting mostly of extended variation sets of common dance tunes. Some of the tunes in the Dixon manuscript correspond to tunes found in early 19th century published and manuscript sources of Northumbrian smallpipe tunes, notably the rare book of 50 tunes, many with variations, by John Peacock.
As Western classical music developed, both in terms of musical sophistication and instrumental technology, bagpipes in many regions fell out of favour due to their limited range and function. This triggered a long, slow decline that continued, in most cases, into the 20th century.
Extensive and documented collections of traditional bagpipes can be found in the Metropolitan Museum of Art in New York City, the International Bagpipe Museum in Gijón, Spain, the Pitt Rivers Museum in Oxford, England and the Morpeth Chantry Bagpipe Museum in Northumberland.
Recent history.
During the expansion of the British Empire, spearheaded by British military forces that included Highland regiments, the Scottish Great Highland bagpipe became well-known worldwide. This surge in popularity was boosted by large numbers of pipers trained for military service in World War I and World War II. The surge coincided with a decline in the popularity of many traditional forms of bagpipe throughout Europe, which began to be displaced by instruments from the classical tradition and later by gramophone and radio.
In the United Kingdom and Commonwealth Nations such as Canada and New Zealand, the Great Highland bagpipe is commonly used in the military and is often played in formal ceremonies. Foreign militaries patterned after the British Army have also taken the Highland bagpipe into use including Uganda, India, Pakistan, Sri Lanka, and Oman. Many police and fire services in Scotland, Canada, Australia, New Zealand, Hong Kong, and the United States have also adopted the tradition of fielding pipe bands.
In recent years, often driven by revivals of native folk music and dance, many types of bagpipes have enjoyed a resurgence in popularity and, in many cases, instruments that were on the brink of obscurity have become extremely popular. In Brittany, the Great Highland bagpipe and concept of the pipe band were appropriated to create a Breton interpretation, the bagad. The pipe band idiom has also been adopted and applied to the Galician gaita as well. Additionally, bagpipes have often been used in various films depicting moments from Scottish and Irish history; the film "Braveheart" and the theatrical show "Riverdance" have served to make the uilleann pipes more commonly known. Bagpipes are sometimes played at formal events in Commonwealth universities, particularly in Canada.
Bagpipe making was once a craft that produced instruments in many distinctive local traditional styles. Today, the world's biggest producer of the instrument is Pakistan, where the industry was worth $6.8 million in 2010. In the late 20th century, various models of electronic bagpipes were invented. The first custom-built MIDI bagpipes were developed by the Asturian piper known as Hevia (José Ángel Hevia Velasco).
Modern usage.
Types of bagpipes.
Dozens of types of bagpipes today are widely spread across Europe and the Middle East, as well as through much of the former British Empire. The name bagpipe has almost become synonymous with its best-known form, the Great Highland bagpipe, overshadowing the great number and variety of traditional forms of bagpipe. Despite the decline of these other types of pipes over the last few centuries, in recent years many of these pipes have seen a resurgence or revival as musicians have sought them out; for example, the Irish piping tradition, which by the mid 20th century had declined to a handful of master players is today alive, well, and flourishing a situation similar to that of the Asturian gaita, the Galician gaita, the Portuguese Gaita transmontana, the Aragonese gaita de boto, Northumbrian smallpipes, the Breton biniou, the Balkan gaida, the Romanian cimpoi, the Black Sea tulum, the Scottish smallpipes and pastoral pipes, as well as other varieties.
Traditionally, one of the purposes of the bagpipe was to provide music for dancing. This has declined with the growth of dance bands, recordings, and the decline of traditional dance. In turn, this has led to many types of pipes developing a performance-led tradition, and indeed much modern music based on the dance music tradition played on bagpipes is no longer suitable for use as dance music.
Usage in non-traditional music.
Since the 1960s, bagpipes have also made appearances in other forms of music, including rock, metal, jazz, hip-hop, punk, and classical music, for example with Paul McCartney's "Mull of Kintyre", AC/DC's "It's A Long Way To The Top", Korn's "Shoots and Ladders", John Farnham's "You're The Voice", Peter Maxwell Davies's composition "Orkney Wedding, With Sunrise" and the German power metal band Grave Digger incorporated bagpipes in many of the songs from their concept album "Tunes Of War". The Canadian crossover band Rawlins Cross also made extensive use of the pipes in their music, with one very popular tune called "Reel and Roll."
Publications.
Periodicals.
"Periodicals covering specific types of bagpipes are addressed in the article for that bagpipe"

</doc>
<doc id="3952" url="http://en.wikipedia.org/wiki?curid=3952" title="Bedrock Records">
Bedrock Records

Bedrock Records is an English record label for trance, house and techno started by Nick Muir and John Digweed.
Its name comes from a nightclub in London that is also called Bedrock. Bedrock Records has released many singles from artists such as Astro & Glyde, Brancaccio & Aisher, Steve Lawler, Shmuel Flash, Steve Porter, Guy J, Henry Saiz, Stelios Vassiloudis, Electric Rescue, The Japanese Popstars and Jerry Bonham. Bedrock is also the name that Digweed and Muir use as their production moniker.

</doc>
<doc id="3954" url="http://en.wikipedia.org/wiki?curid=3954" title="Biochemistry">
Biochemistry

Biochemistry, sometimes called biological chemistry, is the study of chemical processes within and relating to living organisms. By controlling information flow through biochemical signaling and the flow of chemical energy through metabolism, biochemical processes give rise to the complexity of life. Over the last 40 years, biochemistry has become so successful at explaining living processes that now almost all areas of the life sciences from botany to medicine are engaged in biochemical research. Today, the main focus of pure biochemistry is in understanding how biological molecules give rise to the processes that occur within living cells, which in turn relates greatly to the study and understanding of whole organisms.
Biochemistry is closely related to molecular biology, the study of the molecular mechanisms by which genetic information encoded in DNA is able to result in the processes of life. Depending on the exact definition of the terms used, molecular biology can be thought of as a branch of biochemistry, or biochemistry as a tool with which to investigate and study molecular biology.
Much of biochemistry deals with the structures, functions and interactions of biological macromolecules, such as proteins, nucleic acids, carbohydrates and lipids, which provide the structure of cells and perform many of the functions associated with life. The chemistry of the cell also depends on the reactions of smaller molecules and ions. These can be inorganic, for example water and metal ions, or organic, for example the amino acids which are used to synthesize proteins. The mechanisms by which cells harness energy from their environment via chemical reactions are known as metabolism. The findings of biochemistry are applied primarily in medicine, nutrition, and agriculture. In medicine, biochemists investigate the causes and cures of disease. In nutrition, they study how to maintain health and study the effects of nutritional deficiencies. In agriculture, biochemists investigate soil and fertilizers, and try to discover ways to improve crop cultivation, crop storage and pest control.
History.
It once was generally believed that life and its materials had some essential property or substance distinct from any found in non-living matter, and it was thought that only living beings could produce the molecules of life. Then, in 1828, Friedrich Wöhler published a paper on the synthesis of urea, proving that organic compounds can be created artificially.
The dawn of biochemistry may have been the discovery of the first enzyme, diastase (today called amylase), in 1833 by Anselme Payen. Eduard Buchner contributed the first demonstration of a complex biochemical process outside a cell in 1896: alcoholic fermentation in cell extracts of yeast. Although the term "biochemistry" seems to have been first used in 1882, it is generally accepted that the formal coinage of biochemistry occurred in 1903 by Carl Neuberg, a German chemist. Since then, biochemistry has advanced, especially since the mid-20th century, with the development of new techniques such as chromatography, X-ray diffraction, dual polarisation interferometry, NMR spectroscopy, radioisotopic labeling, electron microscopy, and molecular dynamics simulations. These techniques allowed for the discovery and detailed analysis of many molecules and metabolic pathways of the cell, such as glycolysis and the Krebs cycle (citric acid cycle).
Another significant historic event in biochemistry is the discovery of the gene and its role in the transfer of information in the cell. This part of biochemistry is often called molecular biology. In the 1950s, James D. Watson, Francis Crick, Rosalind Franklin, and Maurice Wilkins were instrumental in solving DNA structure and suggesting its relationship with genetic transfer of information. In 1958, George Beadle and Edward Tatum received the Nobel Prize for work in fungi showing that one gene produces one enzyme. In 1988, Colin Pitchfork was the first person convicted of murder with DNA evidence, which led to growth of forensic science. More recently, Andrew Z. Fire and Craig C. Mello received the 2006 Nobel Prize for discovering the role of RNA interference (RNAi), in the silencing of gene expression.
Starting materials: the chemical elements of life.
Around two dozen of the 92 naturally occurring chemical elements are essential to various kinds of biological life. Most rare elements on Earth are not needed by life (exceptions being selenium and iodine), while a few common ones (aluminum and titanium) are not used. Most organisms share element needs, but there are a few differences between plants and animals. For example ocean algae use bromine but land plants and animals seem to need none. All animals require sodium, but some plants do not. Plants need boron and silicon, but animals may not (or may need ultra-small amounts).
Just six elements—carbon, hydrogen, nitrogen, oxygen, calcium, and phosphorus—make up almost 99% of the mass of a human body (see composition of the human body for a complete list). In addition to the six major elements that compose most of the human body, humans require smaller amounts of possibly 18 more.
Biomolecules.
The four main classes of molecules in biochemistry (often called biomolecules) are carbohydrates, lipids, proteins, and nucleic acids. Many biological molecules are polymers: in this terminology, monomers are relatively small micromolecules that are linked together to create large macromolecules known as polymers. When monomers are linked together to synthesize a biological polymer, they undergo a process called dehydration synthesis. Different macromolecules can assemble in larger complexes, often needed for biological activity.
Carbohydrates.
Carbohydrates are made from monomers called "monosaccharides". Some of these monosaccharides include glucose (C6H12O6), fructose (C6H12O6), and deoxyribose (C5H10O4). When two monosaccharides undergo dehydration synthesis, water is produced, as two hydrogen atoms and one oxygen atom are lost from the two monosaccharides' hydroxyl group.
Lipids.
Lipids are usually made from one molecule of glycerol combined with other molecules. In triglycerides, the main group of bulk lipids, there is one molecule of glycerol and three fatty acids. Fatty acids are considered the monomer in that case, and may be saturated (no double bonds in the carbon chain) or unsaturated (one or more double bonds in the carbon chain).
Lipids, especially phospholipids, are also used in various pharmaceutical products, either as co-solubilisers (e.g., in parenteral infusions) or else as drug carrier components (e.g., in a liposome or transfersome).
Proteins.
Proteins are very large molecules – macro-biopolymers – made from monomers called "amino acids". There are 20 standard amino acids, each containing a carboxyl group, an amino group, and a side-chain (known as an "R" group). The "R" group is what makes each amino acid different, and the properties of the side-chains greatly influence the overall three-dimensional conformation of a protein. When amino acids combine, they form a special bond called a peptide bond through dehydration synthesis, and become a polypeptide, or protein.
In order to determine whether two proteins are related, or in other words to decide whether they are homologous or not, scientists use sequence-comparison methods. Methods like Sequence Alignments and Structural Alignments are powerful tools that help scientists identify homologies between related molecules.
The relevance of finding homologies among proteins goes beyond forming an evolutionary pattern of protein families. By finding how similar two protein sequences are, we acquire knowledge about their structure and therefore their function.
Nucleic acids.
Nucleic acids are the molecules that make up DNA, an extremely important substance that all cellular organisms use to store their genetic information. The most common nucleic acids are deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). Their monomers are called nucleotides. A nucleotide consists of a phosphate group, a ribose sugar, and a nitrogenous base. The phosphate group and the sugar of each nucleotide bond with each other to form the backbone of the nucleic acid, while the sequence of nitrogenous bases stores the information. The most common nitrogenous bases are adenine, cytosine, guanine, thymine, and uracil. The nitrogenous bases of each strand of a nucleic acid will form hydrogen bonds with certain other nitrogenous bases in a complimentary strand of nucleic acid (similar to a zipper). Adenine binds with thymine and uracil; Thymine binds only with adenine; and cytosine and guanine can bind only with one another.
Carbohydrates.
The function of carbohydrates includes energy storage and providing structure. Sugars are carbohydrates, but not all carbohydrates are sugars. There are more carbohydrates on Earth than any other known type of biomolecule; they are used to store energy and genetic information, as well as play important roles in cell to cell interactions and communications.
Monosaccharides.
The simplest type of carbohydrate is a monosaccharide, which between other properties contains carbon, hydrogen, and oxygen, mostly in a ratio of 1:2:1 (generalized formula C"n"H2"n"O"n", where "n" is at least 3). Glucose, one of the most important carbohydrates, is an example of a monosaccharide. So is fructose, the sugar commonly associated with the sweet taste of fruits. Some carbohydrates (especially after condensation to oligo- and polysaccharides) contain less carbon relative to H and O, which still are present in 2:1 (H:O) ratio. Monosaccharides can be grouped into aldoses (having an aldehyde group at the end of the chain, e.g. glucose) and ketoses (having a keto group in their chain; e.g. fructose). Both aldoses and ketoses occur in an equilibrium (starting with chain lengths of C4) cyclic forms. These are generated by bond formation between one of the hydroxyl groups of the sugar chain with the carbon of the aldehyde or keto group to form a hemiacetal bond. This leads to saturated five-membered (in furanoses) or six-membered (in pyranoses) heterocyclic rings containing one O as heteroatom.
Disaccharides.
Two monosaccharides can be joined using dehydration synthesis, in which a hydrogen atom is removed from the end of one molecule and a hydroxyl group (—OH) is removed from the other; the remaining residues are then attached at the sites from which the atoms were removed. The H—OH or H2O is then released as a molecule of water, hence the term "dehydration". The new molecule, consisting of two monosaccharides, is called a "disaccharide" and is conjoined together by a glycosidic or ether bond. The reverse reaction can also occur, using a molecule of water to split up a disaccharide and break the glycosidic bond; this is termed "hydrolysis". The most well-known disaccharide is sucrose, ordinary sugar (in scientific contexts, called "table sugar" or "cane sugar" to differentiate it from other sugars). Sucrose consists of a glucose molecule and a fructose molecule joined together. Another important disaccharide is lactose, consisting of a glucose molecule and a galactose molecule. As most humans age, the production of lactase, the enzyme that hydrolyzes lactose back into glucose and galactose, typically decreases. This results in lactase deficiency, also called "lactose intolerance".
Sugar polymers are characterized by having reducing or non-reducing ends. A reducing end of a carbohydrate is a carbon atom that can be in equilibrium with the open-chain aldehyde or keto form. If the joining of monomers takes place at such a carbon atom, the free hydroxy group of the pyranose or furanose form is exchanged with an OH-side-chain of another sugar, yielding a full acetal. This prevents opening of the chain to the aldehyde or keto form and renders the modified residue non-reducing. Lactose contains a reducing end at its glucose moiety, whereas the galactose moiety form a full acetal with the C4-OH group of glucose. Saccharose does not have a reducing end because of full acetal formation between the aldehyde carbon of glucose (C1) and the keto carbon of fructose (C2).
Oligosaccharides and polysaccharides.
When a few (around three to six) monosaccharides are joined, it is called an "oligosaccharide" ("oligo-" meaning "few"). These molecules tend to be used as markers and signals, as well as having some other uses. Many monosaccharides joined together make a polysaccharide. They can be joined together in one long linear chain, or they may be branched. Two of the most common polysaccharides are cellulose and glycogen, both consisting of repeating glucose monomers.
Use of carbohydrates as an energy source.
Glucose is the major energy source in most life forms. For instance, polysaccharides are broken down into their monomers (glycogen phosphorylase removes glucose residues from glycogen). Disaccharides like lactose or sucrose are cleaved into their two component monosaccharides.
Glycolysis (anaerobic).
Glucose is mainly metabolized by a very important ten-step pathway called glycolysis, the net result of which is to break down one molecule of glucose into two molecules of pyruvate; this also produces a net two molecules of ATP, the energy currency of cells, along with two reducing equivalents as converting NAD+ to NADH. This does not require oxygen; if no oxygen is available (or the cell cannot use oxygen), the NAD is restored by converting the pyruvate to lactate (lactic acid) (e.g., in humans) or to ethanol plus carbon dioxide (e.g., in yeast). Other monosaccharides like galactose and fructose can be converted into intermediates of the glycolytic pathway.
Aerobic.
In aerobic cells with sufficient oxygen, as in most human cells, the pyruvate is further metabolized. It is irreversibly converted to acetyl-CoA, giving off one carbon atom as the waste product carbon dioxide, generating another reducing equivalent as NADH. The two molecules acetyl-CoA (from one molecule of glucose) then enter the citric acid cycle, producing two more molecules of ATP, six more NADH molecules and two reduced (ubi)quinones (via FADH2 as enzyme-bound cofactor), and releasing the remaining carbon atoms as carbon dioxide. The produced NADH and quinol molecules then feed into the enzyme complexes of the respiratory chain, an electron transport system transferring the electrons ultimately to oxygen and conserving the released energy in the form of a proton gradient over a membrane (inner mitochondrial membrane in eukaryotes). Thus, oxygen is reduced to water and the original electron acceptors NAD+ and quinone are regenerated. This is why humans breathe in oxygen and breathe out carbon dioxide. The energy released from transferring the electrons from high-energy states in NADH and quinol is conserved first as proton gradient and converted to ATP via ATP synthase. This generates an additional "28" molecules of ATP (24 from the 8 NADH + 4 from the 2 quinols), totaling to 32 molecules of ATP conserved per degraded glucose (two from glycolysis + two from the citrate cycle). It is clear that using oxygen to completely oxidize glucose provides an organism with far more energy than any oxygen-independent metabolic feature, and this is thought to be the reason why complex life appeared only after Earth's atmosphere accumulated large amounts of oxygen.
Gluconeogenesis.
In vertebrates, vigorously contracting skeletal muscles (during weightlifting or sprinting, for example) do not receive enough oxygen to meet the energy demand, and so they shift to anaerobic metabolism, converting glucose to lactate. The liver regenerates the glucose, using a process called gluconeogenesis. This process is not quite the opposite of glycolysis, and actually requires three times the amount of energy gained from glycolysis (six molecules of ATP are used, compared to the two gained in glycolysis). Analogous to the above reactions, the glucose produced can then undergo glycolysis in tissues that need energy, be stored as glycogen (or starch in plants), or be converted to other monosaccharides or joined into di- or oligosaccharides. The combined pathways of glycolysis during exercise, lactate's crossing via the bloodstream to the liver, subsequent gluconeogenesis and release of glucose into the bloodstream is called the Cori cycle.
Proteins.
Like carbohydrates, some proteins perform largely structural roles. For instance, movements of the proteins actin and myosin ultimately are responsible for the contraction of skeletal muscle. One property many proteins have is that they specifically bind to a certain molecule or class of molecules—they may be "extremely" selective in what they bind. Antibodies are an example of proteins that attach to one specific type of molecule. In fact, the enzyme-linked immunosorbent assay (ELISA), which uses antibodies, is one of the most sensitive tests modern medicine uses to detect various biomolecules. Probably the most important proteins, however, are the enzymes. These molecules recognize specific reactant molecules called "substrates"; they then catalyze the reaction between them. By lowering the activation energy, the enzyme speeds up that reaction by a rate of 1011 or more: a reaction that would normally take over 3,000 years to complete spontaneously might take less than a second with an enzyme. The enzyme itself is not used up in the process, and is free to catalyze the same reaction with a new set of substrates. Using various modifiers, the activity of the enzyme can be regulated, enabling control of the biochemistry of the cell as a whole.
In essence, proteins are chains of amino acids. An amino acid consists of a carbon atom bound to four groups. One is an amino group, —NH2, and one is a carboxylic acid group, —COOH (although these exist as —NH3+ and —COO− under physiologic conditions). The third is a simple hydrogen atom. The fourth is commonly denoted "—R" and is different for each amino acid. There are 20 standard amino acids. Some of these have functions by themselves or in a modified form; for instance, glutamate functions as an important neurotransmitter. Also if a glycine amino acid undergoes methylation to a pseudo alanine amino acid, it is an indication of cancer metastasis. 
Amino acids can be joined via a peptide bond. In this dehydration synthesis, a water molecule is removed and the peptide bond connects the nitrogen of one amino acid's amino group to the carbon of the other's carboxylic acid group. The resulting molecule is called a "dipeptide", and short stretches of amino acids (usually, fewer than thirty) are called "peptides" or polypeptides. Longer stretches merit the title "proteins". As an example, the important blood serum protein albumin contains 585 amino acid residues.
The structure of proteins is traditionally described in a hierarchy of four levels. The primary structure of a protein simply consists of its linear sequence of amino acids; for instance, "alanine-glycine-tryptophan-serine-glutamate-asparagine-glycine-lysine-…". Secondary structure is concerned with local morphology (morphology being the study of structure). Some combinations of amino acids will tend to curl up in a coil called an α-helix or into a sheet called a β-sheet; some α-helixes can be seen in the hemoglobin schematic above. Tertiary structure is the entire three-dimensional shape of the protein. This shape is determined by the sequence of amino acids. In fact, a single change can change the entire structure. The alpha chain of hemoglobin contains 146 amino acid residues; substitution of the glutamate residue at position 6 with a valine residue changes the behavior of hemoglobin so much that it results in sickle-cell disease. Finally, quaternary structure is concerned with the structure of a protein with multiple peptide subunits, like hemoglobin with its four subunits. Not all proteins have more than one subunit.
Ingested proteins are usually broken up into single amino acids or dipeptides in the small intestine, and then absorbed. They can then be joined to make new proteins. Intermediate products of glycolysis, the citric acid cycle, and the pentose phosphate pathway can be used to make all twenty amino acids, and most bacteria and plants possess all the necessary enzymes to synthesize them. Humans and other mammals, however, can synthesize only half of them. They cannot synthesize isoleucine, leucine, lysine, methionine, phenylalanine, threonine, tryptophan, and valine. These are the essential amino acids, since it is essential to ingest them. Mammals do possess the enzymes to synthesize alanine, asparagine, aspartate, cysteine, glutamate, glutamine, glycine, proline, serine, and tyrosine, the nonessential amino acids. While they can synthesize arginine and histidine, they cannot produce it in sufficient amounts for young, growing animals, and so these are often considered essential amino acids.
If the amino group is removed from an amino acid, it leaves behind a carbon skeleton called an α-keto acid. Enzymes called transaminases can easily transfer the amino group from one amino acid (making it an α-keto acid) to another α-keto acid (making it an amino acid). This is important in the biosynthesis of amino acids, as for many of the pathways, intermediates from other biochemical pathways are converted to the α-keto acid skeleton, and then an amino group is added, often via transamination. The amino acids may then be linked together to make a protein.
A similar process is used to break down proteins. It is first hydrolyzed into its component amino acids. Free ammonia (NH3), existing as the ammonium ion (NH4+) in blood, is toxic to life forms. A suitable method for excreting it must therefore exist. Different tactics have evolved in different animals, depending on the animals' needs. Unicellular organisms, of course, simply release the ammonia into the environment. Likewise, bony fish can release the ammonia into the water where it is quickly diluted. In general, mammals convert the ammonia into urea, via the urea cycle.
Lipids.
The term lipid composes a diverse range of molecules and to some extent is a catchall for relatively water-insoluble or nonpolar compounds of biological origin, including waxes, fatty acids, fatty-acid derived phospholipids, sphingolipids, glycolipids, and terpenoids (e.g., retinoids and steroids). Some lipids are linear aliphatic molecules, while others have ring structures. Some are aromatic, while others are not. Some are flexible, while others are rigid.
Most lipids have some polar character in addition to being largely nonpolar. In general, the bulk of their structure is nonpolar or hydrophobic ("water-fearing"), meaning that it does not interact well with polar solvents like water. Another part of their structure is polar or hydrophilic ("water-loving") and will tend to associate with polar solvents like water. This makes them amphiphilic molecules (having both hydrophobic and hydrophilic portions). In the case of cholesterol, the polar group is a mere -OH (hydroxyl or alcohol). In the case of phospholipids, the polar groups are considerably larger and more polar, as described below.
Lipids are an integral part of our daily diet. Most oils and milk products that we use for cooking and eating like butter, cheese, ghee etc., are composed of fats. Vegetable oils are rich in various polyunsaturated fatty acids (PUFA). Lipid-containing foods undergo digestion within the body and are broken into fatty acids and glycerol, which are the final degradation products of fats and lipids.
Nucleic acids.
A nucleic acid is a complex, high-molecular-weight biochemical macromolecule composed of nucleotide chains that convey genetic information. The most common nucleic acids are deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). Nucleic acids are found in all living cells and viruses. Aside from the genetic material of the cell, nucleic acids often play a role as second messengers, as well as forming the base molecule for adenosine triphosphate (ATP), the primary energy-carrier molecule found in all living organisms.
Nucleic acid, so called because of its prevalence in cellular nuclei, is the generic name of the family of biopolymers. The monomers are called nucleotides, and each consists of three components: a nitrogenous heterocyclic base (either a purine or a pyrimidine), a pentose sugar, and a phosphate group. Different nucleic acid types differ in the specific sugar found in their chain (e.g., DNA or deoxyribonucleic acid contains 2-deoxyriboses). Also, the nitrogenous bases possible in the two nucleic acids are different: adenine, cytosine, and guanine occur in both RNA and DNA, while thymine occurs only in DNA and uracil occurs in RNA.
Relationship to other "molecular-scale" biological sciences.
Researchers in biochemistry use specific techniques native to biochemistry, but increasingly combine these with techniques and ideas developed in the fields of genetics, molecular biology and biophysics. There has never been a hard-line among these disciplines in terms of content and technique. Today, the terms "molecular biology" and "biochemistry" are nearly interchangeable. The following figure is a schematic that depicts one possible view of the relationship between the fields:
Notes.
a. Fructose is not the only sugar found in fruits. Glucose and sucrose are also found in varying quantities in various fruits, and indeed sometimes exceed the fructose present. For example, 32% of the edible portion of date is glucose, compared with 23.70% fructose and 8.20% sucrose. However, peaches contain more sucrose (6.66%) than they do fructose (0.93%) or glucose (1.47%).

</doc>
<doc id="3956" url="http://en.wikipedia.org/wiki?curid=3956" title="Badminton">
Badminton

Badminton is a racquet sport played by either two opposing players (singles) or two opposing pairs (doubles), who take positions on opposite halves of a rectangular court divided by a net. Players score points by striking a shuttlecock with their racquet so that it passes over the net and lands in their opponents' half of the court. Each side may only strike the shuttlecock once before it passes over the net. A rally ends once the shuttlecock has struck the floor, or if a fault has been called by either the umpire or service judge or, in their absence, the offending player, at any time during the rally.
The shuttlecock (or shuttle) is a feathered (or, mainly in uncompetitive games, plastic) projectile whose unique aerodynamic properties cause it to fly differently from the balls used in most racquet sports; in particular, the feathers create much higher drag, causing the shuttlecock to decelerate more rapidly than a ball. Shuttlecocks have a much higher top speed, when compared to other racquet sports. Because shuttlecock flight is affected by wind, competitive badminton is played indoors. Badminton is also played outdoors as a casual recreational activity, often as a garden or beach game.
Since 1992, badminton has been an Olympic sport with five events: men's and women's singles, men's and women's doubles, and mixed doubles, in which each pair consists of a man and a woman. At high levels of play, especially in singles, the sport demands excellent fitness: players require aerobic stamina, agility, explosive strength, speed and precision. It is also a technical sport, requiring good motor coordination and the development of sophisticated racquet movements.
History and development.
The beginnings of badminton can be traced to the mid-1800s in British India, where it was created by British military officers stationed there. Early photographs show Englishmen adding a net to the traditional English game of battledore and shuttlecock. The sport is related to ball badminton, which originated in Tamil Nadu, and is similar to Hanetsuki which originated in Japan. Being particularly popular in the British garrison town Poona (now Pune), the game also came to be known as "Poona". Initially, balls of wool referred as ball badminton were preferred by the upper classes in windy or wet conditions, but ultimately the shuttlecock stuck. This game was taken by retired officers back to England where it developed and rules were set out.
Although it appears clear that Badminton House, Gloucestershire, owned by the Duke of Beaufort, has given its name to the sports, it is unclear when and why the name was adopted. As early as 1860, Isaac Spratt, a London toy dealer, published a booklet, "Badminton Battledore – a new game", but unfortunately no copy has survived. An 1863 article in "The Cornhill Magazine" describes badminton as "battledore and shuttlecock played with sides, across a string suspended some five feet from the ground". This early use has cast doubt on the origin through expatriates in India, though it is known that it was popular there in the 1870s and that the first rules were drawn up in Poonah in 1873. Another source cites that it was in 1877 at Karachi in (British) India, where the first attempt was made to form a set of rules.
As early as 1875, veterans returning from India started a club in Folkestone. Until 1887, the sport was played in England under the rules that prevailed in British India. The Bath Badminton Club standardized the rules and made the game applicable to English ideas. J.H.E. Hart drew up revised basic regulations in 1887 and, with Bagnel Wild, again in 1890. In 1893, the Badminton Association of England published the first set of rules according to these regulations, similar to today's rules, and officially launched badminton in a house called "Dunbar" at 6 Waverley Grove, Portsmouth, England on September 13 of that year. They also started the All England Open Badminton Championships, the first badminton competition in the world, in 1899.
The International Badminton Federation (IBF) (now known as Badminton World Federation) was established in 1934 with Canada, Denmark, England, France, the Netherlands, Ireland, New Zealand, Scotland, and Wales as its founding members. India joined as an affiliate in 1936. The BWF now governs international badminton and develops the sport globally.
While initiated in England, competitive men's badminton in Europe has traditionally been dominated by Denmark. Asian nations, however, have been the most dominant ones worldwide. China, Indonesia, South Korea, and Malaysia along with Denmark are among the nations that have consistently produced world-class players in the past few decades, with China being the greatest force in both men's and women's competition in recent years.
Rules.
The following information is a simplified summary of badminton rules based on the BWF Statutes publication, "Laws of Badminton".
Playing court dimensions.
The court is rectangular and divided into halves by a net. Courts are usually marked for both singles and doubles play, although badminton rules permit a court to be marked for singles only. The doubles court is wider than the singles court, but both are of same length. The exception, which often causes confusion to newer players, is that the doubles court has a shorter serve-length dimension.
The full width of the court is 6.1 metres (20 ft), and in singles this width is reduced to 5.18 metres (17 ft). The full length of the court is 13.4 metres (44 ft). The service courts are marked by a centre line dividing the width of the court, by a short service line at a distance of 1.98 metres (6 ft 6 inch) from the net, and by the outer side and back boundaries. In doubles, the service court is also marked by a long service line, which is 0.76 metres (2 ft 6 inch) from the back boundary.
The net is 1.55 metres (5 ft 1 inch) high at the edges and 1.524 metres (5 ft) high in the centre. The net posts are placed over the doubles sidelines, even when singles is played.
The minimum height for the ceiling above the court is not mentioned in the Laws of Badminton. Nonetheless, a badminton court will not be suitable if the ceiling is likely to be hit on a high serve.
Equipment rules.
Badminton rules restrict the design and size of racquets and shuttlecocks. Badminton rules also provide for testing a shuttlecock for the correct speed:
Scoring system and service.
Serving.
Each game is played to 21 points, with players scoring a point whenever they win a rally regardless of whether they served (this differs from the old system where players could only win a point on their serve and each game was played to 15 points). A match is the best of three games.
At the start of the rally, the server and receiver stand in diagonally opposite "service courts" (see court dimensions). The server hits the shuttlecock so that it would land in the receiver's service court. This is similar to tennis, except that a badminton serve must be hit below waist height and with the racquet shaft pointing downwards, the shuttlecock is not allowed to bounce and in badminton, the players stand inside their service courts unlike tennis.
When the serving side loses a rally, the serve immediately passes to their opponent(s) (this differs from the old system where sometimes the serve passes to the doubles partner for what is known as a "second serve").
In singles, the server stands in their right service court when their score is even, and in her/his left service court when her/his score is odd.
In doubles, if the serving side wins a rally, the same player continues to serve, but he/she changes service courts so that she/he serves to a different opponent each time. If the opponents win the rally and their new score is even, the player in the right service court serves; if odd, the player in the left service court serves. The players' service courts are determined by their positions at the start of the previous rally, not by where they were standing at the end of the rally. A consequence of this system is that, each time a side regains the service, the server will be the player who did "not" serve last time.
Scoring.
When the server serves, the shuttlecock must pass over the short service line on the opponents' court or it will count as a fault.
If the score reaches 20-all, then the game continues until one side gains a two point lead (such as 24–22), up to a maximum of 30 points (30–29 is a winning score).
At the start of a match, the shuttlecock is cast and the side towards which the shuttlecock is pointing serves first. Alternatively, a coin may be tossed, with the winners choosing whether to serve or receive first, or choosing which end of the court to occupy, and their opponents making the leftover the remaining choice.
In subsequent games, the winners of the previous game serve first. Matches are best out of three: a player or pair must win two games (of 21 points each) to win the match. For the first rally of any doubles game, the serving pair may decide who serves and the receiving pair may decide who receives. The players change ends at the start of the second game; if the match reaches a third game, they change ends both at the start of the game and when the leading player's or pair's score reaches 11 points.
The server and receiver must remain within their service courts, without touching the boundary lines, until the server strikes the shuttlecock. The other two players may stand wherever they wish, so long as they do not block the vision of the server or receiver.
Lets.
If a let is called, the rally is stopped and replayed with no change to the score. Lets may occur because of some unexpected disturbance such as a shuttlecock landing on court (having been hit there by players on an adjacent court) or in small halls the shuttle may touch an overhead rail which can be classed as a let.
If the receiver is not ready when the service is delivered, a let shall be called; yet, if the receiver attempts to return the shuttlecock, he shall be judged to have been ready.
Equipment.
Rackets.
Badminton rackets are lightweight, with top quality racquets weighing between 70 and 95 grams (2.4 to 3.3 ounces) not including grip or strings. They are composed of many different materials ranging from carbon fibre composite (graphite reinforced plastic) to solid steel, which may be augmented by a variety of materials. Carbon fibre has an excellent strength to weight ratio, is stiff, and gives excellent kinetic energy transfer. Before the adoption of carbon fibre composite, racquets were made of light metals such as aluminium. Earlier still, racquets were made of wood. Cheap racquets are still often made of metals such as steel, but wooden racquets are no longer manufactured for the ordinary market, because of their excessive mass and cost. Nowadays, nanomaterials such as fullerene and carbon nanotubes are added to rackets giving them greater durability.
There is a wide variety of racquet designs, although the laws limit the racquet size and shape. Different racquets have playing characteristics that appeal to different players. The traditional oval head shape is still available, but an isometric head shape is increasingly common in new racquets.
Strings.
Badminton strings are thin, high performing strings in the range of about 0.62 to 0.73 mm thickness. Thicker strings are more durable, but many players prefer the feel of thinner strings. String tension is normally in the range of 80 to 160 N (18 to 36 lbf). Recreational players generally string at lower tensions than professionals, typically between 80 and 110 N (18 and 25 lbf). Professionals string between about 110 and 160 N (25 and 36 lbf). Some string manufacturers measure the thickness of their strings under tension so they are actually thicker than specified when slack. Ashaway Micropower is actually 0.7mm but Yonex BG-66 is about 0.72mm.
It is often argued that high string tensions improve control, whereas low string tensions increase power. The arguments for this generally rely on crude mechanical reasoning, such as claiming that a lower tension string bed is more bouncy and therefore provides more power. This is in fact incorrect, for a higher string tension can cause the shuttle to slide off the racquet and hence make it harder to hit a shot accurately. An alternative view suggests that the optimum tension for power depends on the player: the faster and more accurately a player can swing their racquet, the higher the tension for maximum power. Neither view has been subjected to a rigorous mechanical analysis, nor is there clear evidence in favour of one or the other. The most effective way for a player to find a good string tension is to experiment.
Grip.
The choice of grip allows a player to increase the thickness of their racquet handle and choose a comfortable surface to hold. A player may build up the handle with one or several grips before applying the final layer.
Players may choose between a variety of grip materials. The most common choices are PU synthetic grips or towelling grips. Grip choice is a matter of personal preference. Players often find that sweat becomes a problem; in this case, a drying agent may be applied to the grip or hands, sweatbands may be used, the player may choose another grip material or change his/her grip more frequently.
There are two main types of grip: "replacement" grips and "overgrips". Replacement grips are thicker, and are often used to increase the size of the handle. Overgrips are thinner (less than 1 mm), and are often used as the final layer. Many players, however, prefer to use replacement grips as the final layer. Towelling grips are always replacement grips. Replacement grips have an adhesive backing, whereas overgrips have only a small patch of adhesive at the start of the tape and must be applied under tension; overgrips are more convenient for players who change grips frequently, because they may be removed more rapidly without damaging the underlying material.
Shuttlecock.
A shuttlecock (often abbreviated to "shuttle"; also called a "birdie") is a high-drag projectile, with an open conical shape: the cone is formed from sixteen overlapping feathers embedded into a rounded cork base. The cork is covered with thin leather or synthetic material.
Synthetic shuttles are often used by recreational players to reduce their costs as feathered shuttles break easily. These nylon shuttles may be constructed with either natural cork or synthetic foam base, and a plastic skirt.
Shoes.
Badminton shoes are lightweight with soles of rubber or similar high-grip, non-marking materials.
Compared to running shoes, badminton shoes have little lateral support. High levels of lateral support are useful for activities where lateral motion is undesirable and unexpected. Badminton, however, requires powerful lateral movements. A highly built-up lateral support will not be able to protect the foot in badminton; instead, it will encourage catastrophic collapse at the point where the shoe's support fails, and the player's ankles are not ready for the sudden loading, which can cause sprains. For this reason, players should choose badminton shoes rather than general trainers or running shoes, because proper badminton shoes will have a very thin sole, lower a person's centre of gravity, and therefore result in fewer injuries. Players should also ensure that they learn safe and proper footwork, with the knee and foot in alignment on all lunges. This is more than just a safety concern: proper footwork is also critical in order to move effectively around the court.
Strokes.
Forehand and backhand.
Badminton offers a wide variety of basic strokes, and players require a high level of skill to perform all of them effectively. All strokes can be played either "forehand" or "backhand". A player's forehand side is the same side as their playing hand: for a right-handed player, the forehand side is their right side and the backhand side is their left side. Forehand strokes are hit with the front of the hand leading (like hitting with the palm), whereas backhand strokes are hit with the back of the hand leading (like hitting with the knuckles). Players frequently play certain strokes on the forehand side with a backhand hitting action, and vice versa.
In the forecourt and midcourt, most strokes can be played equally effectively on either the forehand or backhand side; but in the rear court, players will attempt to play as many strokes as possible on their forehands, often preferring to play a "round-the-head" forehand overhead (a forehand "on the backhand side") rather than attempt a backhand overhead. Playing a backhand overhead has two main disadvantages. First, the player must turn their back to their opponents, restricting their view of them and the court. Second, backhand overheads cannot be hit with as much power as forehands: the hitting action is limited by the shoulder joint, which permits a much greater range of movement for a forehand overhead than for a backhand. The "backhand clear" is considered by most players and coaches to be the most difficult basic stroke in the game, since precise technique is needed in order to muster enough power for the shuttlecock to travel the full length of the court. For the same reason, "backhand smashes" tend to be weak.
Position of the shuttlecock and receiving player.
The choice of stroke depends on how near the shuttlecock is to the net, whether it is above net height, and where an opponent is currently positioned: players have much better attacking options if they can reach the shuttlecock well above net height, especially if it is also close to the net. In the forecourt, a high shuttlecock will be met with a "net kill", hitting it steeply downwards and attempting to win the rally immediately. This is why it is best to drop the shuttlecock just over the net in this situation. In the midcourt, a high shuttlecock will usually be met with a powerful "smash", also hitting downwards and hoping for an outright winner or a weak reply. Athletic "jump smashes", where players jump upwards for a steeper smash angle, are a common and spectacular element of elite men's doubles play. In the rearcourt, players strive to hit the shuttlecock while it is still above them, rather than allowing it to drop lower. This "overhead" hitting allows them to play smashes, "clears" (hitting the shuttlecock high and to the back of the opponents' court), and dropshots (hitting the shuttlecock so that it falls softly downwards into the opponents' forecourt). If the shuttlecock has dropped lower, then a smash is impossible and a full-length, high clear is difficult.
Vertical position of the shuttlecock.
When the shuttlecock is well below net height, players have no choice but to hit upwards. "Lifts", where the shuttlecock is hit upwards to the back of the opponents' court, can be played from all parts of the court. If a player does not lift, his only remaining option is to push the shuttlecock softly back to the net: in the forecourt this is called a "netshot"; in the midcourt or rearcourt, it is often called a "push" or "block".
When the shuttlecock is near to net height, players can hit "drives", which travel flat and rapidly over the net into the opponents' rear midcourt and rearcourt. Pushes may also be hit flatter, placing the shuttlecock into the front midcourt. Drives and pushes may be played from the midcourt or forecourt, and are most often used in doubles: they are an attempt to regain the attack, rather than choosing to lift the shuttlecock and defend against smashes. After a successful drive or push, the opponents will often be forced to lift the shuttlecock.
Other factors.
When defending against a smash, players have three basic options: lift, block, or drive. In singles, a block to the net is the most common reply. In doubles, a lift is the safest option but it usually allows the opponents to continue smashing; blocks and drives are counter-attacking strokes, but may be intercepted by the smasher's partner. Many players use a backhand hitting action for returning smashes on both the forehand and backhand sides, because backhands are more effective than forehands at covering smashes directed to the body. Hard shots directed towards the body are difficult to defend.
The service is restricted by the Laws and presents its own array of stroke choices. Unlike in tennis, the server's racket must be pointing in a downward direction to deliver the serve so normally the shuttle must be hit upwards to pass over the net. The server can choose a "low serve" into the forecourt (like a push), or a lift to the back of the service court, or a flat "drive serve". Lifted serves may be either "high serves", where the shuttlecock is lifted so high that it falls almost vertically at the back of the court, or "flick serves", where the shuttlecock is lifted to a lesser height but falls sooner.
Deception.
Once players have mastered these basic strokes, they can hit the shuttlecock from and to any part of the court, powerfully and softly as required. Beyond the basics, however, badminton offers rich potential for advanced stroke skills that provide a competitive advantage. Because badminton players have to cover a short distance as quickly as possible, the purpose of many advanced strokes is to deceive the opponent, so that either he is tricked into believing that a different stroke is being played, or he is forced to delay his movement until he actually sees the shuttle's direction. "Deception" in badminton is often used in both of these senses. When a player is genuinely deceived, he will often lose the point immediately because he cannot change his direction quickly enough to reach the shuttlecock. Experienced players will be aware of the trick and cautious not to move too early, but the attempted deception is still useful because it forces the opponent to delay his movement slightly. Against weaker players whose intended strokes are obvious, an experienced player may move before the shuttlecock has been hit, anticipating the stroke to gain an advantage.
"Slicing" and using a "shortened hitting action" are the two main technical devices that facilitate deception. Slicing involves hitting the shuttlecock with an angled racquet face, causing it to travel in a different direction than suggested by the body or arm movement. Slicing also causes the shuttlecock to travel more slowly than the arm movement suggests. For example, a good crosscourt "sliced dropshot" will use a hitting action that suggests a straight clear or smash, deceiving the opponent about both the power and direction of the shuttlecock. A more sophisticated slicing action involves brushing the strings around the shuttlecock during the hit, in order to make the shuttlecock spin. This can be used to improve the shuttle's trajectory, by making it dip more rapidly as it passes the net; for example, a sliced low serve can travel slightly faster than a normal low serve, yet land on the same spot. Spinning the shuttlecock is also used to create "spinning netshots" (also called "tumbling netshots"), in which the shuttlecock turns over itself several times (tumbles) before stabilizing; sometimes the shuttlecock remains inverted instead of tumbling. The main advantage of a spinning netshot is that the opponent will be unwilling to address the shuttlecock until it has stopped tumbling, since hitting the feathers will result in an unpredictable stroke. Spinning netshots are especially important for high level singles players.
The lightness of modern racquets allows players to use a very short hitting action for many strokes, thereby maintaining the option to hit a powerful or a soft stroke until the last possible moment. For example, a singles player may hold his racquet ready for a netshot, but then flick the shuttlecock to the back instead with a shallow lift when she or he notices the opponent has moved before the actual shot was played. A shallow lift takes less time to reach the ground and as mentioned above a rally is over when the shuttlecock touches the ground. This makes the opponent's task of covering the whole court much more difficult than if the lift was hit higher and with a bigger, obvious swing. A short hitting action is not only useful for deception: it also allows the player to hit powerful strokes when he has no time for a big arm swing. A big arm swing is also usually not advised in badminton because bigger swings make it more difficult to recover for the next shot in fast exchanges. The use of grip tightening is crucial to these techniques, and is often described as "finger power". Elite players develop finger power to the extent that they can hit some power strokes, such as net kills, with less than a racquet swing.
It is also possible to reverse this style of deception, by suggesting a powerful stroke before slowing down the hitting action to play a soft stroke. In general, this latter style of deception is more common in the rearcourt (for example, dropshots disguised as smashes), whereas the former style is more common in the forecourt and midcourt (for example, lifts disguised as netshots).
Deception is not limited to slicing and short hitting actions. Players may also use "double motion", where they make an initial racquet movement in one direction before withdrawing the racquet to hit in another direction. Players will often do this to send opponents in the wrong direction. The racquet movement is typically used to suggest a straight angle but then play the stroke cross court, or vice versa. "Triple motion" is also possible, but this is very rare in actual play. An alternative to double motion is to use a "racquet head fake", where the initial motion is continued but the racquet is turned during the hit. This produces a smaller change in direction, but does not require as much time.
Strategy.
To win in badminton, players need to employ a wide variety of strokes in the right situations. These range from powerful jumping smashes to delicate tumbling net returns. Often rallies finish with a smash, but setting up the smash requires subtler strokes. For example, a netshot can force the opponent to lift the shuttlecock, which gives an opportunity to smash. If the netshot is tight and tumbling, then the opponent's lift will not reach the back of the court, which makes the subsequent smash much harder to return.
Deception is also important. Expert players prepare for many different strokes that look identical, and use slicing to deceive their opponents about the speed or direction of the stroke. If an opponent tries to anticipate the stroke, he may move in the wrong direction and may be unable to change his body momentum in time to reach the shuttlecock.
Doubles.
Both pairs will try to gain and maintain the attack, smashing downwards when possible. Whenever possible, a pair will adopt an ideal attacking formation with one player hitting down from the rearcourt, and his partner in the midcourt intercepting all smash returns except the lift. If the rearcourt attacker plays a dropshot, his partner will move into the forecourt to threaten the net reply. If a pair cannot hit downwards, they will use flat strokes in an attempt to gain the attack. If a pair is forced to lift or clear the shuttlecock, then they must defend: they will adopt a side-by-side position in the rear midcourt, to cover the full width of their court against the opponents' smashes. In doubles, players generally smash to the middle ground between two players in order to take advantage of confusion and clashes.
At high levels of play, the backhand serve has become popular to the extent that forehand serves have become fairly rare at a high level of play. The straight low serve is used most frequently, in an attempt to prevent the opponents gaining the attack immediately. Flick serves are used to prevent the opponent from anticipating the low serve and attacking it decisively.
At high levels of play, doubles rallies are extremely fast. Men's doubles is the most aggressive form of badminton, with a high proportion of powerful jump smashes and very quick reflex exchanges. Because of this, spectator interest is sometimes greater for men's doubles than for singles.
Singles.
The singles court is narrower than the doubles court, but the same length. Since one person needs to cover the entire court, singles tactics are based on forcing the opponent to move as much as possible; this means that singles strokes are normally directed to the corners of the court. Players exploit the length of the court by combining lifts and clears with drop shots and net shots. Smashing tends to be less prominent in singles than in doubles because the smasher has no partner to follow up his effort and is thus vulnerable to a skillfully placed return. Moreover, frequent smashing can be exhausting in singles where the conservation of a player's energy is at a premium. However, players with strong smashes will sometimes use the shot to create openings, and players commonly smash weak returns to try to end rallies.
In singles, players will often start the rally with a forehand high serve or with a flick serve. Low serves are also used frequently, either forehand or backhand. Drive serves are rare.
At high levels of play, singles demands extraordinary fitness. Singles is a game of patient positional manoeuvring, unlike the all-out aggression of doubles.
Mixed doubles.
In mixed doubles, both pairs typically try to maintain an attacking formation with the woman at the front and the man at the back. This is because the male players are usually substantially stronger, and can therefore produce smashes that are more powerful. As a result, mixed doubles require greater tactical awareness and subtler positional play. Clever opponents will try to reverse the ideal position, by forcing the woman towards the back or the man towards the front. In order to protect against this danger, mixed players must be careful and systematic in their shot selection.
At high levels of play, the formations will generally be more flexible: the top women players are capable of playing powerfully from the back-court, and will happily do so if required. When the opportunity arises, however, the pair will switch back to the standard mixed attacking position, with the woman in front and men in the back.
Governing bodies.
The Badminton World Federation (BWF) is the internationally recognized governing body of the sport. Five regional confederations are associated with the BWF:
Competitions.
The BWF organizes several international competitions, including the Thomas Cup, the premier men's international team event first held in 1948–1949, and the Uber Cup, the women's equivalent first held in 1956–1957. The competitions now take place once every two years. More than 50 national teams compete in qualifying tournaments within continental confederations for a place in the finals. The final tournament involves 12 teams, following an increase from eight teams in 2004.
The Sudirman Cup, a gender-mixed international team event held once every two years, began in 1989. Teams are divided into seven levels based on the performance of each country. To win the tournament, a country must perform well across all five disciplines (men's doubles and singles, women's doubles and singles, and mixed doubles). Like association football (soccer), it features a promotion and relegation system in every level.
Badminton was a demonstration event in the 1972 and 1988 Summer Olympics. It became an official Summer Olympic sport at the Barcelona Olympics in 1992 and its gold medals now generally rate as the sport's most coveted prizes for individual players.
In the BWF World Championships, first held in 1977, currently only the highest ranked 64 players in the world, and a maximum of four from each country, can participate in any category. In both the Olympic and BWF World competitions restrictions on the number of participants from any one country have caused some controversy because they sometimes result in excluding elite world level players from the strongest badminton nations. The Thomas, Uber, and Sudirman Cups, the Olympics, and the BWF World (and World Junior Championships), are all categorized as level one tournaments.
At the start of 2007, the BWF introduced a new tournament structure for the highest level tournaments aside from those in level one: the BWF Super Series. This level two tournament series, a tour for the world's elite players, stages twelve open tournaments around the world with 32 players (half the previous limit). The players collect points that determine whether they can play in Super Series Final held at the year end. Among the tournaments in this series is the venerable All-England Championships, first held in 1900, which was once considered the unofficial world championships of the sport.
Level three tournaments consist of Grand Prix Gold and Grand Prix event. Top players can collect the world ranking points and enable them to play in the BWF Super Series open tournaments. These include the regional competitions in Asia (Badminton Asia Championships) and Europe (European Badminton Championships), which produce the world's best players as well as the Pan America Badminton Championships.
The level four tournaments, known as International Challenge, International Series and Future Series, encourage participation by junior players.
Comparisons with other racquet sports.
Badminton is frequently compared to tennis. The following is a list of uncontentious comparisons:
Comparisons of speed and athletic requirements.
Statistics such as the smash speed, above, prompt badminton enthusiasts to make other comparisons that are more contentious. For example, it is often claimed that badminton is the fastest racquet sport. Although badminton holds the record for the fastest initial speed of a racket sports projectile, the shuttlecock decelerates substantially faster than other projectiles such as tennis balls. In turn, this qualification must be qualified by consideration of the distance over which the shuttlecock travels: a smashed shuttlecock travels a shorter distance than a tennis ball during a serve.
While fans of badminton and tennis often claim that their sport is the more physically demanding, such comparisons are difficult to make objectively because of the differing demands of the games. No formal study currently exists evaluating the physical condition of the players or demands during game play.
Comparisons of technique.
Badminton and tennis techniques differ substantially. The lightness of the shuttlecock and of badminton rackets allow badminton players to make use of the wrist and fingers much more than tennis players; in tennis the wrist is normally held stable, and playing with a mobile wrist may lead to injury. For the same reasons, badminton players can generate power from a short racket swing: for some strokes such as net kills, an elite player's swing may be less than . For strokes that require more power, a longer swing will typically be used, but the badminton racket swing will rarely be as long as a typical tennis swing.
It is often asserted that power in badminton strokes comes mainly from the wrist. This is a misconception and may be criticised for two reasons. First, it is strictly speaking a category error: the wrist is a joint, not a muscle; the forearm muscles control its movement. Second, wrist movements are weak when compared to forearm or upper arm movements. Badminton biomechanics have not been the subject of extensive scientific study, but some studies confirm the minor role of the wrist in power generation, and indicate that the major contributions to power come from internal and external rotations of the upper and lower arm. Modern coaching resources such as the "Badminton England Technique DVD" reflect these ideas by emphasising forearm rotation rather than wrist movements.
Distinctive characteristics of the shuttlecock.
The shuttlecock differs greatly from the balls used in most other racquet sports.
Aerodynamic drag and stability.
The feathers impart substantial drag, causing the shuttlecock to decelerate greatly over distance. The shuttlecock is also extremely aerodynamically stable: regardless of initial orientation, it will turn to fly cork-first, and remain in the cork-first orientation.
One consequence of the shuttlecock's drag is that it requires considerable skill to hit it the full length of the court, which is not the case for most racquet sports. The drag also influences the flight path of a lifted ("lobbed") shuttlecock: the parabola of its flight is heavily skewed so that it falls at a steeper angle than it rises. With very high serves, the shuttlecock may even fall vertically.
Spin.
Balls may be spun to alter their bounce (for example, topspin and backspin in tennis) or trajectory, and players may slice the ball (strike it with an angled racket face) to produce such spin; but, since the shuttlecock is not allowed to bounce, this does not apply to badminton.
Slicing the shuttlecock so that it spins, however, does have applications, and some are particular to badminton. (See Basic strokes for an explanation of technical terms.)
Due to the way that its feathers overlap, a shuttlecock also has a slight natural spin about its axis of rotational symmetry. The spin is in a counter-clockwise direction as seen from above when dropping a shuttlecock. This natural spin affects certain strokes: a tumbling netshot is more effective if the slicing action is from right to left, rather than from left to right.

</doc>
