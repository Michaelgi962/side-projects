<doc id="840" url="http://en.wikipedia.org/wiki?curid=840" title="Axiom of choice">
Axiom of choice

In mathematics, the axiom of choice, or AC, is an axiom of set theory equivalent to the statement that "the cartesian product of a collection of non-empty sets is non-empty". It states that for every indexed family formula_1 of nonempty sets there exists an indexed family formula_2 of elements such that formula_3 for every formula_4. The axiom of choice was formulated in 1904 by Ernst Zermelo in order to formalize his proof of the well-ordering theorem.
Informally put, the axiom of choice says that given any collection of bins, each containing at least one object, it is possible to make a selection of exactly one object from each bin. In many cases such a selection can be made without invoking the axiom of choice; this is in particular the case if the number of bins is finite, or if a selection rule is available: a distinguishing property that happens to hold for exactly one object in each bin. To give an informal example, for any (even infinite) collection of pairs of shoes, one can pick out the left shoe from each pair to obtain an appropriate selection, but for an infinite collection of pairs of socks (assumed to have no distinguishing features), such a selection can be obtained only by invoking the axiom of choice.
Although originally controversial, the axiom of choice is now used without reservation by most mathematicians, and it is included in Zermelo–Fraenkel set theory with the axiom of choice (ZFC), the standard form of axiomatic set theory. One motivation for this use is that a number of generally accepted mathematical results, such as Tychonoff's theorem, require the axiom of choice for their proofs. Contemporary set theorists also study axioms that are not compatible with the axiom of choice, such as the axiom of determinacy. The axiom of choice is avoided in some varieties of constructive mathematics, although there are varieties of constructive mathematics in which the axiom of choice is embraced.
Statement.
A choice function is a function "f", defined on a collection "X" of nonempty sets, such that for every set "s" in "X", "f"("s") is an element of "s". With this concept, the axiom can be stated:
Formally, this may be expressed as follows:
Thus the negation of the axiom of choice states, there exists a set of nonempty sets that has no choice function.
Each choice function on a collection "X" of nonempty sets is an element of the Cartesian product of the sets in "X". This is not the most general situation of a Cartesian product of a family of sets, where a same set can occur more than once as a factor; however, one can focus on elements of such a product that select the same element every time a given set appears as factor, and such elements correspond to an element of the Cartesian product of all "distinct" sets in the family. The axiom of choice asserts the existence of such elements; it is therefore equivalent to:
Nomenclature ZF, AC, and ZFC.
In this article and other discussions of the Axiom of Choice the following abbreviations are common:
Variants.
There are many other equivalent statements of the axiom of choice. These are equivalent in the sense that, in the presence of other basic axioms of set theory, they imply the axiom of choice and are implied by it.
One variation avoids the use of choice functions by, in effect, replacing each choice function with its range.
This guarantees for any partition of a set "X" the existence of a subset "C" of "X" containing exactly one element from each part of the partition.
Another equivalent axiom only considers collections "X" that are essentially powersets of other sets:
Authors who use this formulation often speak of the "choice function on A", but be advised that this is a slightly different notion of choice function. Its domain is the powerset of "A" (with the empty set removed), and so makes sense for any set "A", whereas with the definition used elsewhere in this article, the domain of a choice function on a "collection of sets" is that collection, and so only makes sense for sets of sets. With this alternate notion of choice function, the axiom of choice can be compactly stated as
which is equivalent to
The negation of the axiom can thus be expressed as:
Restriction to finite sets.
The statement of the axiom of choice does not specify whether the collection of nonempty sets is finite or infinite, and thus implies that every finite collection of nonempty sets has a choice function. However, that particular case is a theorem of Zermelo–Fraenkel set theory without the axiom of choice (ZF); it is easily proved by mathematical induction. In the even simpler case of a collection of "one" set, a choice function just corresponds to an element, so this instance of the axiom of choice says that every nonempty set has an element; this holds trivially. The axiom of choice can be seen as asserting the generalization of this property, already evident for finite collections, to arbitrary collections.
Usage.
Until the late 19th century, the axiom of choice was often used implicitly, although it had not yet been formally stated. For example, after having established that the set "X" contains only non-empty sets, a mathematician might have said "let "F(s)" be one of the members of "s" for all "s" in "X"." In general, it is impossible to prove that "F" exists without the axiom of choice, but this seems to have gone unnoticed until Zermelo.
Not every situation requires the axiom of choice. For finite sets "X", the axiom of choice follows from the other axioms of set theory. In that case it is equivalent to saying that if we have several (a finite number of) boxes, each containing at least one item, then we can choose exactly one item from each box. Clearly we can do this: We start at the first box, choose an item; go to the second box, choose an item; and so on. The number of boxes is finite, so eventually our choice procedure comes to an end. The result is an explicit choice function: a function that takes the first box to the first element we chose, the second box to the second element we chose, and so on. (A formal proof for all finite sets would use the principle of mathematical induction to prove "for every natural number "k", every family of "k" nonempty sets has a choice function.") This method cannot, however, be used to show that every countable family of nonempty sets has a choice function, as is asserted by the axiom of countable choice. If the method is applied to an infinite sequence ("X""i" : "i"∈ω) of nonempty sets, a function is obtained at each finite stage, but there is no stage at which a choice function for the entire family is constructed, and no "limiting" choice function can be constructed, in general, in ZF without the axiom of choice.
Examples.
The nature of the individual nonempty sets in the collection may make it possible to avoid the axiom of choice even for certain infinite collections. For example, suppose that each member of the collection "X" is a nonempty subset of the natural numbers. Every such subset has a smallest element, so to specify our choice function we can simply say that it maps each set to the least element of that set. This gives us a definite choice of an element from each set, and makes it unnecessary to apply the axiom of choice.
The difficulty appears when there is no natural choice of elements from each set. If we cannot make explicit choices, how do we know that our set exists? For example, suppose that "X" is the set of all non-empty subsets of the real numbers. First we might try to proceed as if "X" were finite. If we try to choose an element from each set, then, because "X" is infinite, our choice procedure will never come to an end, and consequently, we will never be able to produce a choice function for all of "X". Next we might try specifying the least element from each set. But some subsets of the real numbers do not have least elements. For example, the open interval (0,1) does not have a least element: if "x" is in (0,1), then so is "x"/2, and "x"/2 is always strictly smaller than "x". So this attempt also fails.
Additionally, consider for instance the unit circle "S", and the action on "S" by a group "G" consisting of all rational rotations. Namely, these are rotations by angles which are rational multiples of "π". Here "G" is countable while "S" is uncountable. Hence "S" breaks up into uncountably many orbits under "G". Using the axiom of choice, we could pick a single point from each orbit, obtaining an uncountable subset "X" of "S" with the property that all of its translates by G are disjoint from "X". The set of those translates partitions the circle into a countable collection of disjoint sets, which are all pairwise congruent. Since "X" is not measurable for any rotation-invariant countably additive finite measure on "S", finding an algorithm to select a point in each orbit requires the axiom of choice. See non-measurable set for more details.
The reason that we are able to choose least elements from subsets of the natural numbers is the fact that the natural numbers are well-ordered: every nonempty subset of the natural numbers has a unique least element under the natural ordering. One might say, "Even though the usual ordering of the real numbers does not work, it may be possible to find a different ordering of the real numbers which is a well-ordering. Then our choice function can choose the least element of every set under our unusual ordering." The problem then becomes that of constructing a well-ordering, which turns out to require the axiom of choice for its existence; every set can be well-ordered if and only if the axiom of choice holds.
Criticism and acceptance.
A proof requiring the axiom of choice may establish the existence of an object without explicitly defining the object in the language of set theory. For example, while the axiom of choice implies that there is a well-ordering of the real numbers, there are models of set theory with the axiom of choice in which no well-ordering of the reals is definable. Similarly, although a subset of the real numbers that is not Lebesgue measurable can be proven to exist using the axiom of choice, it is consistent that no such set is definable.
The axiom of choice produces these intangibles (objects that are proven to exist, but which cannot be explicitly constructed), which may conflict with some philosophical principles. Because there is no canonical well-ordering of all sets, a construction that relies on a well-ordering may not produce a canonical result, even if a canonical result is desired (as is often the case in category theory). This has been used as an argument against the use of the axiom of choice.
Another argument against the axiom of choice is that it implies the existence of objects that may seem counterintuitive. One example is the Banach–Tarski paradox which says that it is possible to decompose the 3-dimensional solid unit ball into finitely many pieces and, using only rotations and translations, reassemble the pieces into two solid balls each with the same volume as the original. The pieces in this decomposition, constructed using the axiom of choice, are non-measurable sets.
Despite these facts, most mathematicians accept the axiom of choice as a valid principle for proving new results in mathematics. The debate is interesting enough, however, that it is considered of note when a theorem in ZFC (ZF plus AC) is logically equivalent (with just the ZF axioms) to the axiom of choice, and mathematicians look for results that require the axiom of choice to be false, though this type of deduction is less common than the type which requires the axiom of choice to be true.
It is possible to prove many theorems using neither the axiom of choice nor its negation; such statements will be true in any model of Zermelo–Fraenkel set theory (ZF), regardless of the truth or falsity of the axiom of choice in that particular model. The restriction to ZF renders any claim that relies on either the axiom of choice or its negation unprovable. For example, the Banach–Tarski paradox is neither provable nor disprovable from ZF alone: it is impossible to construct the required decomposition of the unit ball in ZF, but also impossible to prove there is no such decomposition. Similarly, all the statements listed below which require choice or some weaker version thereof for their proof are unprovable in ZF, but since each is provable in ZF plus the axiom of choice, there are models of ZF in which each statement is true. Statements such as the Banach–Tarski paradox can be rephrased as conditional statements, for example, "If AC holds, then the decomposition in the Banach–Tarski paradox exists." Such conditional statements are provable in ZF when the original statements are provable from ZF and the axiom of choice.
In constructive mathematics.
As discussed above, in ZFC, the axiom of choice is able to provide "nonconstructive proofs" in which the existence of an object is proved although no explicit example is constructed. ZFC, however, is still formalized in classical logic. The axiom of choice has also been thoroughly studied in the context of constructive mathematics, where non-classical logic is employed. The status of the axiom of choice varies between different varieties of constructive mathematics.
In Martin-Löf type theory and higher-order Heyting arithmetic, the appropriate statement of the axiom of choice is (depending on approach) included as an axiom or provable as a theorem. Errett Bishop argued that the axiom of choice was constructively acceptable, saying
In constructive set theory, however, Diaconescu's theorem shows that the axiom of choice implies the Law of excluded middle (unlike in Martin-Löf type theory, where it does not). Thus the axiom of choice is not generally available in constructive set theory. A cause for this difference is that the axiom of choice in type theory does not have the extensionality properties that the axiom of choice in constructive set theory does.
Some results in constructive set theory use the axiom of countable choice or the axiom of dependent choice, which do not imply the law of the excluded middle in constructive set theory. Although the axiom of countable choice in particular is commonly used in constructive mathematics, its use has also been questioned.
Independence.
Assuming ZF is consistent, Kurt Gödel showed that the "negation" of the axiom of choice is not a theorem of ZF by constructing an inner model (the constructible universe) which satisfies ZFC and thus showing that ZFC is consistent. Assuming ZF is consistent, Paul Cohen employed the technique of forcing, developed for this purpose, to show that the axiom of choice itself is not a theorem of ZF by constructing a much more complex model which satisfies ZF¬C (ZF with the negation of AC added as axiom) and thus showing that ZF¬C is consistent. Together these results establish that the axiom of choice is logically independent of ZF. The assumption that ZF is consistent is harmless because adding another axiom to an already inconsistent system cannot make the situation worse. Because of independence, the decision whether to use the axiom of choice (or its negation) in a proof cannot be made by appeal to other axioms of set theory. The decision must be made on other grounds.
One argument given in favor of using the axiom of choice is that it is convenient to use it because it allows one to prove some simplifying propositions that otherwise could not be proved. Many theorems which are provable using choice are of an elegant general character: every ideal in a ring is contained in a maximal ideal, every vector space has a basis, and every product of compact spaces is compact. Without the axiom of choice, these theorems may not hold for mathematical objects of large cardinality.
The proof of the independence result also shows that a wide class of mathematical statements, including all statements that can be phrased in the language of Peano arithmetic, are provable in ZF if and only if they are provable in ZFC. Statements in this class include the statement that P = NP, the Riemann hypothesis, and many other unsolved mathematical problems. When one attempts to solve problems in this class, it makes no difference whether ZF or ZFC is employed if the only question is the existence of a proof. It is possible, however, that there is a shorter proof of a theorem from ZFC than from ZF.
The axiom of choice is not the only significant statement which is independent of ZF. For example, the generalized continuum hypothesis (GCH) is not only independent of ZF, but also independent of ZFC. However, ZF plus GCH implies AC, making GCH a strictly stronger claim than AC, even though they are both independent of ZF.
Stronger axioms.
The axiom of constructibility and the generalized continuum hypothesis each imply the axiom of choice and so are strictly stronger than it. In class theories such as Von Neumann–Bernays–Gödel set theory and Morse–Kelley set theory, there is a possible axiom called the axiom of global choice which is stronger than the axiom of choice for sets because it also applies to proper classes. And the axiom of global choice follows from the axiom of limitation of size.
Equivalents.
There are important statements that, assuming the axioms of ZF but neither AC nor ¬AC, are equivalent to the axiom of choice. The most important among them are Zorn's lemma and the well-ordering theorem. In fact, Zermelo initially introduced the axiom of choice in order to formalize his proof of the well-ordering theorem.
Category theory.
There are several results in category theory which invoke the axiom of choice for their proof. These results might be weaker than, equivalent to, or stronger than the axiom of choice, depending on the strength of the technical foundations. For example, if one defines categories in terms of sets, that is, as sets of objects and morphisms (usually called a small category), or even locally small categories, whose hom-objects are sets, then there is no category of all sets, and so it is difficult for a category-theoretic formulation to apply to all sets. On the other hand, other foundational descriptions of category theory are considerably stronger, and an identical category-theoretic statement of choice may be stronger than the standard formulation, à la class theory, mentioned above.
Examples of category-theoretic statements which require choice include:
Weaker forms.
There are several weaker statements that are not equivalent to the axiom of choice, but are closely related. One example is the axiom of dependent choice (DC). A still weaker example is the axiom of countable choice (ACω or CC), which states that a choice function exists for any countable set of nonempty sets. These axioms are sufficient for many proofs in elementary mathematical analysis, and are consistent with some principles, such as the Lebesgue measurability of all sets of reals, that are disprovable from the full axiom of choice.
Other choice axioms weaker than axiom of choice include the Boolean prime ideal theorem and the axiom of uniformization. The former is equivalent in ZF to the existence of an ultrafilter containing each given filter, proved by Tarski in 1930.
Results requiring AC (or weaker forms) but weaker than it.
One of the most interesting aspects of the axiom of choice is the large number of places in mathematics that it shows up. Here are some statements that require the axiom of choice in the sense that they are not provable from ZF but are provable from ZFC (ZF plus AC). Equivalently, these statements are true in all models of ZFC but false in some models of ZF.
Stronger forms of the negation of AC.
Now, consider stronger forms of the negation of AC. For example, if we abbreviate by BP the claim that every set of real numbers has the property of Baire, then BP is stronger than ¬AC, which asserts the nonexistence of any choice function on perhaps only a single set of nonempty sets. Note that strengthened negations may be compatible with weakened forms of AC. For example, ZF + DC + BP is consistent, if ZF is.
It is also consistent with ZF + DC that every set of reals is Lebesgue measurable; however, this consistency result, due to Robert M. Solovay, cannot be proved in ZFC itself, but requires a mild large cardinal assumption (the existence of an inaccessible cardinal). The much stronger axiom of determinacy, or AD, implies that every set of reals is Lebesgue measurable, has the property of Baire, and has the perfect set property (all three of these results are refuted by AC itself). ZF + DC + AD is consistent provided that a sufficiently strong large cardinal axiom is consistent (the existence of infinitely many Woodin cardinals).
Statements consistent with the negation of AC.
There are models of Zermelo-Fraenkel set theory in which the axiom of choice is false. We will abbreviate "Zermelo-Fraenkel set theory plus the negation of the axiom of choice" by ZF¬C. For certain models of ZF¬C, it is possible to prove the negation of some standard facts.
Note that any model of ZF¬C is also a model of ZF, so for each of the following statements, there exists a model of ZF in which that statement is true.
For proofs, see Thomas Jech, "The Axiom of Choice", American Elsevier Pub. Co., New York, 1973.
Quotes.
"The Axiom of Choice is obviously true, the well-ordering principle obviously false, and who can tell about Zorn's lemma?" — Jerry Bona
"The Axiom of Choice is necessary to select a set from an infinite number of socks, but not an infinite number of shoes." — Bertrand Russell
"Tarski tried to publish his theorem equivalence between AC and 'every infinite set "A" has the same cardinality as "A"x"A"', see above in Comptes Rendus, but Fréchet and Lebesgue refused to present it. Fréchet wrote that an implication between two well known propositions is not a new result, and Lebesgue wrote that an implication between two false propositions is of no interest".
"The axiom gets its name not because mathematicians prefer it to other axioms." — A. K. Dewdney

</doc>
<doc id="841" url="http://en.wikipedia.org/wiki?curid=841" title="Attila">
Attila

Attila ( or ; ?–453), frequently referred to as Attila the Hun, was the ruler of the Huns from 434 until his death in 453. He was leader of the Hunnic Empire, which stretched from the Ural River to the Rhine River and from the Danube River to the Baltic Sea.
During his reign he was one of the most feared enemies of the Western and Eastern Roman Empires. He crossed the Danube twice and plundered the Balkans, but was unable to take Constantinople. His unsuccessful campaign in Persia was followed in 441 by an invasion of the Eastern Roman Empire, the success of which emboldened Attila to invade the West. He also attempted to conquer Roman Gaul (modern France), crossing the Rhine in 451 and marching as far as Aurelianum (Orléans) before being defeated at the Battle of the Catalaunian Plains.
Subsequently he invaded Italy, devastating the northern provinces, but was unable to take Rome. He planned for further campaigns against the Romans but died in 453.
Appearance and character.
While there is no surviving first-person account of Attila's appearance, there is a possible second-hand source, provided by Jordanes, who cites a description given by Priscus.
The description suggests a person typical of Asian or Mongoloid features.
Etymology.
The origin of Attila's name is unclear. Menander used the term "Attila" as the name of the Volga River. Pritsak considers it to mean "universal ruler" in a Turkic language related to Danube Bulgarian.
The turkologist Otto J. Maenchen-Helfen rejects a Turkic etymology, and suggests an East Germanic origin: "Attila is formed from Gothic or Gepidic atta, "father", by means of the diminutive suffix -ila." He finds Pritsak's etymology "ingenious but for many reasons unacceptable". However, he suggests that these names were 
The name of Attila's brother Bleda is also of Germanic origin. Judging by a hypothetical Germanic etymology of Attila's name and the status of Gothic and the lingua franca at his court, historian Peter Heather states that the possibility of Attila being of Germanic ancestry cannot be ruled out.
The name has many variants in modern languages: Atli and Atle in Norse, Attila/Atilla/Etele in Hungarian (Attila is the most popular), Etzel in German (Nibelungenlied), Attila, Atilla, Atilay or Atila in Turkish, and Adil and Edil in Kazakh or Adil ("same/similar") or Edil ("to use") in Mongolian.
Historiography and source.
The historiography of Attila is faced with a major challenge, in that the only complete sources are written in Greek and Latin, by the enemies of the Huns. His contemporaries left many testimonials of his life, but only fragments of these remain. Priscus, a Roman diplomat and historian who wrote in Greek, was both a witness to and an actor in the story of Attila, as a member of the embassy of Theodosius II at the Hunnic court in 449. Although he was obviously biased by his political position, his writing is a major source for the life of Attila and he is the only person known to have recorded a physical description of him. He was the author of an eight-volume work of history covering the period from 434 to 452.
Today we have only fragments of this work, but it was cited extensively by the 6th-century historians Procopius and Jordanes, especially in Jordanes' "The Origin and Deeds of the Goths". As it contains numerous references to Priscus's history, it is an important source of information about the Hunnic empire and its neighbors. Here, he describes the legacy of Attila and the Hunnic people for a century after Attila's death. Marcellinus Comes, a chancellor of Justinian during the same era, also describes the relations between the Huns and the Eastern Roman Empire.
Numerous ecclesiastical writings contain useful albeit scattered information, sometimes difficult to authenticate or distorted by years of hand-copying between the 6th and 17th centuries. The Hungarian writers of the 12th century, wishing to portray the Huns in a positive light as their glorious ancestors, repressed certain historical elements and added their own legends.
The literature and knowledge of the Huns themselves was transmitted solely orally, by means of epics and chanted poems that were handed down from generation to generation. Indirectly, fragments of this oral history have reached us via the literature of the Scandinavians and Germans, neighbors of the Huns who wrote between the 9th and 13th centuries. Attila is a major character in many Medieval epics, such as the Nibelungenlied, as well as various Eddas and sagas. 
Archaeological investigation has uncovered some details about the lifestyle, art and warfare of the Huns. There are a few traces of battles and sieges, but today the tomb of Attila and the location of his capital have not yet been found.
Early life and background.
The Huns were a group of Eurasian nomads, appearing from east of the Volga, who migrated into Europe c. 370 and built up an enormous empire there. Their main military techniques were mounted archery and javelin throwing. They were possibly the descendants of the Xiongnu (Hsiung-nu) who had been northern neighbors of China three hundred years before and may be the first expansion of Turkic people across Eurasia. Even though they were in the process of developing settlements before their arrival in Europe, the Huns were a society of pastoral warriors whose primary form of nourishment was meat and milk, products of their herds.
The origin and language of the Huns has been the subject of debate for centuries. According to some theories, their leaders at least may have spoken a Turkic language, perhaps closest to the modern Chuvash language. One scholar suggests a relationship to Yeniseian. According to the "Encyclopedia of European Peoples", "the Huns, especially those who migrated to the west, may have been a combination of central Asian Turkic, Mongolic, and Ugric stocks."
Attila's father, Mundzuk, was the brother of the kings Octar and Rugila, who reigned jointly over the Hunnic empire in the early fifth century. This form of diarchy was recurrent with the Huns, but historians are unsure whether it was institutionalized, merely customary, or an occasional occurrence. His family was from a noble lineage, but it is uncertain whether they constituted a royal dynasty. Attila's birthdate is not known, but the journalist Éric Deschodt and the writer Herman Schreiber have proposed a date of 395. However, the historian Iaroslav Lebedynsky and archaeologist Katalin Escher prefer an estimate between the 390s and the first decade of the fifth century.
Attila grew up in a rapidly changing world. His people were nomads who had only recently arrived in Europe. After crossing the Volga river during the 370s and annexing the territory of the Alans, they attacked the Gothic kingdom between the Carpathian mountains and the Danube. They were a very mobile people, whose mounted archers had acquired a reputation of invincibility, and the Germanic tribes seemed unable to withstand them. Vast populations fleeing the Huns moved from Germania into the Roman Empire in the west and south, and along the banks of the Rhine and Danube. In 376, the Goths crossed the Danube, initially submitting to the Romans but soon rebelling against the emperor Valens, whom they killed in the Battle of Adrianople in 378. On December 31, 406, to escape the Huns, large numbers of Vandals, Alans, Suebi and Burgundians crossed the Rhine and invaded Roman Gaul. The Roman Empire had been split into half since 395 and was ruled by two distinct governments, one based in Ravenna in the West, and the other in Constantinople in the East. In Attila's lifetime, despite several power struggles, the Roman Emperors both East and West were generally from the same family, the Theodosians.
The Huns dominated a vast territory with nebulous borders determined by the will of a constellation of ethnically varied peoples. Some were assimilated to Hunnic nationality, whereas many retained their own identities and rulers but acknowledged the suzerainty of the king of the Huns. While the Huns were the indirect source of many of the Romans' problems by driving various Germanic tribes into Roman territory, relations between the two empires were cordial: the Romans used the Huns as mercenaries against the Germans and even in their civil wars. Thus, the usurper Joannes was able to recruit thousands of Huns for his army against Valentinian III in 424. They exchanged ambassadors and hostages, the alliance lasting from 401 to 450 and permitting the Romans numerous military victories. The Huns considered the Romans to be paying them tribute, whereas the Romans preferred to view this as payment for services rendered. By the time Attila came of age during the reign of his uncle Rugila, the Huns had become a great power, to the point that the Patriarch of Constantinople, Nestorius, deplored the situation with these words: "They have become both masters and slaves of the Romans."
Campaigns against the Eastern Roman Empire.
The death of Rugila (also known as Rua or Ruga) in 434 left the sons of his brother Mundzuk, Attila and Bleda (Buda), in control of the united Hun tribes. At the time of two brothers' accession, the Hun tribes were bargaining with Eastern Roman Emperor Theodosius II's envoys for the return of several renegades (possibly Hunnic nobles who disagreed with the brothers' assumption of leadership) who had taken refuge within the Eastern Roman Empire.
The following year Attila and Bleda met with the imperial legation at Margus (Požarevac) and, all seated on horseback in the Hunnic manner, negotiated a successful treaty. The Romans agreed, not only to return the fugitives, but also to double their previous tribute of 350 Roman pounds (c. 115 kg) of gold, to open their markets to Hunnish traders, and to pay a ransom of eight "solidi" for each Roman taken prisoner by the Huns. The Huns, satisfied with the treaty, decamped from the Roman Empire and returned to their home in the Great Hungarian Plain, perhaps to consolidate and strengthen their empire. Theodosius used this opportunity to strengthen the walls of Constantinople, building the city's first sea wall, and to build up his border defenses along the Danube.
The Huns remained out of Roman sight for the next few years while they invaded the Sassanid Empire. When defeated in Armenia by the Sassanids, the Huns abandoned their invasion and turned their attentions back to Europe. In 440 they reappeared in force on the borders of the Roman Empire, attacking the merchants at the market on the north bank of the Danube that had been established by the treaty.
Crossing the Danube, they laid waste to the cities of Illyricum and forts on the river, including (according to Priscus) Viminacium, a city of Moesia. Their advance began at Margus, where they demanded that the Romans turn over a bishop who had retained property that Attila regarded as his. While the Romans discussed turning the bishop over, he slipped away secretly to the Huns and betrayed the city to them.
While the Huns attacked city-states along the Danube, the Vandals led by Geiseric captured the Western Roman province of Africa and its capital of Carthage. Carthage was the richest province of the Western Empire and a main source of food for Rome. The Sassanid Shah Yazdegerd II invaded Armenia in 441.
The Romans stripped the Balkan area of forces, sending them to Sicily in order to mount an expedition against the Vandals in Africa. This left Attila and Bleda a clear path through Illyricum into the Balkans, which they invaded in 441. The Hunnish army sacked Margus and Viminacium, and then took Singidunum (Belgrade) and Sirmium. During 442 Theodosius recalled his troops from Sicily and ordered a large issue of new coins to finance operations against the Huns. Believing he could defeat the Huns, he refused the Hunnish kings' demands.
Attila responded with a campaign in 443. Striking along the Danube, the Huns, equipped with new military weapons like the battering rams and rolling siege towers, overran the military centers of Ratiara and successfully besieged Naissus (Niš).
Advancing along the Nišava River, the Huns next took Serdica (Sofia), Philippopolis (Plovdiv), and Arcadiopolis (Lüleburgaz). They encountered and destroyed a Roman army outside Constantinople but were stopped by the double walls of the Eastern capital. They defeated a second army near Callipolis (Gelibolu).
Theodosius, stripped of his armed forces, admitted defeat, sending the "Magister militum per Orientem" Anatolius to negotiate peace terms. The terms were harsher than the previous treaty: the Emperor agreed to hand over 6,000 Roman pounds (c. 2000 kg) of gold as punishment for having disobeyed the terms of the treaty during the invasion; the yearly tribute was tripled, rising to 2,100 Roman pounds (c. 700 kg) in gold; and the ransom for each Roman prisoner rose to 12 "solidi".
Their demands were met for a time; the Hun kings withdrew into the interior of their empire. Following the Huns' withdrawal from Byzantium (probably around 445), Bleda died. Attila then took the throne for himself, becoming the sole ruler of the Huns.
Solitary kingship.
In 447 Attila again rode south into the Eastern Roman Empire through Moesia. The Roman army under the Gothic "magister militum" Arnegisclus met him in the Battle of the Utus and was defeated, though not without inflicting heavy losses. The Huns were left unopposed and rampaged through the Balkans as far as Thermopylae.
Constantinople itself was saved by the Isaurian troops of the "magister militum per Orientem" Zeno and protected by the intervention of the prefect Constantinus, who organized the reconstruction of the walls that had been previously damaged by earthquakes, and, in some places, to construct a new line of fortification in front of the old. An account of this invasion survives:
In the west.
In 450 Attila proclaimed his intent to attack the Visigoth kingdom of Toulouse by making an alliance with Emperor Valentinian III. He had previously been on good terms with the Western Roman Empire and its influential general Flavius Aëtius. Aëtius had spent a brief exile among the Huns in 433, and the troops Attila provided against the Goths and Bagaudae had helped earn him the largely honorary title of "magister militum" in the west. The gifts and diplomatic efforts of Geiseric, who opposed and feared the Visigoths, may also have influenced Attila's plans.
However, Valentinian's sister was Honoria, who, in order to escape her forced betrothal to a Roman senator, had sent the Hunnish king a plea for help—and her engagement ring—in the spring of 450. Though Honoria may not have intended a proposal of marriage, Attila chose to interpret her message as such. He accepted, asking for half of the western Empire as dowry.
When Valentinian discovered the plan, only the influence of his mother Galla Placidia convinced him to exile, rather than kill, Honoria. He also wrote to Attila strenuously denying the legitimacy of the supposed marriage proposal. Attila sent an emissary to Ravenna to proclaim that Honoria was innocent, that the proposal had been legitimate, and that he would come to claim what was rightfully his.
Attila interfered in a succession struggle after the death of a Frankish ruler. Attila supported the elder son, while Aëtius supported the younger. (The location and identity of these kings is not known and subject to conjecture.) Attila gathered his vassals—Gepids, Ostrogoths, Rugians, Scirians, Heruls, Thuringians, Alans, Burgundians, among others–and began his march west. In 451 he arrived in Belgica with an army exaggerated by Jordanes to half a million strong. J. B. Bury believes that Attila's intent, by the time he marched west, was to extend his kingdom—already the strongest on the continent—across Gaul to the Atlantic Ocean.
On April 7 he captured Metz. Other cities attacked can be determined by the hagiographic "vitae" written to commemorate their bishops: Nicasius was slaughtered before the altar of his church in Rheims; Servatus is alleged to have saved Tongeren with his prayers, as Saint Genevieve is to have saved Paris. Lupus, bishop of Troyes, is also credited with saving his city by meeting Attila in person.
Aëtius moved to oppose Attila, gathering troops from among the Franks, the Burgundians, and the Celts. A mission by Avitus, and Attila's continued westward advance, convinced the Visigoth king Theodoric I (Theodorid) to ally with the Romans. The combined armies reached Orléans ahead of Attila, thus checking and turning back the Hunnish advance. (Later accounts of the battle report that the Huns were either already within the city or in the midst of storming it when the Roman-Visigoth army arrived; Jordanes mentions no such thing.) Aëtius gave chase and caught the Huns at a place usually assumed to be near Catalaunum (modern Châlons-en-Champagne).
The two armies clashed in the Battle of Châlons, whose outcome is commonly considered to be a strategic victory for the Visigothic-Roman alliance. Theodoric was killed in the fighting and Aëtius failed to press his advantage, according to Edward Gibbon and Edward Creasy, because he feared the consequences of an overwhelming Visigothic triumph as much as he did a defeat. From Aëtius' point of view, the best outcome was what occurred: Theodoric died, Attila was in retreat and disarray, and the Romans had the benefit of appearing victorious.
Invasion of Italy and death.
Attila returned in 452 to claim his marriage to Honoria anew, invading and ravaging Italy along the way. The city of Venice was founded as a result of these attacks when the residents fled to small islands in the Venetian Lagoon. His army sacked numerous cities and razed Aquileia so completely that it was afterwards hard to recognize its original site.
Legend has it he had his soldiers carry dirt in their helmets to build a hill north of Aquileia from which he could watch the destruction of the city, thus founding the town of Udine, where a castle now stands on the legendary hill. Aëtius, who lacked the strength to offer battle, managed to harass and slow Attila's advance with only a shadow force. Attila finally halted at the River Po. By this point disease and starvation may have broken out in Attila's camp, thus helping to stop his invasion.
Emperor Valentinian III sent three envoys, the high civilian officers Gennadius Avienus and Trigetius, as well as the Bishop of Rome Leo I, who met Attila at Mincio in the vicinity of Mantua, and obtained from him the promise that he would withdraw from Italy and negotiate peace with the Emperor. Prosper of Aquitaine gives a short description of the historic meeting, but gives all the credit of the successful negotiation to Leo. Priscus reports that superstitious fear of the fate of Alaric—who died shortly after sacking Rome in 410—gave him pause.
In reality, Italy had suffered from a terrible famine in 451 and her crops were faring little better in 452; Attila's devastating invasion of the plains of northern Italy this year did not improve the harvest. To advance on Rome would have required supplies which were not available in Italy, and taking the city would not have improved Attila's supply situation. Therefore, it was more profitable for Attila to conclude peace and retreat back to his homeland.
Secondly, an East Roman force had crossed the Danube under the command of another officer also named Aetius—who had participated in the Council of Chalcedon the previous year—and proceeded to defeat the Huns who had been left behind by Attila to safeguard their home territories. Attila, hence, faced heavy human and natural pressures to retire "from Italy without ever setting foot south of the Po." As Hydatius writes in his "Chronica Minora":
After Attila left Italy and returned to his palace across the Danube, he planned to strike at Constantinople again and reclaim the tribute which Marcian had stopped. (Marcian was the successor of Theodosius and had ceased paying tribute in late 450 while Attila was occupied in the west; multiple invasions by the Huns and others had left the Balkans with little to plunder). However, Attila died in the early months of 453.
The conventional account, from Priscus, says that at a feast celebrating his latest marriage to the beautiful and young Ildico (if uncorrupted, the name suggests a Gothic, more likely Ostrogoth origin) he suffered a severe nosebleed and choked to death in a stupor. An alternative theory is that he succumbed to internal bleeding after heavy drinking, possibly a condition called esophageal varices, where dilated veins in the lower part of the esophagus rupture leading to death by hemorrhage.
Another account of his death, first recorded 80 years after the events by the Roman chronicler Marcellinus Comes, reports that "Attila, King of the Huns and ravager of the provinces of Europe, was pierced by the hand and blade of his wife." The "Volsunga saga" and the "Poetic Edda" also claim that King Atli (Attila) died at the hands of his wife, Gudrun. Most scholars reject these accounts as no more than hearsay, preferring instead the account given by Attila's contemporary Priscus. Priscus' version, however, has recently come under renewed scrutiny by Michael A. Babcock. Based on detailed philological analysis, Babcock concludes that the account of natural death, given by Priscus, was an ecclesiastical "cover story" and that Emperor Marcian (who ruled the Eastern Roman Empire from 450 to 457) was the political force behind Attila's death.
Jordanes says: "The greatest of all warriors should be mourned with no feminine lamentations and with no tears, but with the blood of men." His horsemen galloped in circles around the silken tent where Attila lay in state, singing in his dirge, according to Cassiodorus and Jordanes: "Who can rate this as death, when none believes it calls for vengeance?"
Then they celebrated a "strava" (lamentation) over his burial place with great feasting. Legend says that he was laid to rest in a triple coffin made of gold, silver, and iron, along with some of the spoils of his conquests. His men diverted a section of the river, buried the coffin under the riverbed, and then were killed to keep the exact location a secret.
His sons Ellac (his appointed successor), Dengizich, and Ernakh fought over the division of his legacy, specifically which vassal kings would belong to which brother. As a consequence they were divided, defeated and scattered the following year in the Battle of Nedao by the Ostrogoths and the Gepids under Ardaric who had been Attila's most prized chieftain.
Attila's many children and relatives are known by name and some even by deeds, but soon valid genealogical sources all but dry up and there seems to be no verifiable way to trace Attila's descendants. This has not stopped many genealogists from attempting to reconstruct a valid line of descent for various medieval rulers. One of the most credible claims has been that of the khans of Bulgaria (see Nominalia of the Bulgarian khans). A popular, but ultimately unconfirmed, attempt tries to relate Attila to Charlemagne.
Later folklore and iconography.
Attila himself is said to have claimed the titles "Descendant of the Great Nimrod", and "King of the Huns, the Goths, the Danes, and the Medes"—the last two peoples being mentioned to show the extent of his control over subject nations even on the peripheries of his domain.
Jordanes embellished the report of Priscus, reporting that Attila had possessed the "Holy War Sword of the Scythians", which was given to him by Mars and made him a "prince of the entire world."
Attila was the standard source of legitimacy on the European steppe until Genghis Khan. By the end of the 12th century the royal court of Hungary proclaimed their descent from Attila. Lampert of Hersfeld's contemporary chronicles report that shortly before the year 1071, the Sword of Attila had been presented to Otto of Nordheim by the exiled queen of Hungary, Anastasia of Kiev. This sword, a cavalry sabre now in the Kunsthistorisches Museum in Vienna, appears to be the work of Hungarian goldsmiths of the ninth or tenth century. 
Later writers developed the meeting of Leo I and Attila into a pious "fable which has been represented by the pencil of Raphael and the chisel of Algardi", reporting that the Pope, aided by Saint Peter and Saint Paul, convinced Attila to turn away from the city.
According to a version of this legend related in the Chronicon Pictum, a mediaeval Hungarian chronicle, the Pope promised Attila that if he left Rome in peace, one of his successors would receive a holy crown (which has been understood as referring to the Holy Crown of Hungary).
Some histories and chronicles describe him as a great and noble king, and he plays major roles in three Norse sagas: "Atlakviða", "Völsungasaga", and "Atlamál". The "Polish Chronicle" represents Attila's name as "Aquila".
Frutolf of Michelsberg and Otto of Freising pointed out that some songs as "vulgar fables" made Theoderic the Great, Attila and Ermanaric contemporaries, when any reader of Jordanes knew that this was not the case.
In 1812, Ludwig van Beethoven conceived the idea of writing an opera about Attila and approached August von Kotzebue to write the libretto. It was, however, never written.
In World War I, Allied propaganda referred to Germans as the "Huns", based on a 1900 speech by Emperor Wilhelm II praising Attila the Hun's military prowess, according to Jawaharlal Nehru's "Glimpses of World History".
"Der Spiegel" commented on November 6, 1948, that the Sword of Attila was hanging menacingly over Austria.
American writer Cecelia Holland wrote "The Death of Attila" (1973), a historical novel in which Attila appears as a powerful background figure whose life and death deeply impact the protagonists, a young Hunnish warrior and a Germanic one.
In modern Hungary and in Turkey, "Attila" and its Turkish variation "Atilla" are commonly used as a male first name. In Hungary, several public places are named after Attila; for instance, in Budapest there are 10 Attila Streets, one of which is an important street behind the Buda Castle. When the Turkish Armed Forces invaded Cyprus in 1974, the operations were named after Attila ("The Attila Plan").
The 1954 Universal International film "Sign of the Pagan" starred Jack Palance as Attila.

</doc>
<doc id="842" url="http://en.wikipedia.org/wiki?curid=842" title="Aegean Sea">
Aegean Sea

The Aegean Sea (; ; or ) is an elongated embayment of the Mediterranean Sea located between the southern Balkan and Anatolian peninsulas, i.e., between the mainlands of Greece and Turkey. In the north, it is connected to the Marmara Sea and Black Sea by the Dardanelles and Bosporus. The Aegean Islands are within the sea and some bound it on its southern periphery, including Crete and Rhodes.
The sea was traditionally known as "Archipelago" (in Greek, "Αρχιπέλαγος", meaning "chief sea"), but in English this word's meaning has changed to refer to the Aegean Islands and, generally, to any island group.
Name.
In ancient times, there were various explanations for the name "Aegean". It was said to have been named after the Greek town of Aegae, or after Aegea, a queen of the Amazons who died in the sea, or Aigaion, the "sea goat", another name of Briareus, one of the archaic Hecatonchires, or, especially among the Athenians, Aegeus, the father of Theseus, who drowned himself in the sea when he thought his son had died.
A possible etymology is a derivation from the Greek word "" – "aiges" = ""waves"" (Hesychius of Alexandria; metaphorical use of ("aix") "goat"), hence "wavy sea", cf. also (aigialos = aiges "(waves)" + hals "(sea)"), hence meaning "sea-shore".
In some South Slavic languages the sea is often called "White Sea" (, "Byalo more", Macedonian and Serbian: Бело море, "Belo more").
Geography.
The Aegean Sea covers about in area, and measures about longitudinally and latitudinally. The sea's maximum depth is , east of Crete. The Aegean Islands are found within its waters, with the following islands delimiting the sea on the south (generally from west to east): Kythera, Antikythera, Crete, Kasos, Karpathos and Rhodes.
The Aegean Islands, which almost all belong to Greece, can be divided into seven groups:
The word "archipelago" was originally applied specifically to the Aegean Sea and its islands. Many of the Aegean Islands, or chains of islands, are actually extensions of the mountains on the mainland. One chain extends across the sea to Chios, another extends across Euboea to Samos, and a third extends across the Peloponnese and Crete to Rhodes, dividing the Aegean from the Mediterranean.
The bays and gulfs of the Aegean beginning at the South and moving clockwise include on Crete, the Mirabelli, Almyros, Souda and Chania bays or gulfs, on the mainland the Myrtoan Sea to the west, the Saronic Gulf northwestward, the Petalies Gulf which connects with the South Euboic Sea, the Pagasetic Gulf which connects with the North Euboic Sea, the Thermian Gulf northwestward, the Chalkidiki Peninsula including the Cassandra and the Singitic Gulfs, northward the Strymonian Gulf and the Gulf of Kavala and the rest are in Turkey; Saros Gulf, Edremit Gulf, Dikili Gulf, Gulf of Çandarlı, İzmir Gulf, Kuşadası Gulf, Gulf of Gökova, Güllük Gulf.
Extent.
The International Hydrographic Organization defines the limits of the Aegean Sea as follows:
"On the South." A line running from Cape Aspro (28°16'E) in Asia Minor, to Cum Burnù (Capo della Sabbia) the Northeast extreme of the Island of Rhodes, through the island to Cape Prasonisi, the Southwest point thereof, on to Vrontos Point (35°33'N) in Skarpanto [Karpathos], through this island to Castello Point, the South extreme thereof, across to Cape Plaka (East extremity of Crete), through Crete to Agria Grabusa, the Northwest extreme thereof, thence to Cape Apolitares in Antikithera Island, through the island to Psira Rock (off the Northwest point) and across to Cape Trakhili in Kithera Island, through Kithera to the Northwest point (Cape Karavugia) and thence to Cape Santa Maria () in the Morea.
<br><br>"In the Dardanelles". A line joining Kum Kale (26°11'E) and Cape Helles.
Hydrography.
Aegean surface water circulates in a counter-clockwise gyre, with hypersaline Mediterranean water moving northward along the west coast of Turkey, before being displaced by less dense Black Sea outflow. The dense Mediterranean water sinks below the Black Sea inflow to a depth of , then flows through the Dardanelles Strait and into the Sea of Marmara at velocities of 5–15 cm/s. The Black Sea outflow moves westward along the northern Aegean Sea, then flows southwards along the east coast of Greece.
The physical oceanography of the Aegean Sea is controlled mainly by the regional climate, the fresh water discharge from major rivers draining southeastern Europe, and the seasonal variations in the Black Sea surface water outflow through the Dardanelles Strait.
Analysis of the Aegean during 1991 and 1992 revealed 3 distinct water masses:
History.
The current coastline dates back to about 4000 BC. Before that time, at the peak of the last ice age (c. 16,000 BC) sea levels everywhere were 130 metres lower, and there were large well-watered coastal plains instead of much of the northern Aegean. When they were first occupied, the present-day islands including Milos with its important obsidian production were probably still connected to the mainland. The present coastal arrangement appeared c. 7000 BC, with post-ice age sea levels continuing to rise for another 3,000 years after that.
The subsequent Bronze Age civilizations of Greece and the Aegean Sea have given rise to the general term "Aegean civilization". In ancient times, the sea was the birthplace of two ancient civilizations – the Minoans of Crete and the Mycenean Civilization of the Peloponnese.
Later arose the city-states of Athens and Sparta among many others that constituted the Athenian Empire and Hellenic Civilization. Plato described the Greeks living round the Aegean "like frogs around a pond". The Aegean Sea was later invaded by the Persians and the Romans, and inhabited by the Byzantine Empire, the Bulgarians, the Venetians, the Genoese, the Seljuq Turks, and the Ottoman Empire. The Aegean was the site of the original democracies, and its seaways were the means of contact among several diverse civilizations of the Eastern Mediterranean.
Economics and politics.
Many of the islands in the Aegean have safe harbours and bays. In ancient times, navigation through the sea was easier than travelling across the rough terrain of the Greek mainland (and to some extent the coastal areas of Anatolia). Many of the islands are volcanic, and marble and iron are mined on other islands. The larger islands have some fertile valleys and plains. Of the main islands in the Aegean Sea, two belong to Turkey – Bozcaada (Tenedos "Τένεδος") and Gökçeada (Imbros "Ίμβρος"); the rest belong to Greece. Between the two countries, there are political disputes over several aspects of political control over the Aegean space, including the size of territorial waters, air control and the delimitation of economic rights to the continental shelf.
References.
      ^ The word "Aegean" is pronounced "i-Jee-en".

</doc>
<doc id="843" url="http://en.wikipedia.org/wiki?curid=843" title="A Clockwork Orange">
A Clockwork Orange

A Clockwork Orange is a dystopian novella by Anthony Burgess published in 1962. Set in a not-so-distant future English society that has a culture of extreme youth violence, the novel's teenage protagonist, Alex, narrates his violent exploits and his experiences with state authorities intent on reforming him. When the state undertakes to reform Alex—to "redeem" him—the novel asks, "At what cost?". The book is partially written in a Russian-influenced argot called "Nadsat". According to Burgess it was a "jeu d'esprit" written in just three weeks.
In 2005, "A Clockwork Orange" was included on "Time" magazine's list of the 100 best English-language novels written since 1923, and it was named by Modern Library and its readers as one of the 100 best English-language novels of the 20th century. The original manuscript of the book is located at McMaster University in Hamilton, Ontario, Canada since that institution purchased the documents in 1971.
Plot summary.
Part 1: Alex's world.
Alex, a teenager living in near-future dystopian England, leads his gang on a night of opportunistic, random "ultra-violence". Alex's friends ("droogs" in the novel's Anglo-Russian slang, 'Nadsat') are: Dim, a slow-witted bruiser who is the gang's muscle; Georgie, an ambitious second-in-command; and Pete, who mostly plays along as the droogs indulge their taste for ultra-violence. Characterized as a sociopath and a hardened juvenile delinquent, Alex is also intelligent and quick-witted, with sophisticated taste in music, being particularly fond of Beethoven, referred to as "Lovely Ludwig Van".
The novel begins with the droogs sitting in their favorite hangout (the Korova Milk Bar), drinking "milk-plus", a drink consisting of milk, prodded with the customer's choice of certain drugs, including "vellocet", "synthemesc", or "drencrom" (which is what Alex and his droogs were drinking, according to Alex's own first-person narration). This drug, referred to as "knives", would "sharpen you up", as it did for Alex, in preparation of the night's mayhem. They assault a scholar walking home from the public library, rob a store, leaving the owner and his wife bloodied and unconscious, stomp a panhandling derelict, then scuffle with a rival gang. Joyriding through the countryside in a stolen car, they break into an isolated cottage and maul the young couple living there, beating the husband and raping his wife. In a metafictional touch, the husband is a writer working on a manuscript called ""A Clockwork Orange,"" and Alex contemptuously reads out a paragraph that states the novel's main theme before shredding the manuscript. Back at the milk bar, Alex punishes Dim for some crude behaviour, and strains within the gang become apparent. At home in his dreary flat, Alex plays classical music at top volume while fantasizing about more orgiastic violence.
Alex skips school the next day. Following an unexpected visit from P. R. Deltoid, his "post-corrective advisor," Alex meets a pair of ten-year-old girls and takes them back to his parents' flat, where he serves them scotch and soda, injects himself with hard drugs, and then rapes them. That evening, Alex finds his droogs in a mutinous mood. Georgie challenges Alex for leadership of the gang, demanding that they pull a "man-sized" job. Alex quells the rebellion by slashing Dim's hand and fighting with Georgie, then in a show of generosity takes them to a bar, where Alex insists on following through on Georgie's idea to burgle the home of a wealthy old woman. The break-in starts as farce and ends in tragic pathos, as Alex's attack kills the elderly woman. His escape is blocked by an attack by Dim, as payback for the earlier fight, leaving Alex incapacitated on the front step when the police arrive.
Part 2: The Ludovico Technique.
Sentenced to prison for murder, Alex gets a job at the Wing chapel playing religious music on the stereo before and after services as well as during the singing of hymns. The prison chaplain mistakes Alex's Bible studies for stirrings of faith (Alex is actually reading Scripture for the violent passages). After Alex's fellow cellmates blame him for beating a troublesome cellmate to death, he agrees to undergo an experimental behaviour-modification treatment called the Ludovico Technique. The technique is a form of aversion therapy in which Alex receives an injection that makes him feel sick while watching graphically violent films, eventually conditioning him to suffer crippling bouts of nausea at the mere thought of violence. As an unintended consequence, the soundtrack to one of the films—Beethoven's Ninth Symphony—renders Alex unable to listen to his beloved classical music.
The effectiveness of the technique is demonstrated to a group of VIPs, who watch as Alex collapses before a walloping bully, and abases himself before a scantily-clad young woman whose presence has aroused his predatory sexual inclinations. Although the prison chaplain accuses the state of stripping Alex of free will, the government officials on the scene are pleased with the results and Alex is released into society early as a result.
Part 3: After prison.
Since his parents are now renting his room to a lodger, Alex wanders the streets homeless. He enters a public library where he hopes to learn a painless way to commit suicide. There, he accidentally encounters the old scholar he assaulted earlier in the book, who, keen on revenge, beats Alex with the help of his friends. The policemen who come to Alex's rescue turn out to be none other than Dim and former gang rival Billyboy. The two policemen take Alex outside of town and beat him up. Dazed and bloodied, Alex collapses at the door of an isolated cottage, realizing too late that it is the house he and his droogs invaded in the first part of the story. Because the gang wore masks during the assault, the writer does not recognize Alex. The writer, whose name is revealed as F. Alexander, shelters Alex and questions him about the conditioning. During this sequence, it is revealed that Mrs. Alexander died of injuries inflicted during the gang-rape, while her husband has decided to continue living "where her fragrant memory persists" despite the horrid memories. Alex reveals in his description that he has been conditioned to feel intolerable deathly nausea on hearing certain classical music. Alexander, a critic of the government, intends to use Alex's therapy as a symbol of state brutality and thereby prevent the incumbent government from being re-elected, but a careless Alex soon inadvertently reveals that he was the ringleader during the night two years ago. Frightened for his own safety, Alex blurts out a confession to the writer's radical associates after they remove him from F. Alexander's home. Instead of protecting him, however, they imprison Alex in a dreary flat not far from his parents' residence. They pretend to leave, and then while he is sleeping in a locked bedroom subject him to a relentless barrage of classical music, prompting him to attempt suicide by leaping from a high window.
Alex wakes up in a hospital, where he is courted by government officials anxious to counter the bad publicity created by his suicide attempt. With Alexander placed in a mental institution, Alex is offered a well-paying job if he agrees to side with the government. As photographers snap pictures, Alex daydreams of orgiastic violence and reflects upon the news that his Ludovico conditioning has been reversed as part of his recovery: "I was cured, all right".
In the final chapter, Alex finds himself half-heartedly preparing for yet another night of crime with a new trio of droogs. After a chance encounter with Pete, who has reformed and married, Alex finds himself taking less and less pleasure in acts of senseless violence. He begins contemplating giving up crime himself to become a productive member of society and start a family of his own, while reflecting on the notion that his own children will be just as destructive—if not more so—than he himself.
Omission of the final chapter.
The book has three parts, each with seven chapters. Burgess has stated that the total of 21 chapters was an intentional nod to the age of 21 being recognised as a milestone in human maturation. The 21st chapter was omitted from the editions published in the United States prior to 1986. In the introduction to the updated American text (these newer editions include the missing 21st chapter), Burgess explains that when he first brought the book to an American publisher, he was told that U.S. audiences would never go for the final chapter, in which Alex sees the error of his ways, decides he has lost all energy for and thrill from violence and resolves to turn his life around (a slow-ripening but classic moment of metanoia—the moment at which one's protagonist realises that everything he thought he knew was wrong).
At the American publisher's insistence, Burgess allowed their editors to cut the redeeming final chapter from the U.S. version, so that the tale would end on a darker note, with Alex succumbing to his violent, reckless nature—an ending which the publisher insisted would be 'more realistic' and appealing to a U.S. audience. The film adaptation, directed by Stanley Kubrick, is based on the American edition of the book (which Burgess considered to be "badly flawed"). Kubrick called Chapter 21 "an extra chapter" and claimed that he had not read the original version until he had virtually finished the screenplay, and that he had never given serious consideration to using it. In Kubrick's opinion, the final chapter was unconvincing and inconsistent with the book.
Analysis.
Background.
"A Clockwork Orange" was written in Hove, then a senescent seaside town. Burgess had arrived back in Britain after his stint abroad to see that much had changed. A youth culture had grown, including coffee bars, pop music and teenage gangs. England was gripped by fears over juvenile delinquency. Burgess claimed that the novel's inspiration was his first wife Lynne's beating by a gang of drunk American servicemen stationed in England during World War II. She subsequently miscarried. In its investigation of free will, the book's target is ostensibly the concept of behaviourism, pioneered by such figures as B. F. Skinner.
Burgess later stated that he wrote the book in three weeks.
Title.
Burgess gave three possible origins for the title:
In his essay, "Clockwork Oranges," Burgess asserts that "this title would be appropriate for a story about the application of Pavlovian or mechanical laws to an organism which, like a fruit, was capable of colour and sweetness." This title alludes to the protagonist's positively conditioned responses to feelings of evil which prevent the exercise of his free will. To induce this conditioning, the protagonist is subjected to a technique in which violent scenes displayed on screen, which he is forced to watch, are systematically paired with negative stimulation in the form of nausea and "feelings of terror" caused by an emetic medicine administered just before the presentation of the films.
Point of view.
"A Clockwork Orange" is written using a narrative first-person singular perspective of a seemingly biased and unreliable narrator. The protagonist, Alex, never justifies his actions in the narration, giving a sense that he is somewhat sincere; a narrator who, as unlikeable as he may attempt to seem, evokes pity from the reader by telling of his unending suffering, and later through his realisation that the cycle will never end. Alex's perspective is effective in that the way that he describes events is easy to relate to, even if the situations themselves are not.
Use of slang.
The book, narrated by Alex, contains many words in a slang argot which Burgess invented for the book, called Nadsat. It is a mix of modified Slavic words, rhyming slang, derived Russian (like "baboochka"), and words invented by Burgess himself. For instance, these terms have the following meanings in Nadsat: "droog" = friend; "korova" = cow; "gulliver" ('golova') = head; "malchick" or "malchickiwick" = boy; "soomka" = sack or bag; "Bog" = God; "khorosho" ('horrosho') = good; "prestoopnick" = criminal; "rooka" ('rooker') = hand; "cal" = crap; "veck" ('chelloveck') = man or guy; "litso" = face; "malenky" = little; and so on. Compare Polari.
One of Alex's doctors explains the language to a colleague as "odd bits of old rhyming slang; a bit of gypsy talk, too. But most of the roots are Slav propaganda. Subliminal penetration." Some words are not derived from anything, but merely easy to guess, e.g. 'in-out, in-out' or 'the old in-out' means sexual intercourse. "Cutter," however, means 'money,' because 'cutter' rhymes with 'bread-and-butter'; this is rhyming slang, which is intended to be impenetrable to outsiders (especially eavesdropping policemen). Additionally, slang like Appypolly loggy (Apology) seems to derive from school boy slang. This reflects Alex's age of 15.
In the first edition of the book, no key was provided, and the reader was left to interpret the meaning from the context. In his appendix to the restored edition, Burgess explained that the slang would keep the book from seeming dated, and served to muffle "the raw response of pornography" from the acts of violence. Furthermore, in a novel where a form of brainwashing plays a role, the narrative itself brainwashes the reader into understanding Nadsat.
The term "ultraviolence," referring to excessive and/or unjustified violence, was coined by Burgess in the book, which includes the phrase "do the ultra-violent." The term's association with aesthetic violence has led to its use in the media.
Banning and censorship history in the US.
In 1976, "A Clockwork Orange" was removed from an Aurora, Colorado high school because of "objectionable language". A year later in 1977 it was removed from high school classrooms in Westport, Massachusetts over similar concerns with "objectionable" language. In 1982, it was removed from two Anniston, Alabama libraries, later to be reinstated on a restricted basis. Also, in 1973 a bookseller was arrested for selling the novel. Charges were later dropped. However, each of these instances came after the release of Stanley Kubrick's popular 1971 film adaptation of "A Clockwork Orange", itself the subject of much controversy.
Writer's dismissal.
In 1985, Burgess published "Flame into Being: The Life and Work of D. H. Lawrence", and while discussing "Lady Chatterley's Lover" in his biography, Burgess compared that novel's notoriety with "A Clockwork Orange": "We all suffer from the popular desire to make the known notorious. The book I am best known for, or only known for, is a novel I am prepared to repudiate: written a quarter of a century ago, a "jeu d'esprit" knocked off for money in three weeks, it became known as the raw material for a film which seemed to glorify sex and violence. The film made it easy for readers of the book to misunderstand what it was about, and the misunderstanding will pursue me until I die. I should not have written the book because of this danger of misinterpretation, and the same may be said of Lawrence and "Lady Chatterley's Lover"." Burgess also dismissed "A Clockwork Orange" as "too didactic to be artistic".
Awards and nominations and rankings.
The novel was chosen by "Time" magazine as one of the 100 best English-language novels from 1923 to 2005.
Adaptations.
The best known adaptation of the novel to other forms is the 1971 film "A Clockwork Orange" by Stanley Kubrick, starring Malcolm McDowell as Alex.
A 1965 film by Andy Warhol entitled "Vinyl" was an adaptation of Burgess' novel.
After Kubrick's film was released, Burgess wrote a stage play titled "A Clockwork Orange". In it, Dr. Branom defects from the psychiatric clinic when he grasps that the aversion therapy has destroyed Alex's ability to enjoy music. The play restores the novel's original ending.
In 1988, a German adaptation of "A Clockwork Orange" at the intimate theatre of Bad Godesberg featured a musical score by the German punk rock band Die Toten Hosen which, combined with orchestral clips of Beethoven's Ninth Symphony and "other dirty melodies" (so stated by the subtitle), was released on the album "Ein kleines bisschen Horrorschau". The track "Hier kommt Alex" became one of the band's signature songs.
In February 1990, another musical version was produced at the Barbican Theatre in London by the Royal Shakespeare Company. Titled "A Clockwork Orange: 2004", it received mostly negative reviews, with John Peter of "The Sunday Times" of London calling it "only an intellectual "Rocky Horror Show"," and John Gross of "The Sunday Telegraph" calling it "a clockwork lemon." Even Burgess himself, who wrote the script based on his novel, was disappointed. According to "The Evening Standard", he called the score, written by Bono and The Edge of the rock group U2, "neo-wallpaper." Burgess had originally worked alongside the director of the production, Ron Daniels, and envisioned a musical score that was entirely classical. Unhappy with the decision to abandon that score, he heavily criticised the band's experimental mix of hip hop, liturgical and gothic music. Lise Hand of "The Irish Independent" reported The Edge as saying that Burgess' original conception was "a score written by a novelist rather than a songwriter." Calling it "meaningless glitz," Jane Edwardes of "20/20 Magazine" said that watching this production was "like being invited to an expensive French Restaurant - and being served with a Big Mac."
In 1994, Chicago's Steppenwolf Theater put on a production of "A Clockwork Orange" directed by Terry Kinney. The American premiere of novelist Anthony Burgess' own adaptation of his "A Clockwork Orange" starred K. Todd Freeman as Alex. In 2001, UNI Theatre (Mississauga, Ontario) presented the Canadian premiere of the play under the direction of Terry Costa.
In 2002, Godlight Theatre Company presented the New York Premiere adaptation of "A Clockwork Orange" at Manhattan Theatre Source. The production went on to play at the SoHo Playhouse (2002), Ensemble Studio Theatre (2004), 59E59 Theaters (2005) and the Edinburgh Festival Fringe (2005). While at Edinburgh, the production received rave reviews from the press while playing to sold-out audiences. The production was directed by Godlight's Artistic Director, Joe Tantalo.
In 2003, Los Angeles director Brad Mays and the ARK Theatre Company staged a multi-media adaptation of "A Clockwork Orange", which was named "Pick Of The Week" by the "LA Weekly" and nominated for three of the 2004 LA Weekly Theater Awards: Direction, Revival Production (of a 20th-century work), and Leading Female Performance. Vanessa Claire Smith won Best Actress for her gender-bending portrayal of Alex, the music-loving teenage sociopath. This production utilised three separate video streams outputted to seven onstage video monitors - six 19-inch and one 40-inch. In order to preserve the first-person narrative of the book, a pre-recorded video stream of Alex, "your humble narrator," was projected onto the 40-inch monitor, thereby freeing the onstage character during passages which would have been awkward or impossible to sustain in the breaking of the fourth wall.
David Bowie referenced the book/film in various songs in his early 1970s oeuvre: "Suffragette City" mentions "droogie" in its lyrics, which is a reference to a term used in the book. Live appearances would include tracks from the soundtrack album, usually opening with Beethoven's Ninth Symphony segment "Ode To Joy" (as can be heard on live albums "Santa Monica '72" and the "" soundtrack CD & DVD). The song "Sex and Violence" by American thrash metal band Carnivore (band) is about "A Clockwork Orange". The Brazilian heavy metal group Sepultura used the plot of "A Clockwork Orange" for their concept album "A-Lex". German punk rock band Die Toten Hosen wrote an album based on "A Clockwork Orange", titled "Ein kleines bisschen Horrorschau" or "A Tiny Bit of Horrorshow." English punk rock band the Adicts became known for their "droog" image inspired by Kubrick's movie. Their third studio album was also entitled "smart alex", referring to the book's protagonist.

</doc>
<doc id="844" url="http://en.wikipedia.org/wiki?curid=844" title="Amsterdam">
Amsterdam

Amsterdam (; ) is the capital city of The Netherlands and the most populous within the Kingdom of the Netherlands. Its status as the Dutch capital is mandated by the Constitution of the Netherlands though it is not the seat of the Dutch government, which is at The Hague ("Den Haag"). Amsterdam has a population of within the city-proper, in the urban region and in the greater metropolitan area. The city is located in the province of North Holland ("Noord Holland") in the west of the country. It comprises much of the northern part of the Randstad, one of the larger conurbations in Europe, with a population of approximately 7 million.
Amsterdam's name derives from "Amstelredamme", indicative of the city's origin as a dam of the river Amstel. Originating as a small fishing village in the late 12th century, Amsterdam became one of the most important ports in the world during the Dutch Golden Age (17th century), a result of its innovative developments in trade. During that time, the city was the leading center for finance and diamonds. In the 19th and 20th centuries, the city expanded, and many new neighborhoods and suburbs were planned and built. The 17th-century canals of Amsterdam and the 19–20th century Defence Line of Amsterdam are on the UNESCO World Heritage List.
As the commercial capital of the Netherlands and one of the top financial centres in Europe, Amsterdam is considered an alpha world city by the Globalization and World Cities (GaWC) study group. The city is also the cultural capital of the Netherlands. Many large Dutch institutions have their headquarters there, and 7 of the world's top 500 companies, including Philips and ING, are based in the city. In 2012, Amsterdam was ranked 2nd best city to live by the Economist Intelligence Unit (EIU) and 12th globally on quality of living by Mercer. The city was previously ranked 3rd in innovation by 2thinknow in the Innovation Cities Index 2009.
The Amsterdam Stock Exchange, the oldest stock exchange in the world, is located in the city center. Amsterdam's main attractions, including its historic canals, the Rijksmuseum, the Van Gogh Museum, Stedelijk Museum, Hermitage Amsterdam, Anne Frank House, Amsterdam Museum, its red-light district, and its many cannabis coffee shops draw more than 3.66 million international visitors annually.
History.
Etymology.
Shortly after the floods of 1170 en 1173 locals of the river Amstel vicinity built a bridge over- and a dam across the river, hence giving its name to the village: "Aemstelredamme". The earliest recorded use of the name "Aemstelredamme" (Amsterdam) comes from a document dated October 27, 1275. Inhabitants of the village, by this document, were exempted from paying a bridge toll in the County of Holland by Count Floris V.
This meant it had been allowed to the inhabitants of the village of Aemstelredamme to travel freely through the County of Holland without having to pay toll at bridges, locks and dams all through the county. The certificate describes the inhabitants as "homines manentes apud Amestelledamme" (people living near "Amestelledamme"). By 1327, the name had developed into "Aemsterdam".
Founding and Middle Ages.
Amsterdam's founding is relatively recent compared with much older Dutch cities such as Nijmegen, Rotterdam, and Utrecht. In October 2008, historical geographer Chris de Bont suggested that the land around Amsterdam was being reclaimed as early as the late 10th century. This does not necessarily mean that there was already a settlement then since reclamation of land may not have been for farming—it may have been for peat, used as fuel.
Amsterdam was granted city rights in either 1300 or 1306. From the 14th century on, Amsterdam flourished, largely because of trade with the Hanseatic League. In 1345, an alleged Eucharistic miracle in the Kalverstraat rendered the city an important place of pilgrimage until the adoption of the Protestant faith. The "Stille Omgang"—a silent procession in civil attire—is today a remnant of the rich pilgrimage history.
Conflict with Spain.
In the 16th century, the Dutch rebelled against Philip II of Spain and his successors. The main reasons for the uprising were the imposition of new taxes, the tenth penny, and the religious persecution of Protestants by the Spanish Inquisition. The revolt escalated into the Eighty Years' War, which ultimately led to Dutch independence. Strongly pushed by Dutch Revolt leader William the Silent, the Dutch Republic became known for its relative religious tolerance. Jews from the Iberian Peninsula, Huguenots from France, prosperous merchants and printers from Flanders, and economic and religious refugees from the Spanish-controlled parts of the Low Countries found safety in Amsterdam. The influx of Flemish printers and the city's intellectual tolerance made Amsterdam a centre for the European free press.
Center of the Dutch Golden Age.
The 17th century is considered Amsterdam's "Golden Age", during which it became the wealthiest city in the world. Ships sailed from Amsterdam to the Baltic Sea, North America, and Africa, as well as present-day Indonesia, India, Sri Lanka, and Brazil, forming the basis of a worldwide trading network. Amsterdam's merchants had the largest share in both the Dutch East India Company and the Dutch West India Company. These companies acquired overseas possessions that later became Dutch colonies. Amsterdam was Europe's most important point for the shipment of goods and was the leading Financial Centre of the world. In 1602, the Amsterdam office of the Dutch East India Company became the world's first stock exchange by trading in its own shares.
Decline and modernization.
Amsterdam's prosperity declined during the 18th and early 19th centuries. The wars of the Dutch Republic with England and France took their toll on Amsterdam. During the Napoleonic Wars, Amsterdam's significance reached its lowest point, with Holland being absorbed into the French Empire. However, the later establishment of the United Kingdom of the Netherlands in 1815 marked a turning point.
The end of the 19th century is sometimes called Amsterdam's second Golden Age. New museums, a train station, and the Concertgebouw were built; in this same time, the Industrial Revolution reached the city. The Amsterdam-Rhine Canal was dug to give Amsterdam a direct connection to the Rhine, and the North Sea Canal was dug to give the port a shorter connection to the North Sea. Both projects dramatically improved commerce with the rest of Europe and the world. In 1906, Joseph Conrad gave a brief description of Amsterdam as seen from the seaside, in "".
Twentieth century.
Shortly before the First World War, the city began expanding, and new suburbs were built. Even though the Netherlands remained neutral in this war, Amsterdam suffered a food shortage, and heating fuel became scarce. The shortages sparked riots in which several people were killed. These riots are known as the "Aardappeloproer" (Potato rebellion). People started looting stores and warehouses in order to get supplies, mainly food.
After landflood in 1916 the depleted municipalities, Durgerdam, Holysloot, Zunderdorp and Schellingwoude, all lying north of Amsterdam, were, on their own request, annexed to the city on 1-1-1921.
Germany invaded the Netherlands on 10 May 1940 and took control of the country. Some Amsterdam citizens sheltered Jews, thereby exposing themselves and their families to the high risk of being imprisoned or sent to concentration camps. More than 100,000 Dutch Jews were deported to Nazi concentration camps of which some 60.000 lived in Amsterdam. Perhaps the most famous deportee was the young Jewish girl Anne Frank, who died in the Bergen-Belsen concentration camp. At the end of the Second World War, communication with the rest of the country broke down, and food and fuel became scarce. Many citizens traveled to the countryside to forage. Dogs, cats, raw sugar beets, and Tulip bulbs—cooked to a pulp—were consumed to stay alive. Most of the trees in Amsterdam were cut down for fuel, and all the wood was taken from the apartments of deported Jews.
Many new suburbs, such as Osdorp, Slotervaart, "Slotermeer", and "Geuzenveld", were built in the years after the Second World War.
These suburbs contained many public parks and wide, open spaces, and the new buildings provided improved housing conditions with larger and brighter rooms, gardens, and balconies. Because of the war and other incidents of the 20th century, almost the entire city centre had fallen into disrepair. As society was changing, politicians and other influential figures made plans to redesign large parts of it. There was an increasing demand for office buildings and new roads as the automobile became available to most common people. A metro started operating in 1977 between the new suburb of Bijlmer and the centre of Amsterdam. Further plans were to build a new highway above the metro to connect the Central Station and city centre with other parts of the city.
The incorporated large-scale demolitions began in Amsterdam's formerly Jewish neighbourhood. Smaller streets, such as the "Jodenbreestraat", were widened and saw almost all of their houses demolished. During the destruction's peak, the "Nieuwmarktrellen" (Nieuwmarkt riots) broke out, where people expressed their fury about the demolition caused by the restructuring of the city.
As a result, the demolition was stopped, and the highway was never built, with only the metro being finished. Only a few streets remained widened. The new city hall was built on the almost completely demolished "Waterlooplein". Meanwhile, large private organisations, such as "Stadsherstel Amsterdam", were founded with the aim of restoring the entire city centre. Although the success of this struggle is visible today, efforts for further restoration are still ongoing. The entire city centre has reattained its former splendor and, as a whole, is now a protected area. Many of its buildings have become monuments, and in July 2010 the "Grachtengordel" (Herengracht, Keizersgracht, and Prinsengracht) was added to the UNESCO World Heritage List.
Twenty-first century.
At the beginning of the new millennium, social problems such as safety, ethnic discrimination and segregation between religious and social groups began to develop. Forty-five percent of the population of Amsterdam has non-Dutch parents. Large social groups come from Suriname, the Dutch Antilles, Morocco and Turkey. Amsterdam is characterized by its (perceived) social tolerance and diversity. The former mayor of Amsterdam, Job Cohen, and his alderman for integration Ahmed Aboutaleb (Now mayor of Rotterdam) formulated a policy of "keeping things together" which involves social dialogue, tolerance and harsh measures against those who break the law.
Geography.
Amsterdam is located in the western Netherlands, in the province of North Holland. The river Amstel terminates in the city centre and connects to a large number of canals that eventually terminate in the IJ. Amsterdam is situated 2 metres below sea level. The surrounding land is flat as it is formed of large polders. A man made forest, Amsterdamse Bos, is situated southwest. Amsterdam is connected to the North Sea through the long North Sea Canal.
Amsterdam is intensely urbanized, as is the Amsterdam metropolitan area surrounding the city. Comprising of land, the city proper has 4,457 inhabitants per km2 and 2,275 houses per km2. Parks and nature reserves make up 12% of Amsterdam's land area.
Venice of the North.
Amsterdam is home to more than one hundred kilometers of canals. The three main canals are Prinsengracht, Herengracht and Keizersgracht, all 3 of which are navigable by boat. In the Middle Ages, Amsterdam was surrounded by a moat, called the Singel, which now forms the innermost ring in the city, and makes the city center a horseshoe shape. The city is also served by a seaport. It is often nicknamed the "Venice of the North," due to its division into approximately 90 islands, which are linked by more than 1,200 bridges.
Climate.
Amsterdam has an oceanic climate (Köppen climate classification "Cfb"), strongly influenced by its proximity to the North Sea to the west, with prevailing westerly winds. Winters are cold, and summers are mild, although occasionally quite cool. Amsterdam, as well as most of the North Holland province, lies in USDA Hardiness zone 8b. Frosts mainly occur during spells of easterly or northeasterly winds from the inner European continent. Even then, because Amsterdam is surrounded on three sides by large bodies of water, as well as having a significant heat-island effect, nights rarely fall below , while it could easily be in Hilversum, southeast. Summers are moderately warm but rarely hot. The average daily high in August is , and or higher is only measured on average on 2.5 days, placing Amsterdam in AHS Heat Zone 2. The record extremes range from to .
Days with more than of precipitation are common, on average 133 days per year. Amsterdam's average annual precipitation is , more than what is measured at Amsterdam Schiphol Airport. A large part of this precipitation falls as light rain or brief showers. Cloudy and damp days are common during the cooler months of October through March.
Demographics.
Amsterdam has a population of 810,084 inhabitants within city limits. On 1 January 2012, the ethnic makeup of Amsterdam was 49.5% of Dutch ancestry and 50.5% of foreign origin.
In the 16th and 17th century non-Dutch immigrants to
Amsterdam were mostly Huguenots, Flemings, Sephardi Jews and Westphalians. Huguenots came after the Edict of Fontainebleau in 1685, while the Flemish Protestants came during the Eighty Years' War. The Westphalians came to Amsterdam mostly for economic reasons – their influx continued through the 18th and 19th centuries. Before the Second World War, 10% of the city population was Jewish. Just twenty percent of them survived the Shoah.
The first mass immigration in the 20th century were by people from Indonesia, who came to Amsterdam after the independence of the Dutch East Indies in the 1940s and 1950s. In the 1960s guest workers from Turkey, Morocco, Italy and Spain emigrated to Amsterdam. After the independence of Suriname in 1975, a large wave of Surinamese settled in Amsterdam, mostly in the Bijlmer area. Other immigrants, including refugees asylum seekers and illegal immigrants, came from Europe, America, Asia, and Africa. In the 1970s and 1980s, many 'old' Amsterdammers moved to 'new' cities like Almere and Purmerend, prompted by the third planological bill of the Dutch government. This bill promoted suburbanisation and arranged for new developments in so called "groeikernen", literally "cores of growth". Young professionals and artists moved into neighbourhoods de Pijp and the Jordaan abandoned by these Amsterdammers. The non-Western immigrants settled mostly in the social housing projects in Amsterdam-West and the Bijlmer. Today, people of non-Western origin make up approximately one-third of the population of Amsterdam, and more than 50% of children. A tendence to ethnical segregation is clearly visible, with people of non-Western origins, considered as a separate group by Statistics Netherlands, concentrating in specific neighborhoods especially in Nieuw-West, Zeeburg, Bijlmer and in certain areas of Amsterdam-Noord.
The largest religious group are Christians (17% in 2000), who are divided between Roman Catholics and Protestants. The next largest religion is Islam (14% in 2000), most of whose followers are Sunni.
In 1578 the previously Roman Catholic city of Amsterdam joined the revolt against Spanish rule, late in comparison to other major northern Dutch cities. In line with Protestant procedure of that time, all churches were converted to Protestant worship. Calvinism became the dominant religion, and although Catholicism was not forbidden and priests allowed to serve, the Catholic hierarchy was prohibited. This led to the establishment of "schuilkerken", covert churches, behind seemingly ordinary canal side house fronts. One example is the current debate centre de Rode Hoed.
A large influx of foreigners of many religions came to 17th-century Amsterdam, in particular Sefardic Jews from Spain and Portugal, Huguenots from France, and Protestants from the Southern Netherlands. This led to the establishment of many non-Dutch-speaking religious churches. In 1603, the first notification was made of Jewish religious service. In 1639, the first synagogue was consecrated. The Jews came to call the town Jerusalem of the West, a reference to their sense of belonging there.
As they became established in the city, other Christian denominations used converted Catholic chapels to conduct their own services. The oldest English-language church congregation in the world outside the United Kingdom is found at the Begijnhof. Regular services there are still offered in English under the auspices of the Church of Scotland. The Huguenots accounted for nearly 20% of Amsterdam's inhabitants in 1700. Being Calvinists, they soon integrated into the Dutch Reformed Church, though often retaining their own congregations. Some, commonly referred by the moniker 'Walloon', are recognizable today as they offer occasional services in French.
In the second half of the 17th century, Amsterdam experienced an influx of Ashkenazim, Jews from Central and Eastern Europe, which continued into the 19th century. Jews often fled the pogroms in those areas. The first Ashkenazi who arrived in Amsterdam were refugees from the Chmielnicki Uprising in Poland and the Thirty Years' War. They not only founded their own synagogues, but had a strong influence on the 'Amsterdam dialect' adding a large Yiddish local vocabulary.
Despite an absence of an official Jewish ghetto, most Jews preferred to live in the eastern part of the old medieval heart of the city. The main street of this Jewish neighborhood was the "Jodenbreestraat". The neighborhood comprised the "Waterlooplein" and the Nieuwmarkt. Buildings in this neighborhood fell into disrepair after the Second World War, and a large section of the neighbourhood was demolished during the construction of the subway. This led to riots, and as a result the original plans for large-scale reconstruction were abandoned and the neighborhood was rebuilt with smaller-scale residence buildings on the basis of its original layout.
Catholic churches in Amsterdam have been constructed since the restoration of the episcopal hierarchy in 1853. One of the principal architects behind the city's Catholic churches, Cuypers, was also responsible for the Amsterdam Central Station and the Rijksmuseum, which led to a refusal of Protestant King William III to open 'that monastery'.
In 1924, the Roman Catholic Church of the Netherlands hosted the International Eucharistic Congress in Amsterdam, and numerous Catholic prelates visited the city, where festivities were held in churches and stadiums. Catholic processions on the public streets, however, were still forbidden under law at the time. Only in the 20th century was Amsterdam's relation to Catholicism normalized, but despite its far larger population size, the Catholic clergy chose to place its episcopal see of the city in the nearby provincial town of Haarlem.
In recent times, religious demographics in Amsterdam have been changed by large-scale immigration from former colonies. Immigrants from Suriname have introduced Evangelical Protestantism and Lutheranism, from the Hernhutter variety; Hinduism has been introduced mainly from Suriname; and several distinct branches of Islam have been brought from various parts of the world. Islam is now the largest non-Christian religion in Amsterdam. The large community of Ghanaian and Nigerian immigrants have established African churches, often in parking garages in the Bijlmer area, where many have settled. In addition, a broad array of other religious movements have established congregations, including Buddhism, Confucianism and Hinduism.
Although the saying "Leef en laat leven" or "Live and let live" summarizes the Dutch and especially the Amsterdam open and tolerant society, the increased influx of many races, religions, and cultures after the Second World War, has on a number of occasions strained social relations. With 176 different nationalities, Amsterdam is home to one of the widest varieties of nationalities of any city in the world. The share of the population of immigrant ancestry in the city proper now is about 50%.
The city has been at times marked by ethnic tension. In 2004 film director Theo van Gogh was murdered by an Islamic extremist in Amsterdam. Among others, in line with attitude changes in Dutch politics towards certain (especially Islamic) minorities Turkish-language and Arabic-language TV channels have been dropped from the basic cable TV package. In recent years, politicians are actively discouraged against campaigning in minority languages. In the previous local elections politicians were criticized by current Amsterdam mayor Mr van der Laan (then minister of Integration) for distributing election leaflets in minority languages and in some cases leaflets were collected. Due to this anti-Multicultural stand, van der Laan has been accused of hypocrisy by its own party's PvdA main candidate. Also during the same period, possibly due to his belief in integration via (possibly not always voluntary) assimilation, Amsterdam has been one of the municipalities in the Netherlands which provided immigrants with extensive and free Dutch-language courses, which have benefited many immigrants.
Cityscape and architecture.
Amsterdam fans out south from the Amsterdam Centraal railway station. The oldest area of the town is known as "de Wallen" (the quays). It lies to the east of Damrak and contains the city's famous red light district. To the south of de Wallen is the old Jewish quarter of Waterlooplein. The medieval and colonial age canals of Amsterdam, known as "Grachten", embraces the heart of the city where homes have interesting gables. Beyond the Grachtengordel are the former working class areas of Jordaan and de Pijp. The Museumplein with the city's major museums, the Vondelpark, a 19th-century park named after the Dutch writer Joost van den Vondel, and the Plantage neighbourhood, with the zoo, are also located outside the Grachtengordel.
Several parts of the city and the surrounding urban area are polders. This can be recognised by the suffix "-meer" which means "lake", as in Aalsmeer, Bijlmermeer, Haarlemmermeer, and Watergraafsmeer.
Canals.
The Amsterdam canal system is the result of conscious city planning. In the early 17th century, when immigration was at a peak, a comprehensive plan was developed that was based on four concentric half-circles of canals with their ends emerging at the IJ bay. Known as the "Grachtengordel", three of the canals were mostly for residential development: the "Herengracht" (where "Heren" refers to "Heren Regeerders van de stad Amsterdam" (ruling lords of Amsterdam), and "gracht" means canal, so the name can be roughly translated as "Canal of the lords"), "Keizersgracht" (Emperor's Canal), and "Prinsengracht" (Prince's Canal). The fourth and outermost canal is the "Singelgracht", which is often not mentioned on maps, because it is a collective name for all canals in the outer ring. The Singelgracht should not be confused with the oldest and most inner canal "Singel". The canals served for defence, water management and transport. The defences took the form of a moat and earthen dikes, with gates at transit points, but otherwise no masonry superstructures. The original plans have been lost, so historians, such as Ed Taverne, need to speculate on the original intentions: it is thought that the considerations of the layout were purely practical and defensive rather than ornamental.
Construction started in 1613 and proceeded from west to east, across the breadth of the layout, like a gigantic windshield wiper as the historian Geert Mak calls it – and "not" from the centre outwards, as a popular myth has it. The canal construction in the southern sector was completed by 1656. Subsequently, the construction of residential buildings proceeded slowly. The eastern part of the concentric canal plan, covering the area between the Amstel river and the IJ bay, has never been implemented. In the following centuries, the land was used for parks, senior citizens' homes, theatres, other public facilities, and waterways without much planning.
Over the years, several canals have been filled in, becoming streets or squares, such as the Nieuwezijds Voorburgwal and the Spui.
Expansion.
After the development of Amsterdam's canals in the 17th century, the city did not grow beyond its borders for two centuries. During the 19th century, Samuel Sarphati devised a plan based on the grandeur of Paris and London at that time. The plan envisaged the construction of new houses, public buildings and streets just outside the "grachtengordel". The main aim of the plan, however, was to improve public health. Although the plan did not expand the city, it did produce some of the largest public buildings to date, like the "Paleis voor Volksvlijt".
Following Sarphati, "Van Niftrik" and "Kalff" designed an entire ring of 19th century neighbourhoods surrounding the city’s centre, with the city preserving the ownership of all land outside the 17th century limit, thus firmly controlling development. Most of these neighbourhoods became home to the working class.
In response to overcrowding, two plans were designed at the beginning of the 20th century which were very different from anything Amsterdam had ever seen before: "Plan Zuid", designed by the architect Berlage, and "West". These plans involved the development of new neighbourhoods consisting of "housing blocks" for all social classes.
After the Second World War, large new neighbourhoods were built in the western, southeastern, and northern parts of the city. These new neighbourhoods were built to relieve the city's shortage of living space and give people affordable houses with modern conveniences. The neighbourhoods consisted mainly of large housing blocks situated among green spaces, connected to wide roads, making the neighbourhoods easily accessible by motor car. The western suburbs which were built in that period are collectively called the "Westelijke Tuinsteden". The area to the southeast of the city built during the same period is known as the "Bijlmer".
Architecture.
Amsterdam has a rich architectural history. The oldest building in Amsterdam is the Oude Kerk (Old Church), at the heart of the Wallen, consecrated in 1306. The oldest wooden building is "het Houten Huys" at the Begijnhof.
It was constructed around 1425 and is one of only two existing wooden buildings. It is also one of the few examples of Gothic architecture in Amsterdam.
In the 16th century, wooden buildings were razed and replaced with brick ones. During this period, many buildings were constructed in the architectural style of the Renaissance. Buildings of this period are very recognisable with their stepped gable façades, which is the common Dutch Renaissance style. Amsterdam quickly developed its own Renaissance architecture. These buildings were built according to the principles of the architect Hendrick de Keyser. One of the most striking buildings designed by Hendrick de Keyer is the Westerkerk. In the 17th century baroque architecture became very popular, as it was elsewhere in Europe. This roughly coincided with Amsterdam’s Golden Age. The leading architects of this style in Amsterdam were Jacob van Campen, Philips Vingboons and Daniel Stalpaert.
Philip Vingboons designed splendid merchants' houses throughout the city. A famous building in baroque style in Amsterdam is the Royal Palace on Dam Square. Throughout the 18th century, Amsterdam was heavily influenced by French culture. This is reflected in the architecture of that period. Around 1815, architects broke with the baroque style and started building in different neo-styles. Most Gothic style buildings date from that era and are therefore said to be built in a neo-gothic style. At the end of the 19th century, the Jugendstil or Art Nouveau style became popular and many new buildings were constructed in this architectural style. Since Amsterdam expanded rapidly during this period, new buildings adjacent to the city centre were also built in this style. The houses in the vicinity of the Museum Square in Amsterdam Oud-Zuid are an example of Jugendstil. The last style that was popular in Amsterdam before the modern era was Art Deco. Amsterdam had its own version of the style, which was called the Amsterdamse School. Whole districts were built this style, such as the "Rivierenbuurt". A notable feature of the façades of buildings designed in Amsterdamse School is that they are highly decorated and ornate, with oddly shaped windows and doors.
The old city centre is the focal point of all the architectural styles before the end of the 19th century.
Jugendstil and Georgian are mostly found outside the city’s centre in the neighbourhoods built in the early
20th century, although there are also some striking examples of these styles in the city centre.
Most historic buildings in the city centre and nearby are houses, such as the famous merchants' houses lining the canals.
Parks and recreational areas.
Amsterdam has many parks, open spaces, and squares throughout the city. Vondelpark, the largest park in the city, is located in the Oud-Zuid borough and is named after the 17th century Amsterdam author, Joost van den Vondel. Yearly, the park has around 10 million visitors. In the park is an open air theatre, a playground and several horeca facilities. In the Zuid borough, is Beatrixpark, named after Queen Beatrix. Between Amsterdam and Amstelveen is the Amsterdamse Bos (Amsterdam Forest), the largest recreational area in Amsterdam. Annually, almost 4.5 million people visit the park, which has a size of 1,000 hectares and is approximately three times the size of Central Park. Amstelpark in the Zuid borough houses the Rieker windmill, which dates to 1636. Other parks include Sarphatipark in the De Pijp neighborhood, Oosterpark in the Oost borough, and Westerpark in the Westerpark neighborhood. The city has four beaches, the Nemo Beach, Citybeach "Het stenen hoofd" (Silodam), Blijburg, and one in Amsterdam-Noord.
The city has many open squares (plein in Dutch). The namesake of the city as the site of the original dam, Dam Square, is the main town square and has the Royal Palace and National Monument. Museumplein hosts various museums, including the Rijksmuseum, Van Gogh Museum, and Stedelijk Museum. Other squares include Rembrandtplein, Muntplein, Nieuwmarkt, Leidseplein, Spui, and Waterlooplein.
Economy.
Amsterdam is the financial and business capital of the Netherlands.
Amsterdam is currently one of the best European cities in which to locate an international business. It is ranked fifth in this category and is only surpassed by London, Paris, Frankfurt and Barcelona. Many large corporations and banks have their headquarters in Amsterdam, including Akzo Nobel, Heineken International, ING Group, Ahold, TomTom, Delta Lloyd Group and Philips. KPMG International's global headquarters is located in nearby Amstelveen, where many non-Dutch companies have settled as well, because surrounding communities allow full land ownership, contrary to Amsterdam's land-lease system.
Though many small offices are still located on the old canals, companies are increasingly relocating outside the city centre. The Zuidas (English: South Axis) has become the new financial and legal hub. The five largest law firms of the Netherlands, a number of Dutch subsidiaries of large consulting firms like Boston Consulting Group and Accenture, and the World Trade Center Amsterdam are also located in Zuidas.
There are three other smaller financial districts in Amsterdam. The first is the area surrounding Amsterdam Sloterdijk railway station, where several newspapers like De Telegraaf have their offices. Also, Deloitte, the municipal public transport company ("Gemeentelijk Vervoersbedrijf") and the Dutch tax offices ("Belastingdienst") are located there. The second Financial District is the area surrounding Amsterdam Arena. The third is the area surrounding Amsterdam Amstel railway station. The tallest building in Amsterdam, the Rembrandt Tower, is situated there, as is the headquarters of Philips.
The Amsterdam Stock Exchange (AEX), now part of Euronext, is the world's oldest stock exchange and is one of Europe's largest bourses. It is situated near Dam Square in the city's centre.
Together with Eindhoven (Brainport) and Rotterdam (Seaport), Amsterdam (Airport) forms the foundation of the Dutch economy.
Tourism.
Amsterdam is one of the most popular tourist destinations in Europe, receiving more than 4.63 million international visitors annually, this is excluding the 16 million day trippers visiting the city every year. The number of visitors has been growing steadily over the past decade. This can be attributed to an increasing number of European visitors. Two thirds of the hotels are located in the city's centre. Hotels with 4 or 5 stars contribute 42% of the total beds available and 41% of the overnight stays in Amsterdam. The room occupation rate was 78% in 2006, up from 70% in 2005. The majority of tourists (74%) originate from Europe. The largest group of non-European visitors come from the United States, accounting for 14% of the total. Certain years have a theme in Amsterdam to attract extra tourists. For example, the year 2006 was designated "Rembrandt 400", to celebrate the 400th birthday of Rembrandt van Rijn. Some hotels offer special arrangements or activities during these years. The average number of guests per year staying at the four campsites around the city range from 12,000 to 65,000.
Red light district.
De Wallen, also known as Walletjes or Rosse Buurt, is a designated area for legalised prostitution and is Amsterdam's largest and most well known red-light district. This neighborhood has become a famous attraction for tourists. It consists of a network of roads and alleys containing several hundred small, one-room apartments rented by sex workers who offer their services from behind a window or glass door, typically illuminated with red lights.
Retail.
Shops in Amsterdam range from large department stores such as De Bijenkorf founded in 1870 and Maison de Bonneterie a Parisian style store founded in 1889, to small specialty shops. Amsterdam's high-end shops are found in the streets "Pieter Cornelisz Hooftstraat" and "Cornelis Schuytstraat", which are located in the vicinity of the Vondelpark. One of Amsterdam's busiest high streets is the narrow, medieval "Kalverstraat" in the heart of the city. Other shopping areas include the "Negen Straatjes" and Haarlemmerdijk and Haarlemmerstraat. "Negen Straatjes" are nine narrow streets within the "Grachtengordel", the concentric canal system of Amsterdam. The Negen Straatjes differ from other shopping districts with the presence of a large diversity of privately owned shops. The Haarlemmerstraat and Haarlemmerdijk were voted best shopping street in the Netherlands in 2011. These streets have as the "Negen Straatjes" a large diversity of privately owned shops. But as the "Negen Straatjes" are dominated by fashion stores the Haarlemmerstraat and Haarlemmerdijk offer a very wide variety of all kinds of stores, just to name some specialties: candy and other food related stores, lingerie, sneakers, wedding clothing, interior shops, books, Italian deli's, racing and mountain bikes, skatewear, etc.
The city also features a large number of open-air markets such as the "Albert Cuypmarkt", "Westerstraat-markt", "Ten Katemarkt", and "Dappermarkt". Some of these markets are held on a daily basis, like the Albert Cuypmarkt and the Dappermarkt. Others, like the Westerstraatmarkt, are held on a weekly basis.
Fashion.
Fashion brands like G-star, Gsus, BlueBlood, Iris van Herpen, 10 feet and Warmenhoven & Venderbos, and fashion designers like Mart Visser, Viktor & Rolf, Sheila de Vries, Marlies Dekkers and Frans Molenaar are based in Amsterdam. Modelling agencies Elite Models, Touche models and Tony Jones have opened branches in Amsterdam. Supermodels Yfke Sturm, Doutzen Kroes and Kim Noorda started their careers in Amsterdam. Amsterdam has its garment centre in the World Fashion Center. Buildings which formerly housed brothels in the red light district have been converted to ateliers for young fashion designers, AKA eagle fuel. The famous fashion photographers Inez van Lamsweerde and Vinoodh Matadin were born in Amsterdam.
Culture.
During the later part of the 16th century Amsterdam's Rederijkerskamer (Chamber of Rhetoric) organized contests between different Chambers in the reading of poetry and drama. In 1638, Amsterdam opened its first theatre. Ballet performances were given in this theatre as early as 1642. In the 18th century, French theatre became popular. While Amsterdam was under the influence of German music in the 19th century there were few national opera productions; the Hollandse Opera of Amsterdam was built in 1888 for the specific purpose of promoting Dutch opera. In the 19th century, popular culture was centred on the Nes area in Amsterdam (mainly vaudeville and music-hall). The metronome, one of the most important advances in European classical music, was invented here in 1812 by Dietrich Nikolaus Winkel. At the end of this century, the Rijksmuseum and Stedelijk Museum were built. In 1888, the Concertgebouworkest was established. With the 20th century came cinema, radio and television. Though most studios are located in Hilversum and Aalsmeer, Amsterdam's influence on programming is very strong. Many people who work in the television industry live in Amsterdam. Also, the headquarters of SBS 6 is located in Amsterdam.
Museums.
The most important museums of Amsterdam are located on the Museumplein ("Museum Square"), located at the southwestern side of the Rijksmuseum. It was created in the last quarter of the 19th century on the grounds of the former World's fair. The northeastern part of the square is bordered by the very large Rijksmuseum. In front of the Rijksmuseum on the square itself is a long, rectangular pond. This is transformed into an ice rink in winter. The northwestern part of the square is bordered by the Van Gogh Museum, Stedelijk Museum, House of Bols Cocktail & Genever Experience and Coster Diamonds. The southwestern border of the Museum Square is the Van Baerlestraat, which is a major thoroughfare in this part of Amsterdam. The Concertgebouw is situated across this street from the square. To the southeast of the square are situated a number of large houses, one of which contains the American consulate. A parking garage can be found underneath the square, as well as a supermarket. "Het Museumplein" is covered almost entirely with a lawn, except for the northeastern part of the square which is covered with gravel. The current appearance of the square was realized in 1999, when the square was remodeled. The square itself is the most prominent site in Amsterdam for festivals and outdoor concerts, especially in the summer. Plans were made in 2008 to remodel the square again, because many inhabitants of Amsterdam are not happy with its current appearance.
The Rijksmuseum possesses the largest and most important collection of classical Dutch art.
It opened in 1885. Its collection consists of nearly one million objects. The artist most associated with Amsterdam is Rembrandt, whose work, and the work of his pupils, is displayed in the Rijksmuseum. Rembrandt's masterpiece De Nachtwacht ("The Night Watch") is one of top pieces of art of the museum. It also houses paintings from artists like Van der Helst, Vermeer, Frans Hals, Ferdinand Bol, Albert Cuyp, Jacob van Ruisdael and Paulus Potter. Aside from paintings, the collection consists of a large variety of decorative art. This ranges from Delftware to giant dollhouses from the 17th century. The architect of the gothic revival building was P.J.H. Cuypers. The museum underwent a 10 year, 375 million euro renovation starting in 2003. The full collection was reopened to the public on April 13, 2013.
Van Gogh lived in Amsterdam for a short while and there is a museum dedicated to his work. The museum is housed in one of the few modern buildings in this area of Amsterdam. The building was designed by Gerrit Rietveld. This building is where the permanent collection is displayed. A new building was added to the museum in 1999. This building, known as the performance wing, was designed by Japanese architect Kisho Kurokawa. Its purpose is to house temporary exhibitions of the museum. Some of Van Gogh's most famous paintings, like the Aardappeleters ("The Potato Eaters") and Zonnebloemen ("Sunflowers"), are present in the collection. The Van Gogh museum is the most visited museum in Amsterdam.
Next to the Van Gogh museum stands the Stedelijk Museum. This is Amsterdam's most important museum of modern art . The museum is as old as the square it borders and was opened in 1895. The permanent collection consists of works of art from artists like Piet Mondriaan, Karel Appel, and Kazimir Malevich. After renovations lasting several years the museum opened in September 2012 with a new composite extension that has been called "The Bathtub" due to its resemblance to one.
Amsterdam contains many other museums throughout the city. They range from small museums such as the Verzetsmuseum ("Resistance Museum"), the Anne Frank Huis ("Anne Frank House"), and the Rembrandthuis ("Rembrandt House"), to the very large, like the Tropenmuseum ("Museum of the Tropics"), Amsterdam Museum (formerly known as "Amsterdams Historisch Museum", "Amsterdam Historical Museum"), Hermitage Amsterdam (a dependency of the Hermitage Museum of Saint Petersburg) and the Joods Historisch Museum ("Jewish Historical Museum"). The modern-styled NEMO (museum) is dedicated to child-friendly science exhibitions.
Music.
Amsterdam's musical culture includes a large collection of songs which treat the city nostalgically and lovingly. The 1949 song "Aan de Amsterdamse grachten" ("On the canals of Amsterdam") was performed and recorded by many artists, including John Kraaijkamp sr.; the best-known version is probably that by Wim Sonneveld (1962). In the 1950s Johnny Jordaan rose to fame with "Geef mij maar Amsterdam" ("I prefer Amsterdam"), which praises the city above all others (explicitly Paris); Jordaan sang especially about his own neighborhood, the Jordaan ("Bij ons in de Jordaan"). Colleagues and contemporaries of Johnny include Tante Leen, Zwarte Riek, and Manke Nelis. Other notable Amsterdam songs are "Amsterdam" by Jacques Brel (1964) and "Deze Stad" by De Dijk (1989). A 2011 poll by Amsterdam paper "Het Parool" found, somewhat surprisingly, that Trio Bier's "Oude Wolf" was voted "Amsterdams lijflied". Notable Amsterdam bands from the modern era include the Osdorp Posse and The Ex.
The Heineken Music Hall is a concert hall located near the Amsterdam ArenA. Its main purpose is to serve as a podium for pop concerts for big audiences. Many famous international artists have performed there. Two other notable venues, Paradiso and the Melkweg are located near the Leidseplein. Both focus on broad programming, ranging from indie rock to hip hop, R&B, and other popular genres. Other more subculturally focused music venues are OCCII, OT301, De Nieuwe Anita, Winston Kingdom and Zaal 100. Jazz has a strong following in Amsterdam, with the Bimhuis being the premier venue. In 2012, Ziggo Dome was opened, also near Amsterdam ArenA, a state of the art indoor music arena.
The Heineken Music Hall is also host to many electronic dance music festivals, alongside many other venues. Armin van Buuren and Tiesto, some of the worlds leading Trance DJ's hail from the Netherlands and perform frequently in Amsterdam. Each year in October, the city hosts the Amsterdam Dance Event (ADE) which is one of the leading electronic music conferences and one of the biggest club festivals for electronic music in the world. Another popular dance festival is 5daysoff, which takes place in the venues Paradiso and Melkweg. In summer time there are several big outdoor dance parties in or nearby Amsterdam, such as Awakenings, Dance Valley, Mystery Land, Loveland, A Day at the Park, Welcome to the Future, and Valtifest.
Amsterdam has a world-class symphony orchestra, the Royal Concertgebouw Orchestra. Their home is the Concertgebouw, which is across the Van Baerlestraat from the Museum Square. It is considered by critics to be a concert hall with some of the best acoustics in the world. The building contains three halls, Grote Zaal, Kleine Zaal, and Spiegelzaal. Some nine hundred concerts and other events per year take place in the Concertgebouw, for a public of over 700,000, making it one of the most-visited concert halls in the world. The opera house of Amsterdam is situated adjacent to the city hall. Therefore, the two buildings combined are often called the Stopera, (a word originally coined by protesters against it very construction: "Stop the Opera[-house]"). This huge modern complex, opened in 1986, lies in the former Jewish neighbourhood at "Waterlooplein" next to the river Amstel. The "Stopera" is the homebase of Dutch National Opera, Dutch National Ballet and the Holland Symfonia. Muziekgebouw aan 't IJ is a concert hall, which is situated in the IJ near the central station. Its concerts perform mostly modern classical music. Located adjacent to it, is the "Bimhuis", a concert hall for improvised and Jazz music.
Performing arts.
Amsterdam has three main theatre buildings.
The Stadsschouwburg Amsterdam at the Leidseplein is the home base of Toneelgroep Amsterdam. The current building dates from 1894. Most plays are performed in the Grote Zaal (Great Hall). The normal program of events encompasses all sorts of theatrical forms. The Stadsschouwburg is currently being renovated and expanded. The third theater space, to be operated jointly with next door Melkweg, will open in late 2009 or early 2010.
Dutch National Opera & Ballet (formerly known as "Het Muziektheater"), dating from 1986, is the principal opera house and home to Dutch National Opera and Dutch National Ballet.
Royal Theatre Carré was built as a permanent circus theatre in 1887 and is currently mainly used for musicals, cabaret performances and pop concerts.
The recently re-opened DeLaMar Theater houses the more commercial plays and musicals.
The Netherlands has a tradition of cabaret or "kleinkunst", which combines music, storytelling, commentary, theatre and comedy. Cabaret dates back to the 1930s and artists like Wim Kan, Wim Sonneveld and Toon Hermans were pioneers of this form of art in the Netherlands. In Amsterdam is the Kleinkunstacademie (English: Cabaret Academy). Contemporary popular artists are Youp van 't Hek, Freek de Jonge, Herman Finkers, Hans Teeuwen, Theo Maassen, Herman van Veen, Najib Amhali, Raoul Heertje, Jörgen Raymann, Brigitte Kaandorp and Comedytrain. The English spoken comedy scene was established with the founding of Boom Chicago in 1993. They have their own theatre at Leidseplein.
Nightlife.
Amsterdam is famous for its vibrant and diverse nightlife. Amsterdam has many "cafés" (bars). They range from large and modern to small and cozy. The typical "Bruine Kroeg" (brown "café") breathe a more old fashioned atmosphere with dimmed lights, candles, and somewhat older clientele. Most "cafés" have terraces in summertime. A common sight on the Leidseplein during summer is a square full of terraces packed with people drinking beer or wine. Many restaurants can be found in Amsterdam as well. Since Amsterdam is a multicultural city, a lot of different ethnic restaurants can be found. Restaurants range from being rather luxurious and expensive to being ordinary and affordable. Amsterdam also possesses many discothèques. The two main nightlife areas for tourists are the Leidseplein and the Rembrandtplein. The Paradiso, Melkweg and Sugar Factory are cultural centres, which turn into discothèques on some nights. Examples of discothèques near the Rembrandtplein are the Escape and Club Home. Also noteworthy are Panama, Hotel Arena (East), The Sand and The Powerzone. Bimhuis located near the Central Station, with its rich programming hosting the best in the field is considered one of the best jazz clubs in the world. The Reguliersdwarsstraat is the main street for the LGBT community and nightlife.
Festivals.
In 2008, there were 140 festivals and events in Amsterdam.
Famous festivals and events in Amsterdam include: Koninginnedag (In 2013 Koningsdag since the crowning of king Willem-Alexander) (Queen's Day - King's Day); the Holland Festival for the performing arts; the yearly Prinsengrachtconcert (classical concerto on the Prinsen canal) in August; the 'Stille Omgang' (a silent Roman Catholic evening procession held every March); Amsterdam Gay Pride; The Cannabis Cup; and the Uitmarkt. On Koninginnedag—held each year on 30 April—hundreds of thousands of people travel to Amsterdam to celebrate with the city's residents. The entire city becomes overcrowded with people buying products from the "freemarket," or visiting one of the many music concerts.
The yearly Holland Festival attracts international artists and visitors from all over Europe. Amsterdam Gay Pride is a yearly local LGBT parade of boats in Amsterdam's canals, held on the first Saturday in August. The Gay Pride event is a frequent source of both criticism and praise. The annual Uitmarkt is a three-day cultural event at the start of the cultural season in late August. It offers previews of many different artists, such as musicians and poets, who perform on podia.
Sports.
Amsterdam is home of the "Eredivisie" football club Ajax Amsterdam. The stadium Amsterdam ArenA is the home of Ajax. It is located in the south-east of the city next to the new Amsterdam Bijlmer ArenA railway station. Before moving to their current location in 1996, Ajax played their regular matches in De Meer Stadion.
In 1928, Amsterdam hosted the Summer Olympics. The Olympic Stadium built for the occasion has been completely restored and is now used for cultural and sporting events, such as the Amsterdam Marathon. In 1920, Amsterdam assisted in hosting some of the sailing events for the Summer Olympics held in neighboring Antwerp, Belgium by hosting events at Buiten Y.
The city holds the Dam to Dam Run, a 10-mile race from Amsterdam to Zaandam, as well as the Amsterdam Marathon.
The ice hockey team Amstel Tijgers play in the Jaap Eden ice rink. The team competes in the Dutch ice hockey premier league. Speed skating championships have been held on the 400-metre lane of this ice rink.
Amsterdam holds two American Football franchises: the Amsterdam Crusaders and the Amsterdam Panthers.
The Amsterdam Pirates baseball team competes in the Dutch Major League. There are three field hockey teams: Amsterdam, Pinoké and Hurley, who play their matches around the Wagener Stadium in the nearby city of Amstelveen. The basketball team MyGuide Amsterdam competes in the Dutch premier division and play their games in the Sporthallen Zuid.
There is one rugbyclub in Amsterdam, which also hosts sports training classes such as RTC(Rugby Talenten Centrum or Rugby Talent Centre) and the National Rugby stadium.
Since 1999 the city of Amsterdam honours the best sportsmen and women at the Amsterdam Sports Awards. Boxer Raymond Joval and field hockey midfielder Carole Thate were the first to receive the awards, in 1999.
Government.
The administration of the municipality of Amsterdam used to be divided into 15 boroughs or "stadsdelen"; the central one, Centrum, being circled by Westerpark, Bos en Lommer, De Baarsjes, Oud-West, Oud-Zuid, Oost/Watergraafsmeer, Zeeburg and Amsterdam-Noord, with the six outer boroughs (Westpoort, Geuzenveld-Slotermeer, Osdorp, Slotervaart, Zuideramstel, and Zuidoost) creating a further encirclement. On 1 May 2010, the number of boroughs was reduced to eight (Centrum, Noord, Oost, Zuid, West, Nieuw-West, Zuidoost, and Westpoort).
Definitions.
"Amsterdam" is mostly understood to refer to the municipality of Amsterdam. Colloquially, some areas within the municipality, such as the village of Durgerdam, may not be considered part of Amsterdam. Statistics Netherlands uses three other definitions of Amsterdam: metropolitan agglomeration Amsterdam ("Grootstedelijke Agglomeratie Amsterdam", not to be confused with "Grootstedelijk Gebied Amsterdam", a synonym of "Groot Amsterdam"), Greater Amsterdam ("Groot Amsterdam", a COROP region) and the urban region Amsterdam ("Stadsgewest Amsterdam"). The Amsterdam Department for Research and Statistics uses a fourth conurbation, namely the City region Amsterdam. This region is similar to Greater Amsterdam but includes the municipalities Zaanstad and Wormerland. It excludes Graft-De Rijp.
The smallest of these areas is the municipality, with a population of 802,938 in 2013. The metropolitan agglomeration had a population of 1,096,042 in 2013. It includes the municipalities of Zaanstad, Wormerland, Oostzaan, Diemen and Amstelveen only, as well as the municipality of Amsterdam. Greater Amsterdam includes 15 municipalities, and had a population of 1,293,208 in 2013. Though much larger in area, the population of this area is only slightly larger, because the definition excludes the relatively populous municipality of Zaanstad. The largest area by population, the Amsterdam Metropolitan Area (Dutch: Metropoolregio Amsterdam), has a population of 2,33 million. It includes for instance Zaanstad, Wormerveer, Muiden, Abcoude, Haarlem, Almere and Lelystad but excludes Graft-De Rijp. Amsterdam is part of the conglomerate metropolitan area Randstad, with a total population of 6,659,300 inhabitants.
City government.
As with all Dutch municipalities, Amsterdam is governed by a mayor, aldermen, and the municipal council. However, unlike most other Dutch municipalities, Amsterdam is subdivided into seven "stadsdelen" (boroughs), a system that was implemented in the 1980s to improve local governance. The stadsdelen are responsible for many activities that had previously been run by the central city. The city had initially been divided into 15 stadsdelen. 14 of those had their own council, chosen by a popular election. The 15th, Westpoort, covers the harbour of Amsterdam, had very few residents, and was governed by the central municipal council. Local decisions are made at borough level, and only affairs pertaining to the whole city, such as major infrastructure projects, are handled by the central city council.
National government.
Amsterdam is the capital of the Netherlands in a technical legal sense. The present version of the Dutch constitution mentions "Amsterdam" and "capital" only in one place, chapter 2, article 32: The king's confirmation by oath and his coronation take place in "the capital Amsterdam" (""de hoofdstad Amsterdam""). Previous versions of the constitution spoke of "the city of Amsterdam" (""de stad Amsterdam""), without mention of capital. In any case, the seat of the government, parliament and supreme court of the Netherlands is (and always has been, with the exception of a brief period between 1808 and 1810) located at The Hague. Foreign embassies are also in The Hague. The capital of North Holland is Haarlem.
Symbols.
The coat of arms of Amsterdam is composed of several historical elements. First and centre are three St Andrew's crosses, aligned in a vertical band on the city's shield (although Amsterdam's patron saint was Saint Nicholas). These St Andrew's crosses can also be found on the cityshields of neighbours Amstelveen and Ouder-Amstel. This part of the coat of arms is the basis of the flag of Amsterdam, flown by the city government, but also as civil ensign for ships registered in Amsterdam. Second is the Imperial Crown of Austria. In 1489, out of gratitude for services and loans, Maximilian I awarded Amsterdam the right to adorn its coat of arms with the king's crown. Then, in 1508, this was replaced with Maximilian's imperial crown when he was crowned Holy Roman Emperor. In the early years of the 17th century, Maximilian's crown in Amsterdam's coat of arms was again replaced, this time with the crown of Emperor Rudolph II, a crown that became the Imperial Crown of Austria. The lions date from the late 16th century, when city and province became part of the Republic of the Seven United Netherlands. Last came the city's official motto: "Heldhaftig, Vastberaden, Barmhartig" ("Heroic, Determined, Merciful"), bestowed on the city in 1947 by Queen Wilhelmina, in recognition of the city's bravery during the Second World War.
Transport.
In the city centre, driving a car is discouraged. Parking fees are expensive, and many streets are closed to cars or are one-way. The local government sponsors carsharing and carpooling initiatives such as "Autodelen" and "Meerijden.nu".
Regional buses, and some suburban buses, are operated by Connexxion and EBS. Currently, there are sixteen tram lines, and four metro lines, with a fifth line, the North/South line, under construction, all operated by GVB. Three free ferries carry pedestrians and cyclists across the IJ to Amsterdam-Noord, and two fare-charging ferries run east and west along the harbour. There are also water taxis, a water bus, a boat sharing operation, electric rental boats (Boaty) and canal cruises, that transport people along Amsterdam's waterways.
The A10 ringroad surrounding the city connects Amsterdam with the Dutch national network of freeways. Interchanges on the A10 allow cars to enter the city by transferring to one of the 18 "city roads", numbered S101 through to S118. These city roads are regional roads without grade separation, and sometimes without a central reservation. Most are accessible by cyclists. The S100 "Centrumring" is a smaller ringroad circumnavigating the city's centre.
Amsterdam was intended in 1932 to be the hub, a kind of Kilometre Zero, of the highway system of the Netherlands, with freeways numbered One to Eight planned to originate from the city. The outbreak of the Second World War and shifting priorities led to the current situation, where only roads A1, A2, and A4 originate from Amsterdam according to the original plan. The A3 road to Rotterdam was cancelled in 1970 in order to conserve the Groene Hart. Road A8, leading north to Zaandam and the A10 Ringroad were opened between 1968 and 1974. Besides the A1, A2, A4 and A8, several freeways, such as the A7 and A6, carry traffic mainly bound for Amsterdam.
Amsterdam is served by ten stations of the Nederlandse Spoorwegen (Dutch Railways). Six are intercity stops: Sloterdijk, Zuid, Amstel, Bijlmer ArenA, Lelylaan and Amsterdam Centraal. The stations for local services are: RAI, Holendrecht, Muiderpoort and Science Park. Amsterdam Centraal is also an international railway station. From the station there are regular services to destinations such as Austria, Belarus, Belgium, the Czech Republic, Denmark, France, Germany, Hungary, Poland, Russia and Switzerland. Among these trains are international trains of the Nederlandse Spoorwegen (Amsterdam-Berlin) and the Thalys (Amsterdam-Brussels-Paris/Lille), CityNightLine, and InterCityExpress (Amsterdam-Cologne-Frankfurt).
Eurolines has coaches from Amsterdam Amstel railway station to destinations all over Europe. IDBUS has a coach service from Amsterdam Sloterdijk railway station to Paris, Brussels and London. Megabus (Europe) offers coach services from Zuiderzeeweg in east Amsterdam to Paris, Brussels and London.
Amsterdam Airport Schiphol is less than 20 minutes by train from Amsterdam Central Station and is also served by domestic and international intercity trains, such as Thalys and Intercity Brussel. Schiphol is the biggest airport in the Netherlands, the fourth largest in Europe, and the twelfth largest in the world in terms of passengers. It handles about 50 million passengers per year and is the home base of four airlines, KLM, transavia.com, Martinair and Arkefly. As of 2013, Schiphol was the sixth busiest airport in the world measured by international passenger numbers.
Cycling.
Amsterdam is one of the most bicycle-friendly large cities in the world and is a centre of bicycle culture with good facilities for cyclists such as bike paths and bike racks, and several guarded bike storage garages ("fietsenstalling") which can be used for a nominal fee. In 2013, there were about 1,200,000 bicycles in Amsterdam outnumbering the amount of citizens in the city. Theft is widespread – in 2011, about 83,000 bicycles were stolen in Amsterdam. Bicycles are used by all socio-economic groups because of their convenience, Amsterdam's small size, the of bike paths, the flat terrain, and the arguable inconvenience of driving an automobile.
Education.
Amsterdam has two universities: the University of Amsterdam (Universiteit van Amsterdam), and the VU University Amsterdam (Vrije Universiteit or "VU"). Other institutions for higher education include an art school – Gerrit Rietveld Academie, a university of applied sciences - the Hogeschool van Amsterdam, and the Amsterdamse Hogeschool voor de Kunsten. Amsterdam's International Institute of Social History is one of the world's largest documentary and research institutions concerning social history, and especially the history of the labour movement. Amsterdam's Hortus Botanicus, founded in the early 17th century, is one of the oldest botanical gardens in the world, with many old and rare specimens, among them the coffee plant that served as the parent for the entire coffee culture in Central and South America.
Some of Amsterdam's primary schools base their teachings on particular pedagogic theories like the various Montessori schools. The biggest Montessori High School in Amsterdam is the Montessori Lyceum Amsterdam. Many schools, however, are based on religion. This used to be primarily Roman Catholicism and various Protestant denominations, but with the influx of Muslim immigrants there has been a rise in the number of Islamic schools. Jewish schools can be found in the southern suburbs of Amsterdam.
Amsterdam is noted for having five independent grammar schools (Dutch: gymnasia), the Vossius Gymnasium, Barlaeus Gymnasium, St. Ignatius Gymnasium, Het 4e Gymnasium and the Cygnus Gymnasium where a classical curriculum including Latin and classical Greek is taught. Though believed until recently by many to be an anachronistic and elitist concept that would soon die out, the gymnasia have recently experienced a revival, leading to the formation of a fourth and fifth grammar school in which the three aforementioned schools participate. Most secondary schools in Amsterdam offer a variety of different levels of education in the same school. The city also has various colleges ranging from art and design to politics and economics which are mostly also available for students coming from other countries.
Media.
Amsterdam is a prominent center for national and international media. Some locally-based newspapers include Het Parool, a national daily paper; De Telegraaf, the largest Dutch daily newspaper; the daily newspapers Trouw, De Volkskrant and NRC Handelsblad; De Groene Amsterdammer, a weekly newspaper; the free newspapers Sp!ts, Metro, and The Holland Times (printed in English).
Amsterdam is home to the Netherlands' second-largest commercial TV group SBS Broadcasting Group, consisting of TV-stations SBS 6, Net 5 and Veronica. However, Amsterdam is not being considered 'the media city of the Netherlands'. The town of Hilversum, 30 km (19 mi) south-east of Amsterdam, has been crowned with this unofficial title. Hilversum is the principal center for radio and television broadcasting in the Netherlands. Radio Netherlands, heard worldwide via shortwave radio since the 1920s, is also based there. Hilversum is home to an extensive complex of audio and television studios belonging to the national broadcast production company NOS, as well as to the studios and offices of all the Dutch public broadcasting organizations and many commercial TV production companies.
Amsterdam is also featured in John Green's book 'The Fault in Our Stars,' which has also been made in a film, and part of the film takes place in Amsterdam.
Housing.
The housing market is heavily regulated. In Amsterdam, 55% of existing housing and 30% of new housing is owned by Housing Associations, which are Government sponsored entities.
Squat properties are common throughout Amsterdam, due to property law strongly favouring tenants. A number of these squats have become well known, such as OT301, Paradiso, Vrankrijk (closed down by city government), and the Binnenpret, and several are now businesses, such as health clubs and licensed restaurants.
International relations.
Amsterdam is twinned with the following cities:

</doc>
<doc id="846" url="http://en.wikipedia.org/wiki?curid=846" title="Museum of Work">
Museum of Work

The Museum of Work, or "Arbetets museum", is a museum located in Norrköping, Sweden. The museum can be found in the 19th century building "The Iron" in the Motala ström river in central Norrköping.

</doc>
<doc id="848" url="http://en.wikipedia.org/wiki?curid=848" title="Audi">
Audi

Audi AG () is a German automobile manufacturer that designs, engineers, produces, markets and distributes automobiles. Audi oversees worldwide operations from its headquarters in Ingolstadt, Bavaria, Germany. Audi-branded vehicles are produced in nine production facilities worldwide.
Audi has been a majority owned (99.55%) subsidiary of Volkswagen Group since 1966, following a phased purchase of Audi AG's predecessor, Auto Union, from Daimler-Benz. Volkswagen relaunched the Audi brand with the 1965 introduction of the Audi F103 series.
The company name is based on the Latin translation of the surname of the founder, August Horch. "Horch", meaning "listen" in German, becomes "audi" in Latin. The four rings of the Audi logo each represent one of four car companies that banded together to create Audi's predecessor company, Auto Union. Audi's slogan is Vorsprung durch Technik, meaning "Advancement through Technology". Recently in the United States, Audi has updated the slogan to "Truth in Engineering". Audi is a member of the "German Big 3" luxury automakers, along with BMW and Mercedes-Benz, which are the three best-selling luxury automakers in the world.
History.
Birth of the company and its name.
Originally in 1885, automobile company Wanderer was established, later becoming a branch of Audi AG. Another company, NSU, which also later merged into Audi, was founded during this time, and later supplied the chassis for Gottlieb Daimler's four-wheeler.
On 14 November 1899, August Horch (1868–1951) established the company A. Horch & Cie. in the Ehrenfeld district of Cologne. Three years later in 1902 he moved with his company to Reichenbach im Vogtland. On May, 10th, 1904 he founded the August Horch & Cie. Motorwagenwerke AG, a joint-stock company in Zwickau (State of Saxony).
After troubles with Horch chief financial officer, August Horch left Motorwagenwerke and founded in Zwickau on 16 July 1909, his second company, the August Horch Automobilwerke GmbH. His former partners sued him for trademark infringement. The German Reichsgericht (Supreme Court) in Leipzig, eventually determined that the Horch brand belonged to his former company.
Since August Horch was banned from using "Horch" as a trade name in his new car business, he called a meeting with close business friends, Paul and Franz Fikentscher from Zwickau, Germany. At the apartment of Franz Fikentscher, they discussed how to come up with a new name for the company. During this meeting, Franz's son was quietly studying Latin in a corner of the room. Several times he looked like he was on the verge of saying something but would just swallow his words and continue working, until he finally blurted out, "Father – "audiatur et altera pars"... wouldn't it be a good idea to call it "audi" instead of "horch"?" "Horch!" in German means "Hark!" or "hear", which is "Audi" in the singular imperative form of "audire" – "to listen" – in Latin. The idea was enthusiastically accepted by everyone attending the meeting. On 25 April 1910 the Audi Automobilwerke GmbH Zwickau (from 1915 on Audiwerke AG Zwickau) was entered in the company's register of Zwickau registration court.
The first Audi automobile, the Audi Type A 10/ Sport-Phaeton, was produced in the same year, followed by the successor Type B 10/28PS in the same year.
Audi started with a 2,612 cc inline-four engine model Type A, followed by a 3,564 cc model, as well as 4,680 cc and 5,720 cc models. These cars were successful even in sporting events. The first six-cylinder model Type M, 4,655 cc appeared in 1924.
August Horch left the "Audiwerke" in 1920 for a high position at the ministry of transport, but he was still involved with Audi as a member of the board of trustees. In September 1921, Audi became the first German car manufacturer to present a production car, the Audi Type K, with left-handed drive. Left-hand drive spread and established dominance during the 1920s because it provided a better view of oncoming traffic, making overtaking safer.
The merger of the four companies under the logo of four rings.
In August 1928, Jørgen Rasmussen,the owner of Dampf-Kraft-Wagen (DKW), acquired the majority of shares in Audiwerke AG. In the same year, Rasmussen bought the remains of the U.S. automobile manufacturer Rickenbacker, including the manufacturing equipment for eight-cylinder engines. These engines were used in "Audi Zwickau" and "Audi Dresden" models that were launched in 1929. At the same time, six-cylinder and four-cylinder (the "four" with a Peugeot engine) models were manufactured. Audi cars of that era were luxurious cars equipped with special bodywork.
In 1932, Audi merged with Horch, DKW, and Wanderer, to form Auto Union AG, Chemnitz. It was during this period that the company offered the Audi Front that became the first European car to combine a six-cylinder engine with front-wheel drive. It used a powertrain shared with the Wanderer, but turned 180-degrees, so that the drive shaft faced the front.
Before World War II, Auto Union used the four interlinked rings that make up the Audi badge today, representing these four brands. This badge was used, however, only on Auto Union racing cars in that period while the member companies used their own names and emblems. The technological development became more and more concentrated and some Audi models were propelled by Horch or Wanderer built engines.
Reflecting the economic pressures of the time, Auto Union concentrated increasingly on smaller cars through the 1930s, so that by 1938 the company's DKW brand accounted for 17.9% of the German car market, while Audi held only 0.1%. After the final few Audis were delivered in 1939 the "Audi" name disappeared completely from the new car market for more than two decades.
Post-World War II.
Like most German manufacturing, at the onset of World War II the Auto Union plants were retooled for military production, and were a target for allied bombing during the war which left them damaged.
Overrun by the Soviet Army in 1945, on the orders of the Soviet Union military administration the factories were dismantled as part of war reparations. Following this, the company's entire assets were expropriated without compensation. On 17 August 1948, Auto Union AG of Chemnitz was deleted from the commercial register. These actions had the effect of liquidating Germany's Auto Union AG. The remains of the Audi plant of Zwickau became the VEB (for "People Owned Enterprise") Automobilwerk Zwickau or AWZ (in English: Automobile Works Zwickau).
The former Audi factory in Zwickau restarted assembly of the pre-war-models in 1949. These DKW models were renamed to IFA F8 and IFA F9 and were similar to the West German versions. West and East German models were equipped with the traditional and renowned DKW two-stroke engines. The Zwickau plant manufactured the infamous Trabant until 1991, when it came under Volkswagen control—effectively bringing it under the same umbrella as Audi since 1945.
New Auto Union unit.
A new West German headquartered Auto Union was launched in Ingolstadt, Bavaria with loans from the Bavarian state government and Marshall Plan aid. The reformed company was launched 3 September 1949 and continued DKW's tradition of producing front-wheel drive vehicles with two-stroke engines. This included production of a small but sturdy 125 cc motorcycle and a DKW delivery van, the DKW F 89 L at Ingolstadt. The Ingolstadt site was large, consisting of an extensive complex of formerly military buildings which was suitable for administration as well as vehicle warehousing and distribution, but at this stage there was at Ingolstadt no dedicated plant suitable for mass production of automobiles: for manufacturing the company's first post-war mass-market passenger car plant capacity in Düsseldorf was rented from Rheinmetall-Borsig. It was only ten years later, after the company had attracted an investor that funds became available for construction of major car plant at the Ingolstadt head office site.
In 1958, in response to pressure from Friedrich Flick, then their largest single shareholder, Daimler-Benz took an 87% holding in the Auto Union company, and this was increased to a 100% holding in 1959. However, small two-stroke cars were not the focus of Daimler-Benz's interests, and while the early 1960s saw major investment in new Mercedes models and in a state of the art factory for Auto Union's, the company's aging model range at this time did not benefit from the economic boom of the early 1960s to the same extent as competitor manufacturers such as Volkswagen and Opel. The decision to dispose of the Auto Union business was based on its lack of profitability. Ironically, by the time they sold the business, it also included a large new factory and near production-ready modern four-stroke engine, which would enable the Auto Union business, under a new owner, to embark on a period of profitable growth, now producing not Auto Unions or DKWs, but using the "Audi" name, resurrected in 1965 after a 25 year gap. Under the terms of the sale, Daimler-Benz retained the old Düsseldorf plant, which survives to the present day as a centre for Mercedes-Benz commercial vehicle assembly.
In 1964, Volkswagen acquired a 50% holding in the business, which included the new factory in Ingolstadt and the trademark rights of the Auto Union. Eighteen months later, Volkswagen bought complete control of Ingolstadt, and by 1966 were using the spare capacity of the Ingolstadt plant to assemble an additional 60,000 Volkswagen Beetles per year. Two-stroke engines became less popular during the 1960s as customers were more attracted to the smoother four-stroke engines. In September 1965, the DKW F102 was fitted with a four-stroke engine and a facelift for the car's front and rear. Volkswagen dumped the DKW brand because of its associations with two-stroke technology, and having classified the model internally as the F103, sold it simply as the "Audi." Later developments of the model were named after their horsepower ratings and sold as the Audi 60, 75, 80, and Super 90, selling until 1972. Initially, Volkswagen was hostile to the idea of Auto Union as a standalone entity producing its own models having acquired the company merely to boost its own production capacity through the Ingolstadt assembly plant. Then VW chief Heinz Nordhoff explicitly forbade Auto Union from any further product development. Fearing that the company's heritage would disappear underneath VW badge engineering, Auto Union engineers under the leadership of Ludwig Kraus developed the first Audi 100 in secret, without Nordhoff's knowledge. When presented with a finished prototype, Nordhoff was so impressed he authorised the car for production, which when launched in 1968, went on to be a huge success. With this, the resurrection of the Audi brand was now complete, this being followed by the first generation Audi 80 in 1972, which would in turn provide a template for VW's new front wheel drive watercooled range which debuted from the mid-1970s onward.
In 1969, Auto Union merged with NSU, based in Neckarsulm, near Stuttgart. In the 1950s, NSU had been the world's largest manufacturer of motorcycles, but had moved on to produce small cars like the NSU Prinz, the TT and TTS versions of which are still popular as vintage race cars. NSU then focused on new rotary engines based on the ideas of Felix Wankel. In 1967, the new NSU Ro 80 was a car well ahead of its time in technical details such as aerodynamics, light weight, and safety. However, teething problems with the rotary engines put an end to the independence of NSU. The Neckarsulm plant is now used to produce the larger Audi models A6 and A8. The Neckarsulm factory is also home of the quattro GmbH, a subsidiary responsible for development and production of Audi high-performance models: the R8 and the "RS" model range.
The mid-sized car that NSU had been working on, the K70, was intended to slot between the rear-engined Prinz models and the futuristic NSU Ro 80. However, Volkswagen took the K70 for its own range, spelling the end of NSU as a separate brand.
Modern era.
The new merged company was known as Audi NSU Auto Union AG, and saw the emergence of Audi as a separate brand for the first time since the pre-war era. Volkswagen introduced the Audi brand to the United States for the 1970 model year.
The first new car of this regime was the Audi 100 of 1968. This was soon joined by the Audi 80/Fox (which formed the basis for the 1973 Volkswagen Passat) in 1972 and the Audi 50 (later rebadged as the Volkswagen Polo) in 1974. The Audi 50 was a seminal design because it was the first incarnation of the Golf/Polo concept, one that led to a hugely successful world car.
The Audi image at this time was a conservative one, and so, a proposal from chassis engineer Jörg Bensinger was accepted to develop the four-wheel drive technology in Volkswagen's Iltis military vehicle for an Audi performance car and rally racing car. The performance car, introduced in 1980, was named the "Audi Quattro", a turbocharged coupé which was also the first German large-scale production vehicle to feature permanent all-wheel drive through a centre differential. Commonly referred to as the "Ur-Quattro" (the "Ur-" prefix is a German augmentative used, in this case, to mean "original" and is also applied to the first generation of Audi's S4 and S6 Sport Saloons, as in "UrS4" and "UrS6"), few of these vehicles were produced (all hand-built by a single team), but the model was a great success in rallying. Prominent wins proved the viability of all-wheel drive racecars, and the Audi name became associated with advances in automotive technology.
In 1985, with the Auto Union and NSU brands effectively dead, the company's official name was now shortened to simply Audi AG.
In 1986, as the Passat-based Audi 80 was beginning to develop a kind of "grandfather's car" image, the "type 89" was introduced. This completely new development sold extremely well. However, its modern and dynamic exterior belied the low performance of its base engine, and its base package was quite spartan (even the passenger-side mirror was an option.) In 1987, Audi put forward a new and very elegant Audi 90, which had a much superior set of standard features. In the early 1990s, sales began to slump for the Audi 80 series, and some basic construction problems started to surface.
In the early part of the 21st century, Audi set forth on a German racetrack to claim and maintain several world records, such as top speed endurance. This effort was in-line with the company's heritage from the 1930s racing era Silver Arrows.
Through the early 1990s, Audi began to shift its target market upscale to compete against German automakers Mercedes-Benz and BMW. This began with the release of the Audi V8 in 1990. It was essentially a new engine fitted to the Audi 100/200, but with noticeable bodywork differences. Most obvious was the new grille that was now incorporated in the bonnet.
By 1991, Audi had the four-cylinder Audi 80, the 5-cylinder Audi 90 and Audi 100, the turbocharged Audi 200 and the Audi V8. There was also a coupe version of the 80/90 with both 4- and 5-cylinder engines.
Although the five-cylinder engine was a successful and robust powerplant, it was still a little too different for the target market. With the introduction of an all-new Audi 100 in 1992, Audi introduced a 2.8L V6 engine. This engine was also fitted to a face-lifted Audi 80 (all 80 and 90 models were now badged 80 except for the USA), giving this model a choice of four-, five-, and six-cylinder engines, in Saloon, Coupé and Cabriolet body styles.
The five-cylinder was soon dropped as a major engine choice; however, a turbocharged version remained. The engine, initially fitted to the 200 quattro 20V of 1991, was a derivative of the engine fitted to the Sport Quattro. It was fitted to the Audi Coupé, and named the S2 and also to the Audi 100 body, and named the S4. These two models were the beginning of the mass-produced S series of performance cars.
Audi 5000 unintended acceleration allegations.
Sales in the United States fell after a series of recalls from 1982 to 1987 of Audi 5000 models associated with reported incidents of sudden unintended acceleration linked to six deaths and 700 accidents. At the time, NHTSA was investigating 50 car models from 20 manufacturers for sudden surges of power.
A "60 Minutes" report aired 23 November 1986, featuring interviews with six people who had sued Audi after reporting unintended acceleration, showing an Audi 5000 ostensibly suffering a problem when the brake pedal was pushed. Subsequent investigation revealed that "60 Minutes" had engineered the failure – fitting a canister of compressed air on the passenger-side floor, linked via a hose to a hole drilled into the transmission.
Audi contended, prior to findings by outside investigators, that the problems were caused by driver error, specifically pedal misapplication. Subsequently, the National Highway Traffic Safety Administration (NHTSA) concluded that the majority of unintended acceleration cases, including all the ones that prompted the "60 Minutes" report, were caused by driver error such as confusion of pedals. CBS did not acknowledge the test results of involved government agencies, but did acknowledge the similar results of another study.
In a review study published in 2012, NHTSA summarized its past findings about the Audi unintended acceleration problems: "Once an unintended acceleration had begun, in the Audi 5000, due to a failure in the idle-stabilizer system (producing an initial acceleration of 0.3g), pedal misapplication resulting from panic, confusion, or unfamiliarity with the Audi 5000 contributed to the severity of the incident."
This summary is consistent with the conclusions of NHTSA's most technical analysis at the time: "Audi idle-stabilization systems were prone to defects which resulted in excessive idle speeds and brief unanticipated accelerations of up to 0.3g is similar in magnitude to an emergency stop in a subway car. These accelerations could not be the sole cause of [(long-duration) sudden acceleration incidents (SAI)], but might have triggered some SAIs by startling the driver. The defective idle-stabilization system performed a type of electronic throttle control. Significantly: multiple "intermittent malfunctions of the electronic control unit were observed and recorded ... and also observed and reported by Transport Canada."
With a series of recall campaigns, Audi made several modifications; the first adjusted the distance between the brake and accelerator pedal on automatic-transmission models. Later repairs, of 250,000 cars dating back to 1978, added a device requiring the driver to press the brake pedal before shifting out of park. A legacy of the Audi 5000 and other reported cases of sudden unintended acceleration are intricate gear stick patterns and brake interlock mechanisms to prevent inadvertent shifting into forward or reverse. It is unclear how the defects in the idle-stabilization system were addressed.
Audi's U.S. sales, which had reached 74,061 in 1985, dropped to 12,283 in 1991 and remained level for three years. – with resale values falling dramatically. Audi subsequently offered increased warranty protection and renamed the affected models – with the "5000" becoming the "100" and "200" in 1989 – and only reached the same sales levels again by model year 2000.
A 2010 "BusinessWeek" article – outlining possible parallels between Audi's experience and 2009–2010 Toyota vehicle recalls – noted a class-action lawsuit filed in 1987 by about 7,500 Audi 5000-model owners remains unsettled and is currently being contested in county court in Chicago after appeals at the Illinois state and U.S. federal levels.
Model introductions.
In the mid-to-late 1990s, Audi introduced new technologies including the use of aluminum construction. Produced from 1999 to 2005, the Audi A2 was a futuristic super mini, born from the Al2 concept, with many features that helped regain consumer confidence, like the aluminium space frame, which was a first in production car design. In the A2 Audi further expanded their TDI technology through the use of frugal three-cylinder engines. The A2 was extremely aerodynamic and was designed around a wind tunnel. The Audi A2 was criticised for its high price and was never really a sales success but it planted Audi as a cutting-edge manufacturer. The model, a Mercedes-Benz A-Class competitor, sold relatively well in Europe. However, the A2 was discontinued in 2005 and Audi decided not to develop an immediate replacement.
The next major model change came in 1995 when the Audi A4 replaced the Audi 80. The new nomenclature scheme was applied to the Audi 100 to become the Audi A6 (with a minor facelift). This also meant the S4 became the S6 and a new S4 was introduced in the A4 body. The S2 was discontinued. The Audi Cabriolet continued on (based on the Audi 80 platform) until 1999, gaining the engine upgrades along the way. A new A3 hatchback model (sharing the Volkswagen Golf Mk4's platform) was introduced to the range in 1996, and the radical Audi TT coupé and roadster were debuted in 1998 based on the same underpinnings.
The engines available throughout the range were now a 1.4 L, 1.6 L and 1.8 L four-cylinder, 1.8 L four-cylinder turbo, 2.6 L and 2.8 L V6, 2.2 L turbo-charged five-cylinder and the 4.2 L V8 engine. The V6s were replaced by new 2.4 L and 2.8 L 30V V6s in 1998, with marked improvement in power, torque and smoothness. Further engines were added along the way, including a 3.7 L V8 and 6.0 L W12 engine for the A8.
Audi AG today.
Audi's sales grew strongly in the 2000s, with deliveries to customers increasing from 653,000 in 2000 to 1,003,000 in 2008. The largest sales increases came from Eastern Europe (+19.3%), Africa (+17.2%) and the Middle East (+58.5%). China in particular has become a key market, representing 108,000 out of 705,000 cars delivered in the first three quarters of 2009. One factor for its popularity in China is that Audis have become the car of choice for purchase by the Chinese government for officials, and purchases by the government are responsible for 20% of its sales in China. As of late 2009, Audi's operating profit of €1.17-billion ($1.85-billion) made it the biggest contributor to parent Volkswagen Group's nine-month operating profit of €1.5-billion, while the other marques in Group such as Bentley and SEAT had suffered considerable losses. May 2011 saw record sales for Audi of America with the new Audi A7 and Audi A3 TDI Clean Diesel. In May 2012, Audi reported a 10% increase in its sales—from 408 units to 480 in the last year alone.
Audi manufactures vehicles in seven plants around the world, some of which are shared with other VW Group marques although many sub-assemblies such as engines and transmissions are manufactured within other Volkswagen Group plants.
Audi's two principal assembly plants are:
Outside of Germany, Audi produces vehicles at:
In September 2012, Audi announced the construction of its first North American manufacturing plant in Puebla, Mexico. This plant is expected to be operative in 2016 and produce the second generation Q5.
From 2002 up to 2003, Audi headed the Audi Brand Group, a subdivision of the Volkswagen Group's Automotive Division consisting of Audi, Lamborghini and SEAT, that was focused on sporty values, with the marques' product vehicles and performance being under the higher responsibility of the Audi brand.
In 2014 Audi UK falsely claimed that the Audi A7, A8, and R8 were Euro NCAP safety tested, all achieving five out of five stars. In fact none were tested.
Technology.
Bodyshells.
Audi produces 100% galvanised cars to prevent corrosion, and was the first mass-market vehicle to do so, following introduction of the process by Porsche, c.1975. Along with other precautionary measures, the full-body zinc coating has proved to be very effective in preventing rust. The body's resulting durability even surpassed Audi's own expectations, causing the manufacturer to extend its original 10-year warranty against corrosion perforation to currently 12 years (except for aluminium bodies which do not rust).
Space frame.
Audi introduced a new series of vehicles in the mid-1990s and continues to pursue new technology and high performance. An all-aluminium car was brought forward by Audi, and in 1994 the Audi A8 was launched, which introduced aluminium space frame technology (called "Audi Space Frame" or ASF) which saves weight and improves torsion rigidity compared to a conventional steel frame. Prior to that effort, Audi used examples of the Type 44 chassis fabricated out of aluminium as test-beds for the technique. The disadvantage of the aluminium frame is that it is very expensive to repair and requires a specialized aluminium bodyshop. The weight reduction is somewhat offset by the quattro four-wheel drive system which is standard in most markets. Nonetheless, the A8 is usually the lightest all-wheel drive car in the full-size luxury segment, also having best-in-class fuel economy. The Audi A2, Audi TT and Audi R8 also use Audi Space Frame designs.
Drivetrains.
Layout.
For most of its lineup (excluding the A3, A1, and TT models), Audi has not adopted the transverse engine layout which is typically found in economy cars (such as Peugeot and Citroën), since that would limit the type and power of engines that can be installed. In order to be able to mount powerful engines (such as a V8 engine in the Audi S4 and Audi RS4, as well as the W12 engine in the Audi A8L W12), Audi has usually engineered its more expensive cars with a longitudinally front-mounted engine, in an "overhung" position, over the front wheels in front of the axle line. While this allows for the easy adoption of all-wheel drive, it goes against the ideal 50:50 weight distribution.
In all its post Volkswagen-era models, Audi has firmly refused to adopt the traditional rear-wheel drive layout favored by its two arch rivals Mercedes-Benz and BMW, favoring either front-wheel drive or all-wheel drive. The majority of Audi's lineup in the United States features all-wheel drive standard on most of its expensive vehicles (only the entry-level trims of the A4 and A6 are available with front-wheel drive), in contrast to Mercedes-Benz and BMW whose lineup treats all-wheel drive as an option. BMW did not offer all-wheel drive on its V8-powered cars (as opposed to crossover SUVs) until the 2010 BMW 7 Series and 2011 BMW 5 Series, while the Audi A8 has had all-wheel drive available/standard since the 1990s. Regarding high-performance variants, Audi S and RS models have always had all-wheel drive, unlike their direct rivals from BMW M and Mercedes-AMG whose cars are rear-wheel drive only (although their performance crossover SUVs are all-wheel drive).
Audi has recently applied the "quattro" badge to models such as the A3 and TT which do not use the Torsen-based system as in prior years with a mechanical center differential, but with the Haldex Traction electro-mechanical clutch AWD system.
Engines.
In the 1980s, Audi, along with Volvo, was the champion of the inline-five cylinder, 2.1/2.2 L engine as a longer-lasting alternative to more traditional six-cylinder engines. This engine was used not only in production cars but also in their race cars. The 2.1 L inline five-cylinder engine was used as a base for the rally cars in the 1980s, providing well over after modification. Before 1990, there were engines produced with a displacement between 2.0 L and 2.3 L. This range of engine capacity allowed for both fuel economy and power.
For the ultra-luxury version of its Audi A8 fullsize luxury flagship sedan, the Audi A8L W12, Audi uses the Volkswagen Group W12 engine instead of the conventional V12 engine favored by rivals Mercedes-Benz and BMW. The W12 engine configuration (also known as a "WR12") is created by forming two imaginary narrow-angle 15° VR6 engines at an angle of 72°, and the narrow angle of each set of cylinders allows just two overhead camshafts to drive each pair of banks, so just four are needed in total. The advantage of the W12 engine is its compact packaging, allowing Audi to build a 12-cylinder sedan with all-wheel drive, whereas a conventional V12 engine could only have a rear-wheel drive configuration as it would have no space in the engine bay for a differential and other components required to power the front wheels. In fact, the 6.0 L W12 in the Audi A8L W12 is smaller in overall dimensions than the 4.2 L V8 that powers the Audi A8 4.2 variants. The 2011 Audi A8 debuted a revised 6.3-litre version of the W12 (WR12) engine with .
Fuel Stratified Injection.
New models of the A3, A4, A6 and A8 have been introduced, with the ageing 1.8-litre engine now having been replaced by new Fuel Stratified Injection (FSI) engines. Nearly every petroleum burning model in the range now incorporates this fuel-saving technology.
Direct-Shift Gearbox.
At the turn of the century, Volkswagen introduced the Direct-Shift Gearbox (DSG), a type of dual clutch transmission. It is an automated semi-automatic transmission, drivable like a conventional automatic transmission. Based on the gearbox found in the Group B S1, the system includes dual electrohydraulically controlled clutches instead of a torque converter. This is implemented in some VW Golfs, Audi A3, Audi A4 and TT models where DSG is called S-tronic.
LED daytime running lights.
Beginning in 2006, Audi has implemented white LED technology as daytime running lights (DRL) in their products. The distinctive shape of the DRLs has become a trademark of sorts. LEDs were first introduced on the Audi A8 W12, the world's first production car to have LED DRLs, and have since spread throughout the entire model range. The LEDs are present on some Audi billboards.
Since 2010, Audi has also offered the LED technology in low- and high-beam headlights.
Multi Media Interface.
Audi has recently started offering a computerised control system for its cars, called Multi Media Interface (MMI). This came amid criticism of BMW's iDrive control. It is essentially a rotating control knob and 'segment' buttons – designed to control all in-car entertainment devices (radio, CD changer, iPod, TV tuner), satellite navigation, heating and ventilation, and other car controls with a screen. MMI was widely reported to be a considerable improvement on BMW's iDrive, although BMW has since made their iDrive more user-friendly.
MMI has been generally well-received, as it requires less menu-surfing with its segment buttons around a central knob, along with 'main function' direct access buttons – with shortcuts to the radio or phone functions. The screen, either colour or monochrome, is mounted on the upright dashboard, and on the A4 (new), A5, A6, A8, and Q7, the controls are mounted horizontally.
An "MMI-like" system is also available on the A3, TT, A4 (B7), and R8 models – when equipped with the Audi Navigation System Plus (RNS-E) satellite navigation system.
Models.
Current model range.
The following tables list Audi production vehicles that are sold as of 2014:
S and RS models.
RS Q3 Concept
Electric vehicles.
Audi is planning an alliance with the Japanese electronics giant Sanyo to develop a pilot hybrid electric project for the Volkswagen Group. The alliance could result in Sanyo batteries and other electronic components being used in future models of the Volkswagen Group. Concept electric vehicles unveiled to date include the Audi A1 Sportback Concept, Audi A4 TDI Concept E, and the fully electric Audi e-tron Concept Supercar.
Motorsport.
Audi has competed in various forms of motorsports. Audi's tradition in motorsport began with their former company Auto Union in the 1930s. In the 1990s, Audi found success in the Touring and Super Touring categories of motor racing after success in circuit racing in North America.
Rallying.
In 1980, Audi released the Quattro, a four-wheel drive (4WD) turbocharged car that went on to win rallies and races worldwide. It is considered one of the most significant rally cars of all time, because it was one of the first to take advantage of the then-recently changed rules which allowed the use of four-wheel drive in competition racing. Many critics doubted the viability of four-wheel drive racers, thinking them to be too heavy and complex, yet the Quattro was to become a successful car. Leading its first rally it went off the road, however the rally world had been served notice 4WD was the future. The Quattro went on to achieve much success in the World Rally Championship. It won the 1983 (Hannu Mikkola) and the 1984 (Stig Blomqvist) drivers' titles, and brought Audi the manufacturers' title in 1982 and 1984.
In 1984, Audi launched the short-wheelbase Sport Quattro which dominated rally races in Monte Carlo and Sweden, with Audi taking all podium places, but succumbed to problems further into WRC contention. In 1985, after another season mired in mediocre finishes, Walter Röhrl finished the season in his Sport Quattro S1, and helped place Audi second in the manufacturers' points. Audi also received rally honours in the Hong Kong to Beijing rally in that same year. Michèle Mouton, the only female driver to win a round of the World Rally Championship and a driver for Audi, took the Sport Quattro S1, now simply called the "S1", and raced in the Pikes Peak International Hill Climb. The climb race pits a driver and car to drive to the summit of the Pikes Peak mountain in Colorado, and in 1985, Michèle Mouton set a new record of 11:25.39, and being the first woman to set a Pikes Peak record. In 1986, Audi formally left international rally racing following an accident in Portugal involving driver Joaquim Santos in his Ford RS200. Santos swerved to avoid hitting spectators in the road, and left the track into the crowd of spectators on the side, killing three and injuring 30. Bobby Unser used an Audi in that same year to claim a new record for the Pikes Peak Hill Climb at 11:09.22.
In 1987, Walter Röhrl claimed the title for Audi setting a new Pikes Peak International Hill Climb record of 10:47.85 in his Audi S1, which he had retired from the WRC two years earlier. The Audi S1 employed Audi's time-tested inline-five-cylinder turbocharged engine, with the final version generating . The engine was mated to a six-speed gearbox and ran on Audi's famous four-wheel drive system. All of Audi's top drivers drove this car; Hannu Mikkola, Stig Blomqvist, Walter Röhrl and Michèle Mouton. This Audi S1 started the range of Audi 'S' cars, which now represents an increased level of sports-performance equipment within the mainstream Audi model range.
In the USA.
As Audi moved away from rallying and into circuit racing, they chose to move first into America with the Trans-Am in 1988.
In 1989, Audi moved to International Motor Sports Association (IMSA) GTO with the Audi 90, however as they avoided the two major endurance events (Daytona and Sebring) despite winning on a regular basis, they would lose out on the title.
Touring cars.
In 1990, having completed their objective to market cars in North America, Audi returned to Europe, turning first to the Deutsche Tourenwagen Meisterschaft (DTM) series with the Audi V8, and then in 1993, being unwilling to build cars for the new formula, they turned their attention to the fast growing Super Touring series, which are a series of national championships. Audi first entered in the French Supertourisme and Italian Superturismo. In the following year, Audi would switch to the German Super Tourenwagen Cup (known as STW), and then to British Touring Car Championship (BTCC) the year after that.
The Fédération Internationale de l'Automobile (FIA), having difficulty regulating the quattro four-wheel drive system, and the impact it had on the competitors, would eventually ban all four-wheel drive cars from competing in 1998, but by then, Audi switched all their works efforts to sports car racing.
By 2000, Audi would still compete in the US with their RS4 for the SCCA Speed World GT Challenge, through dealer/team Champion Racing competing against Corvettes, Vipers, and smaller BMWs (where it is one of the few series to permit 4WD cars). In 2003, Champion Racing entered an RS6. Once again, the quattro four-wheel drive was superior, and Champion Audi won the championship. They returned in 2004 to defend their title, but a newcomer, Cadillac with the new Omega Chassis CTS-V, gave them a run for their money. After four victories in a row, the Audis were sanctioned with several negative changes that deeply affected the car's performance. Namely, added ballast weights, and Champion Audi deciding to go with different tyres, and reducing the boost pressure of the turbocharger.
In 2004, after years of competing with the TT-R in the revitalised DTM series, with privateer team Abt Racing/Christian Abt taking the 2002 title with Laurent Aïello, Audi returned as a full factory effort to touring car racing by entering two factory supported Joest Racing A4 DTM cars.
24 Hours of Le Mans.
Audi began racing prototype sportscars in 1999, debuting at the Le Mans 24 hour. Two car concepts were developed and raced in their first season - the Audi R8R (open-cockpit 'roadster' prototype) and the Audi R8C (closed-cockpit 'coupé' GT-prototype). The R8R scored a credible podium on its racing debut at Le Mans and was the concept which Audi continued to develop into the 2000 season due to favourable rules for open-cockpit prototypes.
However, most of the competitors (such as BMW, Toyota, Mercedes and Nissan) retired at the end of 1999.
The factory-supported Joest Racing team won at Le Mans three times in a row with the Audi R8 (2000–2002), as well as winning every race in the American Le Mans Series in its first year. Audi also sold the car to customer teams such as Champion Racing.
In 2003, two Bentley Speed 8s, with engines designed by Audi, and driven by Joest drivers "loaned" to the fellow Volkswagen Group company, competed in the GTP class, and finished the race in the top two positions, while the Champion Racing R8 finished third overall, and first in the LMP900 class. Audi returned to the winner's podium at the 2004 race, with the top three finishers all driving R8s: Audi Sport Japan Team Goh finished first, Audi Sport UK Veloqx second, and Champion Racing third.
At the 2005 24 Hours of Le Mans, Champion Racing entered two R8s, along with an R8 from the Audi PlayStation Team Oreca. The R8s (which were built to old LMP900 regulations) received a narrower air inlet restrictor, reducing power, and an additional of weight compared to the newer LMP1 chassis. On average, the R8s were about 2–3 seconds off pace compared to the Pescarolo–Judd. But with a team of excellent drivers and experience, both Champion R8s were able to take first and third, while the Oreca team took fourth. The Champion team was also the first American team to win Le Mans since the Gulf Ford GTs in 1967. This also ends the long era of the R8; however, its replacement for 2006, called the Audi R10 TDI, was unveiled on 13 December 2005.
The R10 TDI employed many new and innovative features, the most notable being the twin-turbocharged direct injection diesel engine. It was first raced in the 2006 12 Hours of Sebring as a race-test in preparation for the 2006 24 Hours of Le Mans, which it later went on to win. Audi has been on the forefront of sports car racing, claiming a historic win in the first diesel sports car at 12 Hours of Sebring (the car was developed with a Diesel engine due to ACO regulations that favor diesel engines). As well as winning the 24 Hours of Le Mans in 2006 making history, the R10 TDI has also shown its capabilities by beating the Peugeot 908 HDi FAP in , and beating Peugeot again in , (however Peugeot won the 24h in 2009) and, in a podium clean-sweep by proving its reliability throughout the race (compared to all four 908 entries retired before the end of the race) while breaking a new distance record (set way back by the Porsche 917K of Martini Racing in ), in with the R15 TDI Plus.
Audi's sports car racing success would continue with the Audi R18's victory at the 2011 24 Hours of Le Mans. Audi Sport Team Joest's Benoît Tréluyer earned Audi their first pole position in five years while the team's sister car locked out the front row. Early accidents eliminated two of Audi's three entries, but the sole remaining Audi R18 TDI of Tréluyer, Marcel Fässler, and André Lotterer held off the trio of Peugeot 908s to claim victory by a margin of 13.8 seconds.
American Le Mans Series.
Audi entered a factory racing team run by Joest Racing into the American Le Mans Series under the Audi Sport North America name in 2000. This was a successful operation with the team winning on its debut in the series at the 2000 12 Hours of Sebring. Factory backed Audi R8s were the dominant car in ALMS taking 25 victories between 2000 and the end of the 2002 season. In 2003 Audi sold customer cars to Champion Racing as well as continuing to race the factory Audi Sport North America team. Champion Racing won many races as a private team running Audi R8s and eventually replaced Team Joest as the Audi Sport North America between 2006 and 2008. Since 2009 Audi has not taken part in full American Le Mans Series Championships, but has competed in the series opening races at Sebring, using the 12 hour race as a test for Le Mans, and also as part of the 2012 FIA World Endurance Championship season calendar.
European Le Mans Series.
Audi participated in the 2003 1000km of Le Mans which was a one-off sports car race in preparation for the 2004 European Le Mans Series. The factory team Audi Sport UK won races and the championship in the 2004 season but Audi was unable to match their sweeping success of Audi Sport North America in the American Le Mans Series, partly due to the arrival of a factory competitor in LMP1, Peugeot. The French manufacturer's 908 HDi FAP became the car to beat in the series from 2008 onwards with 20 LMP wins. However, Audi were able to secure the championship in 2008 even though Peugeot scored more race victories in the season.
World Endurance Championship.
2012.
In 2012, the FIA sanctioned a World Endurance Championship which would be organised by the ACO as a continuation of the ILMC. Audi competed won the first WEC race at Sebring and followed this up with a further three successive wins, including the 2012 24 hours of Le Mans. Audi scored a final 5th victory in the 2012 WEC in Bahrain and were able to win the inaugural WEC Manufacturers' Championship.
2013.
As defending champions, Audi once again entered the Audi R18 e-tron quattro chassis into the 2013 WEC and the team won the first five consecutive races, including the 2013 24 hours of le Mans. The victory at Round 5, Circuit of the Americas, was of particular significance as it marked the 100th win for Audi in Le Mans prototypes. Audi secured their second consecutive WEC Manufacturers' Championship at Round 6 after taking second place and half points in the red-flagged Fuji race.
2014.
For the 2014 season Audi entered a redesigned and upgraded R18 e-tron quattro which featured a 2 MJ energy recovery system. As defending champions, Audi would once again face a challenge in LMP1 from Toyota, and additionally from Porsche who returned to endurance racing after a 16 year absence. The season opening 6hrs of Silverstone was a disaster for Audi who saw both cars retire from the race, marking the first time that an Audi car has failed to score a podium in a World Endurance Championship race.
Formula E.
Audi will provide factory support to a Formula E team in partnership with DTM team Abt Sportsline. This team will be called Audi Sport Abt Formula E Team in the inaugural 2014/15 Formula E season. In the 13th February 2014 the team announced that it's driver line up as Daniel Abt and World Endurance Championship driver Lucas di Grassi.
Marketing.
Branding.
The Audi emblem is four overlapping rings that represent the four marques of Auto Union. The Audi emblem symbolises the amalgamation of Audi with DKW, Horch and Wanderer: the first ring from the left represents Audi, the second represents DKW, third is Horch, and the fourth and last ring Wanderer.
Its similarity to the Olympic rings caused the International Olympic Committee to sue Audi in International Trademark Court in 1995, to which they lost.
As part of Audi's centennial celebration in 2009, the company updated the logo, changing the font to left-aligned Audi Type, and altering the shading for the overlapping rings. The revised logo was designed by Rayan Abdullah.
Audi developed a Corporate Sound concept, with Audi Sound Studio designed for producing the Corporate Sound. The Corporate Sound project began with sound agency Klangerfinder GmbH & Co KG and s12 GmbH. Audio samples were created in Klangerfinder's sound studio in Stuttgart, becoming part of Audi Sound Studio collection. Other Audi Sound Studio components include The Brand Music Pool, The Brand Voice. Audi also developed Sound Branding Toolkit including certain instruments, sound themes, rhythm and car sounds which all are supposed to reflect the AUDI sound character.
Audi started using a beating heart sound trademark beginning in 1996. An updated heartbeat sound logo, developed by agencies KLANGERFINDER GmbH & Co KG of Stuttgart and S12 GmbH of Munich, was first used in 2010 in an Audi A8 commercial with the slogan “The Art of Progress.”
Slogans.
Audi's corporate tagline is "Vorsprung durch Technik", meaning ""Progress through Technology"". The German-language tagline is used in many European countries, including the United Kingdom, and in other markets, such as Latin America, Oceania and parts of Asia including Japan. A few years ago, the North American tagline was ""Innovation through technology"", but in Canada the German tagline "Vorsprung durch Technik" was used in advertising. More recently, however, Audi has updated the tagline to "Truth in Engineering" in the U.S.
Typography.
Audi Sans (based on Univers Extended) was originally created in 1997 by Ole Schäfer for MetaDesign. MetaDesign was later commissioned for a new corporate typeface called Audi Type, designed by Paul van der Laan and Pieter van Rosmalen of Bold Monday. The font began to appear in Audi's 2009 products and marketing materials.
Sponsorships.
Audi is a strong partner of different kinds of sports. In football, long partnerships exist between Audi and domestic clubs including FC Bayern Munich, Hamburger SV, 1. FC Nuremberg, Hertha Berlin, and Borussia Mönchengladbach and international clubs including Chelsea FC, Real Madrid CF, FC Barcelona, AC Milan, Ajax Amsterdam, Queens Park Rangers F.C. and Perspolis F.C.. Audi also sponsors winter sports: The Audi FIS Alpine Ski World Cup is named after the company. Additionally, Audi supports the German Ski Association (DSV) as well as the alpine skiing national teams of Switzerland, Sweden, Finland, France, Liechtenstein, Italy, Austria and the US. For almost two decades Audi fosters golf sport: for example with the Audi quattro Cup and the HypoVereinsbank Ladies German Open presented by Audi. In sailing, Audi is engaged in the Medcup regatta and supports the team Luna Rossa during the Louis Vuitton Pacific Series and also is the primary sponsor of the Melges 20 sailboat. Further, Audi sponsors the regional teams ERC Ingolstadt (hockey) and FC Ingolstadt 04 (soccer).
In 2009, the year of Audis 100th anniversary, the company organises the Audi Cup for the first time. Audi also sponsor the New York Yankees as well. In October 2010 they agreed to a three sponsorship year-deal with Everton. Audi also sponsors the England Polo Team and holds the Audi Polo Awards.
Multitronic campaign.
In 2001, Audi promoted the new multitronic continuously variable transmission with television commercials throughout Europe, featuring an impersonator of musician and actor Elvis Presley. A prototypical dashboard figure – later named "Wackel-Elvis" ("Wobble Elvis" or "Wobbly Elvis") – appeared in the commercials to demonstrate the smooth ride in an Audi equipped with the multitronic transmission. The dashboard figure was originally intended for use in the commercials only, but after they aired the demand for Wackel-Elvis fans grew among fans and the figure was mass-produced in China and marketed by Audi in their factory outlet store.
Audi TDI.
As part of Audi's attempt to promote its Diesel technology in 2009, the company began Audi Mileage Marathon. The driving tour featured a fleet of 23 Audi TDI vehicles from 4 models (Audi Q7 3.0 TDI, Audi Q5 3.0 TDI, Audi A4 3.0 TDI, Audi A3 Sportback 2.0 TDI with S tronic transmission) travelling across the American continent from New York to Los Angeles, passing major cities like Chicago, Dallas and Las Vegas during the 13 daily stages, as well as natural wonders including the Rocky Mountains, Death Valley and the Grand Canyon.
As part of 2014 model year Audi TDI vehicles launch in the US, 3 television commercials ("The Station", "Future", "Range") were produced. In the 60-second 'The Station' ad, a woman at a fueling station reaches for the diesel pump to fill up her Audi A6. In a dramatic fashion, unsuspecting onlookers race towards her and they can't imagine the luxury vehicle is in fact a diesel. The spot ends with the tagline "It's time to rethink diesel – join the club." "The Station" appeared on primetime network and cable 2013 fall programming including Agents of S.H.I.E.L.D, Modern Family, The Big Bang Theory, Hostages, Sons of Anarchy and NBC NFL Sunday Night Football. The 15-second "Range" ad demonstrates the potential to drive from New York to Chicago on a single tank of gas, covering a range of approximately 790 miles. In the 15-second "Future" ad, viewers see the potential for clean diesel as today's leading alternative fuel solution and an intelligent choice for those on the leading-edge. Audi TDI provides drivers with 30% better fuel economy and range without compromises on performance and design. In addition to the three new television spots, Audi also tried to dispel the most common myths of diesel – gas station availability, the smell and perception associated with an older generation of diesel vehicles, weak performance – in a series of four online video shorts that would roll out over the next two months on the Audi YouTube channel (http://www.youtube.com/audiusa). The spots also will appear on The Washington Post and Slate.com in a custom user-generated content hub through 2013-10-31. In addition to standard and high-impact ads, the content hub features custom videos, articles and infographics, along with relevant social conversations. The Audi TDI clean diesel campaign also features print ads that reinforce the message "the future of fuel is here now." Print ads would roll out in select automotive buff books in fall 2013. 'The Station' ad was premiered in Canada in September 2013. 'The Station' (also called 'The Moment of Truth') ad was produced by Venables Bell & Partners, Biscuit Filmworks, Final Cut.
As part of 2014 model year Audi TDI vehicles launch in the US, the 'Truth in 48' driving challenge took place from Audi Pacific dealership at Los Angeles to New York in 48 hours or less, began at 9 a.m. PDT on 2013-09-07. The Coast-to-coast attempt used 2014 Audi A6 TDI and Audi A7 TDI and a 2014 Audi Q5 TDI crossover as the support vehicle, with teams of eight noted hypermilers and four journalists.
Audi e-tron.
The next phase of technology Audi is developing is the e-tron electric drive powertrain system. They have shown several concept cars , each with different levels of size and performance. The original e-tron concept shown at the 2009 Frankfurt motor show is based on the platform of the R8 and has been scheduled for limited production. Power is provided by electric motors at all four wheels. The second concept was shown at the 2010 Detroit Motor Show. Power is provided by two electric motors at the rear axle. This concept is also considered to be the direction for a future mid-engined gas-powered 2-seat performance coupe. The Audi A1 e-tron concept, based on the Audi A1 production model, is a hybrid vehicle with a range extending Wankel rotary engine to provide power after the initial charge of the battery is depleted. It is the only concept of the three to have range extending capability. The car is powered through the front wheels, always using electric power.
It is all set to be displayed at the Auto Expo 2012 in New Delhi, India, from 5 January. Powered by a 1.4 litre engine, and can cover a distance up to 54 km s on a single charge. The e-tron was also shown in the 2013 blockbuster film Iron Man 3 and was driven by Tony Stark (Iron Man).
In video games.
In PlayStation Home, the PlayStation 3's online community-based service, Audi has supported Home by releasing a dedicated Home space in the European version of Home. Audi is the first carmaker to develop a space for Home. On 17 December 2009, Audi released the Audi Space as two spaces; the Audi Home Terminal and the Audi Vertical Run. The Audi Home Terminal features an Audi TV channel delivering video content, an Internet Browser feature, and a view of a city. The Audi Vertical Run is where users can access the mini-game Vertical Run, a futuristic mini-game featuring Audi's e-tron concept. Players collect energy and race for the highest possible speeds and the fastest players earn a place in the Audi apartments located in a large tower in the centre of the Audi Space. In both the Home Terminal and Vertical Run spaces, there are teleports where users can teleport back and forth between the two spaces. Audi has stated that additional content will be added in 2010.

</doc>
<doc id="849" url="http://en.wikipedia.org/wiki?curid=849" title="Aircraft">
Aircraft

An aircraft is a machine that is able to fly by gaining support from the air, or, in general, the atmosphere of a planet. It counters the force of gravity by using either static lift or by using the dynamic lift of an airfoil, or in a few cases the downward thrust from jet engines.
The human activity that surrounds aircraft is called "aviation". Crewed aircraft are flown by an onboard pilot, but unmanned aerial vehicles may be remotely controlled or self-controlled by onboard computers. Aircraft may be classified by different criteria, such as lift type, propulsion, usage and others.
History.
Flying model craft and stories of manned flight go back many centuries, however the first manned ascent – and safe descent – in modern times took place by hot-air balloon in the 18th century. Each of the two World Wars led to great technical advances. Consequently the history of aircraft can be divided into five eras:
Methods of lift.
Lighter than air – aerostats.
Aerostats use buoyancy to float in the air in much the same way that ships float on the water. They are characterized by one or more large gasbags or canopies, filled with a relatively low-density gas such as helium, hydrogen, or hot air, which is less dense than the surrounding air. When the weight of this is added to the weight of the aircraft structure, it adds up to the same weight as the air that the craft displaces.
Small hot-air balloons called sky lanterns date back to the 3rd century BC, and were only the second type of aircraft to fly, the first being kites.
A balloon was originally any aerostat, while the term airship was used for large, powered aircraft designs – usually fixed-wing – though none had yet been built. The advent of powered balloons, called dirigible balloons, and later of rigid hulls allowing a great increase in size, began to change the way these words were used. Huge powered aerostats, characterized by a rigid outer framework and separate aerodynamic skin surrounding the gas bags, were produced, the Zeppelins being the largest and most famous. There were still no fixed-wing aircraft or non-rigid balloons large enough to be called airships, so "airship" came to be synonymous with these aircraft. Then several accidents, such as the Hindenburg disaster in 1937, led to the demise of these airships. Nowadays a "balloon" is an unpowered aerostat and an "airship" is a powered one.
A powered, steerable aerostat is called a "dirigible". Sometimes this term is applied only to non-rigid balloons, and sometimes "dirigible balloon" is regarded as the definition of an airship (which may then be rigid or non-rigid). Non-rigid dirigibles are characterized by a moderately aerodynamic gasbag with stabilizing fins at the back. These soon became known as "blimps". During the Second World War, this shape was widely adopted for tethered balloons; in windy weather, this both reduces the strain on the tether and stabilizes the balloon. The nickname "blimp" was adopted along with the shape. In modern times, any small dirigible or airship is called a blimp, though a blimp may be unpowered as well as powered.
Heavier-than-air – aerodynes.
Heavier-than-air aircraft, such as airplanes, must find some way to push air or gas downwards, so that a reaction occurs (by Newton's laws of motion) to push the aircraft upwards. This dynamic movement through the air is the origin of the term "aerodyne". There are two ways to produce dynamic upthrust: aerodynamic lift, and powered lift in the form of engine thrust.
Aerodynamic lift involving wings is the most common, with fixed-wing aircraft being kept in the air by the forward movement of wings, and rotorcraft by spinning wing-shaped rotors sometimes called rotary wings. A wing is a flat, horizontal surface, usually shaped in cross-section as an aerofoil. To fly, air must flow over the wing and generate lift. A "flexible wing" is a wing made of fabric or thin sheet material, often stretched over a rigid frame. A "kite" is tethered to the ground and relies on the speed of the wind over its wings, which may be flexible or rigid, fixed, or rotary.
With powered lift, the aircraft directs its engine thrust vertically downward. V/STOL aircraft, such as the Harrier Jump Jet and F-35B take off and land vertically using powered lift and transfer to aerodynamic lift in steady flight.
A pure rocket is not usually regarded as an aerodyne, because it does not depend on the air for its lift (and can even fly into space); however, many aerodynamic lift vehicles have been powered or assisted by rocket motors. Rocket-powered missiles that obtain aerodynamic lift at very high speed due to airflow over their bodies are a marginal case.
Fixed-wing.
The forerunner of the fixed-wing aircraft is the kite. Whereas a fixed-wing aircraft relies on its forward speed to create airflow over the wings, a kite is tethered to the ground and relies on the wind blowing over its wings to provide lift. Kites were the first kind of aircraft to fly, and were invented in China around 500 BC. Much aerodynamic research was done with kites before test aircraft, wind tunnels, and computer modelling programs became available.
The first heavier-than-air craft capable of controlled free-flight were gliders. A glider designed by Cayley carried out the first true manned, controlled flight in 1853.
Practical, powered, fixed-wing aircraft (the aeroplane or airplane) were invented by Wilbur and Orville Wright. Besides the method of propulsion, fixed-wing aircraft are in general characterized by their wing configuration. The most important wing characteristics are:
A variable geometry aircraft can change its wing configuration during flight.
A "flying wing" has no fuselage, though it may have small blisters or pods. The opposite of this is a "lifting body", which has no wings, though it may have small stabilizing and control surfaces.
Wing-in-ground-effect vehicles may be considered as fixed-wing aircraft. They "fly" efficiently close to the surface of the ground or water, like conventional aircraft during takeoff. An example is the Russian ekranoplan (nicknamed the "Caspian Sea Monster"). Man-powered aircraft also rely on ground effect to remain airborne with a minimal pilot power, but this is only because they are so underpowered — in fact, the airframe is capable of flying higher.
Rotorcraft.
Rotorcraft, or rotary-wing aircraft, use a spinning rotor with aerofoil section blades (a "rotary wing") to provide lift. Types include helicopters, autogyros, and various hybrids such as gyrodynes and compound rotorcraft.
"Helicopters" have a rotor turned by an engine-driven shaft. The rotor pushes air downward to create lift. By tilting the rotor forward, the downward flow is tilted backward, producing thrust for forward flight. Some helicopters have more than one rotor and a few have rotors turned by gas jets at the tips.
"Autogyros" have unpowered rotors, with a separate power plant to provide thrust. The rotor is tilted backward. As the autogyro moves forward, air blows upward across the rotor, making it spin. This spinning increases the speed of airflow over the rotor, to provide lift. Rotor kites are unpowered autogyros, which are towed to give them forward speed or tethered to a static anchor in high-wind for kited flight.
"Cyclogyros" rotate their wings about a horizontal axis.
"Compound rotorcraft" have wings that provide some or all of the lift in forward flight. They are nowadays classified as "powered lift" types and not as rotorcraft. "Tiltrotor" aircraft (such as the V-22 Osprey), tiltwing, tailsitter, and coleopter aircraft have their rotors/propellers horizontal for vertical flight and vertical for forward flight.
Propulsion.
Unpowered aircraft.
Gliders are heavier-than-air aircraft that do not employ propulsion once airborne. Take-off may be by launching forward and downward from a high location, or by pulling into the air on a tow-line, either by a ground-based winch or vehicle, or by a powered "tug" aircraft. For a glider to maintain its forward air speed and lift, it must descend in relation to the air (but not necessarily in relation to the ground). Many gliders can 'soar' – gain height from updrafts such as thermal currents. The first practical, controllable example was designed and built by the British scientist and pioneer George Cayley, whom many recognise as the first aeronautical engineer. Common examples of gliders are sailplanes, hang gliders and paragliders.
Balloons drift with the wind, though normally the pilot can control the altitude, either by heating the air or by releasing ballast, giving some directional control (since the wind direction changes with altitude). A wing-shaped hybrid balloon can glide directionally when rising or falling; but a spherically shaped balloon does not have such directional control.
Kites are aircraft that are tethered to the ground or other object (fixed or mobile) that maintains tension in the tether or kite line; they rely on virtual or real wind blowing over and under them to generate lift and drag. Kytoons are balloon-kite hybrids that are shaped and tethered to obtain kiting deflections, and can be lighter-than-air, neutrally buoyant, or heavier-than-air.
Powered aircraft.
Powered aircraft have one or more onboard sources of mechanical power, typically aircraft engines although rubber and manpower have also been used. Most aircraft engines are either lightweight piston engines or gas turbines. Engine fuel is stored in tanks, usually in the wings but larger aircraft also have additional fuel tanks in the fuselage.
Propeller aircraft.
Propeller aircraft use one or more propellers (airscrews) to create thrust in a forward direction. The propeller is usually mounted in front of the power source in "tractor configuration" but can be mounted behind in "pusher configuration". Variations of propeller layout include "contra-rotating propellers" and "ducted fans".
Many kinds of power plant have been used to drive propellers. Early airships used man power or steam engines. The more practical internal combustion piston engine was used for virtually all fixed-wing aircraft until World War II and is still used in many smaller aircraft. Some types use turbine engines to drive a propeller in the form of a turboprop or propfan. Human-powered flight has been achieved, but has not become a practical means of transport. Unmanned aircraft and models have also used power sources such as electric motors and rubber bands.
Jet aircraft.
Jet aircraft use airbreathing jet engines, which take in air, burn fuel with it in a combustion chamber, and accelerate the exhaust rearwards to provide thrust.
Turbojet and turbofan engines use a spinning turbine to drive one or more fans, which provide additional thrust. An afterburner may be used to inject extra fuel into the hot exhaust, especially on military "fast jets". Use of a turbine is not absolutely necessary: other designs include the pulse jet and ramjet. These mechanically simple designs cannot work when stationary, so the aircraft must be launched to flying speed by some other method. Other variants have also been used, including the motorjet and hybrids such as the Pratt & Whitney J58, which can convert between turbojet and ramjet operation.
Compared to propellers, jet engines can provide much higher thrust, higher speeds and, above about , greater efficiency. They are also much more fuel-efficient than rockets. As a consequence nearly all large, high-speed or high-altitude aircraft use jet engines.
Rotorcraft.
Some rotorcraft, such as helicopters, have a powered rotary wing or "rotor", where the rotor disc can be angled slightly forward so that a proportion of its lift is directed forwards. The rotor may, like a propeller, be powered by a variety of methods such as a piston engine or turbine. Experiments have also used jet nozzles at the rotor blade tips.
Design and construction.
Aircraft are designed according to many factors such as customer and manufacturer demand, safety protocols and physical and economic constraints. For many types of aircraft the design process is regulated by national airworthiness authorities.
The key parts of an aircraft are generally divided into three categories:
Structure.
The approach to structural design varies widely between different types of aircraft. Some, such as paragliders, comprise only flexible materials that act in tension and rely on aerodynamic pressure to hold their shape. A balloon similarly relies on internal gas pressure but may have a rigid basket or gondola slung below it to carry its payload. Early aircraft, including airships, often employed flexible doped aircraft fabric covering to give a reasonably smooth aeroshell stretched over a rigid frame. Later aircraft employed semi-monocoque techniques, where the skin of the aircraft is stiff enough to share much of the flight loads. In a true monocoque design there is no internal structure left.
The key structural parts of an aircraft depend on what type it is.
Aerostats.
Lighter-than-air types are characterised by one or more gasbags, typically with a supporting structure of flexible cables or a rigid framework called its hull. Other elements such as engines or a gondola may also be attached to the supporting structure.
Aerodynes.
Heavier-than-air types are characterised by one or more wings and a central fuselage. The fuselage typically also carries a tail or empennage for stability and control, and an undercarriage for takeoff and landing. Engines may be located on the fuselage or wings. On a fixed-wing aircraft the wings are rigidly attached to the fuselage, while on a rotorcraft the wings are attached to a rotating vertical shaft. Smaller designs sometimes use flexible materials for part or all of the structure, held in place either by a rigid frame or by air pressure. The fixed parts of the structure comprise the airframe.
Avionics.
The avionics comprise the flight control systems and related equipment, including the cockpit instrumentation, navigation, radar, monitoring, and communication systems.
Flight characteristics.
Flight envelope.
The flight envelope of an aircraft refers to its capabilities in terms of airspeed and load factor or altitude. The term can also refer to other measurements such as maneuverability. When a craft is pushed, for instance by diving it at high speeds, it is said to be flown "outside the envelope", something considered unsafe.
Range.
The range is the distance an aircraft can fly between takeoff and landing, as limited by the time it can remain airborne.
For a powered aircraft the time limit is determined by the fuel load and rate of consumption.
For an unpowered aircraft, the maximum flight time is limited by factors such as weather conditions and pilot endurance. Many aircraft types are restricted to daylight hours, while balloons are limited by their supply of lifting gas. The range can be seen as the average ground speed multiplied by the maximum time in the air.
Flight dynamics.
Flight dynamics is the science of air vehicle orientation and control in three dimensions. The three critical flight dynamics parameters are the angles of rotation around three axes about the vehicle's center of mass, known as "pitch", "roll", and "yaw" (quite different from their use as Tait-Bryan angles).
Flight dynamics is concerned with the stability and control of an aircraft's rotation about each of these axes.
Stability.
An aircraft that is unstable tends to diverge from its current flight path and so is difficult to fly. An aircraft which is very stable tends to stay on its current flight path and is difficult to manoeuvre. So it is important for any design to achieve the desired degree of stability. Since the widespread use of digital computers, it is becoming increasingly common for designs to be inherently unstable and to rely on computerised control systems to provide artificial stability.
A fixed wing is typically unstable in pitch, roll and yaw. Pitch and yaw stabilities of conventional fixed wing designs need horizontal and vertical stabilisers, which act in a similar way to the feathers on an arrow. These stabilizing surfaces allow equilibrium of aerodynamic forces and to stabilise the flight dynamics of pitch and yaw. They are usually mounted on the tail section (empennage), although in the canard layout, the main aft wing replaces the canard foreplane as pitch stabilizer. tandem and Tailless aircraft rely on the same general rule to achieve stability, the aft surface being the stabilising one.
A rotary wing is typically unstable in yaw, requiring a vertical stabiliser.
A balloon is typically very stable in pitch and roll due to the way the payload is hung underneath.
Control.
Flight control surfaces enable the pilot to control an aircraft's flight attitude and are usually part of the wing or mounted on, or integral with, the associated stabilizing surface. Their development was a critical advance in the history of aircraft, which had until that point been uncontrollable in flight.
Aerospace engineers develop control systems for a vehicle's orientation (attitude) about its center of mass. The control systems include actuators, which exert forces in various directions, and generate rotational forces or moments about the aerodynamic center of the aircraft, and thus rotate the aircraft in pitch, roll, or yaw. For example, a pitching moment is a vertical force applied at a distance forward or aft from the aerodynamic center of the aircraft, causing the aircraft to pitch up or down. Control systems are also sometimes used to increase or decrease drag, for example to slow the aircraft to a safe speed for landing.
The two main aerodynamic forces acting on any aircraft are lift supporting it in the air and drag opposing its motion. Control surfaces or other techniques may also be used to affect these forces directly, without inducing any rotation.
Impacts of aircraft use.
Aircraft permit long distance, high speed travel and may be the more fuel efficient mode of transportation in some circumstances. Aircraft have environmental and climate impacts beyond fuel efficiency considerations, however. They are also relatively noisy compared to other forms of travel and high altitude aircraft generate contrails, which experimental evidence suggests may alter weather patterns.
Uses for aircraft.
Aircraft are produced in several different types optimized for various uses; military aircraft, which includes not just combat types but many types of supporting aircraft, and civil aircraft, which include all non-military types, experimental and model.
Military.
A military aircraft is any aircraft that is operated by a legal or insurrectionary armed service of any type. Military aircraft can be either combat or non-combat:
Most military aircraft are powered heavier-than-air types. Other types such as gliders and balloons have also been used as military aircraft; for example, balloons were used for observation during the American Civil War and World War I, and military gliders were used during World War II to land troops.
Civil.
Civil aircraft divide into "commercial" and "general" types, however there are some overlaps.
Commercial aircraft include types designed for scheduled and charter airline flights, carrying passengers, mail and other cargo. The larger passenger-carrying types are the airliners, the largest of which are wide-body aircraft. Some of the smaller types are also used in general aviation, and some of the larger types are used as VIP aircraft.
General aviation is a catch-all covering other kinds of private (where the pilot is not paid for time or expenses) and commercial use, and involving a wide range of aircraft types such as business jets (bizjets), trainers, homebuilt, gliders, warbirds and hot air balloons to name a few. The vast majority of aircraft today are general aviation types.
Experimental.
An experimental aircraft is one that has not been fully proven in flight, or one that carries an FAA airworthiness certificate in the "Experimental" category. Often, this implies that new aerospace technologies are being tested on the aircraft, although the term also refers to amateur- and kit-built aircraft; many of which are based on proven designs.
Model.
A model aircraft is a small unmanned type made to fly for fun, for static display, for aerodynamic research or for other purposes. A scale model is a replica of some larger design.
External links.
History
Information

</doc>
<doc id="851" url="http://en.wikipedia.org/wiki?curid=851" title="Alfred Nobel">
Alfred Nobel

Alfred Bernhard Nobel ( ; 21 October 1833 – 10 December 1896) was a Swedish chemist, engineer, innovator, and armaments manufacturer.
He was the inventor of dynamite. Nobel also owned Bofors, which he had redirected from its previous role as primarily an iron and steel producer to a major manufacturer of cannon and other armaments. Nobel held 350 different patents, dynamite being the most famous. His fortune was used posthumously to institute the Nobel Prizes. The synthetic element nobelium was named after him. His name also survives in modern-day companies such as Dynamit Nobel and AkzoNobel, which are descendants of or mergers with companies Nobel himself established.
Life and career.
Born in Stockholm, Alfred Nobel was the fourth son of Immanuel Nobel (1801–1872), an inventor and engineer, and Karolina Andriette (Ahlsell) Nobel (1805–1889). The couple married in 1827 and had eight children. The family was impoverished, and only Alfred and his three brothers survived past childhood. Through his father, Alfred Nobel was a descendant of the Swedish scientist Olaus Rudbeck (1630–1702), and in his turn the boy was interested in engineering, particularly explosives, learning the basic principles from his father at a young age. Alfred Nobel's interest in technology was inherited from his father, an alumnus of Royal Institute of Technology in Stockholm.
Following various business failures, Nobel's father moved to Saint Petersburg in 1837 and grew successful there as a manufacturer of machine tools and explosives. He invented modern plywood and started work on the "torpedo". In 1842, the family joined him in the city. Now prosperous, his parents were able to send Nobel to private tutors and the boy excelled in his studies, particularly in chemistry and languages, achieving fluency in English, French, German, and Russian. For 18 months, from 1841 to 1842, Nobel went to the only school he ever attended as a child, the Jacobs Apologistic School in Stockholm.
As a young man, Nobel studied with chemist Nikolai Zinin; then, in 1850, went to Paris to further the work; and, at 18, he went to the United States for four years to study chemistry, collaborating for a short period under inventor John Ericsson, who designed the American Civil War ironclad "USS Monitor". Nobel filed his first patent, for a gas meter, in 1857.
The family factory produced armaments for the Crimean War (1853–1856); but, had difficulty switching back to regular domestic production when the fighting ended and they filed for bankruptcy. In 1859, Nobel's father left his factory in the care of the second son, Ludvig Nobel (1831–1888), who greatly improved the business. Nobel and his parents returned to Sweden from Russia and Nobel devoted himself to the study of explosives, and especially to the safe manufacture and use of nitroglycerine (discovered in 1847 by Ascanio Sobrero, one of his fellow students under Théophile-Jules Pelouze at the University of Turin). Nobel invented a detonator in 1863; and, in 1865, he designed the blasting cap.
On 3 September 1864, a shed, used for the preparation of nitroglycerin, exploded at the factory in Heleneborg Stockholm, killing five people, including Nobel's younger brother Emil. Dogged by more minor accidents but unfazed, Nobel went on to build further factories, focusing on improving the stability of the explosives he was developing. Nobel invented dynamite in 1867, a substance easier and safer to handle than the more unstable nitroglycerin. Dynamite was patented in the US and the UK and was used extensively in mining and the building of transport networks internationally. In 1875 Nobel invented gelignite, more stable and powerful than dynamite, and in 1887 patented ballistite, a forerunner of cordite.
Nobel was elected a member of the Royal Swedish Academy of Sciences in 1884, the same institution that would later select laureates for two of the Nobel prizes, and he received an honorary doctorate from Uppsala University in 1893.
Nobel's brothers Ludvig and Robert exploited oilfields along the Caspian Sea and became hugely rich in their own right. Nobel invested in these and amassed great wealth through the development of these new oil regions. During his life Nobel issued 350 patents internationally and by his death had established 90 armaments factories, despite his belief in pacifism.
In 1888, the death of his brother Ludvig caused several newspapers to publish obituaries of Alfred in error. A French obituary stated "Le marchand de la mort est mort" "("The merchant of death is dead")".
In 1891, following the death of his mother and his brother Ludvig and the end of a longstanding relationship, Nobel moved from Paris to San Remo, Italy. Suffering from angina, Nobel died at home, of a cerebral hemorrhage in 1896. Unbeknownst to his family, friends or colleagues, he had left most of his wealth in trust, in order to fund the awards that would become known as the Nobel Prizes. He is buried in Norra begravningsplatsen in Stockholm.
Personal life.
Through baptism and confirmation Alfred Nobel was Lutheran and during his Paris years he frequented regularly the Church of Sweden Abroad led by pastor Nathan Söderblom who would in 1930 also be the recipient of the Nobel Peace Prize.
Nobel travelled for much of his business life, maintaining companies in various countries in Europe and North America and keeping a permanent home in Paris from 1873 to 1891. He remained a solitary character, given to periods of depression. Though Nobel remained unmarried, his biographers note that he had at least three loves. Nobel's first love was in Russia with a girl named Alexandra, who rejected his proposal. In 1876 Austro-Bohemian Countess Bertha Kinsky became Alfred Nobel's secretary. But after only a brief stay she left him to marry her previous lover, Baron Arthur Gundaccar von Suttner. Though her personal contact with Alfred Nobel had been brief, she corresponded with him until his death in 1896, and it is believed that she was a major influence in his decision to include a peace prize among those prizes provided in his will. Bertha von Suttner was awarded the 1905 Nobel Peace prize, 'for her sincere peace activities'.
Nobel's third and longest-lasting relationship was with Sofie Hess from Vienna, whom he met in 1876. The liaison lasted for 18 years. After his death, according to his biographers Evlanoff, Fluor, and Fant, Nobel's letters were locked within the Nobel Institute in Stockholm. They were released only in 1955, to be included with other biographical data.
Despite the lack of formal secondary and tertiary level education, Nobel gained proficiency in six languages: Swedish, French, Russian, English, German and Italian. He also developed sufficient literary skill to write poetry in English. His "Nemesis", a prose tragedy in four acts about Beatrice Cenci, partly inspired by Percy Bysshe Shelley's "The Cenci", was printed while he was dying. The entire stock except for three copies was destroyed immediately after his death, being regarded as scandalous and blasphemous. The first surviving edition (bilingual Swedish–Esperanto) was published in Sweden in 2003. The play has been translated into Slovenian via the Esperanto version and into French. In 2010 it was published in Russia in another bilingual (Russian–Esperanto) edition.
Inventions.
Nobel found that when nitroglycerin was incorporated in an absorbent inert substance like "kieselguhr" (diatomaceous earth) it became safer and more convenient to handle, and this mixture he patented in 1867 as 'dynamite'. Nobel demonstrated his explosive for the first time that year, at a quarry in Redhill, Surrey, England. In order to help reestablish his name and improve the image of his business from the earlier controversies associated with the dangerous explosives, Nobel had also considered naming the highly powerful substance "Nobel's Safety Powder", but settled with Dynamite instead, referring to the Greek word for 'power'.
Nobel later on combined nitroglycerin with various nitrocellulose compounds, similar to collodion, but settled on a more efficient recipe combining another nitrate explosive, and obtained a transparent, jelly-like substance, which was a more powerful explosive than dynamite. 'Gelignite', or blasting gelatin, as it was named, was patented in 1876; and was followed by a host of similar combinations, modified by the addition of potassium nitrate and various other substances. Gelignite was more stable, transportable and conveniently formed to fit into bored holes, like those used in drilling and mining, than the previously used compounds and was adopted as the standard technology for mining in the Age of Engineering bringing Nobel a great amount of financial success, though at a significant cost to his health. An off-shoot of this research resulted in Nobel's invention of ballistite, the precursor of many modern smokeless powder explosives and still used as a rocket propellant.
Nobel Prizes.
In 1888 Alfred's brother Ludvig died while visiting Cannes and a French newspaper erroneously published Alfred's obituary. It condemned him for his invention of dynamite and is said to have brought about his decision to leave a better legacy after his death. The obituary stated, "" ("The merchant of death is dead") and went on to say, "Dr. Alfred Nobel, who became rich by finding ways to kill more people faster than ever before, died yesterday." Alfred was disappointed with what he read and concerned with how he would be remembered.
On 27 November 1895, at the Swedish-Norwegian Club in Paris, Nobel signed his last will and testament and set aside the bulk of his estate to establish the Nobel Prizes, to be awarded annually without distinction of nationality. After taxes and bequests to individuals, Nobel's will allocated 94% of his total assets, 31,225,000 Swedish kronor, to establish the five Nobel Prizes. This converted to GBP £1,687,837 at the time. In 2012, the capital was worth around SEK 3.1 billion (USD 472 million, EUR 337 million), which is almost twice the amount of the initial capital, taking inflation into account.
The first three of these prizes are awarded for eminence in physical science, in chemistry and in medical science or physiology; the fourth is for literary work "in an ideal direction" and the fifth prize is to be given to the person or society that renders the greatest service to the cause of international fraternity, in the suppression or reduction of standing armies, or in the establishment or furtherance of peace congresses.
The formulation for the literary prize being given for a work "in an ideal direction" (' in Swedish), is cryptic and has caused much confusion. For many years, the Swedish Academy interpreted "ideal" as "idealistic" (') and used it as a reason not to give the prize to important but less Romantic authors, such as Henrik Ibsen and Leo Tolstoy. This interpretation has since been revised, and the prize has been awarded to, for example, Dario Fo and José Saramago, who do not belong to the camp of literary idealism.
There was room for interpretation by the bodies he had named for deciding on the physical sciences and chemistry prizes, given that he had not consulted them before making the will. In his one-page testament, he stipulated that the money go to discoveries or inventions in the physical sciences and to discoveries or improvements in chemistry. He had opened the door to technological awards, but had not left instructions on how to deal with the distinction between science and technology. Since the deciding bodies he had chosen were more concerned with the former, the prizes went to scientists more often than engineers, technicians or other inventors.
In 2001, Alfred Nobel's great-grandnephew, Peter Nobel (b. 1931), asked the Bank of Sweden to differentiate its award to economists given "in Alfred Nobel's memory" from the five other awards. This request added to the controversy over whether the Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel is actually a "Nobel Prize".
Monuments.
The "Monument to Alfred Nobel" (, ) in Saint Petersburg is located along the Bolshaya Nevka River on Petrogradskaya Embankment. It was dedicated in 1991 to mark the 90th anniversary of the first Nobel Prize presentation. Diplomat Thomas Bertelman and Professor Arkady Melua initiators of creation of the monument (1989). Professor A. Melua has provided funds for the establishment of the monument (J.S.Co. "Humanistica", 1990-1991). The abstract metal sculpture was designed by local artists Sergey Alipov and Pavel Shevchenko, and appears to be an explosion or branches of a tree. Petrogradskaya Embankment is the street where the Nobel's family lived until until 1859.

</doc>
<doc id="852" url="http://en.wikipedia.org/wiki?curid=852" title="Alexander Graham Bell">
Alexander Graham Bell

Alexander Graham Bell (March 3, 1847 – August 2, 1922) was an eminent scientist, inventor, engineer and innovator who is credited with inventing the first practical telephone.
Bell's father, grandfather, and brother had all been associated with work on elocution and speech, and both his mother and wife were deaf, profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices which eventually culminated in Bell being awarded the first US patent for the telephone in 1876. In retrospect, Bell considered his most famous invention an intrusion on his real work as a scientist and refused to have a telephone in his study.
Many other inventions marked Bell's later life, including groundbreaking work in optical telecommunications, hydrofoils and aeronautics. In 1888, Bell became one of the founding members of the National Geographic Society.
Early life.
Alexander Bell was born in Edinburgh, Scotland on March 3, 1847. The family home was at 16 South Charlotte Street, and has a stone inscription, marking it as Alexander Graham Bell's birthplace. He had two brothers: Melville James Bell (1845–70) and Edward Charles Bell (1848–67). Both of his brothers died of tuberculosis. His father was Professor Alexander Melville Bell, and his mother was Eliza Grace (née Symonds). Although he was born "Alexander", at age 10, he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the middle name "Graham", chosen out of admiration for Alexander Graham, a Canadian being treated by his father and boarder who had become a family friend. To close relatives and friends he remained "Aleck" which his father continued to call him into later life.
First invention.
As a child, young Alexander displayed a natural curiosity about his world, resulting in gathering botanical specimens as well as experimenting even at an early age. His best friend was Ben Herdman, a neighbor whose family operated a flour mill, the scene of many forays. Young Aleck asked what needed to be done at the mill. He was told wheat had to be dehusked through a laborious process and at the age of 12, Bell built a homemade device that combined rotating paddles with sets of nail brushes, creating a simple dehusking machine that was put into operation and used steadily for a number of years. In return, John Herdman gave both boys the run of a small workshop in which to "invent".
From his early years, Bell showed a sensitive nature and a talent for art, poetry and music that was encouraged by his mother. With no formal training, he mastered the piano and became the family's pianist. Despite being normally quiet and introspective, he reveled in mimicry and "voice tricks" akin to ventriloquism that continually entertained family guests during their occasional visits. Bell was also deeply affected by his mother's gradual deafness, (she began to lose her hearing when he was 12) and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead wherein she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.
His family was long associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially his "The Standard Elocutionist" (1860), which appeared in Edinburgh in 1868. "The Standard Elocutionist" appeared in 168 British editions and sold over a quarter of a million copies in the United States alone. In this treatise, his father explains his methods of how to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Aleck's father taught him and his brothers not only to write Visible Speech but to identify any symbol and its accompanying sound. Aleck became so proficient that he became a part of his father's public demonstrations and astounded audiences with his abilities. He could decipher Visible Speech representing virtually every language, including Latin, Scottish Gaelic and even Sanskrit, accurately reciting written tracts without any prior knowledge of their pronunciation.
Education.
As a young child, Bell, like his brothers, received his early schooling at home from his father. At an early age, however, he was enrolled at the Royal High School, Edinburgh, Scotland, which he left at age 15, completing only the first four forms. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology, while he treated other school subjects with indifference, to the dismay of his demanding father. Upon leaving school, Bell travelled to London to live with his grandfather, Alexander Bell. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, the attributes that his pupil would need to become a teacher himself. At age 16, Bell secured a position as a "pupil-teacher" of elocution and music, in Weston House Academy, at Elgin, Moray, Scotland. Although he was enrolled as a student in Latin and Greek, he instructed classes himself in return for board and £10 per session. The following year, he attended the University of Edinburgh; joining his older brother Melville who had enrolled there the previous year. In 1868, not long before he departed for Canada with his family, Aleck completed his matriculation exams and was accepted for admission to the University of London.
First experiments with sound.
Bell's father encouraged Aleck's interest in speech and, in 1863, took his sons to see a unique automaton, developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary "mechanical man" simulated a human voice. Aleck was fascinated by the machine and after he obtained a copy of von Kempelen's book, published in German, and had laboriously translated it, he and his older brother Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a "big prize" if they were successful. While his brother constructed the throat and larynx, Aleck tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could "speak", albeit only a few words. The boys would carefully adjust the "lips" and when a bellows forced air through the windpipe, a very recognizable "Mama" ensued, to the delight of neighbors who came to see the Bell invention.
Intrigued by the results of the automaton, Bell continued to experiment with a live subject, the family's Skye Terrier, "Trouve". After he taught it to growl continuously, Aleck would reach into its mouth and manipulate the dog's lips and vocal cords to produce a crude-sounding "Ow ah oo ga ma ma". With little convincing, visitors believed his dog could articulate "How are you grandma?" More indicative of his playful nature, his experiments convinced onlookers that they saw a "talking dog". However, these initial forays into experimentation with sound led Bell to undertake his first serious work on the transmission of sound, using tuning forks to explore resonance.
At the age of 19, he wrote a report on his work and sent it to philologist Alexander Ellis, a colleague of his father (who would later be portrayed as Professor Henry Higgins in "Pygmalion"). Ellis immediately wrote back indicating that the experiments were similar to existing work in Germany, and also lent Aleck a copy of Hermann von Helmholtz's work, "The Sensations of Tone as a Physiological Basis for the Theory of Music".
Dismayed to find that groundbreaking work had already been undertaken by Helmholtz who had conveyed vowel sounds by means of a similar tuning fork "contraption", he pored over the German scientist's book. Working from his own errant mistranslation of a French edition, Aleck fortuitously then made a deduction that would be the underpinning of all his future work on transmitting sound, reporting: "Without knowing much about the subject, it seemed to me that if vowel sounds could be produced by electrical means, so could consonants, so could articulate speech." He also later remarked: "I thought that Helmholtz had done it ... and that my failure was due only to my ignorance of electricity. It was a valuable blunder ... If I had been able to read German in those days, I might never have commenced my experiments!"
Family tragedy.
In 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and, in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout late 1867, his health faltered mainly through exhaustion. His younger brother, Edward "Ted," was similarly bed-ridden, suffering from tuberculosis. While Bell recovered (by then referring to himself in correspondence as "A.G. Bell") and served the next year as an instructor at Somerset College, Bath, England, his brother's condition deteriorated. Edward would never recover. Upon his brother's death, Bell returned home in 1867. His older brother Melville had married and moved out. With aspirations to obtain a degree at the University College London, Bell considered his next years as preparation for the degree examinations, devoting his spare time at his family's residence to studying.
Helping his father in Visible Speech demonstrations and lectures brought Bell to Susanna E. Hull's private school for the deaf in South Kensington, London. His first two pupils were "deaf mute" girls who made remarkable progress under his tutelage. While his older brother seemed to achieve success on many fronts including opening his own elocution school, applying for a patent on an invention, and starting a family, Bell continued as a teacher. However, in May 1870, Melville died from complications due to tuberculosis, causing a family crisis. His father had also suffered a debilitating illness earlier in life and had been restored to health by a convalescence in Newfoundland. Bell's parents embarked upon a long-planned move when they realized that their remaining son was also sickly. Acting decisively, Alexander Melville Bell asked Bell to arrange for the sale of all the family property, conclude all of his brother's affairs (Bell took over his last student, curing a pronounced lisp), and join his father and mother in setting out for the "New World". Reluctantly, Bell also had to conclude a relationship with Marie Eccleston, who, he had surmised, was not prepared to leave England with him.
Canada.
In 1870, at age 23, Bell, his brother's widow, Caroline (Margaret Ottaway), and his parents travelled on the SS "Nestorian" to Canada. After landing at Quebec City the Bells transferred to another steamer to Montreal and then boarded a train to Paris, Ontario, to stay with the Reverend Thomas Henderson, a family friend. After a brief stay with the Hendersons, the Bell family purchased a farm of at Tutelo Heights (now called Tutela Heights), near Brantford, Ontario. The property consisted of an orchard, large farm house, stable, pigsty, hen-house and a carriage house, which bordered the Grand River.
At the homestead, Bell set up his own workshop in the converted carriage house near to what he called his "dreaming place", a large hollow nestled in trees at the back of the property above the river. Despite his frail condition upon arriving in Canada, Bell found the climate and environs to his liking, and rapidly improved. He continued his interest in the study of the human voice and when he discovered the Six Nations Reserve across the river at Onondaga, he learned the Mohawk language and translated its unwritten vocabulary into Visible Speech symbols. For his work, Bell was awarded the title of Honorary Chief and participated in a ceremony where he donned a Mohawk headdress and danced traditional dances.
After setting up his workshop, Bell continued experiments based on Helmholtz's work with electricity and sound. He also modified a melodeon (a type of pump organ) so that it could transmit its music electrically over a distance. Once the family was settled in, both Bell and his father made plans to establish a teaching practice and in 1871, he accompanied his father to Montreal, where Melville was offered a position to teach his System of Visible Speech.
Work with the deaf.
Bell's father was invited by Sarah Fuller, principal of the Boston School for Deaf Mutes (which continues today as the public Horace Mann School for the Deaf), in Boston, Massachusetts, to introduce the Visible Speech System by providing training for Fuller's instructors, but he declined the post, in favor of his son. Traveling to Boston in April 1871, Bell proved successful in training the school's instructors. He was subsequently asked to repeat the program at the American Asylum for Deaf-mutes in Hartford, Connecticut, and the Clarke School for the Deaf in Northampton, Massachusetts.
Returning home to Brantford after six months abroad, Bell continued his experiments with his "harmonic telegraph". The basic concept behind his device was that messages could be sent through a single wire if each message was transmitted at a different pitch, but work on both the transmitter and receiver was needed. Unsure of his future, he first contemplated returning to London to complete his studies, but decided to return to Boston as a teacher. His father helped him set up his private practice by contacting Gardiner Greene Hubbard, the president of the Clarke School for the Deaf for a recommendation. Teaching his father's system, in October 1872 Alexander Bell opened his "School of Vocal Physiology and Mechanics of Speech" in Boston, which attracted a large number of deaf pupils with his first class numbering 30 students. While he was working as a private tutor, one of his most famous pupils was Helen Keller, who came to him as a young child unable to see, hear, or speak. She was later to say that Bell dedicated his life to the penetration of that "inhuman silence which separates and estranges." In 1893 Keller performed the sod-breaking ceremony for the construction of the new Bell's new Volta Bureau, dedicated to "the increase and diffusion of knowledge relating to the deaf".
Several influential people of the time, including Bell, viewed deafness as something that ought to be eradicated, and also believed that with resources and effort they could teach the deaf to speak and avoid the use of sign language, thus enabling their integration within the wider society from which many were often being excluded. However in several schools children were mistreated, for example by having their hands tied behind their backs so they could not communicate by signing—the only language they knew—in order to force them to attempt oral communication. Due to his efforts to suppress the teaching of sign language, Bell is often viewed negatively by those embracing deaf culture.
Continuing experimentation.
In the following year, Bell became professor of Vocal Physiology and Elocution at the Boston University School of Oratory. During this period, he alternated between Boston and Brantford, spending summers in his Canadian home. At Boston University, Bell was "swept up" by the excitement engendered by the many scientists and inventors residing in the city. He continued his research in sound and endeavored to find a way to transmit musical notes and articulate speech, but although absorbed by his experiments, he found it difficult to devote enough time to experimentation. While days and evenings were occupied by his teaching and private classes, Bell began to stay awake late into the night, running experiment after experiment in rented facilities at his boarding house. Keeping up "night owl" hours, he worried that his work would be discovered and took great pains to lock up his notebooks and laboratory equipment. Bell had a specially made table where he could place his notes and equipment inside a locking cover. Worse still, his health deteriorated as he suffered severe headaches. Returning to Boston in fall 1873, Bell made a fateful decision to concentrate on his experiments in sound.
Deciding to give up his lucrative private Boston practice, Bell only retained two students, six-year old "Georgie" Sanders, deaf from birth and 15-year old Mabel Hubbard. Each pupil would serve to play an important role in the next developments. George's father, Thomas Sanders, a wealthy businessman, offered Bell a place to stay at nearby Salem with Georgie's grandmother, complete with a room to "experiment". Although the offer was made by George's mother and followed the year-long arrangement in 1872 where her son and his nurse had moved to quarters next to Bell's boarding house, it was clear that Mr. Sanders was backing the proposal. The arrangement was for teacher and student to continue their work together with free room and board thrown in. Mabel was a bright, attractive girl who was ten years his junior but became the object of Bell's affection. Losing her hearing after a near-fatal bout of scarlet fever close to her fifth birthday, she had learned to read lips but her father, Gardiner Greene Hubbard, Bell's benefactor and personal friend, wanted her to work directly with her teacher.
Telephone.
By 1874, Bell's initial work on the harmonic telegraph had entered a formative stage with progress it made both at his new Boston "laboratory" (a rented facility) as well as at his family home in Canada a big success.
While working that summer in Brantford, Bell experimented with a "phonautograph", a pen-like machine that could draw shapes of sound waves on smoked glass by tracing their vibrations. Bell thought it might be possible to generate undulating electrical currents that corresponded to sound waves. Bell also thought that multiple metal reeds tuned to different frequencies like a harp would be able to convert the undulating currents back into sound. But he had no working model to demonstrate the feasibility of these ideas.
In 1874, telegraph message traffic was rapidly expanding and in the words of Western Union President William Orton, had become "the nervous system of commerce". Orton had contracted with inventors Thomas Edison and Elisha Gray to find a way to send multiple telegraph messages on each telegraph line to avoid the great cost of constructing new lines. When Bell mentioned to Gardiner Hubbard and Thomas Sanders that he was working on a method of sending multiple tones on a telegraph wire using a multi-reed device, the two wealthy patrons began to financially support Bell's experiments. Patent matters would be handled by Hubbard's patent attorney, Anthony Pollok.
In March 1875, Bell and Pollok visited the famous scientist Joseph Henry, who was then director of the Smithsonian Institution, and asked Henry's advice on the electrical multi-reed apparatus that Bell hoped would transmit the human voice by telegraph. Henry replied that Bell had "the germ of a great invention". When Bell said that he did not have the necessary knowledge, Henry replied, "Get it!" That declaration greatly encouraged Bell to keep trying, even though he did not have the equipment needed to continue his experiments, nor the ability to create a working model of his ideas. However, a chance meeting in 1874 between Bell and Thomas A. Watson, an experienced electrical designer and mechanic at the electrical machine shop of Charles Williams, changed all that.
With financial support from Sanders and Hubbard, Bell hired Thomas Watson as his assistant, and the two of them experimented with acoustic telegraphy. On June 2, 1875, Watson accidentally plucked one of the reeds and Bell, at the receiving end of the wire, heard the overtones of the reed; overtones that would be necessary for transmitting speech. That demonstrated to Bell that only one reed or armature was necessary, not multiple reeds. This led to the "gallows" sound-powered telephone, which could transmit indistinct, voice-like sounds, but not clear speech.
The race to the patent office.
In 1875, Bell developed an acoustic telegraph and drew up a patent application for it. Since he had agreed to share U.S. profits with his investors Gardiner Hubbard and Thomas Sanders, Bell requested that an associate in Ontario, George Brown, attempt to patent it in Britain, instructing his lawyers to apply for a patent in the U.S. only after they received word from Britain (Britain would issue patents only for discoveries not previously patented elsewhere).
Meanwhile, Elisha Gray was also experimenting with acoustic telegraphy and thought of a way to transmit speech using a water transmitter. On February 14, 1876, Gray filed a caveat with the U.S. Patent Office for a telephone design that used a water transmitter. That same morning, Bell's lawyer filed Bell's application with the patent office. There is considerable debate about who arrived first and Gray later challenged the primacy of Bell's patent. Bell was in Boston on February 14 and did not arrive in Washington until February 26.
Bell's patent 174,465, was issued to Bell on March 7, 1876, by the U.S. Patent Office. Bell's patent covered "the method of, and apparatus for, transmitting vocal or other sounds telegraphically ... by causing electrical undulations, similar in form to the vibrations of the air accompanying the said vocal or other sound" Bell returned to Boston the same day and the next day resumed work, drawing in his notebook a diagram similar to that in Gray's patent caveat.
On March 10, 1876, three days after his patent was issued, Bell succeeded in getting his telephone to work, using a liquid transmitter similar to Gray's design. Vibration of the diaphragm caused a needle to vibrate in the water, varying the electrical resistance in the circuit. When Bell spoke the famous sentence "Mr. Watson—Come here—I want to see you" into the liquid transmitter, Watson, listening at the receiving end in an adjoining room, heard the words clearly.
Although Bell was, and still is, accused of stealing the telephone from Gray, Bell used Gray's water transmitter design only after Bell's patent was granted and only as a proof of concept scientific experiment to prove to his own satisfaction that intelligible "articulate speech" (Bell's words) could be electrically transmitted. After March 1876, Bell focused on improving the electromagnetic telephone and never used Gray's liquid transmitter in public demonstrations or commercial use.
The question of priority for the variable resistance feature of the telephone was raised by the Examiner before he approved Bell's patent application. He told Bell that his claim for the variable resistance feature was also described in Gray's caveat. Bell pointed to a variable resistance device in Bell's previous application in which Bell described a cup of mercury, not water. Bell had filed the mercury application at the patent office a year earlier on February 25, 1875, long before Elisha Gray described the water device. In addition, Gray abandoned his caveat, and because Gray did not contest Bell's priority, the Examiner approved Bell's patent on March 3, 1876. Gray had reinvented the variable resistance telephone, but Bell was the first to write down the idea and the first to test it in a telephone.
The patent examiner, Zenas Fisk Wilber, later stated in an affidavit that he was an alcoholic who was much in debt to Bell's lawyer, Marcellus Bailey, with whom he had served in the Civil War. He claimed he showed Gray's patent caveat to Bailey. Wilber also claimed (after Bell arrived in Washington D.C. from Boston) that he showed Gray's caveat to Bell and that Bell paid him $100. Bell claimed they discussed the patent only in general terms, although in a letter to Gray, Bell admitted that he learned some of the technical details. Bell denied in an affidavit that he ever gave Wilber any money.
Later developments.
Continuing his experiments in Brantford, Bell brought home a working model of his telephone. On August 3, 1876, from the telegraph office in Mount Pleasant five miles (8 km) away from Brantford, Bell sent a tentative telegram indicating that he was ready. With curious onlookers packed into the office as witnesses, faint voices were heard replying. The following night, he amazed guests as well as his family when a message was received at the Bell home from Brantford, four miles (six km) distant along an improvised wire strung up along telegraph lines and fences, and laid through a tunnel. This time, guests at the household distinctly heard people in Brantford reading and singing. These experiments clearly proved that the telephone could work over long distances.
Bell and his partners, Hubbard and Sanders, offered to sell the patent outright to Western Union for $100,000. The president of Western Union balked, countering that the telephone was nothing but a toy. Two years later, he told colleagues that if he could get the patent for $25 million he would consider it a bargain. By then, the Bell company no longer wanted to sell the patent. Bell's investors would become millionaires while he fared well from residuals and at one point had assets of nearly one million dollars.
Bell began a series of public demonstrations and lectures to introduce the new invention to the scientific community as well as the general public. A short time later, his demonstration of an early telephone prototype at the 1876 Centennial Exposition in Philadelphia brought the telephone to international attention. Influential visitors to the exhibition included Emperor Pedro II of Brazil. Later Bell had the opportunity to demonstrate the invention personally to Sir William Thomson (later, Lord Kelvin), a renowned Scottish scientist, as well as to Queen Victoria who had requested a private audience at Osborne House, her Isle of Wight home. She called the demonstration "most extraordinary". The enthusiasm surrounding Bell's public displays laid the groundwork for universal acceptance of the revolutionary device.
The Bell Telephone Company was created in 1877, and by 1886, more than 150,000 people in the U.S. owned telephones. Bell company engineers made numerous other improvements to the telephone, which emerged as one of the most successful products ever. In 1879, the Bell company acquired Edison's patents for the carbon microphone from Western Union. This made the telephone practical for longer distances and it was no longer necessary to shout to be heard at the receiving telephone.
In January 1915, Bell made the first ceremonial transcontinental telephone call. Calling from the AT&T head office at 15 Dey Street in New York City, Bell was heard by Thomas Watson at 333 Grant Avenue in San Francisco. The "New York Times" reported:
Competitors.
As is sometimes common in scientific discoveries, simultaneous developments can occur, as evidenced by a number of inventors who were at work on the telephone. Over a period of 18 years, the Bell Telephone Company faced 587 court challenges to its patents, including five that went to the U.S. Supreme Court, but none was successful in establishing priority over the original Bell patent and the Bell Telephone Company never lost a case that had proceeded to a final trial stage. Bell's laboratory notes and family letters were the key to establishing a long lineage to his experiments. The Bell company lawyers successfully fought off myriad lawsuits generated initially around the challenges by Elisha Gray and Amos Dolbear. In personal correspondence to Bell, both Gray and Dolbear had acknowledged his prior work, which considerably weakened their later claims.
On January 13, 1887, the U,S. Government moved to annul the patent issued to Bell on the grounds of fraud and misrepresentation. After a series of decisions and reversals, the Bell company won a decision in the Supreme Court, though a couple of the original claims from the lower court cases were left undecided. By the time that the trial wound its way through nine years of legal battles, the U.S. prosecuting attorney had died and the two Bell patents (No. 174,465 and dated March 7, 1876 and No. 186,787 dated January 30, 1877) were no longer in effect, although the presiding judges agreed to continue the proceedings due to the case's importance as a "precedent". With a change in administration and charges of conflict of interest (on both sides) arising from the original trial, the US Attorney General dropped the lawsuit on November 30, 1897 leaving several issues undecided on the merits.
During a deposition filed for the 1887 trial, Italian inventor Antonio Meucci also claimed to have created the first working model of a telephone in Italy in 1834. In 1886, in the first of three cases in which he was involved, Meucci took the stand as a witness in the hopes of establishing his invention's priority. Meucci's evidence in this case was disputed due to a lack of material evidence for his inventions as his working models were purportedly lost at the laboratory of American District Telegraph (ADT) of New York, which was later incorporated as a subsidiary of Western Union in 1901. Meucci's work, like many other inventors of the period, was based on earlier acoustic principles and despite evidence of earlier experiments, the final case involving Meucci was eventually dropped upon Meucci's death. However, due to the efforts of Congressman Vito Fossella, the U.S. House of Representatives on June 11, 2002 stated that Meucci's "work in the invention of the telephone should be acknowledged", even though this did not put an end to a still contentious issue. Some modern scholars do not agree with the claims that Bell's work on the telephone was influenced by Meucci's inventions. 
The value of the Bell patent was acknowledged throughout the world, and patent applications were made in most major countries, but when Bell had delayed the German patent application, the electrical firm of Siemens & Halske (S&H) managed to set up a rival manufacturer of Bell telephones under their own patent. The Siemens company produced near-identical copies of the Bell telephone without having to pay royalties. The establishment of the International Bell Telephone Company in Brussels, Belgium in 1880, as well as a series of agreements in other countries eventually consolidated a global telephone operation. The strain put on Bell by his constant appearances in court, necessitated by the legal battles, eventually resulted in his resignation from the company.
Family life.
On July 11, 1877, a few days after the Bell Telephone Company was established, Bell married Mabel Hubbard (1857–1923) at the Hubbard estate in Cambridge, Massachusetts. His wedding present to his bride was to turn over 1,487 of his 1,497 shares in the newly formed Bell Telephone Company. Shortly thereafter, the newlyweds embarked on a year-long honeymoon in Europe. During that excursion, Alec took a handmade model of his telephone with him, making it a "working holiday". The courtship had begun years earlier; however, Alexander waited until he was more financially secure before marrying. Although the telephone appeared to be an "instant" success, it was not initially a profitable venture and Bell's main sources of income were from lectures until after 1897. One unusual request exacted by his fiancée was that he use "Alec" rather than the family's earlier familiar name of "Aleck". From 1876, he would sign his name "Alec Bell". They had four children: Elsie May Bell (1878–1964) who married Gilbert Grosvenor of National Geographic fame, Marian Hubbard Bell (1880–1962) who was referred to as "Daisy", and two sons who died in infancy (Edward in 1881 and Robert in 1883). The Bell family home was in Cambridge, Massachusetts, until 1880 when Bell's father-in-law bought a house in Washington, D.C., and later in 1882 bought a home in the same city for Bell's family, so that they could be with him while he attended to the numerous court cases involving patent disputes.
Bell was a British subject throughout his early life in Scotland and later in Canada until 1882, when he became a naturalized citizen of the United States. In 1915, he characterized his status as: "I am not one of those hyphenated Americans who claim allegiance to two countries." Despite this declaration, Bell has been proudly claimed as a "native son" by all three countries he resided in: the United States, Canada and the United Kingdom.
By 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened "The Lodge" was completed and two years later, a larger complex of buildings, including a new laboratory, were begun that the Bells would name Beinn Bhreagh (Gaelic: "beautiful mountain") after Alec's ancestral Scottish highlands. Bell also built the Bell Boatyard on the estate, employing up to 40 people building experimental craft as well as wartime lifeboats and workboats for the Royal Canadian Navy and pleasure craft for the Bell family. An enthusiastic boater, Bell and his family sailed a rowed a long series of vessels on Bras d'Or Lake, ordering additional vessels from the H.W. Embree and Sons boatyard in Port Hawkesbury, Nova Scotia. In his final, and some of his most productive years, Bell split his residency between Washington, D.C., where he and his family initially resided for most of the year, and at Beinn Bhreagh where they spent increasing amounts of time.
Until the end of his life, Bell and his family would alternate between the two homes, but "Beinn Bhreagh" would, over the next 30 years, become more than a summer home as Bell became so absorbed in his experiments that his annual stays lengthened. Both Mabel and Alec became immersed in the Baddeck community and were accepted by the villagers as "their own". The Bells were still in residence at "Beinn Bhreagh" when the Halifax Explosion occurred on December 6, 1917. Mabel and Alec mobilized the community to help victims in Halifax.
Later inventions.
Although Alexander Graham Bell is most often associated with the invention of the telephone, his interests were extremely varied. According to one of his biographers, Charlotte Gray, Bell's work ranged ""unfettered across the scientific landscape"" and he often went to bed voraciously reading the "Encyclopædia Britannica", scouring it for new areas of interest. The range of Bell's inventive genius is represented only in part by the 18 patents granted in his name alone and the 12 he shared with his collaborators. These included 14 for the telephone and telegraph, four for the photophone, one for the phonograph, five for aerial vehicles, four for "hydroairplanes" and two for selenium cells. Bell's inventions spanned a wide range of interests and included a metal jacket to assist in breathing, the audiometer to detect minor hearing problems, a device to locate icebergs, investigations on how to separate salt from seawater, and work on finding alternative fuels.
Bell worked extensively in medical research and invented techniques for teaching speech to the deaf. During his Volta Laboratory period, Bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. Although the trio briefly experimented with the concept, they could not develop a workable prototype. They abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive and other magnetic media.
Bell's own home used a primitive form of air conditioning, in which fans blew currents of air across great blocks of ice. He also anticipated modern concerns with fuel shortages and industrial pollution. Methane gas, he reasoned, could be produced from the waste of farms and factories. At his Canadian estate in Nova Scotia, he experimented with composting toilets and devices to capture water from the atmosphere. In a magazine interview published shortly before his death, he reflected on the possibility of using solar panels to heat houses.
Photophone.
Bell and his assistant Charles Sumner Tainter jointly invented a wireless telephone, named a photophone, which allowed for the transmission of both sounds and normal human conversations on a beam of light. Both men later became full associates in the Volta Laboratory Association.
On June 21, 1880, Bell's assistant transmitted a wireless voice telephone message a considerable distance, from the roof of the Franklin School in Washington, D.C., to Bell at the window of his laboratory, some away, 19 years before the first voice radio transmissions.
Bell believed the photophone's principles were his life's "greatest achievement", telling a reporter shortly before his death that the photophone was "the greatest invention have ever made, greater than the telephone". The photophone was a precursor to the fiber-optic communication systems which achieved popular worldwide usage in the 1980s. Its master patent was issued in December 1880, many decades before the photophone's principles came into popular use.
Metal detector.
Bell is also credited with the invention of the metal detector in 1881. The device was quickly put together in an attempt to find the bullet in the body of U.S. President James Garfield. According to some accounts, the metal detector worked flawlessly in tests but did not find the assassin's bullet partly because the metal bed frame on which the President was lying disturbed the instrument, resulting in static. The president's surgeons, who were skeptical of the device, ignored Bell's requests to move the president to a bed not fitted with metal springs. Alternatively, although Bell had detected a slight sound on his first test, the bullet may have been lodged too deeply to be detected by the crude apparatus.
Bell's own detailed account, presented to the American Association for the Advancement of Science in 1882, differs in several particulars from most of the many and varied versions now in circulation, most notably by concluding that extraneous metal was not to blame for failure to locate the bullet. Perplexed by the peculiar results he had obtained during an examination of Garfield, Bell "...proceeded to the Executive Mansion the next morning...to ascertain from the surgeons whether they were perfectly sure that all metal had been removed from the neighborhood of the bed. It was then recollected that underneath the horse-hair mattress on which the President lay was another mattress composed of steel wires. Upon obtaining a duplicate, the mattress was found to consist of a sort of net of woven steel wires, with large meshes. The extent of the that produced a response from the detector having been so small, as compared with the area of the bed, it seemed reasonable to conclude that the steel mattress had produced no detrimental effect." In a footnote, Bell adds that "The death of President Garfield and the subsequent "post-mortem" examination, however, proved that the bullet was at too great a distance from the surface to have affected our apparatus."
Hydrofoils.
The March 1906 "Scientific American" article by American pioneer William E. Meacham explained the basic principle of hydrofoils and hydroplanes. Bell considered the invention of the hydroplane as a very significant achievement. Based on information gained from that article he began to sketch concepts of what is now called a hydrofoil boat. Bell and assistant Frederick W. "Casey" Baldwin began hydrofoil experimentation in the summer of 1908 as a possible aid to airplane takeoff from water. Baldwin studied the work of the Italian inventor Enrico Forlanini and began testing models. This led him and Bell to the development of practical hydrofoil watercraft.
During his world tour of 1910–11, Bell and Baldwin met with Forlanini in France. They had rides in the Forlanini hydrofoil boat over Lake Maggiore. Baldwin described it as being as smooth as flying. On returning to Baddeck, a number of initial concepts were built as experimental models, including the "Dhonnas Beag", the first self-propelled Bell-Baldwin hydrofoil. The experimental boats were essentially proof-of-concept prototypes that culminated in the more substantial HD-4, powered by Renault engines. A top speed of was achieved, with the hydrofoil exhibiting rapid acceleration, good stability and steering along with the ability to take waves without difficulty. In 1913, Dr. Bell hired Walter Pinaud, a Sydney yacht designer and builder as well as the proprietor of Pinaud's Yacht Yard in Westmount, Nova Scotia to work on the pontoons of the HD-4. Pinaud soon took over the boatyard at Bell Laboratories on Beinn Bhreagh, Bell's estate near Baddeck, Nova Scotia. Pinaud's experience in boat-building enabled him to make useful design changes to the HD-4. After the First World War, work began again on the HD-4. Bell's report to the U.S. Navy permitted him to obtain two engines in July 1919. On September 9, 1919, the HD-4 set a world marine speed record of , a record which stood for ten years.
Aeronautics.
In 1891, Bell had begun experiments to develop motor-powered heavier-than-air aircraft. The AEA was first formed as Bell shared the vision to fly with his wife, who advised him to seek "young" help as Alexander was at the graceful age of 60.
In 1898, Bell experimented with tetrahedral box kites and wings constructed of multiple compound tetrahedral kites covered in maroon silk. The tetrahedral wings were named "Cygnet" I, II and III, and were flown both unmanned and manned ("Cygnet I" crashed during a flight carrying Selfridge) in the period from 1907–1912. Some of Bell's kites are on display at the Alexander Graham Bell National Historic Site.
Bell was a supporter of aerospace engineering research through the Aerial Experiment Association (AEA), officially formed at Baddeck, Nova Scotia, in October 1907 at the suggestion of his wife Mabel and with her financial support after the sale of some of her real estate. The AEA was headed by Bell and the founding members were four young men: American Glenn H. Curtiss, a motorcycle manufacturer at the time and who held the title "world's fastest man", having ridden his self-constructed motor bicycle around in the shortest time, and who was later awarded the Scientific American Trophy for the first official one-kilometre flight in the Western hemisphere, and who later became a world-renowned airplane manufacturer; Lieutenant Thomas Selfridge, an official observer from the U.S. Federal government and the only person in the army who believed aviation was the future; Frederick W. Baldwin, the first Canadian and first British subject to pilot a public flight in Hammondsport, New York, and J.A.D. McCurdy —Baldwin and McCurdy being new engineering graduates from the University of Toronto.
The AEA's work progressed to heavier-than-air machines, applying their knowledge of kites to gliders. Moving to Hammondsport, the group then designed and built the "Red Wing", framed in bamboo and covered in red silk and powered by a small air-cooled engine. On March 12, 1908, over Keuka Lake, the biplane lifted off on the first public flight in North America. The innovations that were incorporated into this design included a cockpit enclosure and tail rudder (later variations on the original design would add ailerons as a means of control). One of the AEA's inventions, a practical wingtip form of the aileron, was to become a standard component on all aircraft. The "White Wing" and "June Bug" were to follow and by the end of 1908, over 150 flights without mishap had been accomplished. However, the AEA had depleted its initial reserves and only a $15,000 grant from Mrs. Bell allowed it to continue with experiments.
Their final aircraft design, the "Silver Dart" embodied all of the advancements found in the earlier machines. On February 23, 1909, Bell was present as the "Silver Dart" flown by J.A.D. McCurdy from the frozen ice of Bras d'Or, made the first aircraft flight in Canada. Bell had worried that the flight was too dangerous and had arranged for a doctor to be on hand. With the successful flight, the AEA disbanded and the "Silver Dart" would revert to Baldwin and McCurdy who began the Canadian Aerodrome Company and would later demonstrate the aircraft to the Canadian Army.
Eugenics.
Bell was connected with the eugenics movement in the United States. In his lecture "Memoir upon the formation of a deaf variety of the human race" presented to the National Academy of Sciences on November 13, 1883 he noted that congenitally deaf parents were more likely to produce deaf children and tentatively suggested that couples where both parties were deaf should not marry. However, it was his hobby of livestock breeding which led to his appointment to biologist David Starr Jordan's Committee on Eugenics, under the auspices of the American Breeders Association. The committee unequivocally extended the principle to man. From 1912 until 1918 he was the chairman of the board of scientific advisers to the Eugenics Record Office associated with Cold Spring Harbor Laboratory in New York, and regularly attended meetings. In 1921, he was the honorary president of the Second International Congress of Eugenics held under the auspices of the American Museum of Natural History in New York. Organisations such as these advocated passing laws (with success in some states) that established the compulsory sterilization of people deemed to be, as Bell called them, a "defective variety of the human race". By the late 1930s, about half the states in the U.S. had eugenics laws, and California's compulsory sterilization law was used as a model for that of Nazi Germany.
Legacy and honors.
Honors and tributes flowed to Bell in increasing numbers as his most famous invention became ubiquitous and his personal fame grew. Bell received numerous honorary degrees from colleges and universities, to the point that the requests almost became burdensome. During his life he also received dozens of major awards, medals and other tributes. These included statuary monuments to both him and the new form of communication his telephone created, notably the Bell Telephone Memorial erected in his honor in "Alexander Graham Bell Gardens" in Brantford, Ontario, in 1917.
A large number of Bell's writings, personal correspondence, notebooks, papers and other documents reside at both the United States Library of Congress Manuscript Division (as the "Alexander Graham Bell Family Papers"), and at the Alexander Graham Bell Institute, Cape Breton University, Nova Scotia; major portions of which are available for online viewing.
A number of historic sites and other marks commemorate Bell in North America and Europe, including the first telephone companies of the United States and Canada. Among the major sites are:
In 1880, Bell received the Volta Prize with a purse of 50,000 francs (approximately US$ in today's dollars) for the invention of the telephone from the Académie française, representing the French government. Among the luminaries who judged were Victor Hugo and Alexandre Dumas. The Volta Prize was conceived by Napoleon Bonaparte in 1801, and named in honor of Alessandro Volta, with Bell receiving the third grand prize in its history. Since Bell was becoming increasingly affluent, he used his prize money to create endowment funds (the 'Volta Fund') and institutions in and around the United States capital of Washington, D.C.. These included the prestigious" 'Volta Laboratory Association' "(1880), also known as the" Volta Laboratory "and as the" 'Alexander Graham Bell Laboratory', "and which eventually led to the Volta Bureau (1887) as a center for studies on deafness which is still in operation in Georgetown, Washington, D.C. The Volta Laboratory became an experimental facility devoted to scientific discovery, and the very next year it improved Edison's phonograph by substituting wax for tinfoil as the recording medium and incising the recording rather than indenting it, key upgrades that Edison himself later adopted. The laboratory was also the site where he and his associate invented his "proudest achievement", "the photophone", the "optical telephone" which presaged fibre optical telecommunications, while the Volta Bureau would later evolve into the Alexander Graham Bell Association for the Deaf and Hard of Hearing (the AG Bell), a leading center for the research and pedagogy of deafness.
In partnership with Gardiner Hubbard, Bell helped establish the publication Science during the early 1880s. In 1888, Bell was one of the founding members of the National Geographic Society and became its second president (1897–1904), and also became a Regent of the Smithsonian Institution (1898–1922). The French government conferred on him the decoration of the Légion d'honneur (Legion of Honor); the Royal Society of Arts in London awarded him the Albert Medal in 1902; the University of Würzburg, Bavaria, granted him a PhD, and he was awarded the Franklin Institute's Elliott Cresson Medal in 1912. He was one of the founders of the American Institute of Electrical Engineers in 1884, and served as its president from 1891–92. Bell was later awarded the AIEE's Edison Medal in 1914 "For meritorious achievement in the invention of the telephone".
The "bel" (B) and the smaller "decibel" (dB) are units of measurement of sound intensity invented by Bell Labs and named after him. Since 1976 the IEEE's Alexander Graham Bell Medal has been awarded to honor outstanding contributions in the field of telecommunications.
In 1936 the US Patent Office declared Bell first on its list of the country's greatest inventors, leading to the US Post Office issuing a commemorative stamp honoring Bell in 1940 as part of its 'Famous Americans Series'. The First Day of Issue ceremony was held on October 28 in Boston, Massachusetts, the city where Bell spent considerable time on research and working with the deaf. The Bell stamp became very popular and sold out in little time. The stamp became, and remains to this day, the most valuable one of the series.
The 150th anniversary of Bell's birth in 1997 was marked by a special issue of commemorative £1 banknotes from the Royal Bank of Scotland. The illustrations on the reverse of the note include Bell's face in profile, his signature, and objects from Bell's life and career: users of the telephone over the ages; an audio wave signal; a diagram of a telephone receiver; geometric shapes from engineering structures; representations of sign language and the phonetic alphabet; the geese which helped him to understand flight; and the sheep which he studied to understand genetics. Additionally, the Government of Canada honored Bell in 1997 with a C$100 gold coin, in tribute also to the 150th anniversary of his birth, and with a silver dollar coin in 2009 to honor of the 100th anniversary of flight in Canada. That first flight was made by an airplane designed under Dr. Bell's tutelage, named the Silver Dart. Bell's image, and also those of his many inventions have graced paper money, coinage and postal stamps in numerous countries worldwide for many dozens of years.
Alexander Graham Bell was ranked 57th among the 100 Greatest Britons (2002) in an official BBC nationwide poll, and among the Top Ten Greatest Canadians (2004), and the 100 Greatest Americans (2005). In 2006 Bell was also named as one of the 10 greatest Scottish scientists in history after having been listed in the National Library of Scotland's 'Scottish Science Hall of Fame'. Bell's name is still widely known and used as part of the names of dozens of educational institutes, corporate namesakes, street and place names around the world.
Honorary degrees.
Alexander Graham Bell, who could not complete the university program of his youth, received numerous Honorary Degrees from academic institutions, including:
Death.
Bell died of complications arising from diabetes on August 2, 1922, at his private estate, Beinn Bhreagh, Nova Scotia, at age 75. Bell had also been afflicted with pernicious anemia. His last view of the land he had inhabited was by moonlight on his mountain estate at 2:00 A.M. While tending to him after his long illness, Mabel, his wife, whispered, "Don't leave me." By way of reply, Bell traced the sign for "no" in the air —and then he died.
On learning of Bell's death, the Canadian Prime Minister, Mackenzie King, cabled Mrs. Bell, saying:
"Government expresses to you our sense of the world's loss in the death of your distinguished husband. It will ever be a source of pride to our country that the great invention, with which his name is immortally associated, is a part of its history. On the behalf of the citizens of Canada, may I extend to you an expression of our combined gratitude and sympathy.
Bell's coffin was constructed of Beinn Bhreagh pine by his laboratory staff, lined with the same red silk fabric used in his tetrahedral kite experiments. To help celebrate his life, his wife asked guests not to wear black (the traditional funeral color) while attending his service, during which soloist Jean MacDonald sang a verse of Robert Louis Stevenson's "Requiem":
"Under a wide and starry sky,<br>
"Dig the grave and let me lie.<br>
"Glad did I live and gladly die<br>
"And I lay me down with a will.
Upon the conclusion of Bell's funeral, ""every phone on the continent of North America was silenced in honor of the man who had given to mankind the means for direct communication at a distance"".
Dr. Alexander Graham Bell was buried atop Beinn Bhreagh mountain, on his estate where he had resided increasingly for the last 35 years of his life, overlooking Bras d'Or Lake. He was survived by his wife Mabel, his two daughters, Elsie May and Marian, and nine of his grandchildren.
External links.
Patents.
"U.S. patent images in TIFF format"

</doc>
<doc id="854" url="http://en.wikipedia.org/wiki?curid=854" title="Anatolia">
Anatolia

Anatolia (from Greek , ' — "east" or "(sun)rise"; in modern ), in geography known as Asia Minor (from ' — "small Asia"), Asian Turkey, Anatolian peninsula, or Anatolian plateau, denotes the westernmost protrusion of Asia, which makes up the majority of the Republic of Turkey. The region is bounded by the Black Sea to the north, the Mediterranean Sea to the south, and the Aegean Sea to the west. The Sea of Marmara forms a connection between the Black and Aegean Seas through the Bosphorus and Dardanelles straits and separates Anatolia from Thrace on the European mainland. Traditionally, Anatolia is considered to extend in the east to a line between the Gulf of İskenderun and the Black Sea, approximately corresponding to the western two-thirds of the Asian part of Turkey. However, since Anatolia is now often considered to be synonymous with Asian Turkey, its eastern and southeastern borders are widely taken to be the Turkish borders with the neighboring countries, which are Georgia, Armenia, Azerbaijan, Iran, Iraq, and Syria, in clockwise direction.
Definition.
The Anatolian peninsula, also called Asia Minor, is bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Aegean Sea to the west, and the Sea of Marmara to the northwest, which separates Anatolia from Thrace in Europe.
Traditionally, Anatolia is considered to extend in the east to an indefinite line running from the Gulf of İskenderun to the Black Sea, coterminous with the Anatolian Plateau. This traditional geographical definition is used, for example, in the latest edition of "Merriam-Webster's Geographical Dictionary", as well as the archeological community. Under this definition, Anatolia is bounded to the East by the Armenian Highland, and the Euphrates before that river bends to the southeast to enter Mesopotamia. To the southeast, it is bounded by the ranges that separate it from the Orontes valley in Syria (region) and the Mesopotamian plain.
However, following the establishment of the Republic of Turkey, Anatolia was defined by the Turkish government as being effectively co-terminous with Asian Turkey. Turkey's First Geography Congress in 1941 created two regions to the east of the Gulf of Iskenderun-Black Sea line named the Eastern Anatolia Region and the Southeastern Anatolia Region, the former largely corresponding to the western part of the Armenian Highland, the latter to the northern part of the Mesopotamian plain. This wider definition of Anatolia has gained widespread currency outside of Turkey and has, for instance, been adopted by "Encyclopædia Britannica" and other encyclopedic and general reference publications.
Etymology.
The oldest known reference to Anatolia – as “Land of the Hatti” – was found on Mesopotamian cuneiform tablets from the period of the Akkadian Empire (2350–2150 BC). The first name the Greeks used for the Anatolian peninsula was Ἀσία (Asía), presumably after the name of the Assuwa league in western Anatolia. As the name of Asia came to be extended to other areas east of the Mediterranean, the name for Anatolia was specified as Μικρὰ Ἀσία ("Mikrá Asía") or Asia Minor, meaning “Lesser Asia”, in Late Antiquity.
The name "Anatolia" derives from the Greek ("") meaning “the East” or more literally “sunrise”, comparable to the Latin derived terms “levant” and “orient”. The precise reference of this term has varied over time, perhaps originally referring to the Aeolian, Ionian and Dorian colonies on the west coast of Asia Minor. In the Byzantine Empire, the Anatolic Theme (Aνατολικόν θέμα) was a "theme" covering the western and central parts of Turkey’s present-day Central Anatolia Region. The modern Turkish form of Anatolia is "Anadolu", which again derives from the Greek name Aνατολή ("Anatolḗ"). The Russian male name Anatoly and the French Anatole share the same linguistic origin.
In English the name of "Turkey" for ancient Anatolia first appeared c. 1369. It is derived from the Medieval Latin "Turchia" (meaning “Land of the Turks”, Turkish "Türkiye"), which was originally used by the Europeans to define the Seljuk controlled parts of Anatolia after the Battle of Manzikert.
History.
Prehistory and antiquity.
Human habitation in Anatolia dates back to the Paleolithic. Neolithic Anatolia has been also proposed as the homeland of the Indo-European language family, although linguists tend to favour a later origin in the steppes north of the Black Sea. However, it is clear that the Indo-European Anatolian languages had been present in Anatolia since at least the 19th century BC.
Eastern Anatolia contains the oldest monumental structures in the world. For example, the monumental structures at Göbekli Tepe were built by hunters and gatherers a thousand years before the development of agriculture. Eastern Anatolia, alongside Mesopotamia and the Levant, is a heart region for the Neolithic Revolution, one of the earliest areas in which humans domesticated plants and animals. Neolithic sites such as Çatalhöyük, Çayönü, Nevalı Çori and Hacilar represent the world's oldest known agricultural towns.
The earliest historical records of Anatolia stem from the southeast of the region and are from the Mesopotamia-based Akkadian Empire during the reign of Sargon of Akkad in the 24th century BC. Scholars generally believe the earliest indigenous populations of Anatolia were the Hattians and Hurrians. The Hattians spoke a language of unclear affiliation, and the Hurrian language belongs to a small family called Hurro-Urartian, all these languages now being extinct; relationships with indigenous languages of the Caucasus have been proposed but are not generally accepted. The region was famous for exporting raw materials, and areas of Hattian- and Hurrian-populated southeast Anatolia were colonised by the Akkadians.
After the fall of the Akkadian empire in the mid-21st century BC, the Assyrians, who were the northern branch of the Akkadian people, colonised parts of the region between the 21st and mid-18th centuries BC and claimed the resources, notably silver. One of the numerous cuneiform records dated circa 20th century BC, found in Anatolia at the Assyrian colony of Kanesh, uses an advanced system of trading computations and credit lines.
Unlike the Semitic Akkadians and their descendants, the Assyrians, whose Anatolian possessions were peripheral to their core lands in Mesopotamia, the Hittites were centred at Hattusa in north-central Anatolia by 2000 BC. They were speakers of an Indo-European language known as the "language of Nesa". Originating from Nesa, they conquered Hattusa in the 18th century BC, imposing themselves over Hattian- and Hurrian-speaking populations.
The Hittites adopted the cuneiform written script, invented in Mesopotamia. During the Late Bronze Age circa 2000 BC, they created an empire, the Hittite New Kingdom, which reached its height in the 14th century BC, controlling much of Asia Minor. The empire included a large part of Anatolia, northwestern Syria and northwest upper Mesopotamia. They failed to reach the Anatolian coasts of the Black Sea, however, as another non-Indo-European people, the Kaskians, had established a kingdom there in the 17th century BC, displacing earlier Palaic speaking Indo-Europeans. Much of the history of the Hittite Empire was concerned with warring with the rival empires of Egypt, Assyria and the Mitanni.
The Mitanni Empire was also an Indo-European (and Hurrian)-speaking and Anatolian-based empire. The Mitanni appeared in the 17th century BC and spoke an Indo-Aryan language related to the Indo-European languages eventually to be found in India.
The Egyptians eventually withdrew from the region after failing to gain the upper hand over the Hittites and becoming wary of the power of Assyria, which had destroyed the Mitanni Empire. The Assyrians and Hittites were then left in the field to battle over control over eastern and southern Anatolia and colonial territories in Syria. The Assyrians had better success than the Egyptians, annexing much Hittite (and Hurrian) territories in these regions.
After 1180 BC, the Hittite empire disintegrated into several independent "Neo-Hittite" states, subsequent to losing much territory to the Middle Assyrian Empire and being finally overrun by the Phrygians, another Indo-European people who are believed to have migrated from the Balkans. The Phrygian expansion into southeast Anatolia was eventually halted by the Assyrians, who controlled that region.
Ancient Anatolia is subdivided by modern scholars into regions named after the Indo-European (and largely Hittite, Luwian or Greek speaking) peoples that occupied them, such as Lydia, Lycia, Caria, Mysia, Bithynia, Phrygia, Galatia, Lycaonia, Pisidia, Paphlagonia, Cilicia, and Cappadocia.
Semitic Arameans encroached over the borders of south central Anatolia in the century or so after the fall of the Hittite empire, and some of the Neo-Hittite states in this region became an amalgam of Hittites and Arameans. These became known as Syro-Hittite states.
In central and western Anatolia, another Indo-European people, the Luwians, came to the fore, circa 2000 BC. Their language was closely related to Hittite. The general consensus amongst scholars is that Luwian was spoken—to a greater or lesser degree—across a large area of western Anatolia, including (possibly) Wilusa (Troy), the Seha River Land (to be identified with the Hermos and/or Kaikos valley), and the kingdom of Mira-Kuwaliya with its core territory of the Maeander valley. From the 9th century BC, Luwian regions coalesced into a number of states such as Lydia, Caria and Lycia, all of which had Hellenic influence.
The north western coasts of Anatolia were inhabited by Greeks of the Achaean/Mycenaean culture from the 20th century BC, related to the Greeks of south eastern Europe and the Aegean.
Beginning with the Bronze Age collapse at the end of the 2nd millennium BC, the west coast of Anatolia was settled by Ionian Greeks, usurping the area of the related but earlier Mycenaean Greeks. Over several centuries, numerous Ancient Greek city-states were established on the coasts of Anatolia. Greeks started Western philosophy on the western coast of Anatolia (Pre-Socratic philosophy).
Hurrian kingdoms, such as Nairi and the powerful state of Urartu arose in northeastern Anatolia from the 10th century BC, before eventually falling to the Assyrians. During the same period the Georgian states of Colchis and Tabal arose around the Black Sea and central Anatolia respectively.
From the late 8th century BC, a new wave of Indo-European-speaking raiders entered northern and northeast Anatolia: the Cimmerians and Scythians. The Cimmerians overran Phrygia and the Scythians threatened to do the same to Urartu and Lydia, before both were finally checked by the Assyrians.
From the 10th to late 7th centuries BC, much of Anatolia (particularly the east, central, southwestern and southeastern regions) fell to the Neo Assyrian Empire, including all of the Neo-Hittite and Syro-Hittite states, Phrygia, Urartu, Nairi, Tabal, Cilicia, Commagene, Caria, Lydia, the Cimmerians and Scythians and swathes of Cappadocia.
The Assyrian empire collapsed due to a bitter series of civil wars followed by a combined attack by Medes, Persians, Scythians and their own Babylonian relations. The last Assyrian city to fall was Harran in southeast Anatolia. This city was the birthplace of the last king of Babylon, the Assyrian Nabonidus and his son and regent Belshazzar. Much of the region then fell to the short-lived Iran-based Median Empire, with the Babylonians and Scythians briefly appropriating some territory.
Anatolia is known as the birthplace of minted coinage (as opposed to unminted coinage, which first appears in Mesopotamia at a much earlier date) as a medium of exchange, some time in the 7th century BC in Lydia. The use of minted coins continued to flourish during the Greek and Roman eras.
During the 6th century BC, most of Anatolia was conquered by the Persian Achaemenid Empire, the Persians having usurped the Medes as the dominant dynasty in Iran. Also in the 6th century BC, the Indo-European Armenians founded the Orontid Dynasty in Urartu. In 499 BC, the Ionian city-states on the west coast of Anatolia rebelled against Persian rule. The Ionian Revolt, as it became known, initiated the Greco-Persian Wars, which ended in a Greek victory in 449 BC, and the Ionian cities regained their independence.
In 334 BC, the Macedonian Greek king Alexander the Great conquered the peninsula. Alexander's conquest opened up the interior of Asia Minor to Greek settlement and influence. Following the death of Alexander and the breakup of his empire, Anatolia was ruled by a series of Hellenistic kingdoms, such as the Attalids of Pergamum and the Seleucids, the latter controlling most of Anatolia. A period of peaceful Hellenization followed, such that the local Anatolian languages had been supplanted by Greek by the 1st century BC. In 133 BC the last Attalid king bequeathed his kingdom to the Roman Republic, and western and central Anatolia came under Roman control, but Hellenistic culture remained predominant. During the 1st century BC the Armenians established the powerful Armenian kingdom under Tigran who reigned throughout much of eastern Anatolia between the Caspian, Black, and Mediterranean seas. Areas of the southeast such as Harran and the Hakkari mountains continued to be inhabited by remnants of the Assyrians, but these regions remained under Parthian and then Sassanid Persian rule.
Medieval and Renaissance periods.
After the division of the Roman Empire, Anatolia became part of the East Roman, or Byzantine Empire. Anatolia was one of the first places where Christianity spread, so that by the 4th century AD, western and central Anatolia were overwhelmingly Christian and Greek-speaking. For the next 600 years, while Imperial possessions in Europe were subjected to barbarian invasions, Anatolia would be the center of the Hellenic world. Byzantine control was challenged by Arab raids starting in the 8th century (see Byzantine–Arab Wars), but in the 9th and 10th century a resurgent Byzantine Empire regained its lost territories and even expanded beyond its traditional borders, into Armenia and Syria (ancient Aram). In the 10 years following the Battle of Manzikert in 1071, the Seljuk Turks from Central Asia established themselves over large areas of Anatolia, with particular concentrations around the north western rim. The Turkish language and the Islamic religion were gradually introduced as a result of the Seljuk conquest, and this period marks the start of Anatolia's slow transition from predominantly Christian and Greek-speaking, to predominantly Muslim and Turkish-speaking (although some ethnic groups such as Armenians, Greeks, Assyrians remained numerous and retained Christianity and their native languages). In the following century, the Byzantines managed to reassert their control in western and northern Anatolia. Control of Anatolia was then split between the Byzantine Empire and the Seljuk Sultanate of Rûm, with the Byzantine holdings gradually being reduced. In 1255, the Mongols swept through eastern and central Anatolia, and would remain until 1335. The Ilkhanate garrison was stationed near Ankara.
By the end of the 14th century, most of Anatolia was controlled by various Anatolian beyliks. Smyrna fell in 1330, and the last Byzantine stronghold in Anatolia, Philadelphia, fell in 1390. The Turkmen Beyliks were under the control of the Mongols, at least nominally, through declining Seljuk Sultans. The Beyliks did not mint coins in the names of their own leaders while they remained under the suzerainty of the Mongol Ilkhanids. The Osmanli ruler Osman I was the first Turkish ruler who minted coins in his own name in 1320s, for it bears the legend "Minted by Osman son of Ertugul". Since the minting of coins was a prerogative accorded in Islamic practice only to a sovereign, it can be considered that Osmanli became formally independent from the Mongol Khans.
After the decline of the Ilkhanate from 1335–1353, the Mongol Empire's legacy in the region was the Uyghur Eretna Dynasty that was overthrown by Kadi Burhan al-Din in 1381. Among the Turkmen leaders the Ottomans emerged as great power under Osman and his son Orhan I. The Anatolian beyliks were in turn absorbed into the rising Ottoman Empire during the 15th century. The Ottomans completed the conquest of the peninsula in 1517 with the taking of Halicarnassus (modern Bodrum) from the Knights of Saint John.
Modern times.
With the beginning of the slow decline of the Ottoman Empire in the early 19th century, and as a result of the expansionist policies of Czarist Russia in the Caucasus, many Muslim nations and groups in that region, mainly Circassians, Tatars, Azeris, Lezgis, Chechens and several Turkic groups left their ancestral homelands and settled in Anatolia. As the Ottoman Empire further shrank in the Balkan regions and then fragmented during the Balkan Wars, much of the non-Christian populations of its former possessions, mainly Balkan Muslims (Bosnians, Albanians, Turks, Muslim Bulgarians and Greek Muslims such as the Vallahades from Greek Macedonia, Bulgaria, Northern Macedonia), were resettled in various parts of Anatolia, mostly in formerly Christian villages throughout Anatolia.
A continuous reverse migration occurred since the early 19th century, when Greeks from Anatolia, Constantinopole and Pontus area migrated toward the newly independent Kingdom of Greece, and also towards the United States, southern part of the Russian Empire, Latin America and rest of Europe. Following the Treaty of Turkmenchay (1828) and the incorporation of the Eastern Armenia into the Russian Empire, another reverse migration involved the large Armenian population of Anatolia, which recorded significant migration rates from Western Armenia (Eastern Anatolia) toward the Russian Empire, especially toward the newly established Armenian provinces of the empire.
Anatolia remained multi-ethnic until the early 20th century (see the rise of nationalism under the Ottoman Empire). During World War I, the Armenian Genocide, the Greek genocide (especially in Pontus), and the Assyrian Genocide almost entirely removed the ancient indigenous communities of Armenian and Assyrian populations in Anatolia, as well as a large part of its ethnic Greek population. Following the Greco-Turkish War of 1919-1922, all remaining ethnic Anatolian Greeks were forced out during the 1923 population exchange between Greece and Turkey. Since the foundation of the Republic of Turkey in 1923, Anatolia has become Turkey, its inhabitants being mainly Turks and Kurds (see demographics of Turkey and history of Turkey).
Geography.
Geology.
Anatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Aegean, Mediterranean, and Black Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the Kızıl River, the coastal plains of Çukurova and the valley floors of the Gediz River and the Büyük Menderes River as well as some interior high plains in Anatolia, mainly around Lake Tuz (Salt Lake) and the Konya Basin ("Konya Ovasi").
Climate.
Anatolia has a varied range of climates. The central plateau is characterized by a continental climate, with hot summers and cold snowy winters. The south and west coasts enjoy a typical Mediterranean climate, with mild rainy winters, and warm dry summers. The Black Sea and Marmara coasts have temperate oceanic climate, with cool foggy summers and much rainfall throughout the year.
Ecoregions.
There is a diverse number of plant and animal communities.
The mountains and coastal plain of northern Anatolia experiences humid and mild climate. There are temperate broadleaf, mixed and coniferous forests. The central and eastern plateau, with its drier continental climate, has deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, contain Mediterranean forests, woodlands, and scrub ecoregions.
Demographics.
Almost 80% of the people currently residing in Anatolia are Turks. Kurds constitute a major community in southeastern Anatolia, and are the largest ethnic minority. Abkhazians, Albanians, Arabs, Arameans, Armenians, Assyrians, Azerbaijanis, Bosniaks, Circassians, Gagauz, Georgians, Serbs, Greeks, Hemshin, Jews, Laz, Levantines, Pomaks, Zazas and a number of other ethnic groups also live in Anatolia in smaller numbers.

</doc>
<doc id="856" url="http://en.wikipedia.org/wiki?curid=856" title="Apple Inc.">
Apple Inc.

Apple Inc. is an American multinational corporation headquartered in Cupertino, California, that designs, develops, and sells consumer electronics, computer software, online services, and personal computers. Its best-known hardware products are the Mac line of computers, the iPod media player, the iPhone smartphone, and the iPad tablet computer. Its online services include iCloud, iTunes Store, and App Store. Its consumer software includes the OS X and iOS operating systems, the iTunes media browser, the Safari web browser, and the iLife and iWork creativity and productivity suites.
Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne on April 1, 1976, to develop and sell personal computers. It was incorporated as Apple Computer, Inc. on January 3, 1977, and was renamed as Apple Inc. on January 9, 2007, to reflect its shifted focus towards consumer electronics.
Apple is the world's second-largest information technology company by revenue after Samsung Electronics, and the world's third-largest mobile phone maker after Samsung and Nokia. "Fortune" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. On September 30, 2013, Apple surpassed Coca-Cola to become the world's most valuable brand in the Omnicom Group's "Best Global Brands" report. However, the company has received criticism for its contractors' labor practices, as well as for its own environmental and business practices.
As of June 2014, Apple maintains 425 retail stores in fourteen countries, as well as the online Apple Store and iTunes Store, the latter of which is the world's largest music retailer. Apple is the largest publicly traded corporation in the world by market capitalization, with an estimated market capitalization of $446 billion by January, 2014. As of September 29, 2012, the company had 72,800 permanent full-time employees and 3,300 temporary full-time employees worldwide. Its worldwide annual revenue in 2013 totalled $170 billion. As of Q1 2014, Apple's five-year growth average is 39% for top line growth and 45% for bottom line growth. In May 2013, Apple entered the top ten of the Fortune 500 list of companies for the first time, rising 11 places above its 2012 ranking to take the sixth position.
History.
1976–80: Founding and incorporation.
Apple was established on April 1, 1976, by Steve Jobs, Steve Wozniak and Ronald Wayne to sell the Apple I personal computer kit, a computer single handedly designed by Wozniak. The kits were hand-built by Wozniak and first shown to the public at the Homebrew Computer Club. The Apple I was sold as a motherboard (with CPU, RAM, and basic textual-video chips), which is less than what is today considered a complete personal computer. The Apple I went on sale in July 1976 and was market-priced at $666.66 ($ in dollars, adjusted for inflation).
Apple was incorporated January 3, 1977, without Wayne, who sold his share of the company back to Jobs and Wozniak for $800. Multi-millionaire Mike Markkula provided essential business expertise and funding of $250,000 during the incorporation of Apple.
During the first five years of operations, revenues doubled every four months, an average growth rate of 700%.
The Apple II, also invented by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, due to its character cell-based color graphics and an open architecture. While early models used ordinary cassette tapes as storage devices, they were superseded by the introduction of a 5 1/4 inch floppy disk drive and interface, the Disk II.
The Apple II was chosen to be the desktop platform for the first "killer app" of the business world, VisiCalc, a spreadsheet program. VisiCalc created a business market for the Apple II and gave home users compatibility with the office, an additional reason to buy an Apple II. Apple was a distant third place to Commodore and Tandy until VisiCalc came along.
By the end of the 1970s, Apple had a staff of computer designers and a production line. The company introduced the Apple III in May 1980 in an attempt to compete with IBM and Microsoft in the business and corporate computing market.
Jobs and several Apple employees, including Jef Raskin, visited Xerox PARC in December 1979 to see the Xerox Alto. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (800,000 split-adjusted shares) of Apple at the pre-IPO price of $10 a share. Jobs was immediately convinced that all future computers would use a graphical user interface (GUI), and development of a GUI began for the Apple Lisa.
On December 12, 1980, Apple went public at $22 per share, generating more capital than any IPO since Ford Motor Company in 1956 and instantly creating more millionaires (about 300) than any company in history.
1981–89: Success with Macintosh.
Apple began working on the Apple Lisa in 1978. In 1982, Jobs was pushed from the Lisa team due to infighting. Jobs took over Jef Raskin's low-cost-computer project, the Macintosh. A race broke out between the Lisa team and the Macintosh team over which product would ship first. Lisa won the race in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price tag and limited software titles.
In 1984, Apple next launched the Macintosh. Its debut was announced by the now famous $1.5 million television commercial "1984". It was directed by Ridley Scott and was aired during the third quarter of Super Bowl XVIII on January 22, 1984. It is now hailed as a watershed event for Apple's success and a "masterpiece".
The Macintosh initially sold well, but follow-up sales were not strong due to its high price and limited range of software titles. The Macintosh was the first personal computer to be sold without a programming language at all.
The machine's fortunes changed with the introduction of the LaserWriter, the first PostScript laser printer to be sold at a reasonable price, and PageMaker, an early desktop publishing package. It has been suggested that the combination of these three products was responsible for the creation of the desktop publishing market. The Mac was particularly powerful in the desktop publishing market due to its advanced graphics capabilities, which had necessarily been built in to create the intuitive Macintosh GUI.
In 1985 a power struggle developed between Jobs and CEO John Sculley, who had been hired two years earlier. The Apple board of directors instructed Sculley to "contain" Jobs and limit his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Sculley found out that Jobs had been attempting to organize a coup and called a board meeting at which Apple's board of directors sided with Sculley and removed Jobs from his managerial duties. Jobs resigned from Apple and founded NeXT Inc. the same year.
The Macintosh Portable was introduced in 1989 and was designed to be just as powerful as a desktop Macintosh, but weighed a bulky with a 12-hour battery life. After the Macintosh Portable, Apple introduced the PowerBook in 1991. The same year, Apple introduced System 7, a major upgrade to the operating system which added color to the interface and introduced new networking capabilities. It remained the architectural basis for Mac OS until 2001.
The success of the PowerBook and other products brought increasing revenue. For some time, Apple was doing incredibly well, introducing fresh new products and generating increasing profits in the process. The magazine "MacAddict" named the period between 1989 and 1991 as the "first golden age" of the Macintosh.
Following the success of the Macintosh LC, Apple introduced the Centris line, a low-end Quadra, and the ill-fated Performa line that was sold with an overwhelming number of configurations and software bundles to avoid competing with the various consumer outlets such as Sears, Price Club, and Wal-Mart (the primary dealers for these models). Consumers ended up confused and did not understand the difference between models.
1990–99: Decline and restructuring.
During this time Apple experimented with a number of other failed consumer targeted products including digital cameras, portable CD audio players, speakers, video consoles, and TV appliances. Enormous resources were also invested in the problem-plagued Newton division based on John Sculley's unrealistic market forecasts. Ultimately, none of these products helped, as Apple's market share and stock prices continued to slide.
Apple saw the Apple II series as too expensive to produce, while taking away sales from the low-end Macintosh. In 1990, Apple released the Macintosh LC with a single expansion slot for the Apple IIe Card to migrate Apple II users to the Macintosh platform. Apple stopped selling the Apple IIe in 1993.
Microsoft continued to gain market share with Windows focusing on delivering software to cheap commodity personal computers while Apple was delivering a richly engineered, but expensive, experience. Apple relied on high profit margins and never developed a clear response. Instead, they sued Microsoft for using a graphical user interface similar to the Apple Lisa in "Apple Computer, Inc. v. Microsoft Corporation". The lawsuit dragged on for years before it was finally dismissed. At the same time, a series of major product flops and missed deadlines sullied Apple's reputation, and Sculley was replaced as CEO by Michael Spindler.
By the early 1990s, Apple was developing alternative platforms to the Macintosh, such as the A/UX. Apple had also begun to experiment in providing a Mac-only online portal which they called eWorld, developed in collaboration with America Online and designed as a Mac-friendly alternative to other online services such as CompuServe. The Macintosh platform was itself becoming outdated because it was not built for multitasking, and several important software routines were programmed directly into the hardware. In addition, Apple was facing competition from OS/2 and UNIX vendors such as Sun Microsystems. The Macintosh would need to be replaced by a new platform, or reworked to run on more powerful hardware.
In 1994, Apple allied with IBM and Motorola in the AIM alliance. The goal was to create a new computing platform (the PowerPC Reference Platform), which would use IBM and Motorola hardware coupled with Apple's software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind, thus countering Microsoft. The same year, Apple introduced the Power Macintosh, the first of many Apple computers to use Motorola's PowerPC processor.
In 1996, Michael Spindler was replaced by Gil Amelio as CEO. Gil Amelio made many changes at Apple, including extensive layoffs. After numerous failed attempts to improve Mac OS, first with the Taligent project, then later with Copland and Gershwin, Amelio chose to purchase NeXT and its NeXTSTEP operating system, bringing Steve Jobs back to Apple as an advisor. On July 9, 1997, Amelio was ousted by the board of directors after overseeing a three-year record-low stock price and crippling financial losses. Jobs acted as the interim CEO and began restructuring the company's product line; it was during this period that Jobs identified Jonathan Ive's design talent and the pair worked collaboratively to rebuild Apple's status.
At the 1997 Macworld Expo, Jobs announced that Apple would join Microsoft to release new versions of Microsoft Office for the Macintosh, and that Microsoft had made a $150 million investment in non-voting Apple stock. On November 10, 1997, Apple introduced the Apple Online Store, tied to a new build-to-order manufacturing strategy.
On August 15, 1998, Apple introduced a new all-in-one computer reminiscent of the Macintosh 128K: the iMac. The iMac design team was led by Ive, who would later design the iPod and the iPhone. The iMac featured modern technology and a unique design, and sold almost 800,000 units in its first five months.
Through this period, Apple purchased several companies to create a portfolio of professional and consumer-oriented digital production software. In 1998, Apple announced the purchase of Macromedia's Final Cut software, signaling its expansion into the digital video editing market. The following year, Apple released two video editing products: iMovie for consumers and, for professionals, Final Cut Pro, which has gone on to be a significant video-editing program, with 800,000 registered users in early 2007. In 2002, Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for their music productivity application Logic, which led to the development of their consumer-level GarageBand application. iPhoto's release the same year completed the iLife suite.
2000–06: Return to profitability.
Mac OS X, based on NeXT's OPENSTEP and BSD Unix, was released on March 24, 2001 after several years of development. Aimed at consumers and professionals alike, Mac OS X aimed to combine the stability, reliability and security of Unix with the ease of use afforded by an overhauled user interface. To aid users in migrating from Mac OS 9, the new operating system allowed the use of OS 9 applications within Mac OS X as the Classic environment, which meant that users were able to continue running their old applications.
On May 19, 2001, Apple opened the first official Apple Retail Stores in Virginia and California. On July 9, they bought Spruce Technologies, a DVD authoring company. On October 23 of the same year, Apple announced the iPod portable digital audio player, and started selling it on November 10. The product was phenomenally successful — over 100 million units were sold within six years. In 2003, Apple's iTunes Store was introduced, offering online music downloads for $0.99 a song and integration with the iPod. The service quickly became the market leader in online music services, with over 5 billion downloads by June 19, 2008.
Since 2001, Apple's design team has progressively abandoned the use of translucent colored plastics first used in the iMac G3. This began with the PowerBook, made with titanium, and was followed by the iBook's white polycarbonate structure and the flat-panel iMac.
At the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would begin producing Intel-based Mac computers in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line—over one year sooner than announced. The Power Mac, iBook and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. On April 29, 2009, "The Wall Street Journal" reported that Apple was building its own team of engineers to design microchips. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.
Apple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. In January 2006, Apple's market cap surpassed that of Dell. Nine years prior, Dell's CEO Michael Dell said that if he ran Apple he would "shut it down and give the money back to the shareholders." Although Apple's market share in computers had grown, it remained far behind competitors using Microsoft Windows, accounting for about 8% of desktops and laptops in the US.
2007–10: Success with mobile devices.
Apple achieved widespread success with its iPhone, iPod Touch and iPad products, which introduced innovations in mobile phones, portable music players and personal computers respectively. In addition, the implementation of a store for the purchase of software applications represented a new business model. Touch screens had been invented and seen in mobile devices before, but Apple was the first to achieve mass market adoption of such a user interface that included particular pre-programmed touch gestures.
Delivering his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced that Apple Computer, Inc. would from that point on be known as Apple Inc., because computers were no longer the main focus of the company, which had shifted its emphasis to mobile electronic devices. The event also saw the announcement of the iPhone and the Apple TV.
The following day, Apple shares hit $97.80, an all-time high at that point. In May, Apple's share price passed the $100 mark.
In an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management (DRM), thereby allowing tracks to be played on third-party players, if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce the corresponding changes to the iTunes Store.
In July 2008, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60 million applications and registered an average daily revenue of $1 million, with Jobs speculating in August 2008 that the App Store could become a billion-dollar business for Apple. An October 2008 announcement by Jobs identified Apple as the third-largest mobile handset supplier in the world due to the popularity of the iPhone.
On December 16, 2008, Apple announced that 2009 would be the last year the corporation would be attending the Macworld Expo, after more than 20 years of attendance. The announcement also explained that senior vice president of Worldwide Product Marketing Philip Schiller would deliver the 2009 keynote address in lieu of the expected Jobs. The official press release explained that Apple was "scaling back" on trade shows generally, with Macworld Tokyo and Apple Expo in Paris, France two other events that the corporation had ceased attendance at. The enormous success of the Apple Retail Stores and website had rendered trade shows into a minor promotional channel and was cited as the primary reason for the change.
On January 14, 2009, an internal memo from Jobs announced that he would be taking a six-month medical leave of absence from Apple until the end of June 2009, during which time he would focus on his health. In the email, Jobs also stated that he realized "the curiosity over my personal health continues to be a distraction not only for me and my family, but everyone else at Apple as well," further explaining that the break would allow the company "to focus on delivering extraordinary products." Despite Jobs's absence, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession with a revenue of $8.16 billion and a profit of $1.21 billion.
After years of speculation and multiple rumored "leaks", Apple announced a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad runs the same touch based operating system that the iPhone uses and many of the same iPhone apps are compatible with the iPad. This gave the iPad a large app catalog on launch even with very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the US and sold more than 300,000 units on that day, reaching 500,000 by the end of the first week. In May of the same year, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.
Apple released the iPhone 4, which introduced video calling, multitasking, and a new uninsulated stainless steel design, which acts as the phone's antenna. Because of this antenna implementation, some iPhone 4 users reported a reduction in signal strength when the phone is held in specific ways. After a large amount of media coverage including mainstream news organizations, Apple held a press conference where they offered buyers a free rubber 'bumper' case, which had been proven to eliminate the signal reduction issue. Later that year Apple again refreshed its iPod line of MP3 players which introduced a multi-touch iPod Nano, iPod Touch with FaceTime, and iPod Shuffle with buttons which brought back the buttons of earlier generations.
In October 2010, Apple shares hit an all-time high, eclipsing $300. Additionally, on October 20, Apple updated their MacBook Air laptop, iLife suite of applications, and unveiled Mac OS X Lion, the last version with the name "Mac OS X". On January 6, 2011, the company opened their Mac App Store, a digital software distribution platform, similar to the existing iOS App Store. Apple was featured in the documentary "Something Ventured" which premiered in 2011.
2011–12: Steve Jobs's death.
On January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence, for an indefinite period, to allow him to focus on his health. Chief operating officer Tim Cook assumed Jobs's day-to-day operations at Apple, although Jobs would still remain "involved in major strategic decisions for the company." Apple became the most valuable consumer-facing brand in the world. In June 2011, Steve Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files and software which replaced MobileMe, Apple's previous attempt at content syncing.
This would be the last product launch Jobs would attend before his death. It has been argued that Apple has achieved such efficiency in its supply chain that the company operates as a monopsony (one buyer, many sellers), in that it can dictate terms to its suppliers. In July 2011, due to the American debt-ceiling crisis, Apple's financial reserves were briefly larger than those of the U.S. Government.
On August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Tim Cook and Jobs became Apple's chairman. Prior to this, Apple did not have a chairman and instead had two co-lead directors, Andrea Jung and Arthur D. Levinson, who continued with those titles until Levinson became Chairman of the Board in November.
On October 4, 2011, Apple announced the iPhone 4S, which included an improved camera with 1080p video recording, a dual core A5 chip capable of 7 times faster graphics than the A4, an "intelligent software assistant" named Siri, and cloud-sourced data with iCloud. (The iPhone 4S was officially released on October 14, 2011.)
On October 5, 2011, Apple announced that Jobs had died, marking the end of an era for Apple Inc.
On October 29, 2011, Apple purchased C3 Technologies, a mapping company, for $240 million, becoming the third mapping company Apple has purchased. On January 10, 2012, Apple paid $500 million to acquire Anobit, an Israeli hardware company that developed and supplies a proprietary memory signal processing technology that improves the performance of flash-memory used in iPhones and iPads.
On January 19, 2012, Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. This was the first major announcement by Apple since the passing of Steve Jobs, who stated in his biography that he wanted to reinvent the textbook and education. The third-generation iPad was announced on March 7, 2012. It includes a Retina display, a new CPU, a five megapixel camera, and 1080p video recording.
On July 24, 2012, during a conference call with investors, Tim Cook said that he loved India, but that Apple was going to expect larger opportunities outside of India, citing the reason as the 30% sourcing requirement from India.
On August 20, 2012, Apple's rising stock rose the company's value to a world-record $624 billion. This beat the non-inflation-adjusted record for market capitalization set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05 billion (£665m) in damages in an intellectual property lawsuit. Samsung said they will appeal the court ruling. Samsung subsequently prevailed on its motion to vacate this damages award, which the Court reduced by $450 million. The Court further granted Samsung's request for a new trial.
On September 12, 2012, Apple unveiled the iPhone 5, featuring an enlarged screen, more powerful processors, and running iOS 6. The latter includes a new mapping application (replacing Google Maps) that has attracted some criticism. It was made available on September 21, 2012, and became Apple's biggest iPhone launch, with over 2 million pre-orders pushing back the delivery date to late October.
On October 23, 2012, Apple unveiled the iPad Mini, which features a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. Apple also released a third-generation 13-inch MacBook Pro with a Retina display; the fourth-generation iPad, featuring a faster processor and a Lightning dock connector; and new iMac and Mac Mini computers. After the launch of Apple's iPad Mini and fourth generation iPad on November 3, 2012, Apple announced that they had sold 3 million iPads in three days of the launch, but it did not mention the sales figures of specific iPad models.
On November 10, 2012, Apple confirmed a global settlement that would dismiss all lawsuits between Apple and HTC up to that date, in favor of a ten-year license agreement for current and future patents between the two companies. It is predicted that Apple will make $280 million a year from this deal with HTC.
In December 2012, in a TV interview for NBC's "Rock Center" and also aired on the "Today" morning show, Apple CEO Tim Cook said that in 2013 the company will produce one of its existing lines of Mac computers in the United States. In January 2013, Cook stated that he expected China to overtake the US as Apple's biggest market.
2013–present: Acquisitions and expansion.
In March 2013, Apple announced a patent for an augmented reality (AR) system that can identify objects in a live video stream and present information corresponding to these objects through a computer-generated information layer overlaid on top of the real-world image.
At the Worldwide Developer's Conference on June 10, 2013, Apple announced the seventh iOS operating system alongside OS X Mavericks, the tenth version of Mac OS X, and a new Internet radio service called iTunes Radio. iTunes Radio, iOS 7 and OS X Mavericks were released fall 2013. The radio service features more than 200 stations according to company's statement.
On July 2, 2013, Apple announced the recruitment of Paul Deneve, Belgian President and CEO of Yves Saint Laurent, to Apple's top ranks. A spokesperson for the company stated, "We're thrilled to welcome Paul Deneve to Apple. He'll be working on special projects as a vice president reporting directly to Tim Cook."
Alongside Google vice-president Vint Cerf and AT&T CEO Randall Stephenson, Cook attended a closed-door summit held by President Obama on August 8, 2013 in regard to government surveillance and the Internet in the wake of the Edward Snowden NSA incident.
A report on August 22, 2013 confirmed that Apple acquired Embark Inc., a small Silicon Valley-based mapping company. Embark builds free transit apps to help smartphone users navigate public transportation in U.S. cities such as New York, San Francisco and Chicago. Following the confirmation of the acquisition, an Apple spokesperson explained, "Apple buys smaller technology companies from time to time, and we generally do not discuss our purpose or plans." In November 2012, Embark claimed that over 500,000 people used its apps.
An anonymous Apple employee revealed to the "Bloomberg" media publication that the opening of a Tokyo, Japan store is planned for 2014. The construction of the store will be completed in February 2014, but as of August 29, 2013, Takashi Takebayashi, a Tokyo-based spokesman for Apple, has not made any comment to the media. A Japanese analyst has stated, "For Apple, the Japanese market is appealing in terms of quantity and price. There is room to expand tablet sales and a possibility the Japanese market expands if Apple’s mobile carrier partners increase.
On October 1, 2013, Apple India executives unveiled a plan to expand further into the Indian market, following Cook's acknowledgment of the country in July 2013 when sales results showed that iPhone sales in India grew 400% during the second quarter of 2013. In attendance at the confidential meeting were 20 CEOs and senior executives from telecom and electronic retail companies.
A mid-October 2013 announcement revealed that Burberry executive Angela Ahrendts will commence as a senior vice president at Apple in mid-2014. Ahrendts oversaw Burberry's digital strategy for almost eight years and, during her tenure, sales increased to about US$3.2 billion (2 billion pounds) and shares gained more than threefold. In a company wide memo sent on the morning of October 15, 2013, Cook explained the decision to hire Ahrendts:
She shares our values and our focus on innovation. She places the same strong emphasis as we do on the customer experience. She cares deeply about people and embraces our view that our most important resource and our soul is our people. She believes in enriching the lives of others and she is wicked smart.
On November 24, 2013, Apple Inc. confirmed the purchase of PrimeSense, an Israeli 3D sensing company based in Tel Aviv. In the following month, Apple Inc. purchased social analytics firm Topsy, one of a small number of firms with real-time access to the messages that appear on Twitter (every tweet published since 2006 is within its scope). Debra Aho Williamson, an analyst with EMarketer Inc., explained: “A key point is they are one of the few companies that has access to the Twitter fire hose and can do real-time analysis of the trends and discussions happening on Twitter.” While an exact amount is unknown, the deal was apparently worth more than US$200 million, according to people with knowledge of the secret deal, and Apple spokespeople refused to disclose a purpose at the time of the acquisition.
On December 6, 2013, Apple Inc. launched iBeacon technology across its 254 U.S. retail stores. Using Bluetooth wireless technology, iBeacon senses the user's exact location within the Apple store and sends the user messages about products, events and other information, tailored to the user's location. iBeacon works as long as the user has downloaded the Apple Store app and has expressly permitted Apple to track them.
Apple Inc. reported that the company sold 51 million iPhones in the Q1 of 2014 (an all-time quarterly record), compared to 47.8 million in the year-ago quarter. Apple also sold 26 million iPads during the quarter, also an all-time quarterly record, compared to 22.9 million in the year-ago quarter. The Company sold 4.8 million Macs, compared to 4.1 million in the year-ago quarter.
On February 4, 2014, Cook met with Abdullah Gül, the President of Turkey, in Ankara to discuss the company's involvement in the Fatih project. Cook also confirmed that Turkey's first Apple Retail Store would be opened in Istanbul in April 2014.
During the proceedings of the "Apple Inc. v. Samsung Electronics Co., Ltd." lawsuits, a previously confidential email, written by Jobs a year before his death, was presented and its content became publicly available in early April 2014. With a subject line that reads "Top 100 – A," the email was sent only to the company's 100 most senior employees and outlines Jobs's vision of Apple Inc.'s future under 10 subheadings, including a "2011 Strategy." Notably, Jobs declares a "Holy War with Google" for 2011 and schedules a "new campus" for 2015.
On May 28, 2014, Apple confirmed its intent to acquire Dr. Dre and Jimmy Iovine's audio company Beats Electronics—producer of the "Beats by Dr. Dre" line of headphones and speaker products, and operator of the music streaming service Beats Music—for $3 billion. Iovine felt that Beats had always "belonged" with Apple, as the company modeled itself after Apple's "unmatched ability to marry culture and technology." In regards to the deal, Tim Cook stated that "Music is such an important part of all of our lives and holds a special place within our hearts at Apple. That's why we have kept investing in music and are bringing together these extraordinary teams so we can continue to create the most innovative music products and services in the world." As a result of the acquisition, Apple plans to offer Beats' products through its retail outlets and resellers, but the company has not made any further indications about how Beats will be integrated into Apple's product line.
Products.
Mac.
Apple sells a variety of computer accessories for Macs, including Thunderbolt Display, Magic Mouse, Magic Trackpad, Wireless Keyboard, Battery Charger, the AirPort wireless networking products, and Time Capsule.
iPad.
On January 27, 2010, Apple introduced their much-anticipated media tablet, the iPad, running a modified version of iOS. It offers multi-touch interaction with multimedia formats including newspapers, magazines, ebooks, textbooks, photos, movies, videos of TV shows, music, word processing documents, spreadsheets, videogames, and most existing iPhone apps. It also includes a mobile version of Safari for web browsing, as well as access to the App Store, iTunes Library, iBookstore, contacts, and notepad. Content is downloadable via Wi-Fi and optional 3G service or synced through the user's computer. AT&T was initially the sole US provider of 3G wireless access for the iPad.
On March 2, 2011, Apple introduced the iPad 2, which had a faster processor and a camera on the front and back. It also added support for optional 3G service provided by Verizon in addition to the existing offering by AT&T. However, the availability of the iPad 2 has been limited as a result of the devastating earthquake and ensuing tsunami in Japan in March 2011.
On March 7, 2012, Apple introduced the third-generation iPad, marketed as "the new iPad". It added LTE service from AT&T or Verizon, the upgraded A5X processor, and the Retina display (2048 by 1536 resolution), originally implemented on the iPhone 4 and iPhone 4S. The dimensions and form factor remained relatively unchanged, with the new iPad being a fraction thicker and heavier than the previous version, and minor positioning changes.
On October 23, 2012, Apple's fourth-generation iPad came out, marketed as the "iPad with Retina display". It added the upgraded A6X processor and replaced the traditional 30-pin dock connector with the all-digital Lightning connector. The iPad Mini was also introduced, with a reduced 7.9-inch display and featuring much of the same internal specifications as the iPad 2.
On October 22, 2013, Apple introduced the iPad Air. It added the new 64 bit Apple-A7 processor. The iPad mini with Retina Display was also introduced, featuring the Apple-A7 processor as well.
Since its launch, iPad users have downloaded three billion apps, while the total number of App Store downloads is over 25 billion.
iPod.
On October 23, 2001, Apple introduced the iPod digital music player. Several updated models have since been introduced, and the iPod brand is now the market leader in portable music players by a significant margin, with more than 350 million units shipped . Apple has partnered with Nike to offer the Nike+iPod Sports Kit, enabling runners to synchronize and monitor their runs with iTunes and the Nike+ website.
Apple currently sells four variants of the iPod:
iPhone.
At the Macworld Conference & Expo in January 2007, Steve Jobs introduced the long-anticipated iPhone, a convergence of an Internet-enabled smartphone and iPod. The first-generation iPhone was released on June 29, 2007 for $499 (4 GB) and $599 (8 GB) with an AT&T contract. On February 5, 2008, it was updated to have 16 GB of memory, in addition to the 8 GB and 4 GB models. It combined a 2.5G quad band GSM and EDGE cellular phone with features found in handheld devices, running scaled-down versions of Apple's Mac OS X (dubbed iPhone OS, later renamed iOS), with various Mac OS X applications such as Safari and Mail. It also includes web-based and Dashboard apps such as Google Maps and Weather. The iPhone features a touchscreen display, Bluetooth, and Wi-Fi (both "b" and "g").
At Worldwide Developers Conference (WWDC) on June 9, 2008, Apple announced the iPhone 3G. It was released on July 11, 2008, with a reduced price of $199 for the 8 GB version, and $299 for the 16 GB version. This version added support for 3G networking and assisted-GPS navigation. The flat silver back and large antenna square of the original model were eliminated in favor of a curved glossy black or white back. Software capabilities were improved with the release of the App Store, providing applications for download that were compatible with the iPhone. On April 24, 2009, the App Store surpassed one billion downloads. At WWDC on June 8, 2009, Apple announced the iPhone 3GS. It provided an incremental update to the device, including faster internal components, support for faster 3G speeds, video recording capability, and voice control.
At WWDC on June 7, 2010, Apple announced the redesigned iPhone 4. It features a 960x640 display, the Apple A4 processor also used in the iPad, a gyroscope for enhanced gaming, 5MP camera with LED flash, front-facing VGA camera and FaceTime video calling. Shortly after its release, reception issues were discovered by consumers, due to the stainless steel band around the edge of the device, which also serves as the phone's cellular signal and Wi-Fi antenna. The issue was corrected by a "Bumper Case" distributed by Apple for free to all owners for a few months. In June 2011, Apple overtook Nokia to become the world's biggest smartphone maker by volume.
On October 4, 2011, Apple unveiled the iPhone 4S, which was first released on October 14, 2011. It features the Apple A5 processor, and is the first model offered by Sprint (joining AT&T and Verizon Wireless as the United States carriers offering iPhone models). On October 19, 2011, Apple announced an agreement with C Spire Wireless to sell the iPhone 4S with that carrier in the near future, marking the first time the iPhone was officially supported on a regional carrier's network. Another notable feature of the iPhone 4S was Siri voice assistant technology, which Apple had acquired in 2010, as well as other features, including an updated 8MP camera with new optics. Apple sold 4 million iPhone 4S phones in the first three days of availability.
On September 12, 2012, Apple introduced the iPhone 5. It added a 4-inch display, 4G LTE connectivity, and the upgraded Apple A6 chip, among several other improvements. Two million iPhones were sold in the first twenty-four hours of pre-ordering and over five million handsets were sold in the first three days of its launch.
A patent filed in July 2013 revealed the development of a new iPhone battery system that uses location data in combination with data on the user's habits to moderate the handsets power settings accordingly. Apple is working towards a power management system that will provide features such as the ability of the iPhone to estimate the length of time a user will be away from a power source to modify energy usage and a detection function that adjusts the charging rate to best suit the type of power source that is being used.
In March 2013, one of the largest cellular phone companies in the United States, T-Mobile, announced that it would begin selling the iPhone 5 on April 12. The announcement of the iPhone came with the announcement that the company would begin implementing 4G cellular service for its users.
Upon the launch of the iPhone 5S and iPhone 5C, Apple sold over nine million devices in the first three days of its launch, which sets a new record for first-weekend smartphone sales. This was the first time that Apple has simultaneously launched two models and the inclusion of China in the list of markets contributed to the record sales result.
On October 15, 2013, U.S. Cellular, the United States fifth largest cell phone provider, announced that it would in fact begin to carry the iPhone. It is the last of the five major carriers, including AT&T, Verizon, Sprint, and T-Mobile to acquire the phone. The phone went on sale on November 8 at U.S. Cellular stores around the country. The finalization of a deal between Apple and China Mobile, the world's largest mobile network, was announced in late December 2013. The multi-year agreement provides iPhone access to over 760 million China Mobile subscribers.
In a March 2014 interview, Ive used the iPhone as an example of Apple's ethos of creating high-quality, life-changing products, explaining that they are comparatively expensive due to the intensive effort that is used to make them:
We don’t take so long and make the way we make for fiscal reasons ... Quite the reverse. The body is made from a single piece of machined aluminium ... The whole thing is polished first to a mirror finish and then is very finely textured, except for the Apple logo. The chamfers edges are cut with diamond-tipped cutters. The cutters don’t usually last very long, so we had to figure out a way of mass-manufacturing long-lasting ones. The camera cover is sapphire crystal. Look at the details around the sim-card slot. It’s extraordinary!
Apple TV.
At the 2007 Macworld conference, Jobs demonstrated the Apple TV, (previously known as the iTV), a set-top video device intended to bridge the sale of content from iTunes with high-definition televisions. The device links up to a user's TV and syncs, either via Wi-Fi or a wired network, with one computer's iTunes library and streams from an additional four. The Apple TV originally incorporated a 40 GB hard drive for storage, includes outputs for HDMI and component video, and plays video at a maximum resolution of 720p. On May 31, 2007 a 160 GB drive was released alongside the existing 40 GB model and on January 15, 2008 a software update was released, which allowed media to be purchased directly from the Apple TV.
In September 2009, Apple discontinued the original 40 GB Apple TV and now continues to produce and sell the 160 GB Apple TV. On September 1, 2010, alongside the release of the new line of iPod devices for the year, Apple released a completely redesigned Apple TV. The new device is 1/4 the size, runs quieter, and replaces the need for a hard drive with media streaming from any iTunes library on the network along with 8 GB of flash memory to cache media downloaded. Apple with the Apple TV has added another device to its portfolio that runs on its A4 processor along with the iPad and the iPhone. The memory included in the device is the half of the iPhone 4 at 256 MB; the same as the iPad, iPhone 3GS, third and fourth-generation iPod Touch.
It has HDMI out as the only video out source. Features include access to the iTunes Store to rent movies and TV shows (purchasing has been discontinued), streaming from internet video sources, including YouTube and Netflix, and media streaming from an iTunes library. Apple also reduced the price of the device to $99. A third generation of the device was introduced at an Apple event on March 7, 2012, with new features such as higher resolution (1080p) and a new user interface.
Software.
Apple develops its own operating system to run on Macs, OS X, the latest version being OS X Mavericks (version 10.9). Apple also independently develops computer software titles for its OS X operating system. Much of the software Apple develops is bundled with its computers. An example of this is the consumer-oriented iLife software package that bundles iMovie, iPhoto and GarageBand. For presentation, page layout and word processing, iWork is available, which includes Keynote, Pages, and Numbers. iTunes, QuickTime media player, and Software Update are available as free downloads for both OS X and Windows.
Apple also offers a range of professional software titles. Their range of server software includes the operating system OS X Server; Apple Remote Desktop, a remote systems management application; and Xsan, a Storage Area Network file system. For the professional creative market, there is Aperture for professional RAW-format photo processing; Final Cut Pro, a video production suite; Logic Pro, a comprehensive music toolkit; and Motion, an advanced effects composition program.
Apple also offers online services with iCloud, which provides cloud storage and syncing for a wide range of data, including email, contacts, calendars, photos and documents. It also offers iOS device backup, and is able to integrate directly with third-party apps for even greater functionality. iCloud is the fourth generation of online services provided by Apple, and was preceded by MobileMe, .Mac and iTools, all which met varying degrees of success.
Corporate identity.
Logo.
According to Steve Jobs, Apple was so named because Jobs was coming back from an apple farm, and he was on a fruitarian diet. He thought the name was "fun, spirited and not intimidating".
Apple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's "rainbow Apple", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. Janoff presented Jobs with several different monochromatic themes for the "bitten" logo, and Jobs immediately took a liking to it. While Jobs liked the logo, he insisted it be in color to humanize the company. The logo was designed with a bite so that it would not be confused with a cherry. The colored stripes were conceived to make the logo more accessible, and to represent the fact the Apple II could generate graphics in color. This logo is often erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his method of suicide. Both Janoff and Apple deny any homage to Turing in the design of the logo.
On August 27, 1999 (the following year after the iMac G3 was introduced), Apple officially dropped the rainbow scheme and began to use monochromatic themes, nearly identical in shape to its previous rainbow incarnation, on various products, packaging and advertising. An Aqua-themed version of the monochrome logo was used from 1999 to 2003, and a Glass-themed version was used from 2007 to 2013. With the release of iOS 7 and OS X Mavericks in late 2013, the logo appears flat and white with no glossy effects.
Steve Jobs and Steve Wozniak were Beatles fans, but Apple Inc. had trademark issues with Apple Corps Ltd., a multimedia company started by the Beatles in 1967, involving their name and logo. This resulted in a series of lawsuits and tension between the two companies. These issues ended with settling of their most recent lawsuit in 2007.
Advertising.
Apple's first slogan, "Byte into an Apple", was coined in the late 1970s. From 1997 to 2002, the slogan "Think Different" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines — for example, "iThink, therefore iMac" was used in 1998 to promote the iMac, and "Say hello to iPhone" has been used in iPhone advertisements. "Hello" was also used to introduce the original Macintosh, Newton, iMac ("hello (again)"), and iPod.
Since the introduction of the Macintosh in 1984 with the 1984 Super Bowl commercial to the more modern 'Get a Mac' adverts, Apple has been recognized in the past for its efforts towards effective advertising and marketing for its products, though its advertising was criticized for the claims made by some later campaigns, particularly the 2005 Power Mac ads and iPhone ads in Britain.
Apple's product commercials gained fame for launching musicians into stardom as a result of their eye-popping graphics and catchy tunes. First, the company popularized Canadian singer Feist's "1234" song in its ad campaign. Later, Apple used the song "New Soul" by French-Israeli singer-songwriter Yael Naïm to promote the MacBook Air. The debut single shot to the top of the charts and sold hundreds of thousands of copies in a span of weeks.
Brand loyalty.
Apple's brand loyalty is considered unusual for any product. At one time, Apple evangelists were actively engaged by the company, but this was after the phenomenon was already firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism "something that was stumbled upon," while Ive explained in 2014 that "People have an incredibly personal relationship" with Apple's products.
Apple supports the continuing existence of a network of Mac User Groups in many areas where Mac computers are available. Mac users previously meet at the European Apple Expo and the San Francisco Macworld Conference & Expo trade shows, where Apple traditionally introduced new products each year, to both the industry and public, until Apple pulled out of both events—the conferences continue, but Apple is not officially represented at either event. Mac developers, in turn, continue to gather at the annual Apple Worldwide Developers Conference.
Apple Store openings can draw crowds of thousands, with some waiting in line as much as a day before the opening or flying in from other countries for the event. The New York City Fifth Avenue "Cube" store had a line as long as half a mile; a few Mac fans took the opportunity of the setting to propose marriage. The Ginza opening in Tokyo was estimated in the thousands with a line exceeding eight city blocks.
John Sculley told "The Guardian" newspaper in 1997: "People talk about technology, but Apple was a marketing company. It was the marketing company of the decade." Research in 2002 by NetRatings indicate that the average Apple consumer was usually more affluent and better educated than other PC company consumers. The research indicated that this correlation could stem from the fact that on average Apple Inc. products are more expensive than other PC products.
In response to a query about the devotion of loyal Apple consumers, Ive responded:
What people are responding to is much bigger than the object. They are responding to something rare — a group of people who do more than simply make something work, they make the very best products they possibly can. It’s a demonstration against thoughtlessness and carelessness.
Corporate affairs.
During the Mac's early history Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since adopted USB, AGP, HyperTransport, Wi-Fi, and other industry standards in its computers and was in some cases a leader in the adoption of standards such as USB. FireWire is an Apple-originated standard that has seen widespread industry adoption after it was standardized as IEEE 1394.
Ever since the first Apple Store opened, Apple has sold third-party accessories. For instance, at one point Nikon and Canon digital cameras were sold inside the store. Adobe, one of Apple's oldest software partners, also sells its Mac-compatible software, as does Microsoft, who sells Microsoft Office for the Mac. Books from John Wiley & Sons, who publishes the "For Dummies" series of instructional books, are a notable exception, however. The publisher's line of books were banned from Apple Stores in 2005 because Steve Jobs disagreed with their decision to publish an unauthorized Jobs biography, "iCon". After the launch of the iBookstore, Apple stopped selling physical books, both online and at the Apple Retail Stores.
Headquarters.
Apple Inc.'s world corporate headquarters are located in the middle of Silicon Valley, at 1–6 Infinite Loop, Cupertino, California. This Apple campus has six buildings that total and was built in 1993 by Sobrato Development Cos.
In 2006, Apple announced its intention to build a second campus on assembled from various contiguous plots (east of N Wolfe Road between Pruneridge Avenue and Vallco Parkway). Later acquisitions increased this to 175 acres. The new campus, also in Cupertino, will be about east of the current campus. The new campus building will be designed by Norman Foster.
On October 15, 2013 it was announced that the Cupertino City Council has approved the proposed "spaceship" design campus. On June 7, 2011, Steve Jobs gave a presentation to Cupertino City Council, detailing the architectural design of the new building and its environs. The new campus is planned to house up to 13,000 employees in one central four-storied circular building (with a café for 3,000 sitting people integrated) surrounded by extensive landscape (with parking mainly underground and the rest centralized in a parking structure). The new campus will be built on the former HP headquarters, next to Interstate 280. The morning of the announcement, Apple CEO Tim Cook tweeted "Our home for innovation and creativity for decades to come. Cupertino City Council Gives Unanimous Approval for Apple's New Campus." The 2.8 million square foot facility, which will include Steve Jobs's original designs for a fitness center and corporate auditorium will be able to house 14,000 employees and will have enough parking to accommodate almost all of them.
Apple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland. The facility, which opened in 1980, was Apple's first location outside of the United States. Apple Sales International, which deals with all of Apple's international sales outside of the USA, is located at Apple's campus in Cork along with Apple Distribution International, which similarly deals with Apple's international distribution network.
On April 20, 2012, Apple announced the addition of 500 new jobs to its European headquarters. This will bring the total workforce from around 2,800 to 3,300 employees. The company will build a new office block on its Hollyhill Campus to accommodate the additional staff.
Corporate culture.
Apple was one of several highly successful companies founded in the 1970s that bucked the traditional notions of what a corporate culture should look like in organizational hierarchy (flat versus tall, casual versus formal attire, etc.). Other highly successful firms with similar cultural aspects from the same period include Southwest Airlines and Microsoft. Originally, the company stood in opposition to staid competitors like IBM by default, thanks to the influence of its founders; Steve Jobs often walked around the office barefoot even after Apple was a Fortune 500 company. By the time of the "1984" TV ad, this trait had become a key way the company attempted to differentiate itself from its competitors. According to a 2011 report in "Fortune," this has resulted in a corporate culture more akin to a startup rather than a multinational corporation.
As the company has grown and been led by a series of chief executives, each with his own idea of what Apple should be, some of its original character has arguably been lost, but Apple still has a reputation for fostering individuality and excellence that reliably draws talented people into its employ. This was especially after Jobs's return. To recognize the best of its employees, Apple created the Apple Fellows program, awarding individuals who made extraordinary technical or leadership contributions to personal computing while at the company. The Apple Fellowship has so far been awarded to a few individuals including Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Al Alcorn, Don Norman, Rich Page, and Steve Wozniak.
Apple is also known for strictly enforcing accountability. Each project has a "directly responsible individual," or "DRI" in Apple jargon. As an example, when iOS senior vice president Scott Forstall refused to sign Apple's official apology for numerous errors in the redesigned Maps app, he was forced to resign.
Numerous employees of Apple have cited that projects without Jobs's involvement often took longer than projects with his involvement.
At Apple, employees are specialists who are not exposed to functions outside their area of expertise. Jobs saw this as a means of having best-in-class employees in every role. For instance, Ron Johnson who was Senior Vice President of Retail Operations until November 1, 2011, was responsible for site selection, in-store service, and store layout, yet he had no control of the inventory in his stores (which is done company wide by then-COO and now CEO Tim Cook who has a background in supply-chain management). This is the opposite of General Electric's corporate culture which has created well-rounded managers.
Under the leadership of Tim Cook, who joined the company in 1998 and ascended to his present position as CEO, Apple has developed an extremely efficient and effective supply chain which has been ranked as the world's best for the four years 2007–2010. The company's manufacturing, procurement and logistics enables it to execute massive product launches without having to maintain large, profit-sapping inventories; Apple's profit margins have been 40 percent compared with 10–20 percent for most other hardware companies in 2011. Cook's catchphrase to describe his focus on the company's operational edge is “Nobody wants to buy sour milk”.
The company previously advertised its products as being made in America up to the late 1990s, however as a result of outsourcing initiatives in the 2000s almost all of its manufacturing is now done abroad. According to a report by the "New York Times", Apple insiders "believe the vast scale of overseas factories as well as the flexibility, diligence and industrial skills of foreign workers have so outpaced their American counterparts that “Made in the U.S.A.” is no longer a viable option for most Apple products".
Unlike other major US companies, Apple has a relatively simple compensation policy for executives, which does not include perks that other CEOs enjoy such as country club fees and private use of company aircraft. The company usually grants stock options to executives every other year.
A media article published in July 2013 provided details about Apple's "At-Home Apple Advisors" customer support program that serves as the corporation's call center. The advisors are employed within the U.S. and work remotely after undergoing a four-week training program that also serves as a testing period. The advisors earn between US$9 and $12 per hour, and receive intensive management to ensure a high quality of customer support.
Litigation.
Apple has been a participant in various legal proceedings and claims since it began operation and, like its competitors and peers, engages in litigation (trying legal cases before the courts) in its normal course of business for a variety of reasons. In particular, Apple is known for and promotes itself as actively and aggressively enforcing its intellectual property interests.
Some examples include Apple v. Samsung, Apple v. Microsoft, Motorola v. Apple, Apple Corps v. Apple Computer.
Finance.
In its fiscal year ending in September 2011, Apple Inc. reported a total of $108 billion in annual revenues – a significant increase from its 2010 revenues of $65 billion – and nearly $82 billion in cash reserves. Apple achieved these results while losing market share in certain product categories. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.
On September 2012, Apple reached a record share price of more than $705 and closed at above 700. With 936,596,000 outstanding shares (as of June 30, 2012), it had a market capitalization of about $660 billion. At the time, this was the highest nominal market capitalization ever reached by a publicly traded company, surpassing a record set by Microsoft in 1999.
Environmental record.
Climate change and clean energy.
On April 21, 2011, Greenpeace released a report highlighting the fact that data centers consumed up to 2% of all global electricity and this amount was projected to increase. Phil Radford of Greenpeace said “we are concerned that this new explosion in electricity use could lock us into old, polluting energy sources instead of the clean energy available today.” On April 17, 2012, following a Greenpeace protest of Apple, Apple Inc. released a statement committing to ending its use of coal and shifting to 100% clean energy. In 2013 Apple announced it was using 100% renewable energy to power their data centers, and overall 75% of its power comes from renewable sources.
In 2010, Climate Counts, a nonprofit organization dedicated to directing consumers toward the greenest companies, gave Apple a score of 52 points out of a possible 100, which puts Apple in their top category "Striding". This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a "stuck icon", adding that Apple at the time was "a choice to avoid for the climate conscious consumer".
Toxics.
Greenpeace has campaigned against Apple because of various environmental issues, including a global end-of-life take-back plan, non-recyclable hardware components and toxins within iPhone hardware. Since 2003 Greenpeace has campaigned against Apple's use of particular chemicals in its products, more specifically, the inclusion of PVC and BFRs in their devices. On May 2, 2007, Steve Jobs released a report announcing plans to eliminate PVC and BFRs by the end of 2008. Apple has since eliminated PVC and BFRs from its product range, becoming the first laptop manufacturer to do so.
In the first edition of the Greenpeace 'Green Electronics Guide', released in August 2006, Apple only scored 2.7/10.
The Environmental Protection Agency rates Apple highest amongst producers of notebooks, and fairly well compared to producers of desktop computers and LCD displays.
In June 2007, Apple upgraded the MacBook Pro, replacing cold cathode fluorescent lamp (CCFL) backlit LCD displays with mercury-free LED backlit LCD displays and arsenic-free glass, and has since done this for all notebooks. Apple has also left out BFRs and PVCs in various internal components. Apple offers information about emissions, materials, and electrical usage concerning each product.
In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, BFRs and had an efficient power adapter.
In October 2009, Apple upgraded the iMac and MacBook, replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays with mercury-free LED backlit LCD displays and arsenic-free glass. This means all Apple computers have mercury free LED backlit displays, arsenic-free glass and are without PVC cables. All Apple computers also have EPEAT Gold status.
In October 2011, Chinese authorities ordered an Apple supplier to close part of its plant in Suzhou after residents living nearby raised significant environmental concerns.
In November 2011, Apple featured in Greenpeace's Guide to Greener Electronics, which ranks electronics manufacturers on sustainability, climate and energy policy, and how "green" their products are. The company ranked fourth of fifteen electronics companies (moving up five places from the previous year) with a score of 4.6/10 down from 4.9. Greenpeace praises Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. It continues to score well on the products rating with all Apple products now being free of PVC vinyl plastic and brominated flame retardants. However, the guide criticizes Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data and for not setting out any targets to reduce emissions. In January 2012, Apple announced plans and requested that their cable maker Volex begin producing halogen-free USB and power cables.
In June 2012, Apple Inc. withdrew its products from the Electronic Product Environmental Assessment Tool (EPEAT) certification system, but reversed this decision in July.
Labor practices.
In 2006, the "Mail on Sunday" reported on the working conditions that existed at factories in China where the contract manufacturers Foxconn and Inventec produced the iPod. The article stated that one complex of factories that assembles the iPod (among other items) had over 200,000 workers that lived and worked in the factory, with employees regularly working more than 60 hours per week. The article also reported that workers made around $100 per month and were required to live pay for rent and food from the company, which generally amounted to a little over half of workers' earnings.
Apple immediately launched an investigation and worked with their manufacturers to ensure acceptable working conditions. In 2007, Apple started yearly audits of all its suppliers regarding worker's rights, slowly raising standards and pruning suppliers that did not comply. Yearly progress reports have been published since 2008. In 2010, workers in China planned to sue iPhone contractors over poisoning by a cleaner used to clean LCD screens. One worker claimed that he and his coworkers had not been informed of possible occupational illnesses. After a spate of suicides in a Foxconn facility in China making iPads and iPhones, albeit at a lower rate than in China as a whole, workers were forced to sign a legally binding document guaranteeing that they would not kill themselves.
In 2011, Apple admitted that its suppliers' child labor practices in China had worsened.
Workers in factories producing Apple products have also been exposed to n-hexane, a neurotoxin that is a cheaper alternative than alcohol for cleaning the products.
In 2013, China Labor Watch said it found violations of the law and of Apple's pledges about working conditions at facilities operated by Pegatron, including discrimination against ethnic minorities and women, withholding employees' pay, excessive work hours, poor living conditions, health and safety problems and pollution.
Tax practices.
Apple created subsidiaries in low-tax places such as the Republic of Ireland, the Netherlands, Luxembourg and the British Virgin Islands to cut the taxes it pays around the world. According to the "New York Times," in the 1980s Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. In the late 1980s Apple was a pioneer of an accounting technique known as the "Double Irish With a Dutch Sandwich," which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean.
British Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple Inc., were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporation tax. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and The Coca-Cola Company, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.
In June 2014 the European Commissioner for Competition launched an investigation of Apple's tax practices in Ireland, as part of a wider probe of multi-national companies' tax arrangements in various European countries.
Charitable causes.
As of 2012, Apple is listed as a partner of the Product RED campaign, together with other brands such as Nike, Girl, American Express and Converse. The campaign's mission is to prevent the transmission of HIV from mother to child by 2015 (its byline is "Fighting For An AIDS Free Generation").
In November 2012, Apple donated $2.5 million to the American Red Cross to aid relief efforts after Hurricane Sandy.

</doc>
<doc id="857" url="http://en.wikipedia.org/wiki?curid=857" title="Aberdeenshire">
Aberdeenshire

Aberdeenshire () is one of the 32 council areas of Scotland, and a lieutenancy area.
The Aberdeenshire council area does not include the City of Aberdeen, a separate council area, from which its name derives. Together, the modern council area and the city form historic Aberdeenshire, one of the counties of Scotland formerly used for local government and still used as a registration county.
Aberdeenshire Council is headquartered at Woodhill House, in Aberdeen, making it the only Scottish council whose headquarters are based outwith its jurisdiction. Aberdeenshire borders Angus and Perth and Kinross to the south, and Highland and Moray to the west.
Traditionally, it has been economically dependent upon the primary sector (agriculture, fishing, and forestry) and related
processing industries. Over the last 40 years, the development of the oil and gas industry and associated service sector has broadened Aberdeenshire's economic base, and contributed to a rapid population growth of some 50%. since 1975, while the land covered represents 8% of Scotland's overall territory. It covers an area of .
History.
Aberdeenshire has a rich prehistoric and historic heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites, including Longman Hill, Kempstone Hill, Catto Long Barrow and Cairn Lee. The area was settled in the Bronze Age by the Beaker culture, who arrived from the south around 2000-1800 BC. Stone circles and cairns are predominantly from this era. In the Iron Age, hill forts were built. Around the 1st century AD, the Taexali people, which have left little history were believed to have resided along the coast. The Picts were the next documented inhabitants of the area, and were no later than 800-900 AD. The Romans also were in the area during this period, as they left signs at Kintore. Christianity influenced the inhabitants early on, and there were Celtic monasteries at Old Deer and Monymusk. Since medieval times there have been a number of crossings of the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.
Aberdeenshire played an important role in the fighting between the Scottish clans. Clan MacBeth and Clan Canmore were 2 of the larger clans. Lumphanan saw Macbeth fall in 1057. During the Anglo-Norman penetration, other families arrives such as House of Balliol, Clan Bruce, and Clan Cumming (Comyn). When the fighting amongst these newcomers resulted in the Scottish Wars of Independence, the English king Edward I traveled across the area twice, in 1296 and 1303. In 1307, Robert the Bruce was victorious near Inverurie. Along with his victory came new families, namely the Forbeses and the Gordons. These new families set the stage for the upcoming rivalries during the 14th and 15th centuries. This rivalry grew worse when religion became a focal point, as the Gordon family adhered to Catholicism and the Forbes to Protestantism. Three universities were founded in the area prior to the 17th century, King's College in Old Aberdeen (1494), Marischal College in Aberdeen (1593), and the University of Fraserburgh (1597).
After the end of the Revolution of 1688, there was a peaceful period, interrupted by minor events such as the Rising of 1715 and the Rising of 1745, which in turn lead to the end of the ascendancy of Episcopalianism, and the feudal power of landowners and in turn lead to the era of increased agricultural and industrial progress. During the 17th century, Aberdeenshire was the location of more fighting, centered around the Marquess of Montrose and the English Civil Wars. This period also saw increased wealth due to the increase in trade with Germany, Poland, and the Low Countries.
The present council area is named after the historic county of Aberdeen, which had different boundaries and was abolished in 1975 under the Local Government (Scotland) Act 1973. It was replaced by Grampian Regional Council and five district councils: Banff and Buchan, Gordon, Kincardine and Deeside, Moray and the City of Aberdeen. The current Aberdeenshire consists of all of former Aberdeenshire, former Kincardineshire and the northeast portions of Banffshire. Local government functions were shared between the two levels. In 1996, under the Local Government etc (Scotland) Act 1994, the Banff and Buchan district, Gordon district and Kincardine and Deeside district were merged to form the present Aberdeenshire council area, with the other two districts becoming autonomous council areas.
Demographics.
The population of the council area has risen over 50% since 1971 to approximately 247,600, representing 4.7% of Scotland's total. Aberdeenshire's population has increased by 9.1% since 2001, while Scotland's total population grew by only 3.8%.
The census lists a relatively high proportion of under 16s and slightly less people of working-age compared with the Scottish average. The twelve biggest settlements in Aberdeenshire (with 2011 population estimates) are:
Economy.
Aberdeenshire's Gross Domestic Product (GDP) is estimated at £3,496m (2011), representing 5.2% of the Scottish total. Aberdeenshire's economy is closely linked to Aberdeen City's (GDP £7,906m) and in 2011 the region as a whole was calculated to contribute 16.8% of Scotland's GDP. Between 2012 and 2014 the combined Aberdeenshire and Aberdeen City economic forecast GDP growth rate is 6.8%, the highest growth rate of any local council area and above the Scottish rate of 4.8%.
A significant proportion of Aberdeenshire's working residents commute to Aberdeen City for work, varying from 11.5% from Fraserburgh to 65% from Westhill.
Average Gross Weekly Earnings (for full-time employees employed in work places in Aberdeenshire in 2011) are £570.60. This is lower than the Scottish average by £4.10 and a fall of 2.6% on the 2010 figure. The average gross weekly pay of people resident in Aberdeenshire is much higher, at £641.90, as many people commute out
of Aberdeenshire, principally into Aberdeen City.
Total employment (excluding farm data) in Aberdeenshire is estimated at 93,700 employees (Business Register and
Employment Survey 2009). The majority of employees work within the service sector, predominantly in public administration, education and health. Almost 19% of employment is within the public sector. Aberdeenshire's economy remains closely linked to Aberdeen City's and the North Sea oil industry, with many employees in oil related jobs.
The average monthly unemployment (claimant count) rate for Aberdeenshire in 2011 was 1.5%. This is lower than the average rates for Aberdeen City (2.3%), Scotland (4.2%) and the UK (3.8%).
Governance and politics.
The council has 68 councillors, elected in 19 multi-member wards by Single Transferable Vote. The 2012 elections resulted in the following representation:
The overall political composition of the council, following subsequent defections and by-elections, is as follows:
The Council's Revenue Budget for 2012/13 totals approx £548 million. The Education, Learning and Leisure Service takes the largest share of budget (52.3%), followed by Housing and Social Work (24.3%), Infrastructure Services (15.9%), Joint Boards (such as Fire and Police) and Misc services (7.9%) and Trading Activities (0.4%).
21.5% of the revenue is raised locally through the Council Tax. Average Band D Council Tax is £1,141 (2012/13), no change on the previous year.
The current chief executive of the Council is Colin D Mackenzie and the elected Council Leader is Jim Gifford. Aberdeenshire also has a Provost, who is Councillor Jill Webster.
The council has devolved power to six area committees: Banff and Buchan; Buchan; Formartine; Garioch; Marr; and Kincardine and Mearns. Each area committee takes decisions on local issues such as planning applications, and the split is meant to reflect the diverse circumstances of each area. (Boundary map)
Notable features.
The following significant structures or places are within Aberdeenshire:
Hydrology and climate.
There are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ury, River Ythan, Water of Feugh, Burn of Myrehouse, Laeca Burn and Luther Water. Numerous bays and estuaries are found along the seacoast of Aberdeenshire, including Banff Bay, Ythan Estuary, Stonehaven Bay and Thornyhive Bay. Aberdeenshire is in the rain shadow of the Grampians, therefore it is a generally dry climate, with portions of the coast, receiving of moisture annually. Summers are mild and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in winter than inland locations. Coastal areas are also subject to haar, or coastal fog.

</doc>
<doc id="859" url="http://en.wikipedia.org/wiki?curid=859" title="Aztlan Underground">
Aztlan Underground

Aztlan Underground is a fusion band from Los Angeles. Since early 1989, Aztlan Underground has played Rapcore. Indigenous drums, flutes, and rattles are commonplace in its musical compositions.
This unique sound is the backdrop for the band's message of dignity for indigenous people, all of humanity, and Earth. Aztlan Underground has been cultivating a grass roots audience across the country, which has become a large and loyal underground following. Their music includes spoken word pieces and elements of punk, hip hop, rock, funk, jazz, and indigenous music, among others.
The artists are Chenek "DJ Bean" (turntables, samples and percussion), Yaotl (vocals, indigenous percussion), Joe "Peps" (bass, rattles), Alonzo Beas (guitars, synth), Caxo (drums, indigenous percussion), and Bulldog (vocals, flute).
Aztlan Underground appeared on television on Culture Clash on Fox in 1993, was part of "Breaking Out", a concert on pay per view in 1998, and was featured in the independent films "Algun Dia" and "Frontierlandia".
The band has been mentioned or featured in various newspapers and magazines: the Vancouver Sun, Northshore News (Vancouver, Canada newspaper), New Times (Los Angeles weekly entertainment newspaper), BLU Magazine (underground hip hop magazine), BAM Magazine (Southern California), La Banda Elastica Magazine, and the Los Angeles Times Calendar section. It is also the subject of a chapter in "It's Not About A Salary", by Brian Cross. They also opened for Rage Against the Machine in Mexico City.
It was nominated in the New Times 1998 "Best Latin Influenced" category, the BAM Magazine 1999 "Best Rock en Español" category, and the LA Weekly 1999 "Best Hip Hop" category.
Aztlan Underground were signed to a Basque record label in 1999 which enabled them to tour Spain extensively and perform in France and Portugal.
Other parts of the world that Aztlan Underground have performed include Canada, Australia, and Venezuela.
The band completed their third album and released it exclusively digital on August 29, 2009. The band is set to begin writing a new record this year.
Aztlan Underground were nominated for four Native American Music Award categories for the Nammys 2010. See Nammys.com
Discography.
"Decolonize".
Year:1995
"Sub-Verses".
Year:1998
"Aztlan Underground".
Year:2009

</doc>
<doc id="863" url="http://en.wikipedia.org/wiki?curid=863" title="American Civil War">
American Civil War

The American Civil War, also known as the War of the Rebellion, War Between the States or simply the American Civil War, was a civil war fought from 1861 to 1865, after seven Southern slave states declared their secession and formed the Confederate States of America (the "Confederacy" or the "South", which grew to include eleven states). The states that remained in the Union were known as the "Union" or the "North". The war had its origin in the fractious issue of slavery, especially the extension of slavery into the western territories. Foreign powers did not intervene. After four years of bloody combat that left over 600,000 Union and Confederate soldiers dead and destroyed much of the South's infrastructure, the Confederacy collapsed, slavery was abolished, and the difficult Reconstruction process of restoring national unity and guaranteeing civil rights to the freed slaves began.
In the 1860 presidential election, Republicans, led by Abraham Lincoln, opposed the expansion of slavery into US territories. Lincoln won, but before his inauguration on March 4, 1861, seven slave states with cotton-based economies formed the Confederacy. The first six to secede had the highest proportions of slaves in their populations, a total of 48.8% for the six. Outgoing Democratic President James Buchanan and the incoming Republicans rejected secession as illegal. Lincoln's inaugural address declared his administration would not initiate civil war. Eight remaining slave states continued to reject calls for secession. Confederate forces seized numerous federal forts within territory claimed by the Confederacy. A peace conference failed to find a compromise, and both sides prepared for war. The Confederates assumed that European countries were so dependent on "King Cotton" that they would intervene; none did and none recognized the new Confederate States of America.
Hostilities began on April 12, 1861, when Confederate forces fired upon Fort Sumter, a key fort held by Union troops in South Carolina. Lincoln called for each state to provide troops to retake the fort; consequently, four more slave states joined the Confederacy, bringing their total to eleven. The Union soon controlled the border states and established a naval blockade that crippled the southern economy. The Eastern Theater was inconclusive in 1861–62. The autumn 1862 Confederate campaign into Maryland (a Union state) ended with Confederate retreat at the Battle of Antietam, dissuading British intervention. Lincoln issued the Emancipation Proclamation, which made ending slavery a war goal. To the west, by summer 1862 the Union destroyed the Confederate river navy, then much of their western armies, and the Union siege of Vicksburg split the Confederacy in two at the Mississippi River. In 1863, Robert E. Lee's Confederate incursion north ended at the Battle of Gettysburg. Western successes led to Ulysses S. Grant's command of all Union armies in 1864. In the Western Theater, William T. Sherman drove east to capture Atlanta and marched to the sea, destroying Confederate infrastructure along the way. The Union marshaled the resources and manpower to attack the Confederacy from all directions, and could afford to fight battles of attrition through the Overland Campaign towards Richmond, the Confederate capital. The defending Confederate army failed, leading to Lee's surrender to Grant at Appomattox Court House on April 9, 1865. All Confederate generals surrendered by that summer.
The American Civil War was one of the earliest true industrial wars. Railroads, the telegraph, steamships, and mass-produced weapons were employed extensively. The mobilization of civilian factories, mines, shipyards, banks, transportation and food supplies all foreshadowed World War I. It remains the deadliest war in American history, resulting in the deaths of an estimated 750,000 soldiers and an undetermined number of civilian casualties. One estimate of the death toll is that ten percent of all Northern males 20–45 years old, and 30 percent of all Southern white males aged 18–40 perished.
Causes of secession.
The causes of the Civil War were complex and have been controversial since the war began. The issue has been further complicated by historical revisionists, who have tried to offer a variety of reasons for the war. Slavery was the central source of escalating political tension in the 1850s. The Republican Party was determined to prevent any spread of slavery, and many Southern leaders had threatened secession if the Republican candidate, Lincoln, won the 1860 election. After Lincoln had won without carrying a single Southern state, many Southern whites felt that disunion had become their only option, because they felt as if they were losing representation, which hampered their ability to promote pro-slavery acts and policies.
Slavery.
The slavery issue was primarily about whether the system of slavery was an anachronistic evil that was incompatible with Republicanism in the United States, or a state-based property system protected by the Constitution. The strategy of the anti-slavery forces was containment — to stop the expansion and thus put slavery on a path to gradual extinction. To slave holding interests in the South, this strategy was perceived as infringing upon their Constitutional rights. Slavery was being phased out of existence in the North and was fading in the border states and urban areas, but was expanding in highly profitable cotton districts of the south.
Despite compromises in 1820 and 1850, the slavery issues exploded in the 1850s. Causes include controversy over admitting Missouri as a slave state in 1820, the acquisition of Texas as a slave state in 1845 and the status of slavery in western territories won as a result of the Mexican–American War and the resulting Compromise of 1850. Following the U.S. victory over Mexico, Northerners attempted to exclude slavery from conquered territories in the Wilmot Proviso; although it passed the House, it failed in the Senate. Northern (and British) readers recoiled in anger at the horrors of slavery as described in the novel and play "Uncle Tom's Cabin" (1852) by abolitionist Harriet Beecher Stowe. Irreconcilable disagreements over slavery ended the Whig and Know Nothing political parties, and later split the Democratic Party between North and South, while the new Republican Party angered slavery interests by demanding an end to its expansion. Most observers believed that without expansion slavery would eventually die out; Lincoln argued this in 1845 and 1858.
Meanwhile, the South of the 1850s saw an increasing number of slaves leave the border states through sale, manumission and escape. During this same period, slave-holding border states had more free African-Americans and European immigrants than the lower South, which increased Southern fears that slavery was threatened with rapid extinction in this area. With tobacco and cotton wearing out the soil, the South believed it needed to expand slavery. Some advocates for the Southern states argued in favor of reopening the international slave trade to populate territory that was to be newly opened to slavery. Southern demands for a slave code to ensure slavery in the territories repeatedly split the Democratic Party between North and South by widening margins.
To settle the dispute over slavery expansion, Abolitionists and proslavery elements sent their partisans into Kansas, both using ballots and bullets. In the 1850s, a miniature civil war in Bleeding Kansas led pro-South Presidents Franklin Pierce and James Buchanan to attempt a forced admission of Kansas as a slave state through vote fraud. The 1857 Congressional rejection of the pro-slavery Lecompton Constitution was the first multi-party solid-North vote, and that solid vote was anti-slavery to support the democratic majority voting in the Kansas Territory. Violence on behalf of Southern honor reached the floor of the Senate in 1856 when a Southern Congressman, Preston Brooks, physically assaulted Republican Senator Charles Sumner when he ridiculed prominent slaveholders as pimps for slavery.
The earlier political party structure failed to make accommodation among sectional differences. Disagreements over slavery caused the Whig and "Know-Nothing" parties to collapse. In 1860, the last national political party, the Democratic Party, split along sectional lines. Anti-slavery Northerners mobilized in 1860 behind moderate Abraham Lincoln because he was most likely to carry the doubtful western states. In 1857, the Supreme Court's "Dred Scott" decision ended the Congressional compromise for Popular Sovereignty in Kansas. According to the court, slavery in the territories was a property right of any settler, regardless of the majority there. Chief Justice Taney's decision said that slaves were "... so far inferior that they had no rights which the white man was bound to respect". The decision overturned the Missouri Compromise, which banned slavery in territory north of the 36°30' parallel.
Republicans denounced the "Dred Scott" decision and promised to overturn it; Abraham Lincoln warned that the next "Dred Scott" decision could threaten the Northern states with slavery. The Republican party platform called slavery "a national evil", and Lincoln believed it would die a natural death if it were contained. The Democrat Stephen A. Douglas developed the Freeport Doctrine to appeal to North and South. Douglas argued, Congress could not decide either for or against slavery before a territory was settled. Nonetheless, the anti-slavery majority in Kansas could stop slavery with its own local laws if their police laws did not protect slavery introduction. Most 1850 political battles followed the arguments of Lincoln and Douglas, focusing on the issue of slavery expansion in the territories.
But political debate was cut short throughout the South with Northern abolitionist John Brown's 1859 raid at Harpers Ferry Armory in an attempt to incite slave insurrections. The Southern political defense of slavery transformed into widespread expansion of local militias for armed defense of their "peculiar" domestic institution. Lincoln's assessment of the political issue for the 1860 elections was that, "This question of Slavery was more important than any other; indeed, so much more important has it become that no other national question can even get a hearing just at present." The Republicans gained majorities in both House and Senate for the first time since the 1856 elections, they were to be seated in numbers that Lincoln might use to govern, a national parliamentary majority even before pro-slavery House and Senate seats were vacated. Meanwhile, Southern Vice President, Alexander Stephens, in the "Cornerstone Speech", declared the new confederate "Constitution has put at rest forever all the agitating questions relating to our peculiar institutions—African slavery as it exists among us—the proper status of the negro in our form of civilization. This was the immediate cause of the late rupture and present revolution." The Republican administration enacted the Confiscation Acts that set conditions for emancipation of slaves prior to the official proclamation of emancipation. Likewise, Lincoln had previously condemned slavery and called for its "extinction."
Considering the relative weight given to causes of the Civil War by contemporary actors, historians such as Chandra Manning argue that both Union and Confederate fighting soldiers believed that slavery caused the Civil War. Union men mainly believed the war was to emancipate the slaves. Confederates fought to protect southern society, and slavery as an integral part of it. Addressing the causes, Eric Foner would relate a historical context with multidimensional political, social and economic variables. The several causes united in the moment by a consolidating nationalism. A social movement that was individualist, egalitarian and perfectionist grew to a political democratic majority attacking slavery, and slavery's defense in the Southern pre-industrial traditional society brought the two sides to war.
States' rights.
Everyone agreed that states had certain rights—but did those rights carry over when a citizen left that state? The Southern position was that citizens of every state had the right to take their property anywhere in the U.S. and not have it taken away—specifically they could bring their slaves anywhere and they would remain slaves. Northerners rejected this "right" because it would violate the right of a free state to outlaw slavery within its borders. Republicans committed to ending the expansion of slavery were among those opposed to any such right to bring slaves and slavery into the free states and territories. The "Dred Scott" Supreme Court decision of 1857 bolstered the Southern case within territories, and angered the North.
Secondly, the South argued that each state had the right to secede—leave the Union—at any time, that the Constitution was a "compact" or agreement among the states. Northerners (including President Buchanan) rejected that notion as opposed to the will of the Founding Fathers who said they were setting up a "perpetual union". Historian James McPherson writes concerning states' rights and other non-slavery explanations:
Sectionalism.
Sectionalism refers to the different economies, social structure, customs and political values of the North and South. It increased steadily between 1800 and 1860 as the North, which phased slavery out of existence, industrialized, urbanized and built prosperous farms, while the deep South concentrated on plantation agriculture based on slave labor, together with subsistence farming for the poor whites. The South expanded into rich new lands in the Southwest (from Alabama to Texas).
However, slavery declined in the border states and could barely survive in cities and industrial areas (it was fading out in cities such as Baltimore, Louisville, and St. Louis), so a South based on slavery was rural and non-industrial. On the other hand, as the demand for cotton grew, the price of slaves soared. Historians have debated whether economic differences between the industrial Northeast and the agricultural South helped cause the war. Most historians now disagree with the economic determinism of historian Charles Beard in the 1920s and emphasize that Northern and Southern economies were largely complementary. While socially different, the sections economically benefited each other.
Fears of slave revolts and abolitionist propaganda made the South militantly hostile to abolitionism. Southerners complained that it was the North that was changing, and was prone to new "isms", while the South remained true to historic republican values of the Founding Fathers (many of whom owned slaves, including Washington, Jefferson, and Madison). Lincoln said that Republicans were following the tradition of the framers of the Constitution (including the Northwest Ordinance and the Missouri Compromise) by preventing expansion of slavery.
In the 1840s and 50s, the issue of accepting slavery (in the guise of rejecting slave-owning bishops and missionaries) split the nation's largest religious denominations (the Methodist, Baptist and Presbyterian churches) into separate Northern and Southern denominations. Industrialization meant that seven European immigrants out of eight settled in the North. The movement of twice as many whites leaving the South for the North as vice versa contributed to the South's defensive-aggressive political behavior.
Protectionism.
Historically, southern slave-holding states, because of their low cost manual labor, had little perceived need for mechanization, and supported having the right to sell cotton and purchase manufactured goods from any nation. Northern states, which had heavily invested in their still-nascent manufacturing, could not compete with the full-fledged industries of Europe in offering high prices for cotton imported from the South and low prices for manufactured exports in return. For this reason, northern manufacturing interests supported tariffs and protectionism while southern planters demanded free trade.
The Democrats in Congress, controlled by Southerners, wrote the tariff laws in the 1830s, 1840s, and 1850s, and kept reducing rates so that the 1857 rates were the lowest since 1816. The South had no complaints but the low rates angered Northern industrialists and factory workers, especially in Pennsylvania, who demanded protection for their growing iron industry. The Whigs and Republicans complained because they favored high tariffs to stimulate industrial growth, and Republicans called for an increase in tariffs in the 1860 election. The increases were finally enacted in 1861 after Southerners resigned their seats in Congress.
Historians in the 1920s emphasized the tariff issue but since the 1950s they have minimized it, noting that few Southerners in 1860–61 said it was of central importance to them. Some secessionist documents do mention the tariff issue, though not nearly as often as the preservation of slavery.
Slave power and free soil.
Antislavery forces in the North identified the "Slave Power" as a direct threat to republican values. They argued that rich slave owners were using political power to take control of the Presidency, Congress and the Supreme Court, thus threatening the rights of the citizens of the North.
"Free soil" was a Northern demand that the new lands opening up in the west be available to independent yeoman farmers and not be bought out by rich slave owners who would buy up the best land and work it with slaves, forcing the white farmers onto marginal lands. This was the basis of the Free Soil Party of 1848, and a main theme of the Republican Party. Free Soilers and Republicans demanded a homestead law that would give government land to settlers; it was defeated by Southerners who feared it would attract to the west European immigrants and poor Southern whites.
Territorial crisis.
Between 1803 and 1854, the United States achieved a vast expansion of territory through purchase, negotiation, and conquest. Of the states carved out of these territories by 1845, all had entered the union as slave states: Louisiana, Missouri, Arkansas, Florida and Texas, as well as the southern portions of Alabama and Mississippi. These were balanced by new free states created within the U.S.' original boundary east of the Mississippi River, and the free state of Iowa in 1846. With the conquest of northern Mexico, including California in 1848, slaveholding interests looked forward to the institution flourishing in much of these lands as well. Southerners also anticipated garnering slaves and slave states in Cuba and Central America. Northern free soil interests vigorously sought to curtail any further expansion of slave soil. It was these territorial disputes that the proslavery and antislavery forces collided over. The Compromise of 1850 over California, tried again to reach some political settlement on these issues.
The existence of slavery in the southern states was far less politically polarizing than the explosive question of the territorial expansion of the institution westward. Moreover, Americans were informed by two well-established readings of the Constitution regarding human bondage: first, that the slave states had complete autonomy over the institution within their boundaries, and second, that the domestic slave trade – trade among the states – was immune to federal interference. The only feasible strategy available to attack slavery was to restrict its expansion into the new territories. Slaveholding interests fully grasped the danger that this strategy posed to them. Both the South and the North drew the same conclusion: "The power to decide the question of slavery for the territories was the power to determine the future of slavery itself."
By 1860, four doctrines had emerged to answer the question of federal control in the territories, and they all claimed they were sanctioned by the Constitution, implicitly or explicitly. Two of the "conservative" doctrines emphasized the written text and historical precedents of the founding document (specifically, the Northwest Ordinance and the Missouri Compromise), while the other two doctrines developed arguments that transcended the Constitution.
The first of these "conservative" theories, represented by the Constitutional Union Party, argued that the historical designation of free and slave apportionments in territories (as done in the Missouri Compromise) should become a Constitutional mandate. The Crittenden Compromise of 1860 was an expression of this view.
The second doctrine of Congressional preeminence, championed by Abraham Lincoln and the Republican Party, insisted that the Constitution did not bind legislators to a policy of balance – that slavery could be excluded altogether (as done in the Northwest Ordinance) in a territory at the discretion of Congress – with one caveat: the due process clause of the Fifth Amendment must apply. In other words, Congress could restrict human bondage, but never establish it. The Wilmot Proviso announced this position in 1846.
Of the two doctrines that rejected federal authority, one was articulated by northern Democrat of Illinois Senator Stephen A. Douglas, and the other by southern Democratic Senator Jefferson Davis of Mississippi and Vice-President John C. Breckinridge of Kentucky.
Douglas proclaimed the doctrine of territorial or "popular" sovereignty, which declared that the settlers in a territory had the same rights as states in the Union to establish or disestablish slavery – a purely local matter. Congress, having created the territory, was barred, according to Douglas, from exercising any authority in domestic matters. To do so would violate historic traditions of self-government, implicit in the US Constitution. The Kansas-Nebraska Act of 1854 legislated this doctrine.
The fourth in this quartet is the theory of state sovereignty ("states' rights"), also known as the "Calhoun doctrine", named after the South Carolinian political theorist and statesman John C. Calhoun. Rejecting the arguments for federal authority or self-government, state sovereignty would empower states to promote the expansion of slavery as part of the Federal Union under the US Constitution – and not merely as an argument for secession. The basic premise was that all authority regarding matters of slavery in the territories resided in each state. The role of the federal government was merely to enable the implementation of state laws when residents of the states entered the territories. The Calhoun doctrine asserted that the federal government in the territories was only the agent of the several sovereign states, and hence incapable of forbidding the bringing into any territory of anything that was legal property in any state. State sovereignty, in other words, gave the laws of the slaveholding states "extra-jurisdictional" effect.
"States' rights" was an ideology formulated and applied as a means of advancing slave state interests through federal authority. As historian Thomas L. Krannawitter points out, the "Southern demand for federal slave protection represented a demand for an unprecedented expansion of federal power."
By 1860, these four doctrines comprised the major ideologies presented to the American public on the matters of slavery, the territories and the US Constitution.
National elections.
Beginning in the American Revolution and accelerating after the War of 1812, the people of the United States grew in their sense of country as an important example to the world of a national republic of political liberty and personal rights. Previous regional independence movements such as the Greek revolt in the Ottoman Empire, division and redivision in the Latin American political map, and the British-French Crimean triumph leading to an interest in redrawing Europe along cultural differences, all conspired to make for a time of upheaval and uncertainty about the basis of the nation-state. In the world of 19th century self-made Americans, growing in prosperity, population and expanding westward, "freedom" could mean personal liberty or property rights. The unresolved difference would cause failure—first in their political institutions, then in their civil life together.
Nationalism and honor.
Nationalism was a powerful force in the early 19th century, with famous spokesmen such as Andrew Jackson and Daniel Webster. While practically all Northerners supported the Union, Southerners were split between those loyal to the entire United States (called "unionists") and those loyal primarily to the southern region and then the Confederacy. C. Vann Woodward said of the latter group, "A great slave society ... had grown up and miraculously flourished in the heart of a thoroughly bourgeois and partly puritanical republic. It had renounced its bourgeois origins and elaborated and painfully rationalized its institutional, legal, metaphysical, and religious defenses ... When the crisis came it chose to fight. It proved to be the death struggle of a society, which went down in ruins." Perceived insults to Southern collective honor included the enormous popularity of "Uncle Tom's Cabin" (1852) and the actions of abolitionist John Brown in trying to incite a slave rebellion in 1859.
While the South moved toward a Southern nationalism, leaders in the North were also becoming more nationally minded, and rejected any notion of splitting the Union. The Republican national electoral platform of 1860 warned that Republicans regarded disunion as treason and would not tolerate it: "We denounce those threats of disunion ... as denying the vital principles of a free government, and as an avowal of contemplated treason, which it is the imperative duty of an indignant people sternly to rebuke and forever silence." The South ignored the warnings: Southerners did not realize how ardently the North would fight to hold the Union together.
Lincoln's election.
The election of Lincoln in November 1860 was the final trigger for secession. Efforts at compromise, including the "Corwin Amendment" and the "Crittenden Compromise", failed.
Southern leaders feared that Lincoln would stop the expansion of slavery and put it on a course toward extinction. The slave states, which had already become a minority in the House of Representatives, were now facing a future as a perpetual minority in the Senate and Electoral College against an increasingly powerful North. Before Lincoln took office in March 1861, seven slave states had declared their secession and joined to form the Confederacy.
Secession and war begins.
Resolves and developments.
Secession of South Carolina.
South Carolina did more to advance nullification and secession than any other Southern state. South Carolina adopted the "Declaration of the Immediate Causes Which Induce and Justify the Secession of South Carolina from the Federal Union" on December 24, 1860. It argued for states' rights for slave owners in the South, but contained a complaint about states' rights in the North in the form of opposition to the Fugitive Slave Act, claiming that Northern states were not fulfilling their federal obligations under the Constitution.
Secession winter.
Before Lincoln took office, seven states had declared their secession from the Union. They established a Southern government, the Confederate States of America on February 4, 1861. They took control of federal forts and other properties within their boundaries with little resistance from outgoing President James Buchanan, whose term ended on March 4, 1861. Buchanan said that the Dred Scott decision was proof that the South had no reason for secession, and that the Union "... was intended to be perpetual," but that, "The power by force of arms to compel a State to remain in the Union," was not among the "... enumerated powers granted to Congress." One quarter of the U.S. Army—the entire garrison in Texas—was surrendered in February 1861 to state forces by its commanding general, David E. Twiggs, who then joined the Confederacy.
As Southerners resigned their seats in the Senate and the House, Republicans were able to pass bills for projects that had been blocked by Southern Senators before the war, including the Morrill Tariff, land grant colleges (the Morill Act), a Homestead Act, a transcontinental railroad (the Pacific Railway Acts),
the National Banking Act and the authorization of United States Notes by the Legal Tender Act of 1862. The Revenue Act of 1861 introduced the income tax to help finance the war.
States align.
Confederate states.
Seven Deep South cotton states seceded by February 1861, starting with South Carolina, Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas. These seven states formed the Confederate States of America (February 4, 1861), with Jefferson Davis as president, and a governmental structure closely modeled on the U.S. Constitution.
Following the attack on Fort Sumter, President Lincoln called for a volunteer army from each state. Within two months, an additional four Southern slave states declared their secession and joined the Confederacy: Virginia, Arkansas, North Carolina and Tennessee. The northwestern portion of Virginia subsequently seceded from Virginia, joining the Union as the new state of West Virginia on June 20, 1863. By the end of 1861, Missouri and Kentucky were effectively under Union control, with Confederate state governments in exile.
Among the ordinances of secession passed by the individual states, those of three – Texas, Alabama, and Virginia – specifically mentioned the plight of the 'slaveholding states' at the hands of northern abolitionists. The rest make no mention of the slavery issue, and are often brief announcements of the dissolution of ties by the legislatures.
However, at least four states – South Carolina,
Mississippi,
Georgia,
and Texas
– also passed lengthy and detailed explanations of their causes for secession, all of which laid the blame squarely on the influence over the northern states of the movement to abolish slavery, something regarded as a Constitutional right by the slaveholding states.
Union states.
Twenty-three states remained loyal to the Union: California, Connecticut, Delaware, Illinois, Indiana, Iowa, Kansas, Kentucky, Maine, Maryland, Massachusetts, Michigan, Minnesota, Missouri, New Hampshire, New Jersey, New York, Ohio, Oregon, Pennsylvania, Rhode Island, Vermont, and Wisconsin. During the war, Nevada and West Virginia joined as new states of the Union. Tennessee and Louisiana were returned to Union military control early in the war.
The territories of Colorado, Dakota, Nebraska, Nevada, New Mexico, Utah, and Washington fought on the Union side. Several slave-holding Native American tribes supported the Confederacy, giving the Indian Territory (now Oklahoma) a small, bloody civil war.
Border states.
The border states in the Union were West Virginia (which separated from Virginia and became a new state), and four of the five northernmost slave states (Maryland, Delaware, Missouri, and Kentucky).
Maryland had numerous pro-Confederate officials who tolerated anti-Union rioting in Baltimore and the burning of bridges. Lincoln responded with martial law and sent in militia units from the North. Before the Confederate government realized what was happening, Lincoln had seized firm control of Maryland and the District of Columbia, by arresting all the prominent secessionists and holding them without trial (they were later released).
In Missouri, an elected convention on secession voted decisively to remain within the Union. When pro-Confederate Governor Claiborne F. Jackson called out the state militia, it was attacked by federal forces under General Nathaniel Lyon, who chased the governor and the rest of the State Guard to the southwestern corner of the state. ("See also: Missouri secession"). In the resulting vacuum, the convention on secession reconvened and took power as the Unionist provisional government of Missouri.
Kentucky did not secede; for a time, it declared itself neutral. When Confederate forces entered the state in September 1861, neutrality ended and the state reaffirmed its Union status, while trying to maintain slavery. During a brief invasion by Confederate forces, Confederate sympathizers organized a secession convention, inaugurated a governor, and gained recognition from the Confederacy. The rebel government soon went into exile and never controlled Kentucky.
After Virginia's secession, a Unionist government in Wheeling asked 48 counties to vote on an ordinance to create a new state on October 24, 1861. A voter turnout of 34% approved the statehood bill (96% approving). The inclusion of 24 secessionist counties in the state and the ensuing guerrilla war engaged about 40,000 Federal troops for much of the war. Congress admitted West Virginia to the Union on June 20, 1863. West Virginia provided about 20,000–22,000 soldiers to both the Confederacy and the Union.
A Unionist secession attempt occurred in East Tennessee, but was suppressed by the Confederacy, which arrested over 3,000 men suspected of being loyal to the Union. They were held without trial.
Beginning the war.
Lincoln's victory in the presidential election of 1860 triggered South Carolina's declaration of secession from the Union in December, and six more states did so by February 1861. A pre-war February Peace Conference of 1861 met in Washington, Lincoln sneaking into town to stay in the Conference's hotel its last three days. The attempt failed at resolving the crisis, but the remaining eight slave states rejected pleas to join the Confederacy following a two-to-one no-vote in Virginia's First Secessionist Convention on April 4, 1861.
Lincoln's policy.
Since December, secessionists with and without state forces had seized Federal Court Houses, U.S. Treasury mints and post offices. Southern governors ordered militia mobilization, seized most of the federal forts and cannon within their boundaries and U.S. armories of infantry weapons. The governors in big-state Republican strongholds of Massachusetts, New York, and Pennsylvania quietly began buying weapons and training militia units themselves. President Buchanan protested seizure of Federal property, but made no military response apart from a failed attempt on January 9, 1861 to resupply Fort Sumter using the ship "Star of the West", which was fired upon by South Carolina forces and turned back before it reached the fort.
On March 4, 1861, Abraham Lincoln was sworn in as President. In his inaugural address, he argued that the Constitution was a "more perfect union" than the earlier Articles of Confederation and Perpetual Union, that it was a binding contract, and called any secession "legally void". He had no intent to invade Southern states, nor did he intend to end slavery where it existed, but said that he would use force to maintain possession of federal property. The government would make no move to recover post offices, and if resisted, mail delivery would end at state lines. Where popular conditions did not allow peaceful enforcement of Federal law, U.S. Marshals and Judges would be withdrawn. No mention was made of bullion lost from U.S. mints in Louisiana, Georgia and North Carolina. In Lincoln's Inaugural, U.S. policy would only collect import duties at its ports, there could be no serious injury to justify revolution in the politics of four years. His speech closed with a plea for restoration of the bonds of union.
The South sent delegations to Washington and offered to pay for the federal properties and enter into a peace treaty with the United States. Lincoln rejected any negotiations with Confederate agents because he claimed the Confederacy was not a legitimate government, and that making any treaty with it would be tantamount to recognition of it as a sovereign government. Secretary of State William Seward who at that time saw himself as the real governor or "prime minister" behind the throne of the inexperienced Lincoln, engaged in unauthorized and indirect negotiations that failed. President Lincoln was determined to hold all remaining Union-occupied forts in the Confederacy, Fort Monroe in Virginia, in Florida, Fort Pickens, Fort Jefferson, and Fort Taylor, and in the cockpit of secession, Charleston, South Carolina's Fort Sumter.
Battle of Fort Sumter.
Ft. Sumter was located in the middle of the harbor of Charleston, South Carolina, where the U.S. forts garrison had withdrawn to avoid incidents with local militias in the streets of the city. Unlike Buchanan who allowed commanders to relinquish possession to avoid bloodshed, Lincoln required Maj. Anderson to hold on until fired upon. Jefferson Davis ordered the surrender of the fort. Anderson gave a conditional reply that the Confederate government rejected, and Davis ordered P. G. T. Beauregard to attack the fort before a relief expedition could arrive. Troops under Beauregard bombarded Fort Sumter on April 12–13, forcing its capitulation. On April 15, Lincoln's Secretary of War then called on Governors for 75,000 volunteers to recapture the fort and other federal property.
Northerners rallied behind Lincoln's call for all the states to send troops to recapture the forts and to preserve the Union, citing presidential powers given by the Militia Acts of 1792. With the scale of the rebellion apparently small so far, Lincoln called for 75,000 volunteers for 90 days. Several Northern governors began to move forces the next day, and Secessionists seized Liberty Arsenal in Liberty, Missouri the next week. Two weeks later, on May 3, 1861, Lincoln called for an additional 42,034 volunteers for a period of three years.
Four states in the middle and upper South had repeatedly rejected Confederate overtures, but now Virginia, Tennessee, Arkansas, and North Carolina refused to send forces against their neighbors, declared their secession, and joined the Confederacy. To reward Virginia, the Confederate capital was moved to Richmond. 
The War.
The Civil War was a contest marked by the ferocity and frequency of battle. Over four years, 237 named battles were fought, and many more minor actions and skirmishes. In the scales of world military history, both sides fighting were characterized by their bitter intensity and high casualties. "The American Civil War was to prove one of the most ferocious wars ever fought". Without geographic objectives, the only target for each side was the enemy's soldier. 
Mobilization.
As the first seven states began organizing a Confederacy in Montgomery, the entire US army numbered 16,000. However, Northern governors had begun to mobilize their militias. The Confederate Congress authorized the new nation up to 100,000 troops sent by governors as early as February. After Fort Sumter, Lincoln called out 75,000 three-month volunteers, by May Jefferson Davis was pushing for 100,000 men under arms for one year or the duration, and that was answered in kind by the U.S. Congress.
In the first year of the war, both sides had far more volunteers than they could effectively train and equip. After the initial enthusiasm faded, reliance on the cohort of young men who came of age every year and wanted to join was not enough. Both sides used a draft law—conscription—as a device to encourage or force volunteering; relatively few were actually drafted and served. The Confederacy passed a draft law in April 1862 for young men aged 18 to 35; overseers of slaves, government officials, and clergymen were exempt. The U.S. Congress followed in July, authorizing a militia draft within a state when it could not meet its quota with volunteers. European immigrants joined the Union Army in large numbers, including 177,000 born in Germany and 144,000 born in Ireland.
When the Emancipation Proclamation went into effect in January 1863, ex-slaves were energetically recruited by the states, and used to meet the state quotas. States and local communities offered higher and higher cash bonuses for white volunteers. Congress tightened the law in March 1863. Men selected in the draft could provide substitutes or, until mid-1864, pay commutation money. Many eligibles pooled their money to cover the cost of anyone drafted. Families used the substitute provision to select which man should go into the army and which should stay home. There was much evasion and overt resistance to the draft, especially in Catholic areas. The great draft riot in New York City in July 1863 involved Irish immigrants who had been signed up as citizens to swell the vote of the city's Democratic political machine, not realizing it made them liable for the draft. Of the 168,649 men procured for the Union through the draft, 117,986 were substitutes, leaving only 50,663 who had their personal services conscripted.
North and South, the draft laws were highly unpopular. An estimated 120,000 men evaded conscription in the North, many of them fleeing to Canada, and another 280,000 Northern soldiers deserted during the war, along with at least 100,000 Southerners, or about 10% all together. However, desertion was a very common event in the 19th century; in the peacetime Army about 15% of the soldiers deserted every year. In the South, many men deserted temporarily to take care of their families, then returned to their units. In the North, "bounty jumpers" enlisted to get the generous bonus, deserted, then went back to a second recruiting station under a different name to sign up again for a second bonus; 141 were caught and executed.
From a tiny frontier force in 1860, in a few years the Union and Confederates armies had grown into the "largest and most efficient armies in the world." European observers at the time dismissed them as amateur and unprofessional, but British historian John Keegan's assessment is that each outmatched the French, Prussian and Russian armies of the time, and but for the Atlantic, would have threatened any of them with defeat.
Motivation.
Perman and Taylor (2010) say that historians are of two minds on why millions of men seemed so eager to fight, suffer and die over four years:
Prisoners.
At the start of the civil war a system of paroles operated. Captives agreed not to fight until they were officially exchanged. Meanwhile they were held in camps run by their own army where they were paid but not allowed to perform any military duties. The system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. After that about 56,000 of the 409,000 POWs died in prisons during the War, accounting for nearly 10% of the conflict's fatalities.
Naval war.
The small U.S. Navy of 1861 was rapidly enlarged to 6,000 officers and 45,000 men in 1865, with 671 vessels, having a tonnage of 510,396. Its mission was to blockade Confederate ports, take control of the river system, defend against Confederate raiders on the high seas, and be ready for a possible war with the British Royal Navy. Meanwhile, the main riverine war was fought in the West, where a series of major rivers gave access to the Confederate heartland, if the U.S. Navy could take control. In the East, the Navy supplied and moved army forces about, and occasionally shelled Confederate installations.
Union blockade.
By early 1861, General Winfield Scott had devised the Anaconda Plan to win the war with as little bloodshed as possible. Scott argued that a Union blockade of the main ports would weaken the Confederate economy. Lincoln adopted parts of the plan, but he overruled Scott's caution about 90-day volunteers. Public opinion however demanded an immediate attack by the army to capture Richmond.
In April 1861, Lincoln announced the Union blockade of all Southern ports; commercial ships could not get insurance and regular traffic ended. The South blundered in embargoing cotton exports in 1861 before the blockade was effective; by the time they realized the mistake it was too late. "King Cotton" was dead, as the South could export less than 10% of its cotton. The blockade shut down the ten Confederate seaports with railheads that moved almost all the cotton, especially New Orleans, Mobile, and Charleston. By June 1861, warships were stationed off the principal Southern ports, and a year later nearly 300 ships were in service.
Modern navy evolves.
The Civil War prompted the industrial revolution and subsequently many naval innovations emerged during this time, most notably the advent of the ironclad warship. It began when the Confederacy, knowing they had to meet or match the Union's naval superiority, responded to the Union blockade by building or converting more than 130 vessels, including twenty-six ironclads and floating batteries. Only half of these saw active service. Many were equipped with ram bows, creating "ram fever" among Union squadrons wherever they threatened. But in the face of overwhelming Union superiority and the Union's own ironclad warships, they were unsuccessful.
The Confederacy experimented with a submarine, which did not work well, and with building an ironclad ship, the CSS "Virginia", which was based on rebuilding a sunken Union ship, the "Merrimac". On its first foray on March 8, 1862, the "Virginia" decimated the Union's wooden fleet, but the next day the first Union ironclad, the USS "Monitor", arrived to challenge it. The Battle of the Ironclads was a draw, but it marks the worldwide transition to ironclad warships.
The Confederacy lost the "Virginia" when the ship was scuttled to prevent capture, and the Union built many copies of the "Monitor". Lacking the technology to build effective warships, the Confederacy attempted to obtain warships from Britain.
Blockade runners.
British investors built small, very fast, steam-driven blockade runners that traded arms and luxuries brought in from Britain through Bermuda, Cuba, and the Bahamas in return for high-priced cotton. The ships were so small that only a small amount of cotton went out. When the Union Navy seized a blockade runner, the ship and cargo were condemned as a Prize of war and sold with the proceeds given to the Navy sailors; the captured crewmen were mostly British and they were simply released. The Southern economy nearly collapsed during the war. There were multiple reasons for this: the severe deterioration of food supplies, especially in cities, the failure of Southern railroads, the loss of control of the main rivers, foraging by Northern armies, and the seizure of animals and crops by Confederate armies. Historians agree that the blockade was a major factor in ruining the Confederate economy. However, Wise argues that they provided just enough of a lifeline to allow Lee to continue fighting for additional months, thanks to fresh supplies of 400,000 rifles, lead, blankets, and boots that the homefront economy could no longer supply.
Economic impact.
Surdam argues that the blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives in combat. Practically, the entire Confederate cotton crop was useless (although was sold to Union traders), costing the Confederacy its main source of income. Critical imports were very scarce and the coastal trade was largely ended as well. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried it. Merchant ships owned in Europe could not get insurance and were too slow to evade the blockade; they simply stopped calling at Confederate ports.
To fight an offensive war the Confederacy purchased ships from Britain, converted them to warships, and raided American merchants ships in the Atlantic and Pacific oceans. Insurance rates skyrocketed and the American flag virtually disappeared from international waters. However, the same ships were reflagged with European flags and continued unmolested. After the war, the U.S. demanded that Britain pay for the damage done, and Britain paid the U.S. $15 million in 1871.
Rivers.
The 1862 Union strategy called for simultaneous advances along four axes. McClellan would lead the main thrust in Virginia towards Richmond. Ohio forces were to advance through Kentucky into Tennessee, the Missouri Department would drive south along the Mississippi River, and the westernmost attack would originate from Kansas.
Ulysses Grant used river transport and Andrew Foote's gunboats of the Western Flotilla to threaten the Confederacy's "Gibraltar of the West" at Columbus, Kentucky. Grant was rebuffed at Belmont, but cut off Columbus. The Confederates, lacking their own gunboats, were forced to retreat and the Union took control of western Kentucky in March 1862.
In addition to ocean-going warships coming up the Mississippi, the Union Navy used timberclads, tinclads, and armored gunboats. Shipyards at Cairo, Illinois, and St. Louis built new boats or modified steamboats for action. They took control of the Red, Tennessee, Cumberland, Mississippi, and Ohio rivers after victories at Fort Henry and Fort Donelson, and supplied Grant's forces as he moved into Tennessee. At Shiloh, (Pittsburg Landing) in Tennessee in April 1862, the Confederates made a surprise attack that pushed Union forces against the river as night fell. Overnight, the Navy landed additional reinforcements, and Grant counter-attacked. Grant and the Union won a decisive victory – the first battle with the high casualty rates that would repeat over and over. Memphis fell to Union forces and became a key base for further advances south along the Mississippi River. In April 1862, US Naval forces under Farragut ran past Confederate defenses south of New Orleans. Confederates abandoned the city, which gave the Union a critical anchor in the deep South.
Naval forces assisted Grant in his long, complex campaign that resulted in the surrender of Vicksburg in July 1863, and full Union control of the Mississippi soon after.
Eastern theater.
Because of the fierce resistance of a few initial Confederate forces at Manassas, Virginia, in July 1861, a march by Union troops under the command of Maj. Gen. Irvin McDowell on the Confederate forces there was halted in the First Battle of Bull Run, or "First Manassas". McDowell's troops were forced back to Washington, D.C., by the Confederates under the command of Generals Joseph E. Johnston and P. G. T. Beauregard. It was in this battle that Confederate General Thomas Jackson received the nickname of "Stonewall" because he stood like a stone wall against Union troops.
Alarmed at the loss, and in an attempt to prevent more slave states from leaving the Union, the U.S. Congress passed the Crittenden-Johnson Resolution on July 25 of that year, which stated that the war was being fought to preserve the Union and not to end slavery.
Maj. Gen. George B. McClellan took command of the Union Army of the Potomac on July 26 (he was briefly general-in-chief of all the Union armies, but was subsequently relieved of that post in favor of Maj. Gen. Henry W. Halleck), and the war began in earnest in 1862. Upon the strong urging of President Lincoln to begin offensive operations, McClellan attacked Virginia in the spring of 1862 by way of the peninsula between the York River and James River, southeast of Richmond. Although McClellan's army reached the gates of Richmond in the Peninsula Campaign, Johnston halted his advance at the Battle of Seven Pines, then General Robert E. Lee and top subordinates James Longstreet and Stonewall Jackson defeated McClellan in the Seven Days Battles and forced his retreat. The Northern Virginia Campaign, which included the Second Battle of Bull Run, ended in yet another victory for the South. McClellan resisted General-in-Chief Halleck's orders to send reinforcements to John Pope's Union Army of Virginia, which made it easier for Lee's Confederates to defeat twice the number of combined enemy troops.
Emboldened by Second Bull Run, the Confederacy made its first invasion of the North. General Lee led 45,000 men of the Army of Northern Virginia across the Potomac River into Maryland on September 5. Lincoln then restored Pope's troops to McClellan. McClellan and Lee fought at the Battle of Antietam near Sharpsburg, Maryland, on September 17, 1862, the bloodiest single day in United States military history. Lee's army, checked at last, returned to Virginia before McClellan could destroy it. Antietam is considered a Union victory because it halted Lee's invasion of the North and provided an opportunity for Lincoln to announce his Emancipation Proclamation.
When the cautious McClellan failed to follow up on Antietam, he was replaced by Maj. Gen. Ambrose Burnside. Burnside was soon defeated at the Battle of Fredericksburg on December 13, 1862, when over 12,000 Union soldiers were killed or wounded during repeated futile frontal assaults against Marye's Heights. After the battle, Burnside was replaced by Maj. Gen. Joseph Hooker.
Hooker, too, proved unable to defeat Lee's army; despite outnumbering the Confederates by more than two to one, he was humiliated in the Battle of Chancellorsville in May 1863. Gen. Stonewall Jackson was mortally wounded by his own men during the battle and subsequently died of complications. Gen. Hooker was replaced by Maj. Gen. George Meade during Lee's second invasion of the North, in June. Meade defeated Lee at the Battle of Gettysburg (July 1 to 3, 1863). This was the bloodiest battle of the war, and has been called the war's turning point. Pickett's Charge on July 3 is often considered the high-water mark of the Confederacy because it signaled the collapse of serious Confederate threats of victory. Lee's army suffered 28,000 casualties (versus Meade's 23,000). However, Lincoln was angry that Meade failed to intercept Lee's retreat, and after Meade's inconclusive fall campaign, Lincoln turned to the Western Theater for new leadership. At the same time, the Confederate stronghold of Vicksburg surrendered, giving the Union control of the Mississippi River, permanently isolating the western Confederacy, and producing the new leader Lincoln needed, Ulysses S. Grant.
Western theater.
While the Confederate forces had numerous successes in the Eastern Theater, they were defeated many times in the West. They were driven from Missouri early in the war as a result of the Battle of Pea Ridge. Leonidas Polk's invasion of Columbus, Kentucky ended Kentucky's policy of neutrality and turned that state against the Confederacy. Nashville and central Tennessee fell to the Union early in 1862, leading to attrition of local food supplies and livestock and a breakdown in social organization.
The Mississippi was opened to Union traffic to the southern border of Tennessee with the taking of Island No. 10 and New Madrid, Missouri, and then Memphis, Tennessee. In April 1862, the Union Navy captured New Orleans, which allowed Union forces to begin moving up the Mississippi. Only the fortress city of Vicksburg, Mississippi, prevented Union control of the entire river.
General Braxton Bragg's second Confederate invasion of Kentucky ended with a meaningless victory over Maj. Gen. Don Carlos Buell at the Battle of Perryville, although Bragg was forced to end his attempt at invading Kentucky and retreat due to lack of support for the Confederacy in that state. Bragg was narrowly defeated by Maj. Gen. William Rosecrans at the Battle of Stones River in Tennessee.
The one clear Confederate victory in the West was the Battle of Chickamauga. Bragg, reinforced by Lt. Gen. James Longstreet's corps (from Lee's army in the east), defeated Rosecrans, despite the heroic defensive stand of Maj. Gen. George Henry Thomas. Rosecrans retreated to Chattanooga, which Bragg then besieged.
The Union's key strategist and tactician in the West was Ulysses S. Grant, who won victories at Forts Henry and Donelson (by which the Union seized control of the Tennessee and Cumberland Rivers); the Battle of Shiloh; and the Battle of Vicksburg, which cemented Union control of the Mississippi River and is considered one of the turning points of the war. Grant marched to the relief of Rosecrans and defeated Bragg at the Third Battle of Chattanooga, driving Confederate forces out of Tennessee and opening a route to Atlanta and the heart of the Confederacy.
Trans-Mississippi.
Extensive guerrilla warfare characterized the trans-Mississippi region, as the Confederacy lacked the troops and the logistics to support regular armies that could challenge Union control. Roving Confederate bands such as Quantrill's Raiders terrorized the countryside, striking both military installations and civilian settlements. The "Sons of Liberty" and "Order of the American Knights" attacked pro-Union people, elected officeholders, and unarmed uniformed soldiers. These partisans could not be entirely driven out of the state of Missouri until an entire regular Union infantry division was engaged.
By 1864, these violent activities harmed the nationwide anti-war movement organizing against the re-election of Lincoln. Missouri not only stayed in the Union, Lincoln took 70 percent of the vote for re-election.
Numerous small-scale military actions south and west of Missouri sought to control Indian Territory and New Mexico Territory for the Union. The Union repulsed Confederate incursions into New Mexico in 1862, and the exiled Arizona government withdrew into Texas. In the Indian Territory, civil war broke out inside the tribes. About 12,000 Indian warriors fought for the Confederacy, and smaller numbers for the Union. The most prominent Cherokee was Brigadier General Stand Watie, the last Confederate general to surrender.
After the fall of Vicksburg in July 1863, General Kirby Smith in Texas was informed by Jefferson Davis that he could expect no further help from east of the Mississippi River. Although he lacked resources to beat Union armies, he built up a formidable arsenal at Tyler, along with his own Kirby Smithdom economy, a virtual "independent fiefdom" in Texas, including railroad construction and international smuggling. The Union in turn did not directly engage him. Its 1864 Red River Campaign to take Shreveport, Louisiana was a failure and Texas remained in Confederate hands throughout the war.
End of war.
Conquest of Virginia.
At the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac, and put Maj. Gen. William Tecumseh Sherman in command of most of the western armies. Grant understood the concept of total war and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would end the war. This was total war not in terms of killing civilians but rather in terms of destroying homes, farms, and railroads. Grant devised a coordinated strategy that would strike at the entire Confederacy from multiple directions. Generals George Meade and Benjamin Butler were ordered to move against Lee near Richmond, General Franz Sigel (and later Philip Sheridan) were to attack the Shenandoah Valley, General Sherman was to capture Atlanta and march to the sea (the Atlantic Ocean), Generals George Crook and William W. Averell were to operate against railroad supply lines in West Virginia, and Maj. Gen. Nathaniel P. Banks was to capture Mobile, Alabama.
Union forces in the East attempted to maneuver past Lee and fought several battles during that phase ("Grant's Overland Campaign") of the Eastern campaign. Grant's battles of attrition at the Wilderness, Spotsylvania, and Cold Harbor resulted in heavy Union losses, but forced Lee's Confederates to fall back repeatedly. An attempt to outflank Lee from the south failed under Butler, who was trapped inside the Bermuda Hundred river bend. Grant was tenacious and, despite astonishing losses (over 65,000 casualties in seven weeks), kept pressing Lee's Army of Northern Virginia back to Richmond. He pinned down the Confederate army in the Siege of Petersburg, where the two armies engaged in trench warfare for over nine months.
Grant finally found a commander, General Philip Sheridan, aggressive enough to prevail in the Valley Campaigns of 1864. Sheridan was initially repelled at the Battle of New Market by former U.S. Vice President and Confederate Gen. John C. Breckinridge. The Battle of New Market was the Confederacy's last major victory of the war. After redoubling his efforts, Sheridan defeated Maj. Gen. Jubal A. Early in a series of battles, including a final decisive defeat at the Battle of Cedar Creek. Sheridan then proceeded to destroy the agricultural base of the Shenandoah Valley, a strategy similar to the tactics Sherman later employed in Georgia.
Meanwhile, Sherman maneuvered from Chattanooga to Atlanta, defeating Confederate Generals Joseph E. Johnston and John Bell Hood along the way. The fall of Atlanta on September 2, 1864, guaranteed the reelection of Lincoln as president. Hood left the Atlanta area to swing around and menace Sherman's supply lines and invade Tennessee in the Franklin-Nashville Campaign. Union Maj. Gen. John Schofield defeated Hood at the Battle of Franklin, and George H. Thomas dealt Hood a massive defeat at the Battle of Nashville, effectively destroying Hood's army.
Leaving Atlanta, and his base of supplies, Sherman's army marched with an unknown destination, laying waste to about 20% of the farms in Georgia in his "March to the Sea". He reached the Atlantic Ocean at Savannah, Georgia in December 1864. Sherman's army was followed by thousands of freed slaves; there were no major battles along the March. Sherman turned north through South Carolina and North Carolina to approach the Confederate Virginia lines from the south, increasing the pressure on Lee's army.
Lee's army, thinned by desertion and casualties, was now much smaller than Grant's. Union forces won a decisive victory at the Battle of Five Forks on April 1, forcing Lee to evacuate Petersburg and Richmond. The Confederate capital fell to the Union XXV Corps, composed of black troops. The remaining Confederate units fled west and after a defeat at Sayler's Creek, it became clear to Robert E. Lee that continued fighting against the United States was both tactically and logistically impossible.
Confederacy surrenders.
Lee surrendered his Army of Northern Virginia on April 9, 1865, at the McLean House in the village of Appomattox Court House.
In an untraditional gesture and as a sign of Grant's respect and anticipation of peacefully restoring Confederate states to the Union, Lee was permitted to keep his sword and his horse, Traveller. On April 14, 1865, President Lincoln was shot by John Wilkes Booth, a Southern sympathizer. Lincoln died early the next morning, and Andrew Johnson became the president. Meanwhile, Confederate forces across the South surrendered as news of Lee's surrender reached them. President Johnson officially declared a virtual end to the insurrection on May 9, 1865, Confederate President Jefferson Davis was captured the following day. On June 23, 1865, Cherokee leader Stand Watie was the last Confederate General to surrender his forces.
Diplomacy.
Europe in the 1860s was more fragmented than it had been since before the American Revolution. France was in a weakened state while Britain was still shocked by its own poor performance in the Crimean War. France was unable or unwilling to support either side without Britain, where popular support remained with the Union though elite opinion was more varied. They were further distracted by Germany and Italy, who were experiencing unification troubles, and by Russia, who was almost unflinching in their support for the Union.
Though the Confederacy hoped that Britain and France would join them against the Union, this was never likely, and so they instead tried to bring Britain and France in as mediators. The Union, under Lincoln and Secretary of State William H. Seward worked to block this, and threatened war if any country officially recognized the existence of the Confederate States of America. In 1861, Southerners voluntarily embargoed cotton shipments, hoping to start an economic depression in Europe that would force Britain to enter the war in order to get cotton, but this did not work. Worse, Europe developed other cotton suppliers, which they found superior, hindering the South's recovery after the war.
Cotton diplomacy proved a failure as Europe had a surplus of cotton, while the 1860–62 crop failures in Europe made the North's grain exports of critical importance. It also helped to turn European opinion further away from the Confederacy. It was said that "King Corn was more powerful than King Cotton", as U.S. grain went from a quarter of the British import trade to almost half. When Britain did face a cotton shortage, it was temporary, being replaced by increased cultivation in Egypt and India. Meanwhile, the war created employment for arms makers, ironworkers, and British ships to transport weapons.
Charles Francis Adams proved particularly adept as minister to Britain for the U.S. and Britain was reluctant to boldly challenge the blockade. The Confederacy purchased several warships from commercial ship builders in Britain. The most famous, the CSS "Alabama", did considerable damage and led to serious postwar disputes. However, public opinion against slavery created a political liability for European politicians, especially in Britain (which had abolished slavery in her colonies in 1834).
War loomed in late 1861 between the U.S. and Britain over the Trent Affair, involving the U.S. Navy's boarding of a British mail steamer to seize two Confederate diplomats. However, London and Washington were able to smooth over the problem after Lincoln released the two. In 1862, the British considered mediation—though even such an offer would have risked war with the U.S. Lord Palmerston reportedly read "Uncle Tom's Cabin" three times when deciding on this.
The Union victory in the Battle of Antietam caused them to delay this decision. The Emancipation Proclamation over time would reinforce the political liability of supporting the Confederacy. Despite sympathy for the Confederacy, France's own seizure of Mexico ultimately deterred them from war with the Union. Confederate offers late in the war to end slavery in return for diplomatic recognition were not seriously considered by London or Paris. After 1863, the Polish revolt against Russia further distracted the European powers, and ensured that they would remain neutral.
Victory and aftermath.
Results.
The causes of the war, the reasons for its outcome, and even the name of the war itself are subjects of lingering contention today. The North and West grew rich while the once-rich South became poor for a century. The national political power of the slaveowners and rich southerners ended. Historians are less sure about the results of the postwar Reconstruction, especially regarding the second class citizenship of the Freedmen and their poverty. The Freedmen did indeed get their freedom, their citizenship, and control of their lives, their families and their churches.
Historians have debated whether the Confederacy could have won the war. Most scholars, such as James McPherson, argue that Confederate victory was at least possible. McPherson argues that the North's advantage in population and resources made Northern victory likely but not guaranteed. He also argues that if the Confederacy had fought using unconventional tactics, they would have more easily been able to hold out long enough to exhaust the Union.
Confederates did not need to invade and hold enemy territory to win, but only needed to fight a defensive war to convince the North that the cost of winning was too high. The North needed to conquer and hold vast stretches of enemy territory and defeat Confederate armies to win. The Confederacy sought to win independence by out-lasting Lincoln; however, after Atlanta fell and Lincoln defeated McClellan in the election of 1864, all hope for a political victory for the South ended. At that point, Lincoln had secured the support of the Republicans, War Democrats, the border states, emancipated slaves, and the neutrality of Britain and France. By defeating the Democrats and McClellan, he also defeated the Copperheads and their peace platform.
Many scholars argue that the Union held an insurmountable long-term advantage over the Confederacy in terms of industrial strength and population. Confederate actions, they argue, only delayed defeat. Civil War historian Shelby Foote expressed this view succinctly: "I think that the North fought that war with one hand behind its back ... If there had been more Southern victories, and a lot more, the North simply would have brought that other hand out from behind its back. I don't think the South ever had a chance to win that War."
A minority view among historians is that the Confederacy lost because, as E. Merton Coulter put it,"people did not will hard enough and long enough to win." The black Marxist historian Armstead Robinson agrees, pointing to a class conflict in the Confederates army between the slave owners and the larger number of non-owners. He argues that the non-owner soldiers grew embittered about fighting to preserve slavery, and fought less enthusiastically. He attributes the major Confederate defeats in 1863 at Vicksburg and Missionary Ridge to this class conflict. However, most historians reject the argument. James M. McPherson, after reading thousands of letters written by Confederate soldiers, found very strong patriotism that continued to the end; they truly believed they were fighting for freedom and liberty. Even as the Confederacy was visibly collapsing in 1864-5, he says most Confederate soldiers were fighting hard. Historian Gary Gallagher cites General Sherman who in early 1864 commented, "The devils seem to have a determination that cannot but be admired." Despite their loss of slaves and wealth, with starvation looming, Sherman continued, "yet I see no sign of let up – some few deserters – plenty tired of war, but the masses determined to fight it out."
Also important were Lincoln's eloquence in rationalizing the national purpose and his skill in keeping the border states committed to the Union cause. Although Lincoln's approach to emancipation was slow, the Emancipation Proclamation was an effective use of the President's war powers. The Confederate government failed in its attempt to get Europe involved in the war militarily, particularly Britain and France. Southern leaders needed to get European powers to help break up the blockade the Union had created around the Southern ports and cities.
Lincoln's naval blockade was 95% effective at stopping trade goods; as a result, imports and exports to the South declined significantly. The abundance of European cotton and Britain's hostility to the institution of slavery, along with Lincoln's Atlantic and Gulf of Mexico naval blockades, severely decreased any chance that either Britain or France would enter the war.
Costs.
The war produced about 1,030,000 casualties (3% of the population), including about 620,000 soldier deaths—two-thirds by disease, and 50,000 civilians. Binghamton University historian J. David Hacker believes the number of soldier deaths was approximately 750,000, 20% higher than traditionally estimated, and possibly as high as 850,000. The war accounted for roughly as many American deaths as all American deaths in other U.S. wars combined.
Based on 1860 census figures, 8% of all white males aged 13 to 43 died in the war, including 6% in the North and 18% in the South. About 56,000 soldiers died in prison camps during the War. An estimated 60,000 men lost limbs in the war.
Confederate death toll estimates vary considerably. Union army dead, amounting to 15% of the over two million who served, was broken down as follows:
Black troops accounted for 10% of the Union death toll, they amounted to 15% of disease deaths but less than 3% of those killed in battle.
Losses can be viewed as high considering that the defeat of Mexico in 1846–48 resulted in fewer than 2,000 soldiers killed in battle. One reason for the high number of battle deaths during the war was the use of Napoleonic tactics, such as charging. With the advent of more accurate rifled barrels, Minié balls and (near the end of the war for the Union army) repeating firearms such as the Spencer Repeating Rifle and the Henry Repeating Rifle, soldiers were mowed down when standing in lines in the open. This led to the adoption of trench warfare, a style of fighting that defined the better part of World War I.
The wealth amassed in slaves and slavery for the Confederacy's 3.5 million blacks effectively ended when Union armies arrived; they were nearly all freed by the Emancipation Proclamation. Slaves in the border states and those located in some former Confederate territory occupied prior to the Emancipation Proclamation were freed by state action or (on December 18, 1865) by the Thirteenth Amendment.
The war destroyed much of the wealth that had existed in the South. All accumulated investment Confederate bonds was forfeit; most banks and railroads were bankrupt. Income per person in the South dropped to less than 40% of that of the North, a condition that lasted until well into the 20th century. Southern influence in the US federal government, previously considerable, was greatly diminished until the latter half of the 20th century. The full restoration of the Union was the work of a highly contentious postwar era known as Reconstruction.
Emancipation.
Issue of Slavery During the War.
While not all Southerners saw themselves as fighting to preserve slavery, most of the officers and over a third of the rank and file in Lee's army had close family ties to slavery. To Northerners, in contrast, the motivation was primarily to preserve the Union, not to abolish slavery. Abraham Lincoln consistently made preserving the Union the central goal of the war, though he increasingly saw slavery as a crucial issue and made ending it an additional goal. Lincoln's decision to issue the Emancipation Proclamation angered both Peace Democrats ("Copperheads") and War Democrats, but energized most Republicans. By warning that free blacks would flood the North, Democrats made gains in the 1862 elections, but they did not gain control of Congress. The Republicans' counterargument that slavery was the mainstay of the enemy steadily gained support, with the Democrats losing decisively in the 1863 elections in the northern state of Ohio when they tried to resurrect anti-black sentiment.
Emancipation Proclamation.
The Emancipation Proclamation enabled African-Americans, both free blacks and escaped slaves, to join the Union Army. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of fundamentally undermining the legitimacy of slavery.
During the Civil War, sentiment concerning slaves, enslavement and emancipation in the United States was divided. In 1861, Lincoln worried that premature attempts at emancipation would mean the loss of the border states, and that "to lose Kentucky is nearly the same as to lose the whole game." Copperheads and some War Democrats opposed emancipation, although the latter eventually accepted it as part of total war needed to save the Union.
At first, Lincoln reversed attempts at emancipation by Secretary of War Simon Cameron and Generals John C. Frémont (in Missouri) and David Hunter (in South Carolina, Georgia and Florida) to keep the loyalty of the border states and the War Democrats. Lincoln warned the border states that a more radical type of emancipation would happen if his gradual plan based on compensated emancipation and voluntary colonization was rejected. But only the District of Columbia accepted Lincoln's gradual plan, which was enacted by Congress. When Lincoln told his cabinet about his proposed emancipation proclamation, Seward advised Lincoln to wait for a victory before issuing it, as to do otherwise would seem like "our last shriek on the retreat". Lincoln laid the groundwork for public support in an open letter published letter to abolitionist Horace Greeley's newspaper.
In September 1862, the Battle of Antietam provided this opportunity, and the subsequent War Governors' Conference added support for the proclamation. Lincoln issued his preliminary Emancipation Proclamation on September 22, 1862, and his final Emancipation Proclamation on January 1, 1863. In his letter to Albert G. Hodges, Lincoln explained his belief that "If slavery is not wrong, nothing is wrong ... And yet I have never understood that the Presidency conferred upon me an unrestricted right to act officially upon this judgment and feeling ... I claim not to have controlled events, but confess plainly that events have controlled me." 
Lincoln's moderate approach succeeded in inducing border states, War Democrats and emancipated slaves to fight for the Union. The Union-controlled border states (Kentucky, Missouri, Maryland, Delaware and West Virginia) and Union controlled regions around New Orleans, Norfolk and elsewhere, were not covered by the Emancipation Proclamation. All abolished slavery on their own, except Kentucky and Delaware.
Since the Emancipation Proclamation was based on the President's war powers, it only included territory held by Confederates at the time. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. The Emancipation Proclamation greatly reduced the Confederacy's hope of getting aid from Britain or France. By late 1864, Lincoln was playing a leading role in getting Congress to vote for the Thirteenth Amendment, which made emancipation universal and permanent.
Texas v. White.
In "Texas v. White", the United States Supreme Court ruled that Texas had remained a state ever since it first joined the Union, despite claims that it joined the Confederate States of America; the court further held that the Constitution did not permit states to unilaterally secede from the United States, and that the ordinances of secession, and all the acts of the legislatures within seceding states intended to give effect to such ordinances, were "absolutely null", under the constitution.
Reconstruction.
Reconstruction began during the war, with the Emancipation Proclamation of January 1, 1863 and continued to 1877. It comprised multiple complex methods to resolve the war, the most important of which were the three "Reconstruction Amendments" to the Constitution, which remain in effect to the present time: the 13th (1865), the 14th (1868) and the 15th (1870). From the Union perspective, the goals of Reconstruction were to guarantee the Union victory on the battlefield by reuniting the Union; to guarantee a "republican form of government for the ex-Confederate states; and to permanently end slavery—and prevent semi-slavery status.
President Johnson took a lenient approach and saw the achievement of the main war goals as realized in 1865, when each ex-rebel state repudiated secession and ratified the Thirteenth Amendment. Radical Republicans demanded strong proof that Confederate nationalism was dead and the slaves were truly free. They came to the fore after the 1866 elections and undid much of Johnson's work. They used the Army to dissolve Southern state governments and hold new elections with Freedmen voting. The result was a Republican coalition that took power in ten states for varying lengths of time, staying in power with the help of U.S. Army units and black voters. Grant was elected president in 1868 and continued the Radical policies. Meanwhile the Freedmen's Bureau, started by Lincoln in 1865 to help the freed slaves, played a major role in helping the blacks and arranging work for them. In opposition paramilitary groups such as the first Ku Klux Klan used violence to thwart these efforts.
The "Liberal Republicans" argued the war goals had been achieved and Reconstruction should end. They ran a ticket in 1872 but were decisively defeated as Grant was reelected. In 1874, Democrats took control of Congress and opposed any more reconstruction. The disputed 1876 elections were resolved by the Compromise of 1877, which put Republican Rutherford B. Hayes in the White House. He pulled out the last federal troops and the last Republican state governments in the South collapsed, marking the end of Civil War and Reconstruction.
Memory and historiography.
The Civil War is one of the central events in America's collective memory. There are innumerable statues, commemorations, books and archival collections. The memory includes the home front, military affairs, the treatment of soldiers, both living and dead, in the war's aftermath, depictions of the war in literature and art, evaluations of heroes and villains, and considerations of the moral and political lessons of the war. The last theme includes moral evaluations of racism and slavery, heroism in combat and behind the lines, and the issues of democracy and minority rights, as well as the notion of an "Empire of Liberty" influencing the world. 
Lost Cause.
Memory of the war in the white South crystallized in the myth of the "Lost Cause", which shaped regional identity and race relations for generations. Alan T. Nolan notes in his chapter “The anatomy of the Myth”, that the Lost Cause was expressly "a rationalization, a cover-up to vindicate the name and fame" of those in rebellion. Some claims revolve around the insignificance of slavery. Some appeals highlight cultural differences North and South. The military conflict by Confederate actors is idealized. In any case, secession was said to be lawful. The two important political legacies flowed from the adoption of the Lost Cause analysis were that it facilitated the reunification of the North and the South, and it excused the “virulent racism” of the 19th century, sacrificing African-American progress to a white man’s reunification. But the Lost Cause legacy to history is “a caricature of the truth. This caricature wholly misrepresents and distorts the facts of the matter” in every instance. 
Beardian historiography.
The most influential interpretation of the Civil War was the Beardian approach presented by Charles A. Beard and Mary R. Beard in "The Rise of American Civilization" (1927). It was highly influential among historians and the general public until the civil rights era of the 1950s. The Beards downplayed slavery, abolitionism, and issues of morality. They ignored constitutional issues of states' rights and even ignored American nationalism as the force that finally led to victory in the war. Indeed the ferocious combat itself was passed over as merely an ephemeral event. Much more important was the calculus of class conflict. The Beards announced that the Civil War was really a:
The Beards themselves abandoned their interpretation by the 1940s and it became defunct among historians in the 1950s, when they shifted to an emphasis on slavery. However, Beardian themes still echo among Lost Cause writers.
Civil War commemoration.
The American Civil War has been commemorated in many capacities ranging from the reenactment of battles, to statues and memorial halls erected, to films being produced, to stamps and coins with Civil War themes being issued, all of which helped to shape public memory. This varied advent occurred in greater proportions on the 100th and 150th anniversary.
Hollywood's take on the war has been especially influential in shaping public memory, as seen in such film classics as "Birth of a Nation" (1915), "Gone with the Wind" (1939), and "Lincoln (2012)".
See also.
General reference
Union
Confederacy
Ethnic articles
Topical articles
National articles

</doc>
