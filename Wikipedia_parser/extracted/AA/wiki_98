<doc id="6910" url="http://en.wikipedia.org/wiki?curid=6910" title="Cloning">
Cloning

In biology, cloning is the process of producing similar populations of genetically identical individuals that occurs in nature when organisms such as bacteria, insects or plants reproduce asexually. Cloning in biotechnology refers to processes used to create copies of DNA fragments (molecular cloning), cells (cell cloning), or organisms. The term also refers to the production of multiple copies of a product such as digital media or software.
The term "clone" is derived from the Ancient Greek word κλών "klōn", "twig", referring to the process whereby a new plant can be created from a twig. In horticulture, the spelling "clon" was used until the twentieth century; the final "e" came into use to indicate the vowel is a "long o" instead of a "short o". Since the term entered the popular lexicon in a more general context, the spelling "clone" has been used exclusively.
In botany, the term lusus was traditionally used.
In the United States, the human consumption of meat and other products from cloned animals was approved by the FDA on December 28, 2006, with no special labeling required because food from cloned organisms has been found to be identical to the organisms from which they were cloned. Such practice has met strong resistance in other regions due to misinformation, such as Europe, particularly over the labeling issue.
Molecular cloning.
Molecular cloning refers to the process of making multiple molecules. Cloning is commonly used to amplify DNA fragments containing whole genes, but it can also be used to amplify any DNA sequence such as promoters, non-coding sequences and randomly fragmented DNA. It is used in a wide array of biological experiments and practical applications ranging from genetic fingerprinting to large scale protein production. Occasionally, the term cloning is misleadingly used to refer to the identification of the chromosomal location of a gene associated with a particular phenotype of interest, such as in positional cloning. In practice, localization of the gene to a chromosome or genomic region does not necessarily enable one to isolate or amplify the relevant genomic sequence. To amplify any DNA sequence in a living organism, that sequence must be linked to an origin of replication, which is a sequence of DNA capable of directing the propagation of itself and any linked sequence. However, a number of other features are needed and a variety of specialised cloning vectors (small piece of DNA into which a foreign DNA fragment can be inserted) exist that allow protein expression, tagging, single stranded RNA and DNA production and a host of other manipulations.
Cloning of any DNA fragment essentially involves four steps
Although these steps are invariable among cloning procedures a number of alternative routes can be selected; these are summarized as a "cloning strategy".
Initially, the DNA of interest needs to be isolated to provide a DNA segment of suitable size. Subsequently, a ligation procedure is used where the amplified fragment is inserted into a vector (piece of DNA). The vector (which is frequently circular) is linearised using restriction enzymes, and incubated with the fragment of interest under appropriate conditions with an enzyme called DNA ligase. Following ligation the vector with the insert of interest is transfected into cells. A number of alternative techniques are available, such as chemical sensitivation of cells, electroporation, optical injection and biolistics. Finally, the transfected cells are cultured. As the aforementioned procedures are of particularly low efficiency, there is a need to identify the cells that have been successfully transfected with the vector construct containing the desired insertion sequence in the required orientation. Modern cloning vectors include selectable antibiotic resistance markers, which allow only cells in which the vector has been transfected, to grow. Additionally, the cloning vectors may contain colour selection markers, which provide blue/white screening (alpha-factor complementation) on X-gal medium. Nevertheless, these selection steps do not absolutely guarantee that the DNA insert is present in the cells obtained. Further investigation of the resulting colonies must be required to confirm that cloning was successful. This may be accomplished by means of PCR, restriction fragment analysis and/or DNA sequencing.
Cell cloning.
Cloning unicellular organisms.
Cloning a cell means to derive a population of cells from a single cell. In the case of unicellular organisms such as bacteria and yeast, this process is remarkably simple and essentially only requires the inoculation of the appropriate medium. However, in the case of cell cultures from multi-cellular organisms, cell cloning is an arduous task as these cells will not readily grow in standard media.
A useful tissue culture technique used to clone distinct lineages of cell lines involves the use of cloning rings (cylinders). According to this technique, a single-cell suspension of cells that have been exposed to a mutagenic agent or drug used to drive selection is plated at high dilution to create isolated colonies; each arising from a single and potentially clonal distinct cell. At an early growth stage when colonies consist of only a few of cells, sterile polystyrene rings (cloning rings), which have been dipped in grease are placed over an individual colony and a small amount of trypsin is added. Cloned cells are collected from inside the ring and transferred to a new vessel for further growth.
Cloning stem cells.
Somatic-cell nuclear transfer, known as SCNT, can also be used to create embryos for research or therapeutic purposes. The most likely purpose for this is to produce embryos for use in stem cell research. This process is also called "research cloning" or "therapeutic cloning." The goal is not to create cloned human beings (called "reproductive cloning"), but rather to harvest stem cells that can be used to study human development and to potentially treat disease. While a clonal human blastocyst has been created, stem cell lines are yet to be isolated from a clonal source.
Therapeutic cloning is achieved by creating embryonic stem cells in the hopes of treating diseases such as diabetes and Alzheimer’s. The process begins by taking out the nucleus (containing the DNA) from an egg cell and putting in it a nucleus from the adult cell to be cloned. In the case of someone with Alzheimer’s disease, the nucleus from a skin cell of that patient is placed into an empty egg. The reprogrammed cell begins to develop into an embryo because the egg reacts with the transferred nucleus. The embryo will become genetically identical to the patient. The embryo will then form a blastocyst which has the potential to form/become any cell in the body.
The reason why SCNT is used for cloning is because somatic cells can be easily acquired and cultured in the lab. This process can either add or delete specific genomes of farm animals. A key point to remember is that cloning is achieved when the oocyte maintains its normal functions and instead of using sperm and egg genomes to replicate, the oocyte is inserted into the donor’s somatic cell nucleus. The oocyte will react on the somatic cell nucleus, the same way it would on sperm cells.
The process of cloning a particular farm animal using SCNT is relatively the same for all animals. The first step is to collect the somatic cells from the animal that will be cloned. The somatic cells could be used immediately or stored in the laboratory for later use. The hardest part of SCNT is removing maternal DNA from an oocyte at metaphase II. Once this has been done, the somatic nucleus can be inserted into an egg cytoplasm. This creates a one-cell embryo. The grouped somatic cell and egg cytoplasm are then introduced to an electrical current. This energy will hopefully allow the cloned embryo to begin development. The successfully developed embryos are then placed in surrogate recipients, such as a cow or sheep in the case of farm animals.
SCNT is seen as a good method for producing agriculture animals for food consumption. It successfully cloned sheep, cattle, goats, and pigs. Another benefit is SCNT is seen as a solution to clone endangered species that are on the verge of going extinct. However, stresses placed on both the egg cell and the introduced nucleus are enormous, leading to a high loss in resulting cells. For example, the cloned sheep Dolly was born after 277 eggs were used for SCNT, which created 29 viable embryos. Only three of these embryos survived until birth, and only one survived to adulthood. As the procedure currently cannot be automated, and has to be performed manually under a microscope, SCNT is very resource intensive. The biochemistry involved in reprogramming the differentiated somatic cell nucleus and activating the recipient egg is also far from being well-understood.
In SCNT, not all of the donor cell's genetic information is transferred, as the donor cell's mitochondria that contain their own mitochondrial DNA are left behind. The resulting hybrid cells retain those mitochondrial structures which originally belonged to the egg. As a consequence, clones such as Dolly that are born from SCNT are not perfect copies of the donor of the nucleus.
Organism cloning.
Organism cloning (also called reproductive cloning) refers to the procedure of creating a new multicellular organism, genetically identical to another. In essence this form of cloning is an asexual method of reproduction, where fertilization or inter-gamete contact does not take place. Asexual reproduction is a naturally occurring phenomenon in many species, including most plants (see vegetative reproduction) and some insects. Scientists have made some major achievements with cloning, including the asexual reproduction of sheep and cows. There is a lot of ethical debate over whether or not cloning should be used. However, cloning, or asexual propagation, has been common practice in the horticultural world for hundreds of years.
Horticultural.
The term "clone" is used in horticulture to refer to descendants of a single plant which were produced by vegetative reproduction or apomixis. Many horticultural plant cultivars are clones, having been derived from a single individual, multiplied by some process other than sexual reproduction. As an example, some European cultivars of grapes represent clones that have been propagated for over two millennia. Other examples are potato and banana. Grafting can be regarded as cloning, since all the shoots and branches coming from the graft are genetically a clone of a single individual, but this particular kind of cloning has not come under ethical scrutiny and is generally treated as an entirely different kind of operation.
Many trees, shrubs, vines, ferns and other herbaceous perennials form clonal colonies naturally. Parts of an individual plant may become detached by fragmentation and grow on to become separate clonal individuals. A common example is in the vegetative reproduction of moss and liverwort gametophyte clones by means of gemmae. Some vascular plants e.g. dandelion and certain viviparous grasses also form seeds asexually, termed apomixis, resulting in clonal populations of genetically identical individuals.
Parthenogenesis.
Clonal derivation exists in nature in some animal species and is referred to as parthenogenesis (reproduction of an organism by itself without a mate). This is an asexual form of reproduction that is only found in females of some insects, crustaceans, nematodes, fish (for example the Hammerhead shark), the Komodo dragon and lizards. The growth and development occurs without fertilization by a male. In plants, parthenogenesis means the development of an embryo from an unfertilized egg cell, and is a component process of apomixis. In species that use the XY sex-determination system, the offspring will always be female. An example is the "Little Fire Ant" ("Wasmannia auropunctata"), which is native to Central and South America but has spread throughout many tropical environments.
Artificial cloning of organisms.
Artificial cloning of organisms may also be called "reproductive cloning".
First moves.
Hans Spemann, a German embryologist was awarded a Nobel Prize in Physiology or Medicine in 1935 for his discovery of the effect now known as embryonic induction, exercised by various parts of the embryo, that directs the development of groups of cells into particular tissues and organs. In 1928 he and his student, Hilde Mangold, were the first to perform somatic-cell nuclear transfer using amphibian embryos – one of the first moves towards cloning.
Methods.
Reproductive cloning generally uses "somatic cell nuclear transfer" (SCNT) to create animals that are genetically identical. This process entails the transfer of a nucleus from a donor adult cell (somatic cell) to an egg from which the nucleus has been removed, or to a cell from a blastocyst from which the nucleus has been removed. If the egg begins to divide normally it is transferred into the uterus of the surrogate mother. Such clones are not strictly identical since the somatic cells may contain mutations in their nuclear DNA. Additionally, the mitochondria in the cytoplasm also contains DNA and during SCNT this mitochondrial DNA is wholly from the cytoplasmic donor's egg, thus the mitochondrial genome is not the same as that of the nucleus donor cell from which it was produced. This may have important implications for cross-species nuclear transfer in which nuclear-mitochondrial incompatibilities may lead to death.
Artificial "embryo splitting" or "embryo twinning", a technique that creates monozygotic twins from a single embryo, is not considered in the same fashion as other methods of cloning. During that procedure, an donor embryo is split in two distinct embryos, that can then be transferred via embryo transfer. It is optimally performed at the 6- to 8-cell stage, where it can be used as an expansion of IVF to increase the number of available embryos. If both embryos are successful, it gives rise to monozygotic (identical) twins.
Dolly the sheep.
Dolly, a Finn-Dorset ewe, was the first mammal to have been successfully cloned from an adult cell. Dolly was formed by taking a cell from the udder of her biological mother. Her biological mother was 6 years old when the cells were taken from her udder. Dolly's embryo was created by taking the cell and inserting it into a sheep ovum. It took 434 attempts before an embryo was successful. The embryo was then placed inside a female sheep that went through a normal pregnancy. She was cloned at the Roslin Institute in Scotland and lived there from her birth in 1996 until her death in 2003 when she was six. She was born on July 5, 1996 but not announced to the world until February 22, 1997. Her stuffed remains were placed at Edinburgh's Royal Museum, part of the National Museums of Scotland.
Dolly was publicly significant because the effort showed that genetic material from a specific adult cell, programmed to express only a distinct subset of its genes, can be reprogrammed to grow an entirely new organism. Before this demonstration, it had been shown by John Gurdon that nuclei from differentiated cells could give rise to an entire organism after transplantation into an enucleated egg. However, this concept was not yet demonstrated in a mammalian system.
Cloning Dolly the sheep had a low success rate per fertilized egg; she was born after 277 eggs were used to create 29 embryos, which only produced three lambs at birth, only one of which lived. Seventy calves have been created and one third of them died young; Prometea took 814 attempts. Notably, although the first clones were frogs, no adult cloned frog has yet been produced from a somatic adult nucleus donor cell.
There were early claims that Dolly the Sheep had pathologies resembling accelerated aging. Scientists speculated that Dolly's death in 2003 was related to the shortening of telomeres, DNA-protein complexes that protect the end of linear chromosomes. However, other researchers, including Ian Wilmut who led the team that successfully cloned Dolly, argue that Dolly's early death due to respiratory infection was unrelated to deficiencies with the cloning process.
Dolly was named after Dolly Parton because the cells cloned to make her were from an udder.
Species cloned.
The modern cloning techniques involving nuclear transfer have been successfully performed on several species. Notable experiments include:
Human cloning.
Human cloning is the creation of a genetically identical copy of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissues. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass legislature regarding human cloning and its legality.
Two commonly discussed types of theoretical human cloning are "therapeutic cloning" and "reproductive cloning". Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants, and is an active area of research, but is not in medical practice anywhere in the world, as of 2014. Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and, more recently, pluripotent stem cell induction. Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.
Ethical issues of cloning.
There are a variety of ethical positions regarding the possibilities of cloning, especially human cloning. While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well. Perspectives on human cloning are theoretical, as human therapeutic and reproductive cloning are not commercially used; animals are currently cloned in laboratories and in livestock production.
Advocates support development of therapeutic cloning in order to generate tissues and whole organs to treat patients who otherwise cannot obtain transplants, to avoid the need for immunosuppressive drugs, and to stave off the effects of aging. Advocates for reproductive cloning believe that parents who cannot otherwise procreate should have access to the technology.
Opponents of cloning have concerns that technology is not yet developed enough to be safe, that it could be prone to abuse (leading to the generation of humans from whom organs and tissues would be harvested), and have concerns about how cloned individuals could integrate with families and with society at large.
Religious groups are divided, with some opposing the technology as usurping God's place and, to the extent embryos are used, destroying a human life; others support therapeutic cloning's potential life-saving benefits.
Cloning of animals is opposed by animal-groups due to the number of cloned animals that suffer from malformations before they die, and while food from cloned animals has been approved by the US FDA, its use is opposed by groups concerned about food safety.
Cloning extinct and endangered species.
Cloning, or more precisely, the reconstruction of functional DNA from extinct species has, for decades, been a dream of some scientists. Current cloning techniques have an average success rate of less than 5 percent, even when working with familiar species; cloning wild animals is usually less than 1 percent successful. The possible implications of this were dramatized in the best-selling novel by Michael Crichton and high budget Hollywood thriller "Jurassic Park". Early hopes to save species through cloning have been dashed as the difficulties of cloning any species have made progress very slow. Several tissue banks have come into existence, including the "Frozen Zoo" at the San Diego Zoo, to store frozen tissue from the world's rarest and most endangered species.
In 2001, a cow named Bessie gave birth to a cloned Asian gaur, an endangered species, but the calf died after two days. In 2003, a banteng was successfully cloned, followed by three African wildcats from a thawed frozen embryo. These successes provided hope that similar techniques (using surrogate mothers of another species) might be used to clone extinct species. Anticipating this possibility, tissue samples from the last "bucardo" (Pyrenean Ibex) were frozen in liquid nitrogen immediately after it died in 2000. Researchers are also considering cloning endangered species such as the giant panda and cheetah.
In 2002, geneticists at the Australian Museum announced that they had replicated DNA of the Thylacine (Tasmanian Tiger), at the time extinct for about 65 years, using polymerase chain reaction. However, on February 15, 2005 the museum announced that it was stopping the project after tests showed the specimens' DNA had been too badly degraded by the (ethanol) preservative. On 15 May 2005 it was announced that the Thylacine project would be revived, with new participation from researchers in New South Wales and Victoria.
In January 2009, for the first time, an extinct animal, the Pyrenean ibex mentioned above was cloned, at the Centre of Food Technology and Research of Aragon, using the preserved DNA of the skin samples from 2001 and domestic goat egg-cells. The ibex died shortly after birth due to physical defects in its lungs.
One of the most anticipated targets for cloning was once the Woolly Mammoth, but attempts to extract DNA from frozen mammoths have been unsuccessful, though a joint Russo-Japanese team is currently working toward this goal. In January 2011, it was reported by Yomiuri Shimbun that a team of scientists headed by Akira Iritani of Kyoto University had built upon research by Dr. Wakayama, saying that they will extract DNA from a mammoth carcass that had been preserved in a Russian laboratory and insert it into the egg cells of an African elephant in hopes of producing a mammoth embryo. The researchers said they hoped to produce a baby mammoth within six years.
Scientists at the University of Newcastle and University of New South Wales announced in March 2013 that the very recently extinct gastric-brooding frog would be the subject of a cloning attempt to resurrect the species.
Lifespan.
After an eight-year project involving the use of a pioneering cloning technique, Japanese researchers created 25 generations of healthy cloned mice with normal lifespans, demonstrating that clones are not intrinsically shorter-lived than naturally born animals.
In popular culture.
In an article in the November 8, 1993 article of Time Magazine, cloning was portrayed in a negative way, modifying Michelangelo's "Creation of Adam" to depict Adam with five identical hands. Newsweek Magazine's March 10, 1997 issue also critiqued the ethics of human cloning, and included a graphic depicting identical babies in beakers.
Cloning is a recurring theme in a wide variety of contemporary science fiction, ranging from action films such as the 2000 film "The 6th Day" and "Resident Evil (film series)", "Jurassic Park (film)", and "The Island (2005 film)", to comedies such as Woody Allen's 1973 film "Sleeper".
Science fiction has used cloning, most commonly and specifically human cloning, due to the fact that it brings up controversial questions of identity. In Aldous Huxley’s "Brave New World" (1932), human cloning is a major plot device that not only drives the story but also makes the reader think critically about what identity means; this concept was re-examined fifty years later in C. J. Cherryh’s novels "Forty Thousand in Gehenna" (1983) and "Cyteen" (1988). Kazuo Ishiguro's 2005 novel "Never Let Me Go" centres on human clones and considers the ethics of the practice. Another book that embodies the ideas of cloning is "The House of the Scorpion" which explores the rights of human clones and organ harvesting, set from the eyes of a clone. The short novel "Containing God" by Dr.S.M.Wasi Haider similarly deals with the ideas of cloning and the ethics, lust, and other issues revolving around the topic, emphasizing the idea that creating life gives people the false sense of divinity. The implications of using clones to replace deceased loved ones are explored in several works of fiction. In Margaret Peterson Haddix's novel "Double Identity", the main character discovers that she is a clone of her deceased older sister. "A Number" is a 2002 play by English playwright Caryl Churchill which addresses the subject of human cloning and identity, especially nature and nurture. The story, set in the near future, is structured around the conflict between a father (Salter) and his sons (Bernard 1, Bernard 2, and Michael Black) – two of whom are clones of the first one. "A Number" was adapted by Caryl Churchill for television, in a co-production between the BBC and HBO Films. Starring Rhys Ifans and Tom Wilkinson, it was broadcast on BBC Two on 10 Sep 2008.
A recurring sub-theme of cloning fiction is the use of clones as a supply of organs for transplantation. The 2005 Kazuo Ishiguro novel "Never Let Me Go" and the 2010 film adaption are set in an alternate history in which cloned humans are created for the sole purpose of providing organ donations to naturally born humans, despite the fact that they are fully sentient and self-aware. The 2005 film "The Island" revolves around a similar plot, with the exception that the clones are unaware of the reason for their existence. In the futuristic novel "The House of the Scorpion", clones are used to grow organs for their wealthy "owners", and the main character was a complete clone.
The use of human cloning for military purposes has also been explored in several works. Star Wars portrays human cloning in "Clone Wars", ' and ', in the form of the Grand Army of the Republic, an army of cloned soldiers. The Expanded Universe also has numerous examples of cloning, including the Thrawn trilogy, The Hand of Thrawn duology, and Clone Wars-era media.
The exploitation of human clones for dangerous and undesirable work was examined in the 2009 British science fiction film "Moon". In the futuristic novel Cloud Atlas and subsequent film"," one of the story lines focuses on a genetically-engineered Fabricant Clone named Sonmi~451 who is one of millions raised in an artificial "wombtank," destined to serve from birth. She is one of thousands of clones created for manual and emotional labor; Sonmi herself works as a server in a restaurant. She later discovers that the sole source of food for clones, called 'Soap', is manufactured from the clones themselves.
In the comedy film "Multiplicity", a man clones himself three times with the help of a geneticist.
Cloning has been used in fiction as a way of recreating historical figures. In the 1976 Ira Levin novel "The Boys from Brazil" and its 1978 film adaptation, Josef Mengele uses cloning to create copies of Adolf Hitler. "A Parade of Mirrors and Reflections", a novel by Anatoly Kudryavitsky, centers on the cloning of deceased Soviet premier Yuri Andropov.
In the anime "A Certain Scientific Railgun", Level 5 esper Mikoto Misaka was cloned commercially over 20,000 times for the purposes of research into the possibility of a "Level 6" esper. In another anime/manga series "Neon Genesis Evangelion", human cloning is a topic which features heavily around the origin of the character Ayanami Rei. In 2012, a Japanese television show named "Bunshin" was created. The story's main character, Mariko, is a woman studying child welfare in Hokkaido. She grew up always doubtful about the love from her mother, who looked nothing like her and who died nine years before. One day, she finds some of her mother's belongings at a relative's house, and heads to Tokyo to seek out the truth behind her birth. She later discovered that she was a clone.
Cloning is also featured in the "Halo" franchise, particularly a technique known as "flash cloning" in which the unstable clone of an individual is created in an incredibly short span of time. Flash cloning is used by the UNSC to kidnap young children for induction into the SPARTAN-II military program, who are surreptitiously replaced by flash clones which die within a short span of time to ensure that no one looks for the children. The MMORPG "EVE Online" and online FPS DUST 514 takes place in the distant future where the player characters are all clones; at the moment of death, the person's brain-state is mapped, transmitted and applied to a 'blank' clone in a station or facility some distance away.
In the 2013 television show "Orphan Black", cloning is used as a scientific study on the behavioral adaptation of the clones.

</doc>
<doc id="6911" url="http://en.wikipedia.org/wiki?curid=6911" title="Cellulose">
Cellulose

Cellulose is an organic compound with the formula , a polysaccharide consisting of a linear chain of several hundred to over ten thousand β(1→4) linked D-glucose units.
Cellulose is an important structural component of the primary cell wall of green plants, many forms of algae and the oomycetes. Some species of bacteria secrete it to form biofilms. Cellulose is the most abundant organic polymer on Earth. The cellulose content of cotton fiber is 90%, that of wood is 40–50% and that of dried hemp is approximately 45%.
Cellulose is mainly used to produce paperboard and paper. Smaller quantities are converted into a wide variety of derivative products such as cellophane and rayon. Conversion of cellulose from energy crops into biofuels such as cellulosic ethanol is under investigation as an alternative fuel source. Cellulose for industrial use is mainly obtained from wood pulp and cotton.
Some animals, particularly ruminants and termites, can digest cellulose with the help of symbiotic micro-organisms that live in their guts, such as Trichonympha. Humans can digest cellulose to some extent, but it mainly acts as a hydrophilic bulking agent for feces and is often referred to as a "dietary fiber".
History.
Cellulose was discovered in 1838 by the French chemist Anselme Payen, who isolated it from plant matter and determined its chemical formula. Cellulose was used to produce the first successful thermoplastic polymer, celluloid, by Hyatt Manufacturing Company in 1870. Production of rayon ("artificial silk") from cellulose began in the 1890s and cellophane was invented in 1912. Hermann Staudinger determined the polymer structure of cellulose in 1920. The compound was first chemically synthesized (without the use of any biologically derived enzymes) in 1992, by Kobayashi and Shoda.
Structure and properties.
Cellulose has no taste, is odorless, is hydrophilic with the contact angle of 20–30, is insoluble in water and most organic solvents, is chiral and is biodegradable. It can be broken down chemically into its glucose units by treating it with concentrated acids at high temperature.
Cellulose is derived from D-glucose units, which condense through β(1→4)-glycosidic bonds. This linkage motif contrasts with that for α(1→4)-glycosidic bonds present in starch, glycogen, and other carbohydrates. Cellulose is a straight chain polymer: unlike starch, no coiling or branching occurs, and the molecule adopts an extended and rather stiff rod-like conformation, aided by the equatorial conformation of the glucose residues. The multiple hydroxyl groups on the glucose from one chain form hydrogen bonds with oxygen atoms on the same or on a neighbor chain, holding the chains firmly together side-by-side and forming "microfibrils" with high tensile strength. This confers tensile strength in cell walls, where cellulose microfibrils are meshed into a polysaccharide "matrix".
Compared to starch, cellulose is also much more crystalline. Whereas starch undergoes a crystalline to amorphous transition when heated beyond 60–70 °C in water (as in cooking), cellulose requires a temperature of 320 °C and pressure of 25 MPa to become amorphous in water.
Several different crystalline structures of cellulose are known, corresponding to the location of hydrogen bonds between and within strands. Natural cellulose is cellulose I, with structures Iα and Iβ. Cellulose produced by bacteria and algae is enriched in Iα while cellulose of higher plants consists mainly of Iβ. Cellulose in regenerated cellulose fibers is cellulose II. The conversion of cellulose I to cellulose II is irreversible, suggesting that cellulose I is metastable and cellulose II is stable. With various chemical treatments it is possible to produce the structures cellulose III and cellulose IV.
Many properties of cellulose depend on its chain length or degree of polymerization, the number of glucose units that make up one polymer molecule. Cellulose from wood pulp has typical chain lengths between 300 and 1700 units; cotton and other plant fibers as well as bacterial cellulose have chain lengths ranging from 800 to 10,000 units. Molecules with very small chain length resulting from the breakdown of cellulose are known as cellodextrins; in contrast to long-chain cellulose, cellodextrins are typically soluble in water and organic solvents.
Plant-derived cellulose is usually found in a mixture with hemicellulose, lignin, pectin and other substances, while bacterial cellulose is quite pure, has a much higher water content and higher tensile strength due to higher chain lengths.
Cellulose is soluble in Schweizer's reagent, cupriethylenediamine (CED), cadmiumethylenediamine (Cadoxen), "N"-methylmorpholine "N"-oxide, and lithium chloride / dimethylformamide. This is used in the production of regenerated celluloses (such as viscose and cellophane) from dissolving pulp. Cellulose is also soluble in many kinds of ionic liquids.
Cellulose consists of crystalline and amorphous regions. By treating it with strong acid, the amorphous regions can be broken up, thereby producing nanocrystalline cellulose, a novel material with many desirable properties. Recently, nanocrystalline cellulose was used as the filler phase in bio-based polymer matrices to produce nanocomposites with superior thermal and mechanical properties.
Processing.
Assay.
Given a cellulose-containing material, the carbohydrate portion that does not dissolve in a 17.5% solution of sodium hydroxide at 20 °C is "α cellulose", which is true cellulose. Acidification of the extract precipitates "β cellulose". The portion that dissolves in base but does not precipitate with acid is "γ cellulose".
Cellulose can be assayed using a method described by Updegraff in 1969, where the fiber is dissolved in acetic and nitric acid to remove lignin, hemicellulose, and xylosans. The resulting cellulose is allowed to react with anthrone in sulfuric acid. The resulting coloured compound is assayed spectrophotometrically at a wavelength of approximately 635 nm.
In addition, cellulose is represented by the difference between acid detergent fiber (ADF) and acid detergent lignin (ADL).
Biosynthesis.
In vascular plants cellulose is synthesized at the plasma membrane by rosette terminal complexes (RTCs). The RTCs are hexameric protein structures, approximately 25 nm in diameter, that contain the cellulose synthase enzymes that synthesise the individual cellulose chains. Each RTC floats in the cell's plasma membrane and "spins" a microfibril into the cell wall.
RTCs contain at least three different cellulose synthases, encoded by "CesA" genes, in an unknown stoichiometry. Separate sets of "CesA" genes are involved in primary and secondary cell wall biosynthesis.
Cellulose synthesis requires chain initiation and elongation, and the two processes are separate.
"CesA" glucosyltransferase initiates cellulose polymerization using a steroid primer, sitosterol-beta-glucoside, and UDP-glucose. Cellulose synthase utilizes UDP-D-glucose precursors to elongate the growing cellulose chain. A cellulase may function to cleave the primer from the mature chain.
Cellulose is also synthesised by animals, particularly in the tests of ascidians (where the cellulose was historically termed "tunicine") although it is also a minor component of mammalian connective tissue.
Breakdown (cellulolysis).
Cellulolysis is the process of breaking down cellulose into smaller polysaccharides called cellodextrins or completely into glucose units; this is a hydrolysis reaction. Because cellulose molecules bind strongly to each other, cellulolysis is relatively difficult compared to the breakdown of other polysaccharides. However, this process can be significantly intensified in a proper solvent, e.g. in an ionic liquid.
Most mammals have only very limited ability to digest dietary fibres such as cellulose. Some ruminants like cows and sheep contain certain symbiotic anaerobic bacteria (like "Cellulomonas") in the flora of the rumen, and these bacteria produce enzymes called cellulases that help the microorganism to break down cellulose; the breakdown products are then used by the bacteria for proliferation. The bacterial mass is later digested by the ruminant in its digestive system (stomach and small intestine). Similarly, lower termites contain in their hindguts certain flagellate protozoa which produce such enzymes; higher termites contain bacteria for the job. Some termites may also produce cellulase of their own. Fungi, which in nature are responsible for recycling of nutrients, are also able to break down cellulose.
The enzymes utilized to cleave the glycosidic linkage in cellulose are glycoside hydrolases including endo-acting cellulases and exo-acting glucosidases. Such enzymes are usually secreted as part of multienzyme complexes that may include dockerins and carbohydrate-binding modules.
Hemicellulose.
Hemicellulose is a polysaccharide related to cellulose that comprises about 20% of the biomass of most plants. In contrast to cellulose, hemicellulose is derived from several sugars in addition to glucose, especially xylose but also including mannose, galactose, rhamnose, and arabinose. Hemicellulose consists of shorter chains – around 200 sugar units. Furthermore, hemicellulose is branched, whereas cellulose is unbranched.
Derivatives.
The hydroxyl groups (-OH) of cellulose can be partially or fully reacted with various reagents to afford derivatives with useful properties like mainly cellulose esters and cellulose ethers (-OR). In principle, though not always in current industrial practice, cellulosic polymers are renewable resources.
Ester derivatives include:
The cellulose acetate and cellulose triacetate are film- and fiber-forming materials that find a variety of uses. The nitrocellulose was initially used as an explosive and was an early film forming material. With camphor, nitrocellulose gives celluloid.
Ether derivatives include:
The sodium carboxymethyl cellulose can be cross-linked to give the croscarmellose sodium (E468) for use as a disintegrant in pharmaceutical formulations.
Applications.
Cellulose for industrial use is mainly obtained from wood pulp and cotton. The kraft process is used to separate cellulose from lignin, another major component of plant matter.
Paper products.
Cellulose is the major constituent of paper, paperboard, and card stock.
Fibers.
Cellulose is the main ingredient of textiles made from cotton, linen, and other plant fibers. It can be turned into rayon, an important fiber that has been used for textiles since the beginning of the 20th century. Both cellophane and rayon are known as "regenerated cellulose fibers"; they are identical to cellulose in chemical structure and are usually made from dissolving pulp via viscose. A more recent and environmentally friendly method to produce a form of rayon is the Lyocell process.
Consumables.
Microcrystalline cellulose (E460i) and powdered cellulose (E460ii) are used as inactive fillers in drug tablets
and as thickeners and stabilizers in processed foods. Cellulose powder is, for example, used in Kraft's Parmesan cheese to prevent caking inside the tube.
Science.
Cellulose is used in the laboratory as a stationary phase for thin layer chromatography. Cellulose fibers are also used in liquid filtration, sometimes in combination with diatomaceous earth or other filtration media, to create a filter bed of inert material.
Energy crops.
The major combustible component of non-food energy crops is cellulose, with lignin second. Non-food energy crops produce more usable energy than edible energy crops (which have a large starch component), but still compete with food crops for agricultural land and water resources. Typical non-food energy crops include industrial hemp (though outlawed in some countries), switchgrass, "Miscanthus", "Salix"(willow), and "Populus" (poplar) species.
Bio Fuel.
TU-103, a strain of "Clostridium" bacteria found in Zebra waste, can convert nearly any form of cellulose into butanol fuel.
Building material.
Hydroxyl bonding of cellulose in water produces a sprayable, moldable material as an alternative to the use of plastics and resins. The recyclable material can be made water- and fire-resistant. It provides sufficient strength for use as a building material.
Cellulose insulation made from recycled paper is becoming popular as an environmentally preferable material for building insulation. It can be treated with boric acid as a fire retardant.
Miscellaneous.
Cellulose can be converted into cellophane, a thin transparent film.
Cellulose is the raw material in the manufacture of nitrocellulose (cellulose nitrate) which is used in smokeless gunpowder. It is the base material for the celluloid that was used for photographic and movie films until the mid-1930s.
Cellulose is used to make water-soluble adhesives and binders such as methyl cellulose and carboxymethyl cellulose which are used in wallpaper paste.
Cellulose is further used to make hydrophilic and highly absorbent sponges.

</doc>
<doc id="6916" url="http://en.wikipedia.org/wiki?curid=6916" title="Colony">
Colony

In politics and history, a colony is a territory under the immediate political control of a state, distinct from the home territory of the sovereign. For colonies in antiquity, city-states would often found their own colonies. Some colonies were historically countries, while others were territories without definite statehood from their inception. The metropolitan state is the state that owns the colony. In Ancient Greece, the city that founded a colony was called the metropolis. Mother country is a reference to the metropolitan state from the point of view of citizens who live in its colony. There is a United Nations list of Non-Self-Governing Territories.
Unlike a puppet state or satellite state, a colony has no independent international representation, and its top-level administration is under direct control of the metropolitan state.
The term "informal colony" is used by some historians to refer to a country under the "de facto" control of another state, although this term is often contentious.
Definitions.
The word Colony comes from the Latin word colōnia. This in turn derives from the word colōnus, which means colonist but also implies a farmer. Cologne is an example of a settlement preserving this etymology. Other, less obvious settlements that began as Roman colonia include cities from Belgrade to York. A tell-tale sign of a settlement once being a Roman Colony is a city centre with a grid pattern. The terminology is taken from architectural analogy, where a column pillar is beneath the (often stylized) head capital, which is also a biological analog of the body as subservient beneath the controlling head (with 'capital' coming from the Latin "caput", meaning 'head'). So colonies are not independently self-controlled, but rather are controlled from a separate entity that serves the capital function.
Roman colonies first appeared when the Romans conquered neighbouring italic peoples. These were small farming settlements that appeared when the Romans had subdued an enemy in war. A colony could take many forms, as a trade outpost or a military base in enemy territory, but its original definition as a settlement created by people migrating from a home in the world territory became the modern definition.
Colonies in ancient civilizations (examples).
"See Colonies in antiquity."
Current colonies.
The Special Committee on Decolonization maintains the United Nations list of Non-Self-Governing Territories, which identifies areas the United Nations (though not without controversy) believes are colonies. Given that dependent territories have varying degrees of autonomy and political power in the affairs of the controlling state, there is disagreement over the classification of "colony".

</doc>
<doc id="6918" url="http://en.wikipedia.org/wiki?curid=6918" title="Rod (optics)">
Rod (optics)

"Rods" (sometimes known as "skyfish", "air rods", or "solar entities") is a term used in cryptozoology, ufology, and outdoor photography to refer to elongated artifacts in the form of light-rods produced by cameras. Videos of rod-shaped objects moving quickly through the air were claimed by some ufologists and cryptozoologists to be alien life forms, "extradimensional" creatures, or very small UFOs. Subsequent experiments showed that these rods appear in film because of an optical illusion/collusion (especially in interlaced video recording), and are typically traces of a flying insect's wingbeats.
Optical analysis.
Various paranormal interpretations appeared in the popular culture, and one of the more outspoken proponents of rods as alien life forms is Jose Escamilla, who claims to have been the first to film them on March 19, 1994 at Roswell, New Mexico, while attempting to film a UFO. Since then, Escamilla has made additional videos and embarked on lecture tours to promote his claims.
The Straight Dope columnist Cecil Adams called rods a hoax "where unscrupulous people are exploiting a gullible public for profit", and said that investigators have shown that rods are mere tricks of light which result from how images (primarily video images) of flying insects are recorded and played back. In particular, the fast passage before the camera of an insect flapping its wings has been shown to produce rodlike effects, due to motion blur, if the camera is shooting with relatively long exposure times.
After attending a lecture by Escamilla, UFO investigator Robert Sheaffer wrote that "some of his “rods” were obviously insects zipping across the field at a high angular rate" and others appeared to be “appendages” which were just birds' wings blurred by the camera exposure.
On August 8/9, 2005, China Central Television (CCTV) aired a two-part documentary about flying rods in China. It reported the events from May to June of the same year at Tonghua Zhenguo Pharmaceutical Company in Tonghua City, Jilin Province, which debunked the flying rods. Surveillance cameras in the facility's compound captured video footage of flying rods identical to those shown in Jose Escamilla's video. Getting no satisfactory answer to the phenomenon, curious scientists at the facility decided that they would try to solve the mystery by attempting to catch these airborne creatures. Huge nets were set up and the same surveillance cameras then captured images of rods flying into the trap. When the nets were inspected, the "rods" were no more than regular moths and other ordinary flying insects. Subsequent investigations proved that the appearance of flying rods on video was an optical illusion created by the slower recording speed of the camera.
Cryptozoology.
In 2012, the Malaysian independent newspaper Daily Express reported that a British traveller named Matthew Lazenby had "discovered" rods in a cave in Sabah. Lazenby described the "flying rods" as insect-like creatures unlike any known animal, and announced his intention to capture a specimen. Previous attempts to capture rods in China only yielded moths and other insects.

</doc>
<doc id="6920" url="http://en.wikipedia.org/wiki?curid=6920" title="Column">
Column

Column or pillar in architecture and structural engineering is a structural element that transmits, through compression, the weight of the structure above to other structural elements below. In other words, a column is a compression member. The term column applies especially to a large round support with a capital and base and made of stone, or appearing to be so. A small wooden or metal support is typically called a post, and supports with a rectangular or other non-round section are usually called piers. For the purpose of wind or earthquake engineering, columns may be designed to resist lateral forces. Other compression members are often termed "columns" because of the similar stress conditions. Columns are frequently used to support beams or arches on which the upper parts of walls or ceilings rest. In architecture, "column" refers to such a structural element that also has certain proportional and decorative features. A column might also be a decorative element not needed for structural purposes; many columns are "engaged", that is to say form part of a wall.
History.
All significant Iron Age civilizations of the Near East and Mediterranean made some use of columns. In Ancient Egyptian architecture as early as 2600 BC the architect Imhotep made use of stone columns whose surface was carved to reflect the organic form of bundled reeds; in later Egyptian architecture faceted cylinders were also common. 
Some of the most elaborate columns in the ancient world were those of the Persians, especially the massive stone columns erected in Persepolis. They included double-bull structures in their capitals. The Hall of Hundred Columns at Persepolis, measuring 70 × 70 metres, was built by the Achaemenid king Darius I (524–486 BC). Many of the ancient Persian columns are standing, some being more than 30 metres tall.
The Egyptians, Persians and other civilizations mostly used columns for the practical purpose of holding up the roof inside a building, preferring outside walls to be decorated with reliefs or painting, but the Ancient Greeks, followed by the Romans, loved to use them on the outside as well, and the extensive use of columns on the interior and exterior of buildings is one of the most characteristic features of classical architecture, in buildings like the Parthenon. The Greeks developed the classical orders of architecture, which are most easily distinguished by the form of the column and its various elements. Their Doric, Ionic, and Corinthian orders were expanded by the Romans to include the Tuscan and Composite orders (see below). 
Columns, or at least large structural exterior ones, became much less significant in the architecture of the Middle Ages, and the classical forms were abandoned in both Byzantine architecture and the Romanesque and Gothic architecture or Europe in favour of more flexible forms, with capitals often using various types of foliage decoration, and in the West scenes with figures carved in relief. Renaissance architecture was keen to revive the classical vocabulary and styles, and the informed use and variation of the classical orders remained fundamental to the training of architects throughout Baroque, Rococo and Neo-classical architecture.
Structure.
Early columns were constructed of stone, some out of a single piece of stone. Monolithic columns are among the heaviest stones used in architecture. Other stone columns are created out of multiple sections of stone, mortared or dry-fit together. In many classical sites, sectioned columns were carved with a centre hole or depression so that they could be pegged together, using stone or metal pins. The design of most classical columns incorporates entasis (the inclusion of a slight outward curve in the sides) plus a reduction in diameter along the height of the column, so that the top is as little as 83% of the bottom diameter. This reduction mimics the parallax effects which the eye expects to see, and tends to make columns look taller and straighter than they are while entasis adds to that effect.
Nomenclature.
Classical columns have a bottom or plinth that rests on the stylobate or foundation. At the top a capital (also known as a chapiter) or finial decorate the column, depending on whether it is attached to a structure or free-standing.
Modern columns are constructed out of steel, poured or precast concrete, or brick. They may then be clad in an architectural covering (or veneer), or left bare. In modern terms the impost (or pier) is the topmost member of a column. The bottom-most part of the arch, called the springing, rests on the impost.
Equilibrium, instability, and loads.
As the axial load on a perfectly straight slender column with elastic material properties is increased in magnitude, this ideal column passes through three states: stable equilibrium, neutral equilibrium, and instability. The straight column under load is in stable equilibrium if a lateral force, applied between the two ends of the column, produces a small lateral deflection which disappears and the column returns to its straight form when the lateral force is removed. If the column load is gradually increased, a condition is reached in which the straight form of equilibrium becomes so-called neutral equilibrium, and a small lateral force will produce a deflection that does not disappear and the column remains in this slightly bent form when the lateral force is removed. The load at which neutral equilibrium of a column is reached is called the critical or buckling load. The state of instability is reached when a slight increase of the column load causes uncontrollably growing lateral deflections leading to complete collapse.
For an axially loaded straight column with any end support conditions, the equation of static equilibrium, in the form of a differential equation, can be solved for the deflected shape and critical load of the column. With hinged, fixed or free end support conditions the deflected shape in neutral equilibrium of an initially straight column with uniform cross section throughout its length always follows a partial or composite sinusoidal curve shape, and the critical load is given by
formula_1
where "r" = radius of gyration of cross-section which is equal to the square root of (I/A), "K" = ratio of the longest half sine wave to the actual column length, and "KL" = effective length (length of an equivalent hinged-hinged column). From Equation (2) it can be noted that the buckling strength of a column is inversely proportional to the square of its length.
When the critical stress, "F"cr ("F"cr ="P"cr/"A", where "A" = cross-sectional area of the column), is greater than the proportional limit of the material, the column is experiencing inelastic buckling. Since at this stress the slope of the material's stress-strain curve, "E""t" (called the tangent modulus), is smaller than that below the proportional limit, the critical load at inelastic buckling is reduced. More complex formulas and procedures apply for such cases, but in its simplest form the critical buckling load formula is given as Equation (3),
formula_2
where "E""t" = tangent modulus at the stress "F"cr
A column with a cross section that lacks symmetry may suffer torsional buckling (sudden twisting) before, or in combination with, lateral buckling. The presence of the twisting deformations renders both theoretical analyses and practical designs rather complex.
Eccentricity of the load, or imperfections such as initial crookedness, decreases column strength. If the axial load on the column is not concentric, that is, its line of action is not precisely coincident with the centroidal axis of the column, the column is characterized as eccentrically loaded. The eccentricity of the load, or an initial curvature, subjects the column to immediate bending. The increased stresses due to the combined axial-plus-flexural stresses result in a reduced load-carrying ability.
Column elements are considered to be massive if minimal side dimension is equal or more than 400 mm. Massive columns have ability to increase concrete strength during long time period (even during exploitation period). Taking into account possible loads onto structure increase in future (and even threat of progressive failure, terroristic attacks, explosions etc.) massive columns have advantage comparing with not ones. A little economy today has no sense as usual for future. Moreover relatively small sections are not technological for reinforced structures during their production. Balance between economy, mass of structures and so called "sustainable" construction is necessary.
Extensions.
When a column is too long to be built or transported in one piece, it has to be extended or spliced at the construction site. A reinforced concrete column is extended by having the steel reinforcing bars protrude a few inches or feet above the top of the concrete, then placing the next level of reinforcing bars to overlap, and pouring the concrete of the next level. A steel column is extended by welding or bolting splice plates on the flanges and webs or walls of the columns to provide a few inches or feet of load transfer from the upper to the lower column section. A timber column is usually extended by the use of a steel tube or wrapped-around sheet-metal plate bolted onto the two connecting timber sections.
when e<12 then it is known as short column
Foundations.
A column that carries the load down to a foundation must have means to transfer the load without overstressing the foundation material. Reinforced concrete and masonry columns are generally built directly on top of concrete foundations. A steel column, when seated on a concrete foundation, must have a base plate to spread the load over a larger area and thereby reduce the bearing pressure. The base plate is a thick rectangular steel plate usually welded to the bottom end of the column.
Classical orders.
The Roman author Vitruvius, relying on the writings (now lost) of Greek authors, tells us that the ancient Greeks believed that their Doric order developed from techniques for building in wood in which the earlier smoothed tree trunk was replaced by a stone cylinder.
Doric order.
The Doric order is the oldest and simplest of the classical orders. It is composed of a vertical cylinder that is wider at the bottom. It generally has neither a base nor a detailed capital. It is instead often topped with an inverted frustum of a shallow cone or a cylindrical band of carvings. It is often referred to as the masculine order because it is represented in the bottom level of the Colosseum and the Parthenon, and was therefore considered to be able to hold more weight. The height-to-thickness ratio is about 8:1. The shaft of a Doric Column is almost always fluted.
The Greek Doric, developed in the western Dorian region of Greece, is the heaviest and most massive of the orders. It rises from the stylobate without any base; it is from four to six times as tall as its diameter; it has twenty broad flutes; the capital consists simply of a banded necking swelling out into a smooth echinus, which carries a flat square abacus; the Doric entablature is also the heaviest, being about one-fourth the height column. The Greek Doric order was not used after c. 100 B.C. until its “rediscovery” in the mid-eighteenth century.
Tuscan order.
The Tuscan order, also known as Roman Doric, is also a simple design, the base and capital both being series of cylindrical disks of alternating diameter. The shaft is almost never fluted. The proportions vary, but are generally similar to Doric columns. Height to width ratio is about 7:1.
Ionic order.
The Ionic column is considerably more complex than the Doric or Tuscan. It usually has a base and the shaft is often fluted (it has grooves carved up its length). On the top is a capital in the characteristic shape of a scroll, called a volute, or scroll, at the four corners. The height-to-thickness ratio is around 9:1. Due to the more refined proportions and scroll capitals, the Ionic column is sometimes associated with academic buildings. Ionic style columns were used on the second level of the Colosseum.
Corinthian order.
The Corinthian order is named for the Greek city-state of Corinth, to which it was connected in the period. However, according to the architectural historian Vitruvius, the column was created by the sculptor Callimachus, probably an Athenian, who drew acanthus leaves growing around a votive basket. In fact, the oldest known Corinthian capital was found in Bassae, dated at 427 BC. It is sometimes called the feminine order because it is on the top level of the Colosseum and holding up the least weight, and also has the slenderest ratio of thickness to height. Height to width ratio is about 10:1.
Composite order.
The Composite order draws its name from the capital being a composite of the Ionic and Corinthian capitals. The acanthus of the Corinthian column already has a scroll-like element, so the distinction is sometimes subtle. Generally the Composite is similar to the Corinthian in proportion and employment, often in the upper tiers of colonnades. Height to width ratio is about 11:1 or 12:1.
Solomonic.
A Solomonic column, sometimes called "barley sugar", begins on a base and ends in a capital, which may be of any order, but the shaft twists in a tight spiral, producing a dramatic, serpentine effect of movement. Solomonic columns were developed in the ancient world, but remained rare there. A famous marble set, probably 2nd century, was brought to St Peter's, Rome by Constantine I, and placed round the saint's shrine, and was thus familiar throughout the Middle Ages, by which time they were thought to have been removed from the Temple of Jerusalem. The style was used in bronze by Bernini for his spectacular St. Peter's baldachin, actually a ciborium (which displaced Constantine's columns), and thereafter became very popular with Baroque and Rococo church architects, above all in Latin America, where they were very often used, especially on a small scale, as they are easy to produce in wood by turning on a lathe (hence also the style's popularity for spindles on furniture and stairs).

</doc>
<doc id="6921" url="http://en.wikipedia.org/wiki?curid=6921" title="Carmilla">
Carmilla

Carmilla is a Gothic novella by Joseph Sheridan Le Fanu. First published in 1871 as a serial narrative in "The Dark Blue", it tells the story of a young woman's susceptibility to the attentions of a female vampire named Carmilla. "Carmilla" predates Bram Stoker's "Dracula" by 26 years, and has been adapted many times for cinema.
Publication.
"Carmilla" was first published in the magazine "The Dark Blue" in late 1871 and early 1872 and then in the author's collection of short stories "In a Glass Darkly" in the latter year.
There were two illustrators for the story, whose work appeared in the magazine but does not appear in modern printings of the book. The two illustrators, David Henry Friston and Michael Fitzgerald, show some inconsistencies in their depiction of the characters, and as a result some confusion has arisen in relating the pictures to the story's continuous plot.
Plot summary.
The story is presented by Le Fanu as part of the casebook of Dr. Hesselius, whose departures from medical orthodoxy rank him as the first occult doctor in literature. The story is narrated by Laura, one of the two main protagonists of the tale.
Laura begins her tale by relating her childhood in a "picturesque and solitary" castle in the midst of an extensive forest in Styria, where she lives with her father, a wealthy English widower, retired from the Austrian Service. When she was six years old, Laura had a vision of a beautiful visitor in her bedchamber. She later claims to have been bitten on the chest, although no wounds are found on her.
12 years later, Laura and her father are admiring the sunset in front of the castle when her father tells her of a letter he received earlier from his friend, General Spielsdorf. The General was supposed to bring his niece, Bertha Rheinfeldt, to visit the two, but the niece suddenly died under mysterious circumstances. The General ambiguously concludes that he will discuss the circumstances in detail when they meet later.
Laura is saddened by the loss of a potential friend, and longs for a companion. A carriage accident outside Laura's home unexpectedly brings a girl of Laura's age into the family's care. Her name is Carmilla. Both girls instantly recognize the other from the "dream" they both had when they were young.
Carmilla appears injured after her carriage accident, but her mysterious mother informs Laura's father that her journey is urgent and cannot be delayed. She arranges to leave her daughter with Laura and her father until she can return in three months. Before she leaves, she sternly notes that her daughter will not disclose any information whatsoever about her family, past or herself, and that Carmilla is of sound mind. Laura comments that this information seems needless to say, and her father laughs it off.
Carmilla and Laura grow to be very close friends, but occasionally Carmilla's mood abruptly changes. She sometimes makes unsettling romantic advances towards Laura. Carmilla refuses to tell anything about herself or her background, despite questioning from Laura. Her secrecy isn't the only mysterious thing about her. Carmilla sleeps much of the day, and seems to sleepwalk at night. When a funeral procession passes by the two girls and Laura begins singing a hymn, Carmilla bursts out in rage and scolds Laura for singing a Christian song. When a shipment of family heirloom restored portraits arrives at the castle, Laura finds one of her ancestors, "Mircalla, Countess Karnstein", dated 1698. The portrait resembles Carmilla exactly, down to the mole on her neck.
During Carmilla's stay, Laura has nightmares of a fiendish cat-like beast entering her room at night and biting her on the chest. The beast then takes the form of a female figure and disappears through the door without opening it. Laura's health declines and her father has a doctor examine her. He speaks privately with her father and only asks that Laura never be left unattended.
Her father then sets out with Laura in a carriage for the ruined village of Karnstein. They leave a message behind asking Carmilla and one of the governesses entreated to follow after once the perpetually late-sleeping Carmilla wakes up. En route to Karnstein, Laura and her father encounter General Spielsdorf. He tells them his own ghastly story.
Spielsdorf and his niece had met a young woman named Millarca and her enigmatic mother at a costume ball. The General's niece was immediately taken with Millarca. The mother convinced the General that she was an old friend of his and asked that Millarca be allowed to stay with them for three weeks while she attended to a secret matter of great importance.
The General's niece fell mysteriously ill and suffered exactly the same symptoms as Laura. After consulting with a priestly doctor who he had specially ordered, the General came to the realization that his niece was being visited by a vampire. He hid in a closet with a sword and waited until seeing a fiendish cat-like creature stalk around his niece's bedroom and bite her on the neck. He then leapt from his hiding place and attacked the beast, which took the form of Millarca. She fled through the locked door, unharmed. The General's niece died immediately afterward.
When they arrive at Karnstein, the General asks a nearby woodsman where he can find the tomb of Mircalla Karnstein. The woodsman relates that the tomb was relocated long ago by the hero who vanquished the vampires that haunted the region.
While the General and Laura are left alone in the ruined chapel, Carmilla appears. The General and Carmilla both fly into a rage upon seeing each other and the General attacks her with an axe. Carmilla flees and the General explains to Laura that Carmilla is also Millarca, both anagrams for the original name of the vampire Countess Mircalla Karnstein.
The party is then joined by Baron Vordenburg, the descendant of the hero who rid the area of vampires long ago. Vordenburg is an authority on vampires and has discovered that his ancestor was romantically involved with the Countess Karnstein, before she died and became one of the undead. Using his forefather's notes, he locates the hidden tomb of Carmilla. An imperial commission is then summoned, who exhume and destroy the body of the vampire on behalf of the ruling Habsburg Monarchy, within whose domains Styria is situated.
Afterwards, Laura's father takes her on a year-long vacation to recover from the trauma and regain her health.
Sources.
As with "Dracula", critics have looked for the sources used in the writing of the text. Matthew Gibson proposes that Le Fanu used Dom Augustin Calmet's "Dissertations sur les apparitions des anges, des demons et des esprits, et sur les revenants et vampires de Hongrie, de Boheme, de Moravie, et de Silesie" (1746), which was first anonymously translated into English in a single volume in 1759 as "Dissertations Upon the Apparitions of Angels, Daemons, and Ghosts, and Concerning the Vampires of Hungary, Bohemia, Moravia, and Silesia," and later translated into English in 1850 in two volumes as "The phantom world, or, The philosophy of spirits, apparitions, &c." Gibson also believes that the Reverend Sabine Baring-Gould's "The Book of Were-wolves" (1863), and his account of Elizabeth Báthory, Coleridge's "Christabel", and Captain Basil Hall's "Schloss Hainfeld; or a Winter in Lower Styria" (London and Edinburgh, 1836) are other sources for Le Fanu's work. Hall's account provides much of the Styrian background and in particular a model for both Carmilla and Laura in the figure of Jane Anne Cranstoun, Countess Purgstall.
Influence.
Carmilla, the title character, is the original prototype for a legion of female and lesbian vampires. Though Le Fanu portrays his vampire's sexuality with the circumspection that one would expect for his time, it is evident that lesbian attraction is the main dynamic between Carmilla and the narrator of the story:
When compared to other literary vampires of the 19th century, Carmilla is a similar product of a culture with strict sexual mores and tangible religious fear. While Carmilla selected exclusively female victims, she only becomes emotionally involved with a few. Carmilla had nocturnal habits, but was not confined to the darkness. She had unearthly beauty, and was able to change her form and to pass through solid walls. Her animal alter ego was a monstrous black cat, not a large dog as in "Dracula". She did, however, sleep in a coffin. Carmilla works as a gothic horror story because her victims are portrayed as succumbing to a perverse and unholy temptation that has severe metaphysical consequences for them.
Some critics, among them William Veeder, suggest that "Carmilla", notably in its outlandish use of narrative frames, was an important influence on Henry James' "The Turn of the Screw".
Bram Stoker's "Dracula".
Although "Carmilla" is a lesser known and far shorter Gothic vampire story than the generally-considered master work of that genre, "Dracula", the latter is heavily influenced by Le Fanu's novella.
In the earliest manuscript of "Dracula", dated 8 March 1890, the castle is set in Styria, although the setting was changed to Transylvania six days later. Stoker's posthumously published short story "Dracula's Guest", known as the deleted first chapter to "Dracula", shows a more obvious and intact debt to "Carmilla": Both stories are told in the first person. "Dracula" expands on the idea of a first person account by creating a series of journal entries and logs of different persons and creating a plausible background story for them having been compiled. Stoker also indulges the air of mystery further than Le Fanu by allowing the characters to solve the enigma of the vampire along with the reader.
The descriptions of Carmilla and the character of Lucy in "Dracula" are similar, and have become archetypes for the appearance of the waif-like victims and seducers in vampire stories as being rosy-cheeked, slender, languid, and with large eyes, full lips and soft voices. Both women also sleepwalk.
Stoker's Dr. Abraham Van Helsing is a direct parallel to Le Fanu's vampire expert Baron Vordenburg: both characters used to investigate and catalyse actions in opposition to the vampire, and symbolically represent knowledge of the unknown and stability of mind in the onslaught of chaos and death.

</doc>
<doc id="6922" url="http://en.wikipedia.org/wiki?curid=6922" title="Clitoridectomy">
Clitoridectomy

Clitoridectomy or clitorectomy is the surgical removal of the clitoris. It is used rarely as a therapeutic medical procedure, such as when cancer has developed in or spread to the clitoris. Most removals of the clitoris occur as female genital mutilation, defined by the World Health Organization (WHO) as "all procedures involving partial or total removal of the external female genitalia or other injury to the female genital organs whether for cultural, religious or other non-therapeutic reasons." This procedure is also ritual practice in certain tribes in Africa.
Clitoral reconstructive surgery was developed by French surgeon Pierre Foldès. It has been clinically proven to allow women who have undergone female genital mutilation by clitoridectomy, to achieve clitoral orgasms and reduce pain. One organization, Campaign Against Female Genital Mutilation (CAGeM), offers this surgical treatment for free to victims of female genital mutilation.
Historical use of clitoridectomy.
Clitoridectomy was once used to curb female masturbation. Gynaecologists in 19th-century Europe and the United States removed the clitoris to treat insanity and masturbation. The first reported clitoridectomy in the West was carried out in 1822 by a surgeon in Berlin, a Dr. Graefe, on a teenage girl regarded as an "imbecile" who was masturbating frequently.
Isaac Baker Brown (1812–1873), an English gynaecologist who was president of the Medical Society of London in 1865, believed that the "unnatural irritation" of the clitoris caused epilepsy, hysteria, and mania, and he worked "to remove whenever he had the opportunity of doing so", according to his obituary in the "Medical Times and Gazette". Peter Lewis Allen writes that Brown's views caused outrage, and he died penniless after being expelled from the Obstetrical Society.

</doc>
<doc id="6924" url="http://en.wikipedia.org/wiki?curid=6924" title="Cabal">
Cabal

A cabal is a group of people united in some close design together, usually to promote their private views or interests in a church, state, or other community, often by . Cabals are sometimes secret societies composed of a few designing persons, and at other times are manifestations of emergent behavior in society or governance on the part of a community of persons who have well established public affiliation or kinship. The term can also be used to refer to the designs of such persons or to the practical consequences of their emergent behavior, and also holds a general meaning of intrigue and conspiracy. The use of this term usually carries strong connotations of shadowy corners, back rooms and insidious influence. The term is frequently used in conspiracy theories; some Masonic conspiracy theories describe Freemasonry as an internationalist secret cabal.
Origins of the word.
The term "cabal" derives from Cabala (a word that has numerous spelling variations), the Jewish mystical interpretation of the Hebrew scripture. In Hebrew it means "reception" or "tradition", denoting the "sod" (secret) level of Jewish exegesis. In European culture (Christian Cabala, Hermetic Qabalah) it became associated with occult doctrine or a secret.
Association with Charles II.
The term took on its present meaning from a group of ministers of King Charles II of England (Sir Thomas Clifford, Lord Arlington, the Duke of Buckingham, Lord Ashley, and Lord Lauderdale), whose initial letters coincidentally spelled CABAL, and who were the signatories of the Secret Treaty of Dover that allied England to France in a prospective war against the Netherlands. However, the Cabal Ministry they formed can hardly be seen as such; the Scot Lauderdale was not much involved in English governance at all, while the Catholic ministers of the Cabal (Clifford and Arlington) were never much in sympathy with the Protestants (Buckingham and Ashley). Nor did Buckingham and Ashley get on very well with each other. Thus the "Cabal Ministry" never really unified in its members' aims and sympathies, and fell apart by 1672; Lord Ashley, who became Earl of Shaftesbury, later became one of Charles II's fiercest opponents. The theory that the word originated as an acronym from the names of the group of ministers is a folk etymology, although the coincidence was noted at the time and could possibly have popularized its use. The group, who came to prominence after the fall of Charles' first Chief Minister, Lord Clarendon, in 1667, was rather called the Cabal because of its secretiveness and lack of responsibility to the "Country party" then run out of power.
In technology.
During the early years of the Usenet internet messaging system, the term "backbone cabal" was used as a semi-ironic description of the efforts of people to maintain some order over the structure of the community, and led to a popular phrase in the network, "There Is No Cabal" (abbreviated to "TINC").
The computer game company Valve Software uses "Cabal Rooms" when working on specific areas of projects.
The Conficker Cabal is a team of specialists working to defeat the Conficker computer worm, including several notable computer security specialists.
Notable uses.
Former British Prime Minister Gordon Brown denounced the leaders of the regime in Zimbabwe as a "criminal cabal".

</doc>
<doc id="6925" url="http://en.wikipedia.org/wiki?curid=6925" title="Cytochrome">
Cytochrome

Cytochromes are, membrane-bound (i.e. inner mitochondrial membrane) hemeproteins containing heme groups and are primarily responsible for the generation of ATP via electron transport.
They are found either as monomeric proteins (e.g., cytochrome c) or as subunits of bigger enzymatic complexes that catalyze redox reactions.
History.
Cytochromes were initially described in 1884 by MacMunn as respiratory pigments (myohematin or histohematin). In the 1920s, Keilin rediscovered these respiratory pigments and named them the cytochromes, or “cellular pigments”, and classified these heme proteins, on the basis of the position of their lowest energy absorption band in the reduced state, as
cytochromes "a" (605 nm), "b" (~565 nm), and "c" (550 nm). The UV-visible spectroscopic signatures of hemes are still used to identify heme type from the reduced bis-pyridine-ligated state, i.e., the pyridine hemochrome method. Within each class, cytochrome "a", "b", or "c", early cytochromes are numbered consecutively, e.g. cyt "c", cyt "c1", and cyt "c2", with more recent examples designated by their reduced state R-band maximum, e.g. cyt "c559".
Structure and function.
The heme group is a highly conjugated ring system (which allows its electrons to be very mobile) surrounding a metal ion, which readily interconverts between the oxidation states. For many cytochromes, the metal ion present is that of "iron", which interconverts between Fe2+ (reduced) and Fe3+ (oxidized) states (electron-transfer processes) or between Fe2+ (reduced) and Fe3+ (formal, oxidized) states (oxidative processes). Cytochromes are, thus, capable of performing oxidation and reduction. Because the cytochromes (as well as other complexes) are held within membranes in an organized way, the redox reactions are carried out in the proper sequence for maximum efficiency.
In the process of oxidative phosphorylation, which is the principal energy-generating process undertaken by organisms, other membrane-bound and -soluble complexes and cofactors are involved in the chain of redox reactions, with the additional net effect that protons (H+) are transported across the mitochondrial inner membrane. The resulting transmembrane proton gradient (force) is used to generate ATP, which is the universal chemical energy currency of life. ATP is consumed to drive cellular processes that require energy (such as synthesis of macromolecules, active transport of molecules across the membrane, and assembly of flagella).
Types.
Several kinds of cytochrome exist and can be distinguished by spectroscopy, exact structure of the heme group, inhibitor sensitivity, and reduction potential.
Three types of cytochrome are distinguished by their prosthetic groups:
The definition of cytochrome c is not defined in terms of the heme group. There is no "cytochrome e," but there is a cytochrome f, which is often considered a type of cytochrome c.
In mitochondria and chloroplasts, these cytochromes are often combined in electron transport and related metabolic pathways:
A completely distinct family of cytochromes is known as the cytochrome P450 oxidases, so named for the characteristic Soret peak formed by absorbance of light at wavelengths near 450 nm when the heme iron is reduced (with sodium dithionite) and complexed to carbon monoxide. These enzymes are primarily involved in steroidogenesis and detoxification.

</doc>
<doc id="6927" url="http://en.wikipedia.org/wiki?curid=6927" title="Crowded House">
Crowded House

Crowded House is a rock band formed in Melbourne, Australia, in 1985. The founding members were New Zealander Neil Finn (vocalist, guitarist, primary songwriter), and Australians Paul Hester (drums) and Nick Seymour (bass). Later band members included Neil's brother, Tim Finn, and Americans Mark Hart and Matt Sherrod.
Originally active from 1985 to 1996, the band has had consistent commercial and critical success in Australia and New Zealand and international chart success in two phases, beginning with their self-titled debut album, which reached number twelve on the US Album Chart in 1987 and provided the Top Ten hits, "Don't Dream It's Over" and "Something So Strong". Further international success came in the UK and Europe with their third and fourth albums, "Woodface" and "Together Alone" and the compilation album "Recurring Dream", which included the hits "Fall at Your Feet", "Weather with You", "Distant Sun", "Locked Out", "Instinct" and "Not the Girl You Think You Are". Queen Elizabeth II bestowed an OBE on both Neil and Tim Finn, in June 1993, for their contribution to the music of New Zealand.
Founding drummer Hester left in May 1994, citing family reasons, but briefly returned for their "Farewell to the World" concerts in Melbourne and Sydney in 1996. Neil Finn had decided to end the band to concentrate on his solo career and the Finn Brothers project with Tim. On 26 March 2005 Hester committed suicide, aged 46.
In 2006 the group re-formed with new drummer Matt Sherrod and have since released two further albums, both of which reached number one on Australia's Album Chart.
History.
Neil Finn (vocals, guitar, piano) and drummer Paul Hester (ex-The Cheks, Deckchairs Overboard) were former members of New Zealand band Split Enz, which spent part of 1975–6 in Australia and several years in England. Neil is the younger brother of Split Enz founding member Tim Finn, who joined Crowded House in 1990 on vocals, guitars and keyboards for the album "Woodface". Bassist Nick Seymour (ex-Plays with Marionettes, Bang, The Horla) is the younger brother of singer-songwriter and guitarist Mark Seymour of the now defunct Australian rock group Hunters & Collectors.
Formation and name change (1984–1986).
Finn and Hester decided to form a new band during the first Split Enz farewell tour, "Enz with a Bang", in late 1984. Seymour approached Finn during the after party for the Melbourne show and asked if he could audition for the new band. The Mullanes formed in Melbourne in early 1985 with Finn, Hester, Seymour and guitarist Craig Hooper (ex-The Reels) and first performed on 11 June. They secured a record contract with Capitol Records, but Hooper left the band before the remaining trio moved to Los Angeles to record their debut album. At Capitol's behest, the band's name was changed to Crowded House, which alluded to the lack of space at the West Hollywood apartment they shared during the recording of the album "Crowded House". Former Split Enz keyboardist Eddie Rayner produced the track "Can't Carry On" and was asked to join the band. He toured with them in 1988, but was unable to become a full member due to family commitments.
Early albums (1986–1990).
The single, "Don't Dream It's Over", was released in December 1986 and proved a big international hit, reaching number two on the US Billboard Hot 100 and number one in Canada. New Zealand radio stations initially gave the song little support until months later when it became successful internationally. Ultimately the song reached number one on the New Zealand Singles Chart, and number eight in Australia. It remains the group's most commercially successful song.
In March 1987, the group were awarded 'Best New Talent', along with 'Song of the Year' and 'Best Video' for "Don't Dream It's Over", at the inaugural ARIA Music Awards. The video also earned the group the MTV Video Music Award for Best New Artist that year. The song has often been covered by other artists and gave Paul Young a hit single in 1991. It was also used for a New Zealand Tourism Board advertisement in its "100% Pure New Zealand" worldwide promotion from October 2005. In May 2001, "Don't Dream it's Over" was voted 7th in a poll of the Best Australian Songs of all time by the Australasian Performing Rights Association.
In June 1987, a year after its release, "Crowded House" finally reached number one on the Kent Music Report Album Charts. It also reached number three in New Zealand and number twelve on the US Billboard 200 album chart. The follow-up to "Don't Dream it's Over", "Something So Strong", was not as successful as its predecessor but reached the top ten in New Zealand, America and Canada. "World Where You Live" and "Now We're Getting Somewhere" were also released as singles with some minor chart success.
As the band's primary songwriter, Neil Finn was under pressure to create a second album to match their debut and the band joked that one potential title for the new release was "Mediocre Follow-Up". Eventually titled "Temple of Low Men", their second album was released in July 1988 with strong promotion by Capitol Records. The album did not fare as well as their debut in the US, only reaching number 40, but it achieved Australasian success, reaching number one in Australia and number two in New Zealand. The first single "Better Be Home Soon" peaked at number two on both Australian and New Zealand singles charts and reached top 50 in the US, though the following four singles were less successful. Crowded House undertook a short tour of Australia and Canada to promote the album, with Eddie Rayner on keyboards. Multi-instrumentalist Mark Hart, who would eventually become a full band member, replaced Rayner in January 1989. After the tour, Finn fired Seymour from the band. Music journalist Ed Nimmervoll claimed that Seymour's temporary departure was because Finn blamed him for causing his writer's block, however Finn cited "artistic differences" as the reason. Seymour said that after a month he contacted Finn and they agreed that he would return to the band.
Early nineties (1991–1994).
Crowded House took a break after the Canadian leg of the "Temple of Low Men" tour. Neil Finn and his brother Tim recorded songs they had co-written for their own album, "Finn". Following the recording sessions with Tim, Neil began writing and recording a third Crowded House album with Hester and Seymour, but these tracks were rejected by the record company, so Neil asked Tim if Crowded House could use the "Finn" songs. Tim jokingly agreed on the proviso that he become a member, which Neil apparently took literally. With Tim as an official member, the band returned to the studio. The new tracks, as well as some from the previously rejected recordings were combined to make "Woodface", which was released in July 1991. The album features eight tracks co-written by Neil and Tim, which feature the brothers harmonising on lead vocals, except on the sombre "All I Ask" on which Tim sang lead. The track was later used on AIDS awareness commercials in Australia. Five of the album's tracks were Neil's solo compositions and two were by Hester, the exuberant "Italian Plastic", which became a crowd favourite at concerts and the hidden track "I'm Still Here".
"Chocolate Cake", a humorous comment on American excesses that wasn't taken well by some US critics and sections of the American public, was released in June 1991 as the first single. Perhaps unsurprisingly it failed to chart in the US, however it reached number two on Billboard's Modern Rock Tracks chart. The song peaked at number seven in New Zealand and reached the top 20 in Australia. The second single, "Fall at Your Feet", was less successful in Australia and New Zealand but did at least reach the US Hot 100. The album reached number one in New Zealand, number two in Australia, number six in the UK and made the top 20 in several European countries. The third single from "Woodface", "Weather With You", peaked at No. 7 in early 1992 giving the band their highest UK chart placement. By contrast, the album had limited success in the US, only reaching number 83 on the Billboard 200 Album Chart.
Tim left Crowded House during the "Woodface" tour in November 1991, part-way through the UK leg. Performances on this tour, at the Town and Country Club in London, were recorded live and given a limited release in Australia, while individual songs from those shows were released as B-sides of singles in some countries. In June 1993 the New Zealand Government recommended that the Queen award an OBE to Neil and Tim Finn for their contribution to the music of New Zealand.
For their fourth album, "Together Alone", Crowded House used producer Martin Glover (aka Youth) and invited touring musician Mark Hart (guitar & keyboards) to become a permanent band member. The album was recorded at Karekare Beach, New Zealand, which gave its name to the opening track, "Kare Kare". The album was released in October 1993 and sold well internationally on the strength of lead single "Distant Sun" and followup "Private Universe". It topped the New Zealand Album Chart, reached number 2 in Australia and number 4 in the UK. "Locked Out" was the album's first US single and received airplay on MTV and VH1. This track and "My Sharona" by The Knack, which were both included the soundtrack of the film "Reality Bites", were bundled together on a jukebox single to promote the film soundtrack.
Saying farewell (1994–1996).
Crowded House were mid way through a US tour when Paul Hester quit the band on 15 April 1994. He flew home to Melbourne to await the birth of his first child and indicated that he required more time with his family. Wally Ingram, drummer for support act Sheryl Crow, temporarily filled in until a replacement, Peter Jones (ex-Harem Scarem, Vince Jones, Kate Ceberano's Septet) was found. After the tour, the Finn Brothers released their album "Finn" in November 1995. In June 1996, at a press conference to announce the release of their greatest hits album "Recurring Dream", Neil revealed that Crowded House were to disband. The June 1996 concerts in Europe and Canada were to be their final performances.
"Recurring Dream" contained four songs from each of the band's studio albums, along with three new songs. The album debuted at number one in Australia, New Zealand and the UK in July 1996. Early copies included a bonus CD of live material. The album's three new songs, which were released as singles, were "Instinct", "Not the Girl You Think You Are" and "Everything Is Good for You", which featured backing vocals from Pearl Jam's Eddie Vedder. Paul Hester returned to the band to play drums on the three new tracks.
Worried that their goodbye had been too low-key and had disregarded their home fans, the band performed the "Farewell to the World" concert on the steps of the Sydney Opera House on 24 November 1996, which raised funds for the Sydney Children's Hospital. The concert featured the line-up of Neil Finn, Nick Seymour, Mark Hart and Paul Hester. Tim Finn and Peter Jones both made guest appearances. Support bands on the day were Custard, Powderfinger and You Am I. The concert had one of the highest live audiences in Australian history with the crowd being estimated at between 120,000 and 250,000 people. "Farewell to the World" was released on VHS in December 1996. In 2007, a double CD and a DVD were issued as to commemorate the concert's ten-year anniversary. The DVD featured newly recorded audio commentary by Finn, Hart and Seymour and other new bonus material.
Between farewell and reunion (1996–2006).
Tim Finn had resumed his solo career after leaving the group in 1992 and he also worked with Neil on a second Finn Brothers album, "Everyone Is Here", which was released in 2004. Paul Hester joined The Finn Brothers on stage for three songs at their Palais Theatre show in Melbourne at the end of 2004. Nick Seymour also joined them on stage in Dublin, where he was living, in 2004. Peter Jones and Nick Seymour joined Australian group Deadstar for their second album, "Milk", in 1997. Seymour later worked as a record producer in Dublin, producing Irish group Bell X1's debut album, "Neither Am I" in 2000. Mark Hart rejoined Supertramp in the late 1990s and later toured with Ringo Starr & His All-Starr Band. In 2001 he released a solo album, "Nada Sonata".
Paul Hester worked with children's entertainers The Wiggles, playing "Paul the Cook". He also had his own ABC show "Hessie's Shed" in Australia from late 1997. He formed the band Largest Living Things, which was the name rejected by Capitol Records in favour of Crowded House. It was on "Hessie's Shed" that Finn, Hester and Seymour last shared a stage, on an episode filmed as part of Finn's promotion for his solo album "Try Whistling This" in 1998. Finn and Hester performed "Not the Girl You Think You Are" with Largest Living Things, before being joined by Seymour for "Sister Madly" and a version of Paul Kelly's "Leaps and Bounds", which also featured Kelly on vocals. In late 2003, Hester hosted the series "Music Max's Sessions". Hester and Seymour were reunited when they both joined singer-songwriter Matt O'Donnell's Melbourne-based group Tarmac Adam. The band released one album, 2003's "Handheld Torch", which was produced by Seymour.
In May 1999 Crowded House issued a compilation of unreleased songs, "Afterglow", which included the track "Recurring Dream", recorded when the group were still called The Mullanes and included Craig Hooper on guitar. The album's liner notes included information about the songs, written by music journalist David Hepworth. Some limited-release versions included a second CD with songwriting commentary by Finn. The liner notes confirmed that Crowded House had no plans to reunite at that time. A 2003 compilation album, "Classic Masters", was released only in the US, while 2005 saw the release of the album "She Will Have Her Way", a collection of cover versions of Crowded House, Split Enz, Tim Finn and Finn Brothers songs by Australasian female artists. The album reached the top 5 in Australia and New Zealand.
On 26 March 2005 Paul Hester was found dead, after hanging himself from a tree in a park near his home in Melbourne. He was 46 years old. His obituary in "The Sydney Morning Herald" stated that he had fought "a long battle with depression." Following the news of Hester's death, Nick Seymour joined The Finn Brothers on stage at the Royal Albert Hall in London, where the three played in memory of Paul. A snare drum with a top hat on it stood at the front of the stage as a tribute. Writing in 2010 Neil Finn said, "When we lost Paul it was like someone pulled the rug out from underneath everything, a terrible jolt out of the dark blue. He was the best drummer I had ever played with and for many years, my closest friend."
Reunion and "Time on Earth" (2006–2009).
On 17 March 2007 the band played a live show at their rehearsal studio in front of around fifty fans, friends and family. The performance was streamed live as a webcast. The two-and-a-half-hour set included some new tracks, including "Silent House" co-written by Finn with the Dixie Chicks. A concert onboard "The Thekla", moored in Bristol, followed on 19 March. Crowded House played at the Marquee Theatre in Tempe, Arizona on 26 April as a warm-up for their appearance at the Coachella Festival on 29 April in Indio, California. They also played at the Australian Live Earth concert in Sydney on 7 July. The next day, Finn and Seymour were interviewed on "Rove Live" and the band, with Hart and Sherrod, performed "Don't Stop Now" to promote the new album, which was titled "Time on Earth". The single was a minor hit in Australia and the UK. The album was released worldwide in June and July. It topped the album chart in New Zealand and made number 2 in Australia and number 3 in the UK.
On 6 December 2008 Crowded House played the Homebake festival in Sydney, with warm up gigs at small venues in Hobart, Melbourne and Sydney. For these shows the band were augmented by multi-instrumentalist Don McGlashan and Neil's younger son, Elroy Finn, on guitar. On 14 March 2009 the band joined Neil's older son, Liam Finn, on stage for three songs at the Sound Relief concert in Melbourne.
"Intriguer" (2009–current).
Crowded House undertook an extensive world tour in 2010 in support of "Intriguer". This was the first album where the band regularly interacted with fans via the internet on their own re-launched website, Twitter and Facebook. The band sold recordings of the shows on the "Intriguer" tour on USB flash drives and made individual live tracks available for free download.
A new compilation album, The Very Very Best of Crowded House, was released in October 2010 to celebrate the band's 25th anniversary. It includes 19 of the band's greatest hits and is also available in a box set with a 25 track DVD of their music videos. A deluxe digital version, available for download only, has 32 tracks including a rare 1987 live recording of the band's version of the Hunters & Collectors song "Throw Your Arms Around Me". No mention of this album has been made on the band's official website or Twitter page, which suggests that they are not involved with its release.
Following the success of the album "She Will Have Her Way" in 2005, a second album of cover versions of Finn Brothers songs, "He Will Have His Way", was released on 12 November 2010. All tracks on this album are performed by Australasian male artists. In November 2011 there was an Australian tour by various artists involved with the "She Will Her Way" and "He Will Have His Way" projects, under the name "They Will Have Their Way." The tour featured Paul Dempsey, Clare Bowditch, Seeker Lover Keeper (Sarah Blasko, Sally Seltmann and Holly Throsby), Alexander Gow (Oh Mercy) and Lior.
Former Crowded House drummer Peter Jones died from brain cancer on 18 May 2012 aged 49. A statement issued by the band described him as, "A warm-hearted, funny and talented man, who was a valuable member of Crowded House."
Style.
Songwriting and musical influences.
As the primary songwriter for the band, Neil Finn has always set the tone for the band's sound. Allmusic said that Finn "has consistently proven his knack for crafting high-quality songs that combine irresistible melodies with meticulous lyrical detail." Neil's brother Tim was an early and important musical influence. Neil first saw Tim play with Split Enz in 1972, and said "that performance and those first songs made a lasting impression on me." His mother was another significant musical influence, encouraging him to listen to a variety of genres, including Irish folk music and Māori music. She would play piano at family parties and encourage Neil and Tim to accompany her.
Album covers, costumes and set design.
Bassist Nick Seymour, who is also an artist, designed or co-designed all of the band's album covers and interior artwork. He also designed some of the costumes worn by the group, notably those from the cover of the group's debut album "Crowded House". Seymour collaborated with Finn and Hester on the set design of some of their early music videos, including "Don't Dream It's Over" and "Better Be Home Soon". Since the band reunited, Seymour has again designed their album covers.
The majority of the covers for the band's singles were not designed by Seymour. The artwork for "Pineapple Head" was created by Reg Mombassa of Mental As Anything. For the first four albums Mombassa and Noel Crombie, who had been the main designer of Split Enz's artwork, assisted Seymour in creating sets and costumes. For the "Farewell to the World" concerts Crombie designed the set, while Mombassa and Seymour designed promotional materials and artwork.
Awards.
Crowded House has won several national and international awards. In Australia, the group has won eleven ARIA Awards from 26 nominations, including the inaugural "Best New Talent" award in 1987. The majority of their ARIAs were awarded for their first two albums, "Crowded House" and "Temple of Low Men". They won eight APRA Awards from eleven nominations and were nominated for "The New Zealand Silver Scroll" for "Don't Stop Now" in 2007. "Don't Dream It's Over" was named the seventh best Australian song of all time in 2001. In 1987, Crowded House won the American MTV Video Music Award for "Best New Artist" for their song "Don't Dream It's Over", which was also nominated for three other awards. In 1994, the group was named "International Group of the Year" at the BRIT Awards. In 2009, "Don't Dream It's Over" was ranked number fifty on the Triple J "Hottest 100 of All Time", voted by the Australian public.

</doc>
<doc id="6928" url="http://en.wikipedia.org/wiki?curid=6928" title="Colette">
Colette

Colette () was the surname of the French novelist and performer Sidonie-Gabrielle Colette (28 January 1873 – 3 August 1954). She is best known for her novel "Gigi", upon which Lerner and Loewe based the stage and film musical comedies of the same title.
Early life and marriage.
Colette was born to retired military officer Jules-Joseph Colette and his wife Adèle Eugénie Sidonie "Sido" Colette (nėe Landoy) in Saint-Sauveur-en-Puisaye, Yonne, in the Burgundy Region of France. She studied piano as a child and received her primary school diploma with high marks in mathematics and dictation. In 1893, at age 20, she married Henry Gauthier-Villars, a famous wit known as "Willy", who was 15 years her senior. He was a writer, music critic, and described as a "literary charlatan and degenerate".
Her first books, the "Claudine" series, were published under her husband's pen name "Willy". "Claudine" still has the power to charm; in "belle époque", France it was downright shocking, much to Willy's satisfaction and profit.
According to one writer, "Colette had a poor relationship with her own daughter, Bel-Gazou."
Music hall career, affairs with women.
In 1906, she left the unfaithful Gauthier-Villars, living for a time at the home of the American writer and salonist Natalie Clifford Barney. The two had a short affair, and remained friends until Colette's death.
Colette went to work in the music halls of Paris, under the wing of Mathilde de Morny, Marquise de Belbeuf, known as Missy, with whom she became romantically involved. In 1907, the two performed together in a pantomime entitled "Rêve d'Égypte" at the Moulin Rouge. Their onstage kiss nearly caused a riot, which the police were called in to suppress. As a result of this scandal, further performances of "Rêve d'Égypte" were banned, and Colette and de Morny were no longer able to live together openly, though their relationship continued for five years. She also was involved in a heterosexual relationship during this time, with the Italian writer Gabriele d'Annunzio. According to one writer, Colette "never gave Missy as much love" and took "advantage of her and more or less appropriating Rozven, a Brittany villa, from her after they split up." Another affair during this period was with the automobile-empire scion Auguste Heriot.
Second marriage, affair with stepson.
In 1912, Colette married Henri de Jouvenel, the editor of the newspaper "Le Matin". The couple had one daughter, Colette de Jouvenel, known to the family as Bel-Gazou ("beautiful babbling/chirping" in local dialect). Colette de Jouvenel later stated that her mother did not want a child and left her in the care of an English nanny, only rarely visiting her.
In 1914, during World War I, Colette was approached to write a ballet for the Paris Opera, which she outlined under the title "Divertissements pour ma fille". After Colette herself chose Maurice Ravel to write the music, he reimagined the work as an opera, to which Colette agreed. Ravel received the libretto to "L'enfant et les sortilèges" in 1918, and it was first performed on 21 March 1925.
During the war, she converted her husband's Saint-Malo estate into a hospital for the wounded, and was made a Chevalier of the Legion of Honour (1920). She divorced Henri de Jouvenel in 1924 after a much talked-about affair with her stepson, Bertrand de Jouvenel.
Third marriage.
In 1935, Colette married Maurice Goudeket, an uncle of Juliet Goudeket alias Jetta Goudal. After 1935, her legal name was simply Sidonie Goudeket. Maurice Goudeket published a book about his wife, "Close to Colette: An Intimate Portrait of a Woman of Genius". An English translation was published in 1957 by Farrar, Straus & Cudahy, New York.
Continued writings.
Post-World War I, her writing career bloomed following the publication of "Chéri" (1920). Chéri tells a story of the end of a six-year affair between an aging retired courtesan, Léa, and a pampered young man, Chéri. Turning stereotypes upside-down, it is Chéri who wears silk pajamas and Léa's pearls, and who is the object of gaze. In the end, Léa demonstrates all the survival skills, which Colette associates with femininity. (The story continued in "La Fin de Chéri" (1926), which contrasts Léa's strength and Chéri's fragility and decline.) Considered nowadays to be Colette's masterpiece, "Chéri" was originally met with controversy because of its choice of setting - the demimonde of the Parisian courtesans - and also because of its portrayal of the hedonistic Chéri.
After "Chéri", Colette entered the world of modern poetry and painting revolving around Jean Cocteau, who was later her neighbor in Jardins du Palais-Royal. Their relationship and life is vividly depicted in their books. By 1927, she was frequently acclaimed as France's greatest woman writer. "It ... has no plot, and yet tells of three lives all that should be known", wrote Janet Flanner of "Sido" on its publication in 1930. "Once again, and at greater length than usual, she has been hailed for her genius, humanities and perfect prose by those literary journals which years ago ... lifted nothing at all in her direction except the finger of scorn."
During World War II, Colette remained in Paris during the German Occupation and continuing to write and publish because "she said that she had to make a living." "Gigi", set in the same Belle Epoque world as "Cheri", became a bestseller because it took place during a glamorous time that "sweep her readers away from their everyday concerns of wartime shortages and danger."
She spent her final years in a wheelchair, being cared for by Goudeket, whom she called "a saint". In 1951 she attended the premiere of a documentary about her life, and at the end she was heard saying to Goudeket, ""What a beautiful life I've had"".
Upon her death in Paris in 1954, Colette left 50 published novels in total, many with autobiographical elements. Her themes can be roughly divided into idyllic natural tales or dark struggles in relationships and love. All her novels were marked by clever observation and dialogue with an intimate, explicit style.
Her popular novella "Gigi" was made into a Broadway play and a highly successful Hollywood motion picture of the same name, starring Leslie Caron, Louis Jourdan, and Maurice Chevalier. Colette is directly credited with the discovery of a young, unknown Audrey Hepburn, whom the elder chose on sight to play the eponymous Broadway lead in "Gigi". According to Hepburn herself, she was garrisoned with the 1952 film production company of Monte Carlo Baby at a hotel in the south of France for brief location shooting, the relatively unglamorous assignment part of a standard contract. Hepburn at the time commanded barely more stature than many unknowns after the Armistice in a European film industry decimated by World War II. Colette chanced to see the young Hepburn walking across the lobby of the hotel and immediately said to her companion of the moment, "There is my Gigi!" In 2009, an adaptation by Christopher Hampton of both "Chéri" and "La Fin de Chéri" was made into a film starring Michelle Pfeiffer, Rupert Friend, and Kathy Bates and directed by Stephen Frears. 
A pre-Broadway production of the musical, newly adapted by Heidi Thomas ("Call the Midwife, Cranford, Upstairs Downstairs") and directed by Eric D. Schaeffer ("Follies, Million Dollar Quartet") is planned to run at the Kennedy Center in January 2015.
Legacy.
A controversial figure throughout her life, Colette flaunted her lesbian affairs. 
She was a member of the Belgian Royal Academy (1935), president of the Académie Goncourt (1949) (and the first woman to be admitted into it, in 1945), and a Chevalier (1920) and a Grand Officier (1953) of the Légion d'honneur.
During the German occupation of France during World War II, she aided her Jewish friends, including hiding her husband in her attic all through the war. When she died in Paris on 3 August 1954, she was the first woman given a state funeral in France, although she was refused Roman Catholic rites because of her divorces. Colette is interred in Père Lachaise Cemetery in Paris.
Singer-songwriter Rosanne Cash paid tribute to the writer in the song, "The Summer I Read Colette", on her 1996 album "10 Song Demo".
Truman Capote wrote a short story about her (1970) called "The White Rose".
The Colette Study Centre in France has numerorous items relation to Colette's life. Dr. Jane Gilmour, Ph.D, wrote "" (Hardie Grant Books), which is a book "about Colette’s life through the places where she lived."

</doc>
<doc id="6932" url="http://en.wikipedia.org/wiki?curid=6932" title="Charles Alston">
Charles Alston

Charles Henry Alston (November 28, 1907 – April 27, 1977) was an African-American painter, sculptor, illustrator, muralist and teacher who lived and worked in the New York City neighborhood of Harlem. Alston was active in the Harlem Renaissance; Alston was the first African-American supervisor for the Works Progress Administration's Federal Art Project. Alston designed and painted murals at the Harlem Hospital and the Golden State Mutual Life Insurance Building. In 1990 Alston's bust of Martin Luther King, Jr. became the first image of an African American displayed at the White House.
Personal life.
Early life.
Charles Henry Alston was born on November 28, 1907 in Charlotte, North Carolina to Reverend Primus Priss Alston and Anna Elizabeth Miller Alston, and was the youngest of five children. Only three survived past infancy: His sister Rousmaniere, and his brothers Wendell and Charles. His father was born into slavery in 1851 in Pittsboro, North Carolina; after the Civil War, he graduated from St. Augustine's College and became a prominent minister and founder of St. Michael's Episcopal Church. He was described as a "race man": an African American who dedicated his skills to the furtherance of the black race. Reverend Alston met his wife when she was a student at his school. Charles was nicknamed "Spinky" by his father, and kept the nickname as an adult. In 1910, when Charles was three, his father died suddenly of a cerebral hemorrhage. Locals described him in admiration as the "Booker T. Washington of Charlotte".
In 1913 Anna Alston married Harry Bearden. Through the marriage, the future artist Romare Bearden became Charles’ cousin. The two Bearden families lived across the street from each other; the friendship between Romare and Charles would last a lifetime. As a child Alston was inspired by his older brother Wendell's drawings of trains and cars, which the young artist copied. Charles also played with clay, creating a sculpture of North Carolina. As an adult he reflected on his memories of sculpting with clay as a child: "I’d get buckets of it and put it through strainers and make things out of it. I think that's the first art experience I remember, making things." His mother was a skilled embroiderer and took up painting at the age of 75. His father was also good at drawing, wooing Alston's mother with small sketches in the medians of letters he wrote her.
In 1915 the family moved to New York, as many African-American families did during the Great Migration. Alston's step-father, Henry Bearden, left before his wife and children to secure a job overseeing elevator operations and the newsstand staff at the Bretton Hotel in the Upper West Side. The family lived in Harlem and was considered middle-class. During the Great Depression, the people of Harlem suffered economically. The "stoic strength" seen within the community was later expressed in Charles’ fine art. At Public School 179 in Manhattan, the boy's artistic abilities were recognized and he was asked to draw all of the school posters during his years there.
Higher education.
Alston graduated from DeWitt Clinton High School, where he was nominated for academic excellence and was the art editor of the school's magazine, "The Magpie". He was a member of the Arista - National Honor Society and also studied drawing and anatomy at the Saturday school of the National Academy of Art . In high school he was given his first oil paints and learned about his aunt Bessye Bearden's art salons, which stars like Duke Ellington and Langston Hughes attended. After graduating in 1925, he attended Columbia University, turning down a scholarship to the Yale School of Fine Arts. Alston entered the pre-architectural program only to lose interest upon seeing the lack of success many African American architects had in the field. After also experimenting with pre-med, he decided that math, physics and chemistry "was not just my bag" and he entered the fine arts program. During his time at Columbia he joined Alpha Phi Alpha, worked on the university's "Columbia Daily Spectator" and drew cartoons for the school's magazine "Jester". He also hung out in Harlem restaurants and clubs, where his love for jazz and black music would be fostered. In 1929 he graduated and received a fellowship to study at Teachers College, where he obtained his Master's in 1931.
Later life.
For the years 1942–1943 Alston was stationed in the army at Fort Huachuca in Arizona. Upon returning to New York on April 8, 1944, he married Dr. Myra Adele Logan, an intern at the Harlem Hospital. They met when he was working on a mural project at the hospital. Their home, including his studio, as on Edgecombe Avenue near Highbridge Park. The couple lived close to family; at their frequent gatherings Alston enjoyed cooking and Myra played piano. During the 1940s Alston also took occasional art classes studying under Alexander Kostellow.
In January 1977 Myra Logan died. Months later on April 27, 1977, Charles "Spinky" Alston died after a long bout with cancer. His memorial service was held at St. Martins Episcopal Church on May 21, 1977 in New York City.
Professional career.
While obtaining his master's degree, Alston was the boys’ work director at the Utopia Children's House, started by James Lesesne Wells. He also began teaching at the Harlem Arts Workshop, founded by Augusta Savage in the basement of what is now the Schomburg Center for Research in Black Culture. Alston's teaching style was influenced by the work of John Dewey, Arthur Wesley Dow, and Thomas Munro. During this period, Alston began to teach the 10-year old Jacob Lawrence, whom he strongly influenced. Alston was introduced to African art by the poet Alain Locke. In the late 1920s Alston joined Bearden and other black artists who refused to exhibit in William E. Harmon Foundation shows, which featured all-black artists in their traveling exhibits. Alston and his friends thought the exhibits were curated for a white audience, a form of segregation which the men protested. They did not want to be set aside but exhibited on the same level as art peers of every skin color.
In 1938 the Rosenwald Fund provided money for Alston to travel to the South, which was his first return there since leaving as a child. His travel with Giles Hubert, an inspector for the Farm Security Administration, gave him access to certain situations and he photographed many aspects of rural life. These photographs serves as the basis for a series of genre portraits' depicting southern black life. In 1940 he completed "Tobacco Farmer", the portrait of a young black farmer in white overalls and a blue shirt with a youthful yet serious look upon his face, sitting in front of the landscape and buildings he works on and in. That same year he received a second round of funding from the Rosenwald Fund to travel South, and he spent extended time at Atlanta University.
During the 1930s and early 1940s, Alston created illustrations for magazines such as "Fortune", "Mademoiselle", "The New Yorker", "Melody Maker" and others. He also designed album covers for artists such as Duke Ellington and Coleman Hawkins. Alston became staff artist at the Office of War Information and Public Relations in 1940, creating drawings of notable African Americans. These images were used in over 200 black newspapers across the country by the government to "foster goodwill with the black citizenry,".
Eventually Alston left commercial work to focus on his own artwork. In 1950, he became the first African-American instructor at the Art Students League, where he remained on faculty until 1971. In 1950, his "Painting" was exhibited at the Metropolitan Museum of Art and his artwork was one of few purchased by the museum. He landed his first solo exhibition in 1953 at the John Heller Gallery, who represented artists such as Roy Lichtenstein. He exhibited there five times from 1953–1958.
In 1956, he became the first African-American instructor at the Museum of Modern Art, where he taught for a year before going to Belgium on behalf of MOMA and the State Department. He coordinated the children's community center at Expo 58. In 1958 he was awarded a grant from and was elected as a member of the American Academy of Arts and Letters.
In 1963, Alston co-founded Spiral with Romare Bearden and Hale Woodruff. Spiral served as a collective of conversation and artistic exploration for a large group of artists who "addressed how black artists should relate to American society in a time of segregation." Artists and arts supporters gathered for Spiral, such as Emma Amos, Perry Ferguson and Merton Simpson. 
In 1968, Alston received a presidential appointment from Lyndon Johnson to the National Council of Culture and the Arts. Mayor John Lindsay appointed him to the New York City Art Commission in 1969. He was made full professor at City College of New York in 1973 where he had taught since 1968. In 1975 he was awarded the first Distinguished Alumni Award from Teachers College. The Art Student's League created a 21-year merit scholarship in 1977 under Alston's name to commemorate each year of his tenure.
Painting a person and a culture.
Alston shared studio space with Henry Bannarn at 306 W. 141st St, which served as an open space for artists, photographers, musicians, writers and the like. Other artists held studio space at 306, such as Jacob Lawrence, Addison Bate and his brother Leon. During this time Alston founded the Harlem Artists’ Guild with Savage and Elba Lightfoot to work towards equality in WPA art programs in New York. During the early years of 306, Alston focused on mastering portraiture. Early works such as "Portrait of a Man" (1929) show Alston's detailed and realistic style depicted through pastels and charcoals, inspired by the style of Winold Reiss. In his "Girl in a Red Dress" (1934) and "The Blue Shirt" (1935), he used modern and innovative techniques for his portraits of young individuals in Harlem. "Blue Shirt" is thought to be a portrait of Jacob Lawrence. During this time he also created "Man Seated with Travel Bag" (c. 1938–40), showing the seedy and bleak environment, contrasting with work like the racially charged "Vaudeville" (c. 1930) and its caricature style of a man in blackface.
Inspired from his trip South, Alston began his "family series" in the 1940s. Intensity and angularity come through in the faces of the youth in his portraits "Untitled (Portrait of a Girl)" and "Untitled (Portrait of a Boy)". These works also show the influence that African sculpture had on his portraiture, showing, with "Portrait of a Boy" showing more cubist features. Later family portraits show Alston's exploration of religious symbolism, color, form and space. His family group portraits are often faceless, which Alston states is the way that white America views blacks. Paintings such as "Family" (1955) show a woman seated and a man standing with two children – the parents seem almost solemn while the children are described as hopeful and with a use of color made famous by Cézanne. In "Family Group" (c. 1950) Alston's use of grey and ochre tones brings together the parents and son as if one with geometric patterns connecting them together as if a puzzle. The simplicity of the look, style and emotion upon the family is reflective and probably inspired by Alston's trip south. His work during this time has been described as being "characterized by his reductive use of form combined with a sun-hued". During this time he also started to experiment with ink and wash painting seen in work like "Portrait of a Woman" (1955) as well as creating portraits to illustrate the music surrounding him in Harlem. "Blues Singer #4" shows a female singer on stage with a white flower on her shoulder and a bold red dress, reminiscent of Ella Fitzgerald. "Girl in a Red Dress" is thought to may be Bessie Smith, for whom he drew many times when she was recording and performing. Jazz was an important influence in Alston's work and social life, representing itself in other works like "Jazz" (1950) and "Harlem at Night".
The 1960s civil rights movement influenced his work heavily with artworks influenced by inequality and race relations in the United States. One of his few religious artworks was created in 1960, "Christ Head", with an angular "Modiglianiesque" portrait of Jesus Christ. Seven years later he created "You never really meant it, did you, Mr. Charlie?" which, in a similar style as "Christ Head" shows a black man standing against a red sky "looking as frustrated as any individual can look", according to Alston.
Modernism.
Experimenting with the use of negative space and organic forms in the late 1940s, by the mid-1950s Alston began creating notably modernist style paintings. "Woman with Flowers" (1949) has been described as a tribute to Modigliani and African art makes another strong appearance in "Ceremonial" (1950). Untitled works during the era show his use of color overlay using muted colors to create simple layered abstracts of still live. "Symbol" (1953) relates to Picasso's "Guernica", which was a favorite work of Alston's. His final work of the 1950s, "Walking" serves as a precursor to the 1960s: civil rights movement. The painting, which was inspired by the Montgomery Bus Boycott, has come to represent "the surge of energy among African Americans to organize in their struggle for full equality." About the artwork, Alston is quoted "The idea of a march was growing...It was in the air...and this painting just came. I called it "Walking" on purpose. It wasn't the militancy that you saw later. It was a very definite walk-not going back, no hesitation."
Black and white.
The civil rights movement of the 1960s was a major influence on Alston. Considered to be one of his most powerful and impressive periods in the late 1950s he began working in black and white up until the mid-1960s. Some of the works are simple abstracts of black ink on white paper, similar to a Rorschach test. "Untitled" (c. 1960s) shows a boxing match in great simplicity with an attempt to express the drama of the fight through few brushstrokes. Alston worked with oil-on-Masonite during this period as well, utilizing impasto, cream and ochre to create a moody cave-like artwork. "Black and White #1" (1959) is one of Alston's more "monumental" works. Gray, white and black come together to fight for space on an abstract canvas, in a softer form than the more harsh Franz Kline. Alston continued to explore the relationship between monochromatic hues throughout the series which Wardlaw describes as "some of the most profoundly beautiful works of twentieth-century American art."
Murals.
In the beginning Charles Alston's mural work was inspired by the work of Aaron Douglas, Diego Rivera and José Clemente Orozco, the latter who he met when they did mural work in New York. In 1943 Alston was elected to the board of directors of the National Society of Mural Painters. He created murals for the Harlem Hospital, Golden State Mutual, American Museum of Natural History, Public School 154, the Bronx Family and Criminal Court and the Abraham Lincoln High School in Brooklyn, New York.
Harlem Hospital Murals.
Originally hired as an easel painter, in 1935 Alston became the first African American supervisor to work for the WPA's Federal Art Project in New York, which would also serve as his first mural work. At this time he was awarded WPA Project Number 1262 – an opportunity to oversee a group of artists creating murals and to supervise their painting for the Harlem Hospital. The first government commission ever awarded to African American artists including Beauford Delaney, Seabrook Powell and Vertis Hayes. He also had the chance to create and paint his own contribution to the collection: "Magic in Medicine" and "Modern Medicine". These paintings were part of a diptych completed in 1936 depicting the history of medicine in the African American community and Beauford Delaney served as assistant. When creating the murals Alston was inspired by the work of Aaron Douglas, who a year earlier had created the public art piece "Aspects of Negro Life" for the New York Public Library, and researched traditional African culture, including traditional African medicine. "Magic in Medicine", which depicts African culture and holistic healing, is considered one of "America's first public scenes of Africa". All of the murals sketches submitted were accepted by the FAP, however, four were denied creation by the hospital superintendent Lawrence T. Dermody and commissioner of hospitals S.S. Goldwater due to the excessive amount of African-American representation in the works. The artists fought the response through letter writing and four years later succeeded in gaining the right to complete the murals. The sketches for "Magic in Medicine" and "Modern Medicine" were exhibited in the Museum of Modern Art's "New Horizons in American Art".
Condition.
Alston's murals were hung in the Women's Pavilion of the hospital over uncapped radiators which caused the paintings to deteriorate from the steam. Plans failed to recap the radiators. In 1959 Alston estimated, in a letter to the Department of Public Works, that the conservation would cost $1,500 but the funds were never acquired. In 1968, after Martin Luther King Jr.'s death, Alston was asked to create another mural for the hospital to be placed in a pavilion named after the assassinated civil rights leader titled "Man Emerging from the Darkness of Poverty and Ignorance into the Light of a Better World"." After Alston's death in 1977 a committee was formed, unable to raise funds for conservation on the original murals. In 1991 the Municipal Art Society's Adopt-a-Mural program was launched and the Harlem Hospital murals were chosen. A grant from Alston's sister Rousmaniere Wilson and step-sister Aida Bearden Winters assisted in completing a restoration of the works in 1993. In 2005 Harlem Hospital announced a $2 million project to conserve Alston's murals and three other pieces in the original commissioned project as part of a $225 million hospital expansion.
Golden State Mutual Murals.
In the late 1940s Alston became involved in a mural project commissioned by Golden State Mutual Life Insurance Company which asked the artists to create work involving African American contributions to the settling of California. Alston worked with Hale Woodruff on the murals in a large studio space in New York where they utilized ladders to reach the upper parts of the canvas. The artworks, which are considered "priceless contributions to American narrative art", consists of two panels: "Exploration and Colonization" by Alston and "Settlement and Development" by Woodruff. Alston's piece covers the post-colonial period of 1527 to 1850. Images of James Beckworth, Biddy Mason, and William Leidesdorff are portrayed in the well detailed historical mural. While both artists kept in contact with African Americans on the West Coast during its creation, influencing the content and depictions. The murals, which were unveiled in 1949, have been on display in the lobby of the Golden State Mutual Headquarters. Due to economic downturn Golden State was forced to sell their entire art collection to ward off its mounting debts and as of spring 2011 the National Museum of African American History and Culture had offered $750,000 to purchase the artworks which led to a controversy regarding the importance of the artworks which have been estimated to be worth at least $5 million. It was requested that the murals be covered by city landmark protections by the Los Angeles Conservancy. The state of California had declined philanthropic proposals to keep the murals in their original location and the Smithsonian withdrew their offer. The murals are currently awaiting their fate in California courts.
Sculpture.
Alston also created sculptures. "Head of a Woman" (1957) shows his move towards a "reductive and modern approach to sculpture...where facial features were suggested rather than fully formulated in three dimensions,". In 1970 Alston was commissioned by the Community Church of New York to create a bust of Martin Luther King Jr. for $5,000, with limited copies produced. In 1990 Alston's bronze bust of Martin Luther King Jr. (1970), became the first image of an African American displayed in the White House.
Reception.
Art critic Emily Genauer stated that Alston "refused to be pigeonholed", regarding his varied exploration in his artwork. Patron Lemoine Pierce said of Alston's work: "Never thought of as an innovative artist, Alston generally ignored popular art trends and violated many mainstream art conventions; he produced abstract and figurative paintings often simultaneously, refusing to be stylistically consistent, and during his 40-year career he worked prolifically and unapologetically in both commercial and fine art." Romare Bearden described Alston as "...one of the most versatile artists whose enormous skill led him to a diversity of styles..." Bearden also describes the professionalism and impact that Alston had on Harlem and the African American community: "'was a consummate artist and a voice in the development of African American art who never doubted the excellence of all people's sensitivity and creative ability. During his long professional career, Alston significantly enriched the cultural life of Harlem. In a profound sense, he was a man who built bridges between Black artists in varying fields, and between other Americans." Writer June Jordan described Alston as "an American artist of first magnitude, and he is a Black American artist of undisturbed integrity."

</doc>
<doc id="6933" url="http://en.wikipedia.org/wiki?curid=6933" title="Chromatin">
Chromatin

Chromatin is the combination or complex of DNA and proteins that make up the contents of the nucleus of a cell. The primary functions of chromatin are 1) to package DNA into a smaller volume to fit in the cell, 2) to strengthen the DNA to allow mitosis, 3) to prevent DNA damage, and 4) to control gene expression and DNA replication. The primary protein components of chromatin are histones that compact the DNA. Chromatin is only found in eukaryotic cells: prokaryotic cells have a very different organization of their DNA, which is referred to as a genophore (a chromosome without chromatin).
The structure of chromatin depends on several factors. The overall structure depends on the stage of the cell cycle. During interphase, the chromatin is structurally loose to allow access to RNA and DNA polymerases that transcribe and replicate the DNA. The local structure of chromatin during interphase depends on the genes present on the DNA: DNA coding genes that are actively transcribed ("turned on") are more loosely packaged and are found associated with RNA polymerases (referred to as euchromatin) while DNA coding inactive genes ("turned off") are found associated with structural proteins and are more tightly packaged (heterochromatin). Epigenetic chemical modification of the structural proteins in chromatin also alter the local chromatin structure, in particular chemical modifications of histone proteins by methylation and acetylation. As the cell prepares to divide, i.e. enters mitosis or meiosis, the chromatin packages more tightly to facilitate segregation of the chromosomes during anaphase. During this stage of the cell cycle this makes the individual chromosomes in many cells visible by optical microscope.
In general terms, there are three levels of chromatin organization:
There are, however, many cells that do not follow this organisation. For example, spermatozoa and avian red blood cells have more tightly packed chromatin than most eukaryotic cells, and trypanosomatid protozoa do not condense their chromatin into visible chromosomes for mitosis.
During interphase.
The structure of chromatin during interphase is optimized to allow easy access of transcription and DNA repair factors to the DNA while compacting the DNA into the nucleus. The structure varies depending on the access required to the DNA. Genes that require regular access by RNA polymerase require the looser structure provided by euchromatin.
Change in structure.
Chromatin undergoes various forms of change in its structure. Histone proteins, the foundation blocks of chromatin, are modified by various post-translational modification to alter DNA packing. Acetylation results in the loosening of chromatin and lends itself to replication and transcription. When certain residues are methylated, they hold DNA together strongly and restrict access to various enzymes. A recent study showed that there is a bivalent structure present in the chromatin: methylated lysine residues at location 4 and 27 on histone 3. It is thought that this may be involved in development; there is more methylation of lysine 27 in embryonic cells than in differentiated cells, whereas lysine 4 methylation positively regulates transcription by recruiting nucleosome remodeling enzymes and histone acetylases.
Polycomb-group proteins play a role in regulating genes through modulation of chromatin structure.
For additional information, see Histone modifications in chromatin regulation and RNA polymerase control by chromatin structure.
DNA structure.
The vast majority of DNA within the cell is the normal DNA structure. However, in nature, DNA can form three structures, A-, B-, and Z-DNA. A and B chromosomes are very similar, forming right-handed helices, whereas Z-DNA is a more unusual left-handed helix with a zig-zag phosphate backbone. Z-DNA is thought to play a specific role in chromatin structure and transcription because of the properties of the junction between B- and Z-DNA.
At the junction of B- and Z-DNA, one pair of bases is flipped out from normal bonding. These play a dual role of a site of recognition by many proteins and as a sink for torsional stress from RNA polymerase or nucleosome binding.
The nucleosome and "beads-on-a-string".
The basic repeat element of chromatin is the nucleosome, interconnected by sections of linker DNA, a far shorter arrangement than pure DNA in solution.
In addition to the core histones, there is the linker histone, H1, which contacts the exit/entry of the DNA strand on the nucleosome. The nucleosome core particle, together with histone H1, is known as a chromatosome. Nucleosomes, with about 20 to 60 base pairs of linker DNA, can form, under non-physiological conditions, an approximately 10 nm "beads-on-a-string" fibre. (Fig. 1-2). .
The nucleosomes bind DNA non-specifically, as required by their function in general DNA packaging. There are, however, large DNA sequence preferences that govern nucleosome positioning. This is due primarily to the varying physical properties of different DNA sequences: For instance, adenosine and thymine are more favorably compressed into the inner minor grooves. This means nucleosomes can bind preferentially at one position approximately every 10 base pairs (the helical repeat of DNA)- where the DNA is rotated to maximise the number of A and T bases that will lie in the inner minor groove. (See mechanical properties of DNA.)
30-nanometer chromatin fibre.
With addition of H1, the "beads-on-a-string" structure in turn coils into a 30 nm diameter helical structure known as the 30 nm fibre or filament. The precise structure of the chromatin fibre in the cell is not known in detail, and there is still some debate over this .
This level of chromatin structure is thought to be the form of euchromatin, which contains actively transcribed genes. EM studies have demonstrated that the 30 nm fibre is highly dynamic such that it unfolds into a 10 nm fiber ("beads-on-a-string") structure when transversed by an RNA polymerase engaged in transcription.
The existing models commonly accept that the nucleosomes lie perpendicular to the axis of the fibre, with linker histones arranged internally.
A stable 30 nm fibre relies on the regular positioning of nucleosomes along DNA. Linker DNA is relatively resistant to bending and rotation. This makes the length of linker DNA critical to the stability of the fibre, requiring nucleosomes to be separated by lengths that permit rotation and folding into the required orientation without excessive stress to the DNA.
In this view, different length of the linker DNA should produce different folding topologies of the chromatin fiber. Recent theoretical work, based on electron-microscopy images
of reconstituted fibers support this view.
Spatial organization of chromatin in the cell nucleus.
The layout of the genome within the nucleus is not random - specific regions of the genome have a tendency to be found in certain spaces. Specific regions of the chromatin are enriched at the nuclear membrane, while other regions are bound together by protein complexes. The layout of this is not, however, well-characterised apart from the compaction of one of the two X chromosomes in mammalian females into the Barr body. This serves the role of permanently deactivating these genes, which prevents females from getting a 'double dose' relative to males. The extent to which the inactive X is actually compacted is a matter of some controversy.
Chromatin and bursts of transcription.
Chromatin and its interaction with enzymes has been researched, and a conclusion being made is that it is relevant and an important factor in gene expression. Vincent G. Allfrey, a professor at Rockefeller University, stated that RNA synthesis is related to histone acetylation. The lysine amino acid attached to the end of the histones is positively charged. The acetylation of these tails would make the chromatin ends neutral, allowing for DNA access.
When the chromatin decondenses, the DNA is open to entry of molecular machinery. Fluctuations between open and closed chromatin may contribute to the discontinuity of transcription, or transcriptional bursting. Other factors are probably involved, such as the association and dissociation of transcription factor complexes with chromatin. The phenomenon, as opposed to simple probabilistic models of transcription, can account for the high variability in gene expression occurring between cells in isogenic populations
Metaphase chromatin.
The metaphase structure of chromatin differs vastly to that of interphase. It is optimised for physical strength and manageability, forming the classic chromosome structure seen in karyotypes. The structure of the condensed chromosome is thought to be loops of 30 nm fibre to a central scaffold of proteins. It is, however, not well-characterised.
The physical strength of chromatin is vital for this stage of division to prevent shear damage to the DNA as the daughter chromosomes are separated. To maximise strength the composition of the chromatin changes as it approaches the centromere, primarily through alternative histone H1 anologues.
It should also be noted that, during mitosis, while most of the chromatin is tightly compacted, there are small regions that are not as tightly compacted. These regions often correspond to promoter regions of genes that were active in that cell type prior to entry into cromitosis. The lack of compaction of these regions is called bookmarking, which is an epigenetic mechanism believed to be important for transmitting to daughter cells the "memory" of which genes were active prior to entry into mitosis. This bookmarking mechanism is needed to help transmit this memory because transcription ceases during mitosis.
Alternative chromatin organizations.
During metazoan spermiogenesis, the spermatid's chromatin is remodelled into a more spaced-packaged, widened, almost crystal-like structure. This process is associated with the cessation of transcription and involves nuclear protein exchange. The histones are mostly displaced, and replaced by protamines (small, arginine-rich proteins).
Nobel Prizes.
The following scientists were recognized for their contributions to chromatin research with Nobel Prizes:

</doc>
<doc id="6934" url="http://en.wikipedia.org/wiki?curid=6934" title="Condition number">
Condition number

In the field of numerical analysis, the condition number of a function with respect to an argument measures how much the output value of the function can change for a small change in the input argument. This is used to measure how sensitive a function is to changes or errors in the input, and how much error in the output results from an error in the input. Very frequently, one is solving the inverse problem – given formula_1 one is solving for "x," and thus the condition number of the (local) inverse must be used.
The condition number is an application of the derivative, and is formally defined as the value of the asymptotic worst-case relative change in output for a relative change in input. The "function" is the solution of a problem and the "arguments" are the data in the problem. The condition number is frequently applied to questions in linear algebra, in which case the derivative is straightforward but the error could be in many different directions, and is thus computed from the geometry of the matrix. More generally, condition numbers can be defined for non-linear functions in several variables.
A problem with a low condition number is said to be well-conditioned, while a problem with a high condition number is said to be ill-conditioned. The condition number is a property of the problem. Paired with the problem are any number of algorithms that can be used to solve the problem, that is, to calculate the solution. Some algorithms have a property called backward stability. In general, a backward stable algorithm can be expected to accurately solve well-conditioned problems. Numerical analysis textbooks give formulas for the condition numbers of problems and identify the backward stable algorithms.
As a general rule of thumb, if the condition number formula_2, then you may lose up to formula_3 digits of accuracy on top of what would be lost to the numerical method due to loss of precision from arithmetic methods. However, the condition number does not give the exact value of the maximum inaccuracy that may occur in the algorithm. It generally just bounds it with an estimate (whose computed value depends on the choice of the norm to measure the inaccuracy).
Matrices.
For example, the condition number associated with the linear equation
"Ax" = "b" gives a bound on how inaccurate the solution "x" will be after approximation. Note that this is before the effects of round-off error are taken into account; conditioning is a property of the matrix, not the algorithm or floating point accuracy of the computer used to solve the corresponding system. In particular, one should think of the condition number as being (very roughly) the rate at which the solution, "x", will change with respect to a change in "b". Thus, if the condition number is large, even a small error in "b" may cause a large error in "x". On the other hand, if the condition number is small then the error in "x" will not be much bigger than the error in "b".
The condition number is defined more precisely to be the maximum ratio of the relative error in "x" divided by the relative error in "b".
Let "e" be the error in "b". Assuming that "A" is a square matrix, the error in the solution "A"−1"b" is "A"−1"e". The ratio of the relative error in the solution to the relative error in "b" is
This is easily transformed to
The maximum value (for nonzero "b" and "e") is easily seen to be the product of the two operator norms:
The same definition is used for any consistent norm, i.e. one that satisfies
When the condition number is exactly one, then the algorithm may find an approximation of the solution with an arbitrary precision. However it does not mean that the algorithm will converge rapidly to this solution, just that it won't diverge arbitrarily because of inaccuracy on the source data (backward error), provided that the forward error introduced by the algorithm does not diverge as well because of accumulating intermediate rounding errors.
The condition number may also be infinite, in which case the algorithm will not reliably find a solution to the problem, not even a weak approximation of it (and not even its order of magnitude) with any reasonable and provable accuracy.
Of course, this definition depends on the choice of norm:
If the condition number is close to one, the matrix is well conditioned which means its inverse can be computed with good accuracy. If the condition number is large, then the matrix is said to be ill-conditioned. Practically, such a matrix is almost singular, and the computation of its inverse, or solution of a linear system of equations is prone to large numerical errors. A matrix that is not invertible has the condition number equal to infinity.
Non-linear.
Condition numbers can also defined for nonlinear functions, and can be computed using calculus. The condition number varies with the point; in some cases one can use the maximum (or supremum) condition number over the domain of the function or domain of the question as an overall condition number, while in other cases the condition number at a particular point is of more interest.
One variable.
The condition number of a differentiable function "f" in one variable as a function is formula_26 Evaluated at a point "x" this is:
Most elegantly, this can be understood as (the absolute value of) the ratio of the logarithmic derivative of "f," which is formula_28 and the logarithmic derivative of "x," which is formula_29 yielding a ratio of formula_26 This is because the logarithmic derivative is the infinitesimal rate of relative change in a function: it is the derivative formula_31 scaled by the value of "f." Note that if a function has a zero at a point, its condition number at the point is infinite, as infinitesimal changes in the input can change the output from zero to positive or negative, yielding a ratio with zero in the denominator, hence infinite relative change.
More directly, given a small change formula_32 in "x," the relative change in "x" is formula_33 while the relative change in formula_34 is formula_35 Taking the ratio yields:
The last term is the difference quotient (the slope of the secant line), and taking the limit yields the derivative.
Condition numbers of common elementary functions are particularly important in computing significant figures, and can be computed immediately from the derivative; see significance arithmetic of transcendental functions. A few important ones are given below:
Several variables.
Condition numbers can be defined for any function "ƒ" mapping its data from some domain (e.g. an "m"-tuple of real numbers "x") into some codomain an "n"-tuple of real numbers "ƒ"("x"), where both the domain and codomain are Banach spaces. They express how sensitive that function is to small changes (or small errors) in its arguments. This is crucial in assessing the sensitivity and potential accuracy difficulties of numerous computational problems, for example polynomial root finding or computing eigenvalues.
The condition number of "ƒ" at a point "x" (specifically, its relative condition number) is then defined to be the maximum ratio of the fractional change in "ƒ"("x") to any fractional change in "x", in the limit where the change δ"x" in "x" becomes infinitesimally small:
where formula_54 is a norm on the domain/codomain of "ƒ"("x").
If "ƒ" is differentiable, this is equivalent to:
where "J" denotes the Jacobian matrix of partial derivatives of "ƒ" and formula_56 is the induced norm on the matrix.

</doc>
<doc id="6936" url="http://en.wikipedia.org/wiki?curid=6936" title="Cheddar cheese">
Cheddar cheese

Cheddar cheese is a relatively hard, pale-yellow-to-off-white (unless artificially coloured), sometimes "sharp" (i.e., acidic)-tasting, natural cheese. Originating in the English village of Cheddar in Somerset, cheeses of this style are produced beyond this region and in several countries around the world.
Cheddar is the most popular type of cheese in the UK, accounting for 51 percent of the country's £1.9 billion annual cheese market. It is also the second-most-popular cheese in the U.S.A. (behind mozzarella), with an average annual consumption of per capita. 
The United States produced in 2010, and the UK in 2008. The term "cheddar cheese" is widely used, but has no Protected Designation of Origin (PDO) within the European Union. However, only cheddar produced from local milk within four counties of South West England, may use the name "West Country Farmhouse Cheddar". Cheddar produced in Orkney is registered as protected geographical indication (PGI) under the name "Orkney Scottish Island Cheddar".
History.
The cheese originates from the village of Cheddar in Somerset, South West England. Cheddar Gorge on the edge of the village contains a number of caves, which provided the ideal humidity and steady temperature for maturing the cheese. Cheddar cheese traditionally had to be made within of Wells Cathedral.
Cheddar has been produced since at least the 12th century. A pipe roll of King Henry II from 1170 records the purchase of at a farthing per pound (totaling £10.13s.4d., about £10.67 in decimal currency). 
Charles I (1600–1649) also bought cheese from the village.
Romans may have brought the recipe to Britain from the Cantal region of France.
Central to the modernisation and standardisation of cheddar cheese, was the 19th century Somerset dairyman Joseph Harding.
For his technical innovations, promotion of dairy hygiene, and volunteer dissemination of modern cheese-making techniques, he has been dubbed "the father of cheddar cheese".
Harding introduced new equipment to the process of cheese-making, including his "revolving breaker" for curd cutting, saving much manual effort.
The "Joseph Harding method" was the first modern system for cheddar production based upon scientific principles. Harding stated that cheddar cheese is "not made in the field, nor in the byre, nor even in the cow, it is made in the dairy". He and his wife were behind the introduction of the cheese into Scotland and North America. His sons, Henry and William Harding, were responsible for introducing cheddar cheese production to Australia and facilitating the establishment of the cheese industry in New Zealand respectively.
During the Second World War, and for nearly a decade after, most milk in Britain was used for the making of one single kind of cheese nicknamed "government cheddar" as part of war economies and rationing. This almost resulted in wiping out all other cheese production in the country. Before the First World War there were more than 3,500 cheese producers in Britain; fewer than 100 remained after the Second World War.
According to a United States Department of Agriculture researcher, cheddar cheese is the world's most popular variety of cheese, and the most studied type of cheese in scientific publications.
Process.
The curds and whey are separated using rennet, an enzyme complex normally produced from the stomachs of newborn calves (in vegetarian or kosher cheeses, bacterial-, yeast- or mould-derived chymosin is used).
"Cheddaring" refers to an additional step in the production of cheddar cheese where, after heating, the curd is kneaded with salt, cut into cubes to drain the whey and then stacked and turned. Strong, extra-mature cheddar, sometimes called vintage, needs to be matured for up to 15 months. The cheese is kept at a constant temperature often requiring special facilities. As with other hard cheese varieties produced worldwide, caves provide an ideal environment for maturing cheese; still, today, some cheddar cheese is matured in the caves at Wookey Hole and Cheddar Gorge. Additionally, some versions of cheddar cheese are smoked.
Character.
The ideal quality of the original Somerset cheddar was described by Joseph Harding in 1864 as "close and firm in texture, yet mellow in character or quality; it is rich with a tendency to melt in the mouth, the flavour full and fine, approaching to that of a hazelnut".
Cheddar made in the classical way tends to have a sharp, pungent flavour, often slightly earthy. Its texture is firm, with farmhouse traditional cheddar being slightly crumbly; it should also, if mature, contain large cheese crystals consisting of calcium lactate – often precipitated when matured for times longer than six months.
Cheddar is usually a deep to pale yellow (off-white) colour, but food colourings are sometimes used in industrial varieties of cheddar-style cheeses. One commonly used example is annatto, extracted from seeds of the tropical achiote tree. The largest producer of industrial cheddar-style cheese in the United States, Kraft, uses a combination of annatto and oleoresin paprika, an extract of the lipophilic (oily) portion of paprika. Coloured cheddar cheese has long been sold, but even as early as 1860, the real reason for this was unclear: Joseph Harding stated "to the cheese consumers of London who prefer an adulterated food to that which is pure I have to announce an improvement in the annatto with which they compel the cheesemakers to colour the cheese." According to David Feldman, an author of trivia books, "The only reason why cheesemakers colour their product is because consumers seem to prefer it."
Cheddar cheese was sometimes (and still can be found) packaged in black wax, but was more commonly packaged in larded cloth, which was impermeable to contaminants, but still allowed the cheese to "breathe", although this practice is now limited to artisan cheese makers.
The Slow Food Movement has created a "Cheddar Presidium", claiming that only three cheeses should be called "original cheddar". Their specifications, which go further than the "West Country Farmhouse Cheddar" Protected Designation of Origin (PDO), require that cheddar cheese be made in Somerset and with traditional methods, such as using raw milk, traditional animal rennet, and a cloth wrapping.
Notable cheddar cheeses include "Quickes", which in 2009 was awarded cheese of the year by the British Cheese Association, "Keen's", with a strong tang, and "Montgomery's", with an apple aftertaste. Lincolnshire Poacher cheese is an example of a cheese made in the style of a traditional cheddar in Lincolnshire.
International production.
Status.
The cheddar cheese name is used internationally; its name does not have a protected designation of origin (PDO) but the use of the name "West Country Farmhouse Cheddar" does. Countries making cheddar cheese include Australia, Argentina, Belgium, Canada, Ireland, the Netherlands, New Zealand, South Africa, Sweden, the United Kingdom and the United States. Cheddars can be industrial or artisan cheeses. The flavour, colour and quality of industrial cheese varies significantly, and food packaging will usually indicate a strength, such as mild, medium, strong, tasty, sharp, extra sharp, mature, old, or vintage; this may indicate the maturation period, or food additives used to enhance the flavour. Artisan varieties develop strong and diverse flavours over time.
Canada.
Following a wheat midge outbreak in Canada in the mid-nineteenth century, farmers in Ontario began to convert to dairy farming in large numbers, and cheddar cheese became their main exportable product, even being exported to England. By the turn of the twentieth century there were 1,242 cheddar factories in Ontario, and cheddar had become Canada’s second largest export after timber. Cheddar exports totaled in 1904, but by 2012, Canada was a net importer of cheese. James L. Kraft grew up on a dairy farm in Ontario, before moving to Chicago. According to the writer Sarah Champman, "Although we cannot wholly lay the decline of cheese craft in Canada at the feet of James Lewis Kraft, it did correspond with the rise of Kraft’s processed cheese empire." Most Canadian cheddar is produced by a number of large companies in Ontario, though other provinces produce some and there are some smaller artisanal producers. The annual production is 120,000 tons It is aged a minimum of three months, but much of it is held for much longer, up to 10 years.
Canadian cheddar cheese soup is a featured dish at the Canada pavilion at Epcot, in Walt Disney World.
New Zealand.
Much of the cheddar cheese in New Zealand is factory produced but of good quality. Most of it is sold young within the country. The Anchor dairy company ships New Zealand cheddars to the UK, where they mature for another year or so.
United Kingdom.
Only one producer of the cheese is now based in Cheddar itself, The Cheddar Gorge Cheese Co. The name "cheddar" is not protected by the European Union, though the name "West Country Farmhouse Cheddar" has an EU protected designation of origin, and may only be produced in Somerset, Devon, Dorset and Cornwall, using milk sourced from those counties. Cheddar is usually sold as mild, medium, mature, extra mature or vintage. Mature cheddar is the best selling variety in the UK.
United States of America.
The state of Wisconsin produces the most cheddar cheese in the U.S.A.; other centres of production include: California; Idaho; upstate New York; Vermont; Tillamook, Oregon; Texas; and, Oklahoma. It is sold in several varieties (mild, medium, sharp, extra-sharp, New York-style, white-, and, Vermont-). New York-style cheddar is particularly "sharp"/acidic, but tends to physically be somewhat softer than the milder-tasting varieties. Cheese that has "not" been artificially coloured the familiar yellow-orange hue, is frequently labelled "white cheddar" or "Vermont cheddar" (regardless of whether it was actually produced there). Vermont has three creameries that produce what is regarded as first-class cheddar cheeses: the Cabot Creamery, which produces the sixteen-month-old "Private Stock Cheddar", the Grafton Village Company, and Shelburne Farms.
Some cheeses called "cheddar" are actually flavoured processed cheeses or "cheese foods"; they often bear little resemblance to their natural namesakes. Examples include Easy Cheese: a cheese-food packaged in a pressurized spray can; also, as packs of square, sliced, individually-wrapped, "processed cheese" (sometimes also pasteurized).
Cheddar is one of several products used by the United States Department of Agriculture to track the status of America's overall dairy industry; reports are issued weekly detailing prices and production quantities.
Record cheddars.
U.S. President Andrew Jackson once held an open house party at the White House at which he served a 1,400-pound (640 kg) block of cheddar cheese.
A cheese of was produced in Ingersoll, Ontario, in 1866 and exhibited in New York and Britain; it was immortalised in the poem "Ode on the Mammoth Cheese Weighing over 7,000 Pounds" by James McIntyre, a Canadian poet.
In 1893, farmers from the town of Perth, Ontario, produced "The Mammoth Cheese", which weighed for the Chicago World's Fair. It was planned to be exhibited at the Canadian display, but the mammoth cheese fell through the floor and was placed on a reinforced concrete floor in the Agricultural Building. It received the most journalistic attention at the fair and was awarded the bronze medal. A larger, Wisconsin cheese of was made for the 1964 New York World's Fair. A cheese this size would use the equivalent of the daily milk production of 16,000 cows.
Oregon members of the Federation of American Cheese-makers created the largest cheddar cheese in 1989. The cheese weighed .

</doc>
<doc id="6938" url="http://en.wikipedia.org/wiki?curid=6938" title="Classical order">
Classical order

A classical order is one of the ancient styles of classical architecture, each distinguished by its proportions and characteristic profiles and details, and most readily recognizable by the type of column employed. Three ancient orders of architecture—the Doric, Ionic, and Corinthian—originated in Greece. To these the Romans added the Tuscan, which they made simpler than Doric, and the Composite, which was more ornamental than the Corinthian. The order of a classical building is akin to the mode or key of classical music, the grammar or rhetoric of a written composition. It is established by certain "modules" like the intervals of music, and it raises certain expectations in an audience attuned to its language.
Elements.
Each style has distinctive capitals and entablatures. The column shaft is sometimes articulated with vertical hollow grooves known as fluting. The shaft is wider at the bottom than at the top, because its entasis, beginning a third of the way up, imperceptibly makes the column slightly more slender at the top, although some Doric columns are visibly "flared", with straight profiles that narrow going up the shaft. 
The capital rests on the shaft. It has a load-bearing function, which concentrates the weight of the entablature on the supportive column, but it primarily serves an aesthetic purpose. The necking is the continuation of the shaft, but is visually separated by one or many grooves. The echinus lies atop the necking. It is a circular block that bulges outwards towards the top to support the abacus, which is a square or shaped block that in turn supports the entablature. The entablature consists of three horizontal layers, all of which are visually separated from each other using moldings or bands. In Roman and post-Renaissance work, the entablature may be carried from column to column in the form of an arch that springs from the column that bears its weight, retaining its divisions and sculptural enrichment, if any.
Measurement.
The height of columns are calculated in terms of a ratio between the diameter of the shaft at its base and the height of the column. A Doric column can be described as seven diameters high, an Ionic column as eight diameters high and a Corinthian column nine diameters high, although the actual ratios used vary considerably in both ancient and revived examples, but keeping to the trend of increasing slimness between the orders. Sometimes this is phrased as "lower diameters high", to establish which part of the shaft has been measured.
Greek orders.
There are three distinct orders in Ancient Greek architecture: Doric, Ionic, and Corinthian. These three were adopted by the Romans, who modified their capitals. The Roman adoption of the Greek orders took place in the 1st century BC. The three Ancient Greek orders have since been consistently used in neo-classical European architecture.
Sometimes the Doric order is considered the earliest order, but there is no evidence to support this. Rather, the Doric and Ionic orders seem to have appeared at around the same time, the Ionic in eastern Greece and the Doric in the west and mainland.
Both the Doric and the Ionic order appear to have originated in wood. The Temple of Hera in Olympia is the oldest well-preserved temple of Doric architecture. It was built just after 600 BC. The Doric order later spread across Greece and into Sicily where it was the chief order for monumental architecture for 800 years.
Doric order.
The Doric order originated on the mainland and western Greece. It is the simplest of the orders, characterized by short, faceted, heavy columns with plain, round capitals (tops) and no base. With a height that is only four to eight times its diameter, the columns are the most squat of all orders. The shaft of the Doric order is channeled with 20 flutes. The capital consists of a necking which is of a simple form. The echinus is convex and the abacus is square.
Above the capital is a square abacus connecting the capital to the entablature. The Entablature is divided into three horizontal registers, the lower part of which is either smooth or divided by horizontal lines. The upper half is distinctive for the Doric order. The frieze of the Doric entablature is divided into triglyphs and metopes. A triglyph is a unit consisting of three vertical bands which are separated by grooves. Metopes are the plain or carved reliefs between two triglyphs.
The Greek forms of the Doric order come without an individual base. They instead are placed directly on the stylobate. Later forms, however, came with the conventional base consisting of a plinth and a torus. The Roman versions of the Doric order have smaller proportions. As a result they appear lighter than the Greek orders.
Ionic order.
The Ionic order came from eastern Greece, where its origins are entwined with the similar but little known Aeolic order. It is distinguished by slender, fluted pillars with a large base and two opposed "volutes" (also called "scrolls") in the echinus of the capital. The echinus itself is decorated with an egg-and-dart motif. The Ionic shaft comes with four more flutes than the Doric counterpart (totalling 24). The Ionic base has two convex moldings called "tori" which are separated by a scotia.
The Ionic order is also marked by an entasis, a curved tapering in the column shaft. A column of the ionic order is nine times its lower diameter. The shaft itself is eight diameters high. The architrave of the entablature commonly consists of three stepped bands ("fasciae"). The frieze comes without the Doric "triglyph" and "metope". The frieze sometimes comes with a continuous ornament such as carved figures instead.
Corinthian order.
The Corinthian order is the most ornate of the Greek orders, characterized by a slender fluted column having an ornate capital decorated with two rows of acanthus leaves and four scrolls. It is commonly regarded as the most elegant of the three orders. The shaft of the Corinthian order has 24 flutes. The column is commonly ten diameters high.
The Roman writer Vitruvius credited the invention of the Corinthian order to Callimachus, a Greek sculptor of the 5th century BC. The oldest known building built according to this order is the Choragic Monument of Lysicrates in Athens, constructed from 335 to 334 BC. The Corinthian order was raised to rank by the writings of Vitruvius in the 1st century BC.
Roman orders.
The Romans adapted all the Greek orders and also developed two orders of their own, basically modification of Greek orders. The Romans also invented the superposed order. A superposed order is when successive stories of a building have different orders. The heaviest orders were at the bottom, whilst the lightest came at the top. This means that the Doric order was the order of the ground floor, the Ionic order was used for the middle story, while the Corinthian or the Composite order was used for the top story.
The Colossal order was invented by architects in the Renaissance. The Colossal order is characterized by columns that extend the height of two or more stories.
Tuscan order.
The Tuscan order has a very plain design, with a plain shaft, and a simple capital, base, and frieze. It is a simplified adaptation of the Doric order by the Romans. The Tuscan order is characterized by an unfluted shaft and a capital that only consists of an echinus and an abacus. In proportions it is similar to the Doric order, but overall it is significantly plainer. The column is normally seven diameters high. Compared to the other orders, the Tuscan order looks the most solid.
Composite order.
The Composite order is a mixed order, combining the volutes of the Ionic with the leaves of the Corinthian order. Until the Renaissance it was not ranked as a separate order. Instead it was considered as a late Roman form of the Corinthian order. The column of the Composite order is ten diameters high.
Historical development of the orders.
The Renaissance period saw renewed interest in the ruins left by the ancient cultures of Greece and Rome, and the fertile development of a new architecture based on classical principles. The handbook "De architectura" by Roman writer, architect and engineer Vitruvius, is the only architectural writing that survived from Antiquity. Rediscovered in the 15th century, Vitruvius was instantly hailed as the authority on classical orders and on architecture in general.
Architects of the Renaissance and the Baroque periods in Europe based their rules on Vitruvius' writings. What was added were rules for the use of the classical orders, and the exact proportions of the orders down to the most minute detail. Commentary on the appropriateness of the orders for temples devoted to particular deities (Vitruvius I.2.5) were elaborated by Renaissance theorists, with Doric characterized as bold and manly, Ionic as matronly, and Corinthian as maidenly.
Vignola's orders.
Following the examples of Vitruvius and the five books of the "Regole generali d'architettura" by Sebastiano Serlio, published from 1537 onwards, Giacomo Barozzi da Vignola produced an architecture rule book that was more practical than the previous two books, which were more philosophical in nature, his "Cinque ordini di erchitettura" ("The Five Orders of Architecture ") from 1562; the book is considered "one of the most successful architectural textbooks ever written", despite having no text apart from the notes and the introduction. The book consisted simply of an introduction followed by 32 annotated plates, with views from the Pantheon illustrating the Corinthian order and the Theatre of Marcellus for the Doric order. Later editions had more illustrations. By 1700, it had been reprinted 15 times in Italian, and was translated in Dutch, English, French, German, Russian and Spanish.
Each period interpreted the orders in their own way. The architecture of every subsequent period of European architecture was based on the classical orders. In the later 18th century the rules of the Renaissance and the Baroque periods came to be disregarded, and the original use of the orders revived, based on first-hand study of the ruins of classical antiquity - often hailed as the 'correct' use of the orders. 
In America, "The American Builder's Companion", written in the early 19th century by the architect Asher Benjamin, influenced many builders in the eastern states, particularly those who developed what became known as the Federal style.
The break from the classical mode came first with the Gothic revival, then the development of modernism during the 19th century. The Bauhaus promoted pure functionalism, stripped of superfluous ornament, and that has become one of the defining characteristics of modern architecture. There are some exceptions. Postmodernism introduced an ironic use of the orders as a cultural reference, divorced from the strict rules of composition. On the other hand, a few practitioners e.g. Quinlan Terry still work in a traditional classical idiom.
Nonce orders.
Several orders, usually based upon the composite order and only varying in the design of the capitals, have been invented under the inspiration of specific occasions, but have not been used again. Thus they may be termed "nonce orders" on the analogy of nonce words. Robert Adam's brother James was in Rome in 1762, drawing antiquities under the direction of Clérisseau; he invented a British Order, of which his ink-and-wash rendering with red highlighting, is at the Avery Library, Columbia University. Adam published an engraving of it. In its capital the heraldic lion and unicorn take the place of the Composite's volutes, a Byzantine/Romanesque conception, but expressed in terms of neoclassical realism. In 1789 George Dance invented an Ammonite Order, a variant of Ionic substituting volutes in the form of fossil ammonites for John Boydell's Shakespeare Gallery in Pall Mall, London.
In the United States Benjamin Latrobe, the architect of the Capitol building in Washington DC, designed a series of botanically American orders. Most famous is the order substituting corncobs and their husks, which was executed by Giuseppe Franzoni and employed in the small domed Vestibule of the Supreme Court. Only the Supreme Court survived the fire of August 24, 1814, nearly intact. With peace restored, Latrobe designed an American order that substituted for the acanthus tobacco leaves, of which he sent a sketch to Thomas Jefferson in a letter, November 5, 1816. He was encouraged to send a model of it, which remains at Monticello. In the 1830s Alexander Jackson Davis admired it enough to make a drawing of it. In 1809 Latrobe invented a second American order, employing magnolia flowers constrained within the profile of classical mouldings, as his drawing demonstrates. It was intended for "the Upper Columns in the Gallery of the Entrance of the Chamber of the Senate" (United States Capitol exhibit).
Edwin Lutyens, who from 1912 laid out New Delhi as the new seat of government for the British Empire in India, designed a Delhi Order having a capital displaying a band of vertical ridges, and with bells hanging at each corner as a replacement for volutes. His design for the new city's central palace, Viceroy's House, now the Presidential residence Rashtrapati Bhavan, was a thorough integration of elements of Indian architecture into a building of classical forms and proportions, and made use of the order throughout. The Delhi Order reappears in some later Lutyens buildings including Campion Hall, Oxford.
These nonce orders all express the "speaking architecture" ("architecture parlante") that was taught in the Paris courses, most explicitly by Étienne-Louis Boullée, in which sculptural details of classical architecture could be enlisted to speak symbolically, the better to express the purpose of the structure and enrich its visual meaning with specific appropriateness. This idea was taken up strongly in the training of Beaux-Arts architecture, ca 1875-1915: see architecture parlante.

</doc>
<doc id="6941" url="http://en.wikipedia.org/wiki?curid=6941" title="Colin Kapp">
Colin Kapp

Colin Kapp (3 April 1928 – 3 August 2007) was a British science fiction author.
A contemporary of Brian Aldiss and James White, Kapp is best known for his stories about the Unorthodox Engineers.
Works.
Short stories.
Unorthodox Engineers.
Collected in "The Unorthodox Engineers" (1979)

</doc>
<doc id="6942" url="http://en.wikipedia.org/wiki?curid=6942" title="Catherine of Aragon">
Catherine of Aragon

Catherine of Aragon (Castilian: Catalina; 16 December 1485 – 7 January 1536) was Queen of England from 1509 until 1533 as the first wife of King Henry VIII; she was previously Princess of Wales as the wife of Prince Arthur.
The daughter of Queen Isabella I of Castile and King Ferdinand II of Aragon, Catherine was three years old when she was betrothed to Prince Arthur, heir apparent to the English throne. They married in 1501, and Arthur died five months later. In 1507, she held the position of ambassador for the Spanish Court in England, becoming the first female ambassador in European history. Catherine subsequently married Arthur's younger brother, the recently succeeded Henry VIII, in 1509. For six months in 1513, she served as regent of England while Henry VIII was in France. During that time the English won the Battle of Flodden, an event in which Catherine played an important part.
By 1525, Henry VIII was infatuated with his mistress, Anne Boleyn, and dissatisfied that his marriage to Catherine had produced no surviving sons, leaving their daughter, the future Mary I of England, as heiress presumptive at a time when there was no established precedent for a woman on the throne. He sought to have their marriage annulled, setting in motion a chain of events that led to England's schism with the Catholic Church. When Pope Clement VII refused to annul the marriage, Henry defied him by assuming supremacy over religious matters. In 1533 their marriage was declared invalid and Henry married Anne on the judgement of clergy in England, without reference to the Pope. Catherine refused to accept Henry as Supreme Head of the Church of England and considered herself the King's rightful wife and queen, attracting much popular sympathy. Despite this, she was acknowledged only as Dowager Princess of Wales by Henry. After being banished from court, she lived out the remainder of her life at Kimbolton Castle, and died there on 7 January 1536.
Catherine's English subjects held her in high esteem, and her death set off tremendous mourning among the English people.
The controversial book "The Education of Christian Women" by Juan Luis Vives, which claimed women have the right to an education, was commissioned by and dedicated to her. Such was Catherine's impression on people, that even her enemy, Thomas Cromwell, said of her "If not for her sex, she could have defied all the heroes of History." She successfully appealed for the lives of the rebels involved in the Evil May Day, for the sake of their families. Catherine also won widespread admiration by starting an extensive programme for the relief of the poor. She was a patron of Renaissance humanism, and a friend of the great scholars Erasmus of Rotterdam and Thomas More.
Early life.
Catherine was born at the Archbishop's Palace in Alcalá de Henares near Madrid, on the night of 16 December 1485. She was the youngest surviving child of King Ferdinand II of Aragon and Queen Isabella I of Castile. Catherine was quite short in stature with long red hair, wide blue eyes, a round face, and a fair complexion. She was descended, on her maternal side, from the English royal house; her great-grandmother Catherine of Lancaster, after whom she was named, and her great-great-grandmother Philippa of Lancaster were both daughters of John of Gaunt and granddaughters of Edward III of England. Consequently she was third cousin of her father-in-law, Henry VII of England, and fourth cousin of her mother-in-law Elizabeth of York.
Catherine was educated by a tutor, Alessandro Geraldini, who was a clerk in Holy Orders. She studied religion, the classics, Latin histories, canon and civil law, heraldry, and genealogy. She had a strong religious upbringing and developed a faith that would play a major role in later life. She learned to speak, read and write in Spanish and Latin, and spoke French and Greek. She was also taught domestic skills, such as needlepoint, lace-making, embroidery, music and dancing. The great scholar Erasmus later said that Catherine "loved good literature which she had studied with success since childhood".
At an early age, Catherine was considered a suitable wife for Arthur, Prince of Wales, heir apparent to the English throne, due to the English ancestry she inherited from her mother. By means of her mother, Catherine had a stronger legitimate claim to the English throne than King Henry VII himself through the first two wives of John of Gaunt, 1st Duke of Lancaster: Blanche of Lancaster and Constance of Castile. In contrast, Henry VII was the descendant of Gaunt's third marriage to Katherine Swynford, whose children were born out of wedlock and only legitimised after the death of Constance and the marriage of John to Katherine. The children of John and Katherine, while legitimised, were barred from ever inheriting the English throne, a stricture that was ignored in later generations. Because of Henry's descent through illegitimate children barred from succession to the English throne, the Tudor monarchy was not accepted by all European kingdoms. At the time, the house of Trastámara was the most prestigious in Europe, due to the rule of the Catholic Monarchs, so the alliance of Catherine and Arthur validated the House of Tudor in the eyes of European royalty and also strengthened the Tudor claim to the English throne via Catherine of Aragon's ancestry. It would also have given a male heir an indisputable claim to the throne. The two were married by proxy on 19 May 1499 and corresponded in Latin until Arthur turned fifteen, when it was decided that they were old enough to be married.
When Catherine of Aragon travelled to London she brought a group of her African attendants with her, including one identified as the trumpeter John Blanke. They are the first recorded Africans to arrive in London at the time, and were considered luxury servants. They caused a great impression about the princess and the power of her family.
As wife and widow of Arthur.
The couple met on 4 November at Dogmersfield in Hampshire. Little is known about their first impressions of each other, but Arthur did write to his parents-in-law that he would be "a true and loving husband" and told his parents that he was immensely happy to "behold the face of his lovely bride". The couple found that they could not understand each other, since they had learned different pronunciations of Latin. Ten days later, on 14 November 1501, they were married at Old St. Paul's Cathedral. A dowry of 200,000 crowns had been agreed, and half was paid shortly after the marriage.
Once married, Arthur was sent to Ludlow Castle on the borders of Wales to preside over the Council of Wales and the Marches, as was his duty as Prince of Wales, and his bride accompanied him. The couple stayed at Castle Lodge, Ludlow. A few months later, they both became ill, possibly with the sweating sickness which was sweeping the area. Arthur died on 2 April 1502; Catherine recovered to find herself a widow.
At this point, Henry VII faced the challenge of avoiding the obligation to return her dowry, half of which he had not yet received, to her father. To settle the matter, it was agreed that Catherine would marry Henry VII's second son, Henry, Duke of York, who was five years younger than she was. The death of Catherine's mother, however, meant that her "value" in the marriage market decreased. Castile was a much larger kingdom than Aragon, and it was inherited by Catherine's mentally unstable elder sister, Joanna. Ostensibly, the marriage was delayed until Henry was old enough, but Henry VII procrastinated so much over payment of the remainder of Catherine's dowry that it became doubtful that the marriage would take place. She lived as a virtual prisoner at Durham House in London. Some of the letters she wrote to her father complaining of her treatment have survived. In one of these letters she tells him that "I choose what I believe, and say nothing. For I am not as simple as I may seem." She had little money and struggled to cope, as she had to support her ladies-in-waiting as well as herself. In 1507 she served as the Spanish ambassador to England, the first female ambassador in European history. While Henry VII and his councillors expected her to be easily manipulated, Catherine went on to prove them wrong.
Marriage to Arthur's brother depended on the Pope granting a dispensation because canon law forbade men to marry their brother's widow. Catherine testified that her marriage to Arthur was never consummated as, also according to canon law, a marriage was not valid until consummated.
Queen of England (1509–1533).
Wedding.
Catherine's wedding took place on 11 June 1509, seven years after Prince Arthur's death. She married Henry VIII, who had only just acceded to the throne, in a private ceremony at Greenwich Church. She was 23 years of age. The king was just days short of his 18th birthday.
Coronation.
On Saturday 23 June, the traditional eve-of-coronation procession to Westminster was greeted by a large and enthusiastic crowd. As was the custom, the couple spent the night before their coronation at the Tower of London. On Midsummer's Day, Sunday, 1509, Henry VIII and Catherine were anointed and crowned together by the Archbishop of Canterbury at a lavish ceremony at Westminster Abbey. The coronation was followed by a banquet in Westminster Hall. Many new Knights of the Bath were created in honour of the coronation.
In that month that followed, many social occasions presented the new Queen to the English public. She made a fine impression and was well received by the people of England.
Pregnancies and children.
On 31 January 1510, Catherine gave birth prematurely to a stillborn daughter. A son, Henry, Duke of Cornwall, was born on New Year's Day 1511. On 23 February 1511 the young prince died suddenly, living only 52 days. The cause of his death was not recorded. In 1513, Catherine was pregnant again. Catherine had lost another son when Henry returned from France. He was either stillborn or died shortly after birth. In December 1514, she had another son, Prince Henry who died shortly after birth. On 18 February 1516, Catherine delivered a healthy girl. She was named Mary and christened three days later with great ceremony at the Church of Observant Friars. In 1518, Catherine became pregnant for the last time. She gave birth to a daughter on 10 November, but the child was weak and lived either only a few hours or at most a week. Catherine was pregnant six times altogether.
Influence.
On 11 June 1513, Henry appointed Catherine Regent or Governor of England while he went to France on a military campaign.
When Louis d'Orléans, Duke of Longueville, was captured at Thérouanne, Henry sent him to stay in Catherine's household. She wrote to Wolsey that she and her council would prefer the Duke to stay in the Tower of London as the Scots were "so busy as they now be" and she added her prayers for "God to sende us as good lukke against the Scotts, as the King hath ther." The war with Scotland occupied her subjects, and she was "horrible busy with making standards, banners, and badges" at Richmond Palace. The Scots invaded and on 3 September she ordered Thomas Lovell to raise an army in the midland counties.
Catherine rode north in full armour to address the troops, despite being heavily pregnant at the time. (She gave birth to a stillborn son c. October.) Her fine speech was reported to the historian Peter Martyr d'Anghiera in Valladolid within a fortnight. Although an Italian newsletter said she was 100 miles north of London when news of the victory at Battle of Flodden Field reached her, she was near Buckingham. From Woburn Abbey she sent a letter to Henry along with a piece of the bloodied coat of King James IV of Scotland, who died in the battle, for Henry to use as a banner at the siege of Tournai.
Catherine's religious dedication increased as she aged, as did her interest in academics. She continued to broaden her knowledge and provide training for her daughter. Education among women became fashionable, partly because of Catherine's influence. She also donated large sums of money to several colleges. Henry, however, still considered a male heir essential. The Tudor dynasty was new, and its legitimacy might still be tested. A long civil war (1135–54) had been fought the last time a woman, (Empress Matilda), had inherited the throne. The disasters of civil war were still fresh in living memory from the Wars of the Roses.
In 1520, Catherine's nephew Holy Roman Emperor Charles V paid a state visit to England, and she urged Henry to enter an alliance with Charles rather than with France. Immediately after his departure, she accompanied Henry to France on the celebrated visit to Francis I, the so-called Field of the Cloth of Gold. Within two years, war was declared against France and the Emperor was once again welcome in England, where plans were afoot to betroth him to Catherine's daughter Mary.
The King's "great matter".
In 1525, Henry VIII became enamoured of Anne Boleyn, a lady-in-waiting to Queen Catherine who was 9 years younger than Henry. Henry began pursuing her; Catherine was no longer able to bear children by this time. Henry began to believe that his marriage was cursed and sought confirmation from the Bible, which he interpreted to say that if a man marries his brother's wife, the couple will be childless. Even if her marriage to Arthur had not been consummated (and Catherine would insist to her dying day that she had come to Henry's bed a virgin), Henry's interpretation of that biblical passage meant that their marriage had been wrong in the eyes of God. Whether the Pope at the time of Henry and Catherine's marriage had had the right to overrule Henry's claimed scriptural impediment would become a hot topic in Henry's campaign to wrest an annulment from the present Pope. It is possible that the idea of annulment had been suggested to Henry much earlier than this, and is highly probable that it was motivated by his desire for a son. Before Henry's father ascended the throne, England was beset by civil warfare over rival claims to the English crown, and Henry may have wanted to avoid a similar uncertainty over the succession.
It soon became the one absorbing object of Henry's desires to secure an annulment. Catherine was defiant when it was suggested that she quietly retire to a nunnery, saying, "God never called me to a nunnery. I am the King's true and legitimate wife". He set his hopes upon an appeal to the Holy See, acting independently of Cardinal Thomas Wolsey, whom he told nothing of his plans. William Knight, the King's secretary, was sent to Pope Clement VII to sue for an annulment, on the grounds that the dispensing bull of Pope Julius II was obtained by false pretences.
As the Pope was, at that time, the prisoner of Catherine's nephew, Emperor Charles V, following the Sack of Rome in May 1527, Knight had difficulty in obtaining access to him. In the end, Henry's envoy had to return without accomplishing much. Henry now had no choice but to put this great matter into the hands of Thomas Wolsey, and Wolsey did all he could to secure a decision in Henry's favour.
When Henry decided to annul his marriage to Catherine, John Fisher became her most trusted counsellor and one of her chief supporters. He appeared in the legates' court on her behalf, where he shocked people with the directness of his language, and by declaring that, like John the Baptist, he was ready to die on behalf of the indissolubility of marriage. Henry was so enraged by this that he wrote a long Latin address to the legates in answer to Fisher's speech. Fisher's copy of this still exists, with his manuscript annotations in the margin which show how little he feared Henry's anger. The removal of the cause to Rome ended Fisher's role in the matter, but Henry never forgave him. Other people who supported Catherine's case included Thomas More, Henry's own sister Mary Tudor, Queen of France - though as a member of the Tudor family and of royal blood, she was safe from any punishment and execution - Maria de Salinas, Holy Roman Emperor Charles V, Pope Paul III and Protestant Reformers Martin Luther and William Tyndale.
Banishment and death.
Upon returning to Dover from a meeting with King Francis I of France in Calais, Henry married Anne Boleyn in a secret ceremony. Some sources speculate that Anne was already pregnant at the time (and Henry did not want to risk a son being born illegitimate), but others testify that Anne (who had seen her sister Mary Boleyn taken up as the king's mistress and summarily cast aside) refused to sleep with Henry until they were married. Henry defended the legality of their union by pointing out that Catherine had previously been married. If she and Arthur had consummated their marriage, Henry by canon law had the right to remarry.On 23 May 1533, Cranmer, sitting in judgement at a special court convened at Dunstable Priory to rule on the validity of Henry's marriage to Catherine, declared the marriage illegal, even though Catherine testified she and Arthur had never had physical relations. Cranmer ruled Henry and Anne's marriage valid five days later, on 28 May 1533.
Until the end of her life, Catherine would refer to herself as Henry's only lawful wedded wife and England's only rightful queen, and her servants continued to address her by that title. Henry refused her the right to any title but "Dowager Princess of Wales" in recognition of her position as his brother's widow.
Catherine went to live at The More castle in the winter of 1531/32.
In 1535 she was transferred to Kimbolton Castle. There, she confined herself to one room (which she left only to attend Mass), dressed only in the hair shirt of the Order of St. Francis, and fasted continuously. While she was permitted to receive occasional visitors, she was forbidden to see her daughter Mary. They were also forbidden to communicate in writing, but sympathizers discreetly ferried letters between the two. Henry offered both mother and daughter better quarters and permission to see each other if they would acknowledge Anne Boleyn as his new Queen. Both refused.
In late December 1535, sensing her death was near, Catherine made her will, and wrote to her nephew, the Emperor Charles V, asking him to protect her daughter. She then penned one final letter to Henry, her "most dear lord and husband":
Catherine died at Kimbolton Castle on 1536. The following day, news of her death reached the king. At the time there were rumours that she was poisoned, possibly by Gregory di Casale. According to the chronicler Edward Hall, Anne Boleyn wore yellow for the mourning, which has been interpreted in various ways; Polydore Vergil interpreted this to mean that Anne did not mourn. Chapuys reported that it was King Henry who decked himself in yellow, celebrating the news and making a great show of his and Anne's daughter, Elizabeth, to his courtiers. This was seen as distasteful and vulgar by many. Another theory is that the dressing in yellow was out of respect for the late queen-princess dowager as yellow was said to be the Spanish colour of mourning. Certainly, later in the day it is reported that Henry and Anne both individually and privately wept for her death. On the day of Catherine's funeral, Anne Boleyn miscarried a son. Rumours then circulated that Catherine had been poisoned by Anne or Henry, or both, as Anne had threatened to murder both Catherine and Mary on several occasions. The rumours were born after the apparent discovery during her embalming that there was a black growth on her heart that might have been caused by poisoning. Modern medical experts are in agreement that her heart's discolouration was due not to poisoning, but to cancer, something which was not understood at the time.
Catherine was buried in Peterborough Cathedral with the ceremony due to a Dowager Princess of Wales, not a queen. Henry did not attend the funeral and forbade Mary to attend.
Faith.
Catherine was a member of the Third Order of Saint Francis and she was punctilious in her religious obligations in the Order, integrating without demur her necessary duties as queen with her personal piety.
The outward celebration of saints and holy relics formed no major part of her personal devotions, which she rather expressed in the Mass, prayer, confession and penance. Privately, however, she was aware of what she identified as the shortcomings of the papacy and church officialdom. Her doubts about Church improprieties certainly did not extend so far as to support the allegations of corruption made public by Martin Luther in Wittenberg in 1517, which were soon to have such far-reaching consequences in initiating the Protestant Reformation.
In 1523 Alfonso de Villa Sancta, a learned friar of the Observant (reform) branch of the Friars Minor and friend of the king's old advisor Erasmus, dedicated to the queen his book "De Liberio Arbitrio adversus Melanchthonem" denouncing Philipp Melanchthon, a supporter of Luther. Acting as her confessor, he was able to nominate her for the title of "Defender of the Faith" for denying Luther's arguments.
Appearance.
Catherine was of a very fair complexion, had blue eyes, and had a hair colour that was between reddish-blonde and auburn like her mother and sister Joanna. During her lifetime she was described as "The most beautiful creature in the world" and that there was "Nothing lacking in her that the most beautiful girl should have." Thomas More and Lord Herbert would reflect later in her lifetime that in regard to her appearance "There were few women who could compete with the Queen in her prime."
Legacy, memory, and historiography.
The controversial book "The Education of Christian Women" by Juan Luis Vives, which claimed women have the right to an education, was dedicated to and commissioned by her. Such was Catherine's impression on people, that even her enemy, Thomas Cromwell, said of her "If not for her sex, she could have defied all the heroes of History." She successfully appealed for the lives of the rebels involved in the Evil May Day for the sake of their families. Furthermore, Catherine won widespread admiration by starting an extensive programme for the relief of the poor. She was also a patron of Renaissance humanism, and a friend of the great scholars Erasmus of Rotterdam and Saint Thomas More. Some saw her as a martyr.
In the reign of her daughter Mary I of England, her marriage to Henry VIII was declared "good and valid." Her daughter Queen Mary also had several portraits commissioned of Catherine, and it would not by any means be the last time she was painted. After her death, numerous portraits were painted of her, particularly of her speech at the Legatine Trial, a moment accurately rendered in Shakespeare's play about Henry VIII.
Her tomb in Peterborough Cathedral can be seen and there is hardly ever a time when it is not decorated with flowers or pomegranates, her heraldic symbol. It bears the title "Katharine Queen of England".
In the 20th century, George V's wife, Mary of Teck, had her grave upgraded and there are now banners there denoting Catherine as a Queen of England. Every year at Peterborough Cathedral there is a service in her memory. There are processions, prayers, and various events in the Cathedral including processions to Catherine's grave in which candles, pomegranates, flowers and other offerings are placed on her grave. On the service commemorating the 470th anniversary of her death, the Spanish Ambassador to the United Kingdom attended. During the 2010 service a rendition of Catherine of Aragon's speech before the Legatine court was read by Jane Lapotaire. There is a statue of her in her birthplace of Alcalá de Henares, as a young woman holding a book and a rose.
Catherine has remained a popular biographical subject to the present day. The American historian Garrett Mattingly was the author of a popular biography "Katherine of Aragon" in 1942. In 1966, Catherine and her many supporters at court were the subjects of "Catherine of Aragon and her Friends", a biography by John E. Paul. In 1967, Mary M. Luke wrote the first book of her Tudor trilogy, "Catherine the Queen" which portrayed her and the controversial era of English history through which she lived.
Spelling of her name.
Her baptismal name was "Catalina", but "Catherine" was soon the accepted form in England after her marriage to Arthur (who later died of natural causes). Catherine herself signed her name "Katherine", "Katherina", "Katharine" and sometimes "Katharina". In a letter to her, Arthur, her husband, addressed her as "Princess Katerine". Her daughter Queen Mary I called her "Quene Kateryn", in her will. Rarely were names, particularly first names, written in an exact manner during the sixteenth century and it is evident from Catherine's own letters that she endorsed different variations.
Loveknots built into his various palaces by her husband, Henry VIII, display the initials "H & K", as do other items belonging to Henry and Catherine, including gold goblets, a gold salt cellar, basins of gold, and candlesticks. Her tomb in Peterborough Cathedral is marked "Katharine Queen of England.
In art and media.
Over the years, numerous artistic and cultural works have been dedicated to her, written about her, or mentioned her, including some by her husband Henry VIII, who wrote "Grene growth the holy" about and for her, and Juan Luis Vives, who dedicated "The Education of Christian Women" to her.
Catherine of Aragon has been portrayed in film, television, plays, books, and other forms many times, and as a result she has stayed very much in popular memory. There has never been a film or television series where she is the main character although an arguable exception is the first episode of "The Six Wives of Henry VIII" which is told from her point of view and where she is portrayed by Annette Crosbie. There are also many novels, songs, and poems written about her. Shakespeare's play "Henry VIII" is tremendously successful in recreating, with great accuracy, Catherine's statement about the legitimacy of her marriage at the court in Blackfriars before King Henry, and Catherine's portrayal is very sympathetic therein. However, most of the rest of the play is an attempt to absolve many, especially Henry VIII, and the timing of key incidents (including Catherine's death) is changed and other events are avoided (the play makes Henry nearly an innocent pawn in the hands of a dastard Cardinal Wolsey, and the play stops short of Anne Boleyn's execution).
Although Catherine is often portrayed in film and on stage as having possessed the stereotypical Spanish traits of dark hair and eyes as well an olive complexion, existing portraits and contemporary descriptions depict her as having had blue eyes, fair skin, and reddish-blonde hair, not uncommon for Spaniards from the northern regions of Spain, such as those from her father's land of Aragon. Furthermore, she was part English, through her ancestors, Katherine of Lancaster and Philippa of Lancaster, who were both daughters of John of Gaunt, 1st Duke of Lancaster.
She is often played with a Spanish accent; from most reports, this is accurate, as she never fully mastered the English language.
In January 2013 the National Portrait Gallery in London revealed that its curators had recently discovered a portrait of Catherine at Lambeth Palace. Formerly believed to be a portrait of Catherine Parr, the canvas was a portrait of Catherine of Aragon. The National Portrait Gallery announced that the painting, which had hung in a private sitting room of the Archbishop of Canterbury since at least the 19th century, would be paired with a portrait of Henry VIII, already in the museum's collection, and would remain at the museum on loan.
Books.
Catherine is the main character in:
Catherine is a character in:
Theatre, film, stage, and TV.
Catherine was portrayed by:

</doc>
<doc id="6943" url="http://en.wikipedia.org/wiki?curid=6943" title="Cathode ray">
Cathode ray

Cathode rays (also called an electron beam or e-beam) are streams of electrons observed in vacuum tubes. If an evacuated glass tube is equipped with two electrodes and a voltage is applied, the glass opposite of the negative electrode is observed to glow, due to electrons emitted from and travelling perpendicular to the cathode (the electrode connected to the negative terminal of the voltage supply). They were first observed in 1869 by German physicist Johann Hittorf, and were named in 1876 by Eugen Goldstein "Kathodenstrahlen", or cathode rays.
Electrons were first discovered as the constituents of cathode rays. In 1897 British physicist J. J. Thomson showed the rays were composed of a previously unknown negatively charged particle, which was later named the "electron". Cathode ray tubes (CRTs) use a focused beam of electrons deflected by electric or magnetic fields to create the image in a classic television set.
Description.
Cathode rays are so named because they are emitted by the negative electrode, or cathode, in a vacuum tube. To release electrons into the tube, they first must be detached from the atoms of the cathode. In the early cold cathode vacuum tubes, called Crookes tubes, this was done by using a high electrical potential between the anode and the cathode to ionize the residual gas in the tube; the ions were accelerated by the electric field and released electrons when they collided with the cathode. Modern vacuum tubes use thermionic emission, in which the cathode is made of a thin wire filament which is heated by a separate electric current passing through it. The increased random heat motion of the filament atoms knocks electrons out of the atoms at the surface of the filament, into the evacuated space of the tube.
Since the electrons have a negative charge, they are repelled by the cathode and attracted to the anode. They travel in straight lines through the empty tube. The voltage applied between the electrodes accelerates these low mass particles to high velocities. Cathode rays are invisible, but their presence was first detected in early vacuum tubes when they struck the glass wall of the tube, exciting the atoms of the glass and causing them to emit light, a glow called fluorescence. Researchers noticed that objects placed in the tube in front of the cathode could cast a shadow on the glowing wall, and realized that something must be travelling in straight lines from the cathode. After the electrons reach the anode, they travel through the anode wire to the power supply and back to the cathode, so cathode rays carry electric current through the tube.
The current in a beam of cathode rays through a tube can be controlled by passing it through a metal screen of wires (a grid) to which a small voltage is applied. The electric field of the wires deflects some of the electrons, preventing them from reaching the anode. Thus a small voltage on the grid can be made to control a much larger voltage on the anode. This is the principle used in vacuum tubes to amplify electrical signals. High speed beams of cathode rays can also be steered and manipulated by electric fields created by additional metal plates in the tube to which voltage is applied, or magnetic fields created by coils of wire (electromagnets). These are used in cathode ray tubes, found in televisions and computer monitors, and in electron microscopes.
History.
After the 1654 invention of the vacuum pump by Otto von Guericke, physicists began to experiment with passing high voltage electricity through rarefied air. In 1705, it was noted that electrostatic generator sparks travel a longer distance through low pressure air than through atmospheric pressure air.
Gas discharge tubes.
In 1838, Michael Faraday passed a current through a rarefied air filled glass tube and noticed a strange light arc with its beginning at the cathode (negative electrode) and its end almost at the anode (positive electrode). In 1857, German physicist and glassblower Heinrich Geissler sucked even more air out with an improved pump, to a pressure of around 10−3 atm and found that, instead of an arc, a glow filled the tube. The voltage applied between the two electrodes of the tubes, generated by an induction coil, was anywhere between a few kilovolts and 100 kV. These were called Geissler tubes, similar to today's neon signs.
The explanation of these effects was that the high voltage accelerated electrically charged atoms (ions) naturally present in the air of the tube. At low pressure, there was enough space between the gas atoms that the ions could accelerate to high enough speeds that when they struck another atom they knocked electrons off of it, creating more positive ions and free electrons in a chain reaction. The positive ions were all attracted to the cathode. When they struck it they knocked many electrons out of the metal. The free electrons were all attracted to the anode.
Due to the primitive vacuum pumps of the time, Geissler tubes had so much air in them that the electrons could only travel a tiny distance before colliding with an atom. The electrons in these tubes moved in a slow diffusion process, never gaining much speed, so these tubes didn't produce cathode rays. Instead they produced a colorful glow discharge (as in a modern neon light), caused when the electrons or ions struck gas atoms, exciting their orbital electrons to higher energy levels. The electrons released this energy as light. This process is called fluorescence.
Cathode rays.
By the 1870s, British physicist William Crookes and others were able to evacuate tubes to a lower pressure, below 10−6 atm. These were called Crookes tubes. Faraday had been the first to notice a dark space just in front of the cathode, where there was no luminescence. This came to be called the "cathode dark space", "Faraday dark space" or "Crookes dark space". Crookes found that as he pumped more air out of the tubes, the Faraday dark space spread down the tube from the cathode toward the anode, until the tube was totally dark. But at the anode (positive) end of the tube, the glass of the tube itself began to glow.
What was happening was that as more air was pumped from the tube, the electrons could travel farther, on average, before they struck a gas atom. By the time the tube was dark, most of the electrons could travel in straight lines from the cathode to the anode end of the tube without a collision. With no obstructions, these low mass particles were accelerated to high velocities by the voltage between the electrodes. These were the cathode rays.
When they reached the anode end of the tube, they were travelling so fast that, although they were attracted to it, they often flew past the anode and struck the back wall of the tube. When they struck atoms in the glass wall, they excited their orbital electrons to higher energy levels, causing them to fluoresce. Later researchers painted the inside back wall with fluorescent chemicals such as zinc sulfide, to make the glow more visible.
Cathode rays themselves are invisible, but this accidental fluorescence allowed researchers to notice that objects in the tube in front of the cathode, such as the anode, cast sharp-edged shadows on the glowing back wall. In 1869, German physicist Johann Hittorf was first to realize that something must be travelling in straight lines from the cathode to cast the shadows. Eugen Goldstein named them "cathode rays".
Discovery of the electron.
At this time, atoms were the smallest particles known, and were believed to be indivisible. What carried electric currents was a mystery. During the last quarter of the 19th century many experiments were done to determine what cathode rays were. There were two theories. Crookes and Arthur Schuster believed they were particles of "radiant matter", that is, electrically charged atoms. German scientists Eilhard Wiedemann, Heinrich Hertz and Goldstein believed they were "aether waves", some new form of electromagnetic radiation, and were separate from what carried the electric current through the tube.
The debate was resolved in 1897 when J. J. Thomson measured the mass of cathode rays, showing they were made of particles, but were around 1800 times lighter than the lightest atom, hydrogen. Therefore they were not atoms, but a new particle, the first "subatomic" particle to be discovered, which he originally called ""corpuscle"" but was later named "electron", after particles postulated by George Johnstone Stoney in 1874. He also showed they were identical with particles given off by photoelectric and radioactive materials. It was quickly recognised that they are the particles that carry electric currents in metal wires, and carry the negative electric charge of the atom.
Thomson was given the 1906 Nobel prize for physics for this work. Philipp Lenard also contributed a great deal to cathode ray theory, winning the Nobel prize for physics in 1905 for his research on cathode rays and their properties.
Vacuum tubes.
The gas ionization (or cold cathode) method of producing cathode rays used in Crookes tubes was unreliable, because it depended on the pressure of the residual air in the tube. Over time, the air was adsorbed by the walls of the tube, and it stopped working.
A more reliable and controllable method of producing cathode rays was investigated by Hittorf and Goldstein, and rediscovered by Thomas Edison in 1880. A cathode made of a wire filament heated red hot by a separate current passing through it would release electrons into the tube by a process called thermionic emission. The first true electronic vacuum tubes, invented in 1904, used this hot cathode technique, and they superseded Crookes tubes. These tubes didn't need gas in them to work, so they were evacuated to a lower pressure, around 10−9 atm (10−4 P). The ionization method of creating cathode rays used in Crookes tubes is today only used in a few specialized gas discharge tubes such as krytrons.
Lee De Forest in 1906 found that a small voltage on a grid of metal wires could control a much larger current in a beam of cathode rays passing through a vacuum tube. His invention, called the triode, was the first device that could amplify electric signals, and founded the field of "electronics". Vacuum tubes made radio and television broadcasting possible, as well as radar, talking movies, audio recording, and long distance telephone service, and were the foundation of consumer electronic devices until the 1960s when the transistor brought the era of vacuum tubes to a close.
Cathode rays are now usually called electron beams. The technology of manipulating electron beams pioneered in these early tubes was applied practically in the design of vacuum tubes, particularly in the invention of the cathode ray tube by Ferdinand Braun in 1897 and is today employed in sophisticated devices such as electron microscopes, electron beam lithography and particle accelerators.
Properties of cathode rays.
Like a wave, cathode rays travel in straight lines, and produce a shadow when obstructed by objects. Ernest Rutherford demonstrated that rays could pass through thin metal foils, behavior expected of a particle. These conflicting properties caused disruptions when trying to classify it as a wave or particle. Crookes insisted it was a particle, while Hertz maintained it was a wave. The debate was resolved when an electric field was used to deflect the rays by J. J. Thomson. This was evidence that the beams were composed of particles because scientists knew it was impossible to deflect electromagnetic waves with an electric field. These can also create mechanical effects, fluorescence, etc.
Louis de Broglie later (1924) showed in his doctoral dissertation that electrons are in fact much like photons in the respect that they act both as waves and as particles in a dual manner as Einstein had shown earlier for light. The wave-like behaviour of Cathode Ray particles was later directly demonstrated using a crystal lattice by Davisson and Germer in 1927.

</doc>
<doc id="6944" url="http://en.wikipedia.org/wiki?curid=6944" title="Cathode">
Cathode

A cathode is the electrode from which a conventional current leaves a polarized electrical device. This definition is sometimes remembered using the mnemonic CCD for "cathode current departs". A conventional current describes the direction in which positive electronic charges move. s have a negative charge, so the movement of electrons is opposite to the conventional current flow. Consequently, the mnemonic "cathode current departs" also means that electrons flow into the device's cathode.
Cathode polarity with respect to the anode can be positive or negative; it depends on how the device operates. Although positively charged cations always move towards the cathode (hence their name) and negatively charged anions move away from it, cathode polarity depends on the device type, and can even vary according to the operating mode. In a device which consumes power, the cathode is negative, and in a device which provides power, the cathode is positive:
An electrode through which current flows the other way (into the device) is termed an anode.
Etymology.
The word was coined in 1834 from the Greek κάθοδος ("kathodos"), 'descent' or 'way down', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the "decomposing body" (electrolyte) in a direction "from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move", the cathode is where the current leaves the electrolyte, on the West side: ""kata" downwards, "`odos" a way ; the way which the sun sets".
The use of 'West' to mean the 'out' direction (actually 'out' → 'West' → 'sunset' → 'down', i.e. 'out of view') may appear unnecessarily contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term "exode" (the doorway where the current exits). His motivation for changing it to something meaning 'the West electrode' (other candidates had been "westode", "occiode" and "dysiode") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the West electrode would not have been the 'way out' any more. Therefore "exode" would have become inappropriate, whereas "cathode" meaning 'West electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the cathode's function any more, but more importantly because, as we now know, the Earth's magnetic field direction on which the "cathode" term is based is subject to reversals whereas the current direction convention on which the "exode" term was based has no reason to change in the future.
Since the later discovery of the electron, an easier to remember, and more durably technically correct (although historically false), etymology has been suggested: cathode, from the Greek "kathodos", 'way down', 'the way (down) into the cell (or other device) for electrons'.
Flow of electrons.
The flow of electrons is almost always from anode to cathode outside of the cell or device, regardless of the cell or device type and operating mode. An exception is when a diode reverse-conducts, either by accident (breakdown of a normal diode) or by design (breakdown of a Zener diode, photo-current of a photodiode or solar cell).
In chemistry.
In chemistry, a cathode is the electrode of an electrochemical cell at which reduction occurs; a useful mnemonic to remember this is AnOx RedCat (Oxidation at the Anode = Reduction at the Cathode). Another mnemonic is to note the cathode has a 'c', as does 'reduction'. Hence, reduction at the cathode. The cathode can be negative like when the cell is electrolytic (where electrical energy provided to the cell is being used for decomposing chemical compounds); or positive like when the cell is galvanic (where chemical reactions are used for generating electrical energy). The cathode supplies electrons to the positively charged cations which flow to it from the electrolyte (even if the cell is galvanic, i.e., when the cathode is positive and therefore would be expected to repel the positively charged cations; this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems in a galvanic cell).
The cathodic current, in electrochemistry, is the flow of electrons from the cathode interface to a species in solution. The anodic current is the flow of electrons into the anode from a species in solution.
Electrolytic cell.
In an electrolytic cell, the cathode is where the negative polarity is applied to drive the cell. Common results of reduction at the cathode are hydrogen gas or pure metal from metal ions. When discussing the relative reducing power of two redox agents, the couple for generating the more reducing species is said to be more "cathodic" with respect to the more easily reduced reagent.
Galvanic cell.
In a galvanic cell, the cathode is where the positive pole is connected to allow the circuit to be completed: as the anode of the galvanic cell gives off electrons, they return from the circuit into the cell through the cathode.
Electroplating metal cathode (a.k.a Electrolysis).
When metal ions are reduced from ionic solution, they form a pure metal surface on the cathode. Items to be plated with pure metal are attached to and become part of the cathode in the electrolytic solution.
In electronics.
In physics or electronics, a cathode is an electrode that emits electrons into the device. This contrasts with an anode, which accepts electrons. 
Vacuum tubes.
In a vacuum tube or electronic vacuum system, the cathode is a metal surface which emits free electrons into the evacuated space. Since the electrons are attracted to the positive nuclei of the metal atoms, they normally stay inside the metal and require energy to leave it; this is called the "work function" of the metal. Cathodes are induced to emit electrons by several mechanisms: 
Cathodes can be divided into two types:
Hot cathode.
A hot cathode is a cathode that is heated by a filament to produce electrons by thermionic emission. The filament is a thin wire of a refractory metal like tungsten heated red-hot by an electric current passing through it. Before the advent of transistors in the 1960s, virtually all electronic equipment used hot-cathode vacuum tubes. Today hot cathodes are used in vacuum tubes in radio transmitters and microwave ovens, to produce the electron beams in older cathode ray tube (CRT) type televisions and computer monitors, in x-ray machines, electron microscopes, and fluorescent tubes. 
There are two types of hot cathodes:
In order to improve electron emission, cathodes are treated with chemicals, usually compounds of metals with a low work function. Treated cathodes require less surface area, lower temperatures and less power to supply the same cathode current. The untreated tungsten filaments used in early tubes (called "bright emitters") had to be heated to 2500°F (1400°C), white-hot, to produce sufficient thermionic emission for use, while modern coated cathodes produce far more electrons at a given temperature so they only have to be heated to 800-1100°F (425-600°C) There are two main types of treated cathodes: 
Cold cathode.
This is a cathode that is not heated by a filament. They may emit electrons by field electron emission, and in gas-filled tubes by secondary emission. Some examples are electrodes in neon lights, cold-cathode fluorescent lamps (CCFLs) used as backlights in laptops, thyratron tubes, and Crookes tubes. They do not necessarily operate at room temperature; in some devices the cathode is heated by the electron current flowing through it to a temperature at which thermionic emission occurs. For example, in some fluorescent tubes a momentary high voltage is applied to the electrodes to start the current through the tube; after starting the electrodes are heated enough by the current to keep emitting electrons to sustain the discharge.
Cold cathodes may also emit electrons by photoelectric emission. These are often called "photocathodes" and are used in phototubes used in scientific instruments and image intensifier tubes used in night vision goggles.
Diodes.
In a semiconductor diode, the cathode is the N–doped layer of the PN junction with a high density of free electrons due to doping, and an equal density of fixed positive charges, which are the dopants that have been thermally ionized. In the anode, the converse applies: It features a high density of free "holes" and consequently fixed negative dopants which have captured an electron (hence the origin of the holes).
When P and N-doped layers are created adjacent to each other, diffusion ensures that electrons flow from high to low density areas: That is, from the N to the P side. They leave behind the fixed positively charged dopants near the junction. Similarly, holes diffuse from P to N leaving behind fixed negative ionised dopants near the junction. These layers of fixed positive and negative charges, collectively known as the depletion layer because they are depleted of free electrons and holes. The depletion layer at the junction is at the origin of the diode's rectifying properties. This is due to the resulting internal field and corresponding potential barrier which inhibit current flow in reverse applied bias which increases the internal depletion layer field. Conversely, they allow it in forwards applied bias where the applied bias reduces the built in potential barrier.
Electrons which diffuse from the cathode into the P-doped layer, or anode, become what is termed "minority carriers" and tend to recombine there with the majority carriers, which are holes, on a timescale characteristic of the material which is the p-type minority carrier lifetime. Similarly, holes diffusing into the N-doped layer become minority carriers and tend to recombine with electrons. In equilibrium, with no applied bias, thermally assisted diffusion of electrons and holes in opposite directions across the depletion layer ensure a zero net current with electrons flowing from cathode to anode and recombining, and holes flowing from anode to cathode across the junction or depletion layer and recombining.
Like a typical diode, there is a fixed anode and cathode in a Zener diode, but it will conduct current in the reverse direction (electrons flow from anode to cathode) if its breakdown voltage or "Zener voltage" is exceeded.

</doc>
<doc id="6945" url="http://en.wikipedia.org/wiki?curid=6945" title="Chrominance">
Chrominance

Chrominance ("chroma" or C for short) is the signal used in video systems to convey the color information of the picture, separately from the accompanying luma signal (or Y for short). Chrominance is usually represented as two color-difference components: U = B′ − Y′ (blue − luma) and V = R′ − Y′ (red − luma). Each of these difference components may have scale factors and offsets applied to it, as specified by the applicable video standard. 
In composite video signals, the U and V signals modulate a color subcarrier signal, and the result is referred to as the chrominance signal; the phase and amplitude of this modulated chrominance signal correspond approximately to the hue and saturation of the color. In digital-video and still-image color spaces such as Y′CbCr, the luma and chrominance components are digital sample values.
Separating RGB color signals into luma and chrominance allows the bandwidth of each to be determined separately. Typically, the chrominance bandwidth is reduced in analog composite video by reducing the bandwidth of a modulated color subcarrier, and in digital systems by chroma subsampling.
History.
The idea of transmitting a color television signal with distinct luma and chrominance components originated with Georges Valensi, who patented the idea in 1938. Valensi's patent application described:
The use of two channels, one transmitting the predominating color (signal T), and the other the mean brilliance (signal t) output from a single television transmitter to be received not only by color television receivers provided with the necessary more expensive equipment, but also by the ordinary type of television receiver which is more numerous and less expensive and which reproduces the pictures in black and white only.
Previous schemes for color television systems, which were incompatible with existing monochrome receivers, transmitted RGB signals in various ways.
Television standards.
In analog television, chrominance is encoded into a video signal using a subcarrier frequency. Depending on the video standard, the chrominance subcarrier may be either quadrature-amplitude-modulated (NTSC and PAL) or frequency-modulated (SECAM).
In the PAL system, the color subcarrier is 4.43 MHz above the video carrier, while in the NTSC system it is 3.58 MHz above the video carrier. The NTSC and PAL standards are the most commonly used, although there are other video standards that employ different subcarrier frequencies. For example, PAL-M (Brazil) uses a 3.58 MHz subcarrier, and SECAM uses two different frequencies, 4.250 MHz and 4.40625 MHz above the video carrier.
The presence of chrominance in a video signal is indicated by a color burst signal transmitted on the back porch, just after horizontal synchronization and before each line of video starts. If the color burst signal were visible on a television screen, it would appear as a vertical strip of a very dark olive color. In NTSC and PAL, hue is represented by a phase shift of the chrominance signal relative to the color burst, while saturation is determined by the amplitude of the subcarrier. In SECAM (R′ − Y′) and (B′ − Y′) signals are transmitted alternately and phase does not matter.
Chrominance is represented by the U-V color plane in PAL and SECAM video signals, and by the I-Q color plane in NTSC.
Digital systems.
Digital video and digital still photography systems sometimes use a luma/chroma decomposition for improved compression. For example, when an ordinary RGB digital image is compressed via the JPEG standard, the RGB colorspace is first converted (by a rotation matrix) to a YCbCr colorspace, because the three components in that space have less correlation redundancy and because the chrominance components can then be subsampled by a factor of 2 or 4 to further compress the image. On decompression, the Y′CbCr space is rotated back to RGB.

</doc>
<doc id="6946" url="http://en.wikipedia.org/wiki?curid=6946" title="Chirality (disambiguation)">
Chirality (disambiguation)

Chirality ("handedness") is a property of asymmetry.
Chirality may also refer to:

</doc>
<doc id="6947" url="http://en.wikipedia.org/wiki?curid=6947" title="Campus">
Campus

A campus is traditionally the land on which a college or university and related institutional buildings are situated. Usually a campus includes libraries, lecture halls, residence halls, student centers or dining halls, and park-like settings. The definition currently describes a collection of buildings that belong to a given institution, either academic or non-academic.
Etymyology.
The word derives from a Latin word for "field" and was first used to describe the grounds of a college at the College of New Jersey (now Princeton University) during the 18th century. Some other American colleges later adopted the word to describe individual fields at their own institutions, but "campus" did not yet describe the whole university property. A school might have one space called a campus, one called a field, and another called a yard.
History.
The tradition of a campus did not start in America, but with the medieval European universities where the students and teachers lived and worked together in a cloistered environment. It was the notion of the importance of the setting to academic life that migrated to America, and early colonial educational institutions were based on the Scottish and English collegiate system.
Uses.
The meaning expanded to include the whole institutional property during the 20th century, with the old meaning persisting into the 1950s in some places. 
Office buildings.
Sometimes the lands on which company office buildings sit, along with the buildings, are called campuses. The Microsoft Campus in Redmond, Washington, as well as hospitals use the term to describe the territory of their facilities. 
Universities.
The word "campus" has also been applied to European universities, although most such institutions are characterized by ownership of individual buildings in urban settings rather than park-like lawns in which buildings are placed.

</doc>
<doc id="6948" url="http://en.wikipedia.org/wiki?curid=6948" title="Crossbow">
Crossbow

A crossbow is a type of weapon, based on the bow, consisting of a horizontal bow-like assembly mounted on a stock, that shoots projectiles called bolts or quarrels. The medieval crossbow was called by many names, most of which derived from the word ballista, a torsion siege engine resembling a crossbow.
Historically, crossbows played a significant role in the warfare of East Asia, Europe and the Mediterranean. The invention of the crossbow caused a major shift in the role of ranged weaponry among armies, as the traditional bow and arrow had long been a specialized weapons system which required a considerable degree of lifetime training, physical strength and expertise to operate with any degree of efficiency; in many cultures, despite being usually drawn from the common class, bowmen were considered a separate and superior caste, as their archery skill-set (similar to many horseman cultures) was essentially developed from birth and impossible to reproduce outside a pre-established cultural tradition, which many nations lacked. In contrast, the crossbow was the first projectile weapon to be simple, cheap and physically-undemanding enough to be operated by large numbers of conscript soldiers, thus enabling virtually any nation with sufficient coin to field a potent force of ranged crossbowmen with little expense beyond the cost of the weapons themselves. This led to the ascendancy of large mercenary armies of crossbowmen (best exemplified by the Genoese crossbowmen), and the eventual death of the heavily armored aristocratic knight as armies became progressively dominated by conscripts equipped with increasingly-powerful ranged projectile weapons.
In modern times, although largely supplanted by firearms in most roles, crossbows are still widely used for shooting sports, hunting, and when shooting in relative silence is an important consideration.
Construction.
A crossbow is a bow mounted on a stick (called a tiller or stock) with a mechanism in it which holds the drawn bow string. The earliest designs featured a slot in the stock, down into which the string was placed. To shoot this design, a vertical rod is thrust up through a hole in the bottom of the notch, forcing the string out. This rod is usually attached perpendicular to a rear-facing lever called a trigger or "tickler". A later design implemented a rolling cylindrical pawl called a "nut" to retain the string. This nut has a perpendicular center slot for the bolt, and an intersecting axial slot for the string, along with a lower face or slot against which the internal trigger sits. They often also have some form of strengthening internal "sear" or trigger face, usually of metal. These "roller nuts" were either free-floating in their close-fitting hole across the stock, tied in with a binding of sinew or other strong cording, or mounted on a metal axle or pins. Removable or integral plates of wood, ivory or metal on the sides of the stock kept the nut in place laterally. Nuts were made of antler, bone, or metal. Bows could be kept and ready to shoot for some time with little effort, allowing crossbowmen to aim better.
The bow (called the "prod" or "lath" on a crossbow) of early crossbows was made of a single piece of wood, usually ash or yew. Composite bows are made from layers of different material—often wood, horn and sinew—glued together and bound with animal tendon. These composite bows, made of several layers, are much stronger and more efficient in releasing energy than simple wooden bows. As steel became more widely available in Europe around the 14th century, steel prods came into use.
The crossbow prod is very short compared to ordinary bows, resulting in a short draw length. This leads to a higher draw weight in order to store the same amount of energy. Furthermore the thick prods are a bit less efficient at releasing energy, but more energy can be stored by a crossbow. Traditionally the prod was often lashed to the stock with rope, whipcord, or other strong cording. This cording is called the "bridle".
The strings for a crossbow are typically made of strong fibers that would not tend to fray. Whipcord was very common; however linen, hemp, and sinew were used as well. In wet conditions, twisted mulberry root was occasionally used.
Very light crossbows can be drawn by hand, but heavier types need the help of mechanical devices. The simplest version of mechanical cocking device is a hook attached to a belt, drawing the bow by straightening the legs. Other devices are hinged levers which either pulled or pushed the string into place, cranked rack-and-pinion devices called "cranequins" and multiple cord-and-pulley cranked devices called windlasses.
Variants.
Crossbows exist in different variants. One way to classify them is the acceleration system, while another is the size and energy, degree of automation or projectiles.
A recurve crossbow is a bow that has tips curving away from the archer. The recurve bow's bent limbs have a longer draw length than an equivalent straight-limbed bow, giving more acceleration to the projectile and less hand shock. Recurved limbs also put greater strain on the materials used to make the bow, and they may make more noise with the shot.
Multiple bow systems have a special system of pulling the sinew via several bows (which can be recurve bows). The workings can be compared to a modern compound bow system. The weapon uses several different bows instead of one bow with a tackle system to achieve a higher acceleration of the sinew via the multiplication with each bow's pulling effect.
A compound crossbow is a modern crossbow and is similar to a compound bow. The limbs are usually much stiffer than those of a recurve crossbow. This limb stiffness makes the compound bow more energy efficient than other bows, but the limbs are too stiff to be drawn comfortably with a string attached directly to them. The compound bow has the string attached to the pulleys, one or both of which has one or more cables attached to the opposite limb. When the string is drawn back, the string causes the pulleys to turn. This causes the pulleys to pull the cables, which in turn causes the limbs to bend and thus store energy. Other types of compound bows use either (one or both) cam shaped or eccentrically mounted pulleys in order to provide a "let off", such that the archer is not holding against the maximum draw weight of the bow while trying to aim. But in a crossbow the string is held back mechanically, so there is no advantage in providing a let off. Therefore, compound crossbows generally use only pulleys that are both round and concentrically mounted, in order to capture the maximum available energy from the relatively short draw length.
The smallest crossbows are pistol crossbows. Others are simple long stocks with the crossbow mounted on them. These could be shot from under the arm. The next step in development was stocks of the shape that would later be used for firearms, which allowed better aiming. The arbalest was a heavy crossbow which required special systems for pulling the sinew via windlasses. For siege warfare the size of crossbows was further increased to hurl large projectiles such as rocks at fortifications. The required crossbows needed a massive base frame and powerful windlass devices. Such devices include the oxybeles. The ballista has torsion springs replacing the elastic prod of the oxybeles, but later also developed into smaller versions. "Ballista" is still the root word for crossbow in Romance languages such as Italian ("balestra") and Spanish ("ballesta").
The repeating crossbow automated the separate actions of stringing the bow, placing the projectile and shooting. This way the task can be accomplished with a simple one-handed movement, while keeping the weapon stationary. As a result, it is possible to shoot at a faster rate compared to unmodified version. The Greek Polybolos was an ancient repeating ballista reputedly invented by Dionysius of Alexandria in the 3rd century BC. The Chinese repeating crossbow, Chu Ko Nu, is a handheld crossbow that accomplishes the task with a magazine containing a number of bolts on top. The mechanism is worked by moving a rectangular lever forward and backward. The weapon was mainly used as a weapon against lightly armored soldiers, since it shot small bolts that were often dipped in poison.
A bullet crossbow is a type of handheld crossbow which rather than arrows or bolts shoots spherical projectiles made of stone, clay or lead. There are two variants; one has a double string with a pocket for the projectile, and the other has a barrel with a slot for the string.
Projectiles.
The arrow-like projectiles of a crossbow are called bolts. These are much shorter than arrows, but can be several times heavier. There is an optimum weight for bolts to achieve maximum kinetic energy, which varies depending on the strength and characteristics of the crossbow, but most could pass through common chain mail. In ancient times the bolts of a strong crossbow were usually several times heavier than arrows. Modern bolts are stamped with a proof mark to ensure their consistent weight. Bolts do not have fletching, i.e. feathered ends like those commonly seen on arrows. Crossbow bolts can be fitted with a variety of heads, some with sickle-shaped heads to cut rope or rigging; but the most common today is a four-sided point called a quarrel. A highly specialized type of bolt is employed to collect blubber biopsy samples used in biology research.
Most modern crossbows are designed to shoot arrows instead of bolts. Crossbow arrows are of similar construction to ordinary bow arrows, just shorter in length because of reduced power stroke.
Crossbows can also be adapted to shoot lead bullets or rocks, in which case they are called stone-bows. Primarily used for hunting wildfowl, these usually have a double string with a pouch between the strings to hold the projectile.
Accessories.
The ancient crossbow often included a metal grid serving as iron sights. Modern crossbow sights often use similar technology to modern firearm sights, such as red dot sights and telescopic sights. Many crossbow scopes feature multiple crosshairs to compensate for the significant effects of gravity over different ranges. In most cases, a newly-bought crossbow will need to be "sighted" for accurate shooting.
Quivers can be mounted to hold ammunition. These are often made from plastic and usually hold the bolts in fixed positions along the structure. A popular detachable design consists of a main arm that is attached to the weapon, a plate on one end that secures four or more individual bolts at a point on their shafts and at the other end a cover that secures their heads. This kind of quiver is attached under the front of the crossbow, parallel to the string and is designed to be quickly detached and reattached. Other designs hold bolts underneath the crossbow parallel to the stock, sometimes on either side of the crossbow.
A major cause of the sound of shooting a crossbow is vibration of various components. Crossbow silencers are multiple components placed on high vibration parts, such as the string and limbs, to dampen vibration and suppress the sound of loosing the bolt.
History.
East Asia.
According to Sir Joseph Needham in his Science and Civilisation in China, though there is no way of answering the question of whether the crossbow first arose among the cultures neighboring ancient China before the rise of Chinese culture in their midst, or whether it spread outwards from China to all the environing peoples; the former seems the more probable hypothesis given linguistic evidence, which posits that the Chinese word for 'crossbow' came from an Austroasiatic language.
Bronze crossbow bolts dating as early as the mid-5th century BC were found at a State of Chu burial site in Yutaishan, Hubei. The earliest handheld crossbow stocks with bronze trigger, dating from the 6th century BC, comes from Tomb 3 and 12 found at Qufu, Shandong, capital of the State of Lu. Other early finds of crossbows were discovered in Tomb 138 at Saobatang, Hunan dated to the mid-4th century BC. Repeating crossbows, first mentioned in the "Records of the Three Kingdoms", were discovered in 1986 in Tomb 47 at Qinjiazui, Hubei dated to around the 4th century BC. The earliest Chinese document mentioning a crossbow is in scripts from the 4th to 3rd centuries BC attributed to the followers of Mozi. This source refers to the use of a giant crossbow in the 6th to 5th centuries BC, corresponding to the late Spring and Autumn Period. Sun Tzu's influential book "The Art of War" (first appearance dated in between 500 BC to 300 BC) refers in chapter V to the traits and in XII to the use of crossbows. One of the earliest reliable records of this weapon in warfare is from an ambush, the Battle of Ma-Ling in 341 BC. By the 200s BC, the crossbow () was well developed and quite widely used in China.
The earliest textual evidence of the "handheld" crossbow used in battle dates to the 4th century BC. Handheld crossbows with complex bronze trigger mechanisms have also been found with the Terracotta Army in the tomb of Qin Shihuang (r. 221–210 BC) that are similar to specimens from the subsequent Han Dynasty (202 BC–220 AD), while crossbowmen described in the Qin and Han Dynasty learned drill formations, some were even mounted as cavalry units, and Han Dynasty writers attributed the success of numerous battles against the Xiongnu to massed crossbow volleys. The bronze triggers were designed in such a way that they were able to store a large amount of energy within the bow when drawn, but was easily shot with little recoil when the trigger were pulled (this allowed it for precision shooting). The metal portions of the crossbow were also mass-produced with precision, with the bronze mechanisms being interchangeable. Finally, the Qin and Han Dynasties also developed crossbow shooting lines, with alternating rows of crossbowmen shooting and reloading in a manner similar to a musket firing line.
In Vietnamese historical legend, the ruler and general Thục Phán who ruled over the ancient kingdom of Âu Lạc from 257 to 207 BC is said to have owed his power to a magic crossbow, capable of shooting thousands of arrows at once.
Different varieties of crossbows were also developed, such as the repeating crossbow, multi-shot crossbow, and repeating multi-shot crossbow.
Ancient Greece.
The earliest reasonably reliable date for the crossbow in the Greek world is from the 5th century BC. The historian Diodorus Siculus (fl. 1st century BC), described the invention of a mechanical arrow shooting catapult ("katapeltikon") by a Greek task force in 399 BC. According to the inventor Hero of Alexandria (fl. 1st century AD), who referred to the now lost works of the 3rd-century BC engineer Ctesibius, this weapon was inspired by an earlier hand crossbow, called the "gastraphetes" ("belly shooter"), which could store more energy than the Greek bows. A detailed description of the "gastraphetes", along with a drawing, is found in Heron's technical treatise "Belopoeica". The "gastraphetes" was powered by a composite bow. It was cocked by resting the stomach in a concavity at the rear of the stock and pressing down with all strength. In this way considerably more energy can be summoned up than by using only one arm of the archer as in the hand-bow. The heavy weight and bulk of the "gastraphetes" may have necessitated a prop to keep it standing, i.e. by mounting it on a defensive wall or using a portable prop.
A third Greek author, Biton (fl. 2nd century BC), whose reliability has been positively reevaluated by recent scholarship, described two advanced forms of the "gastraphetes", which he credits to Zopyros, an engineer from southern Italy. Zopyrus has been plausibly equated with a Pythagorean of that name who seems to have flourished in the late 5th century BC. He probably designed his bow-machines on the occasion of the sieges of Cumae and Milet between 421 BC and 401 BC. The bows of these machines already featured a winched pull back system and could apparently throw two missiles at once.
From the mid-4th century BC onwards, evidence of the Greek use of crossbows becomes more dense and varied: Arrow shooting machines ("katapeltai") are briefly mentioned by Aeneas Tacticus in his treatise on siegecraft written around 350 BC. An Athenian inventory from 330–329 BC includes catapults bolts with heads and flights. Arrow shooting machines in action are reported from Philip II's siege of Perinthos in Thrace in 340 BC. At the same time, Greek fortifications began to feature high towers with shuttered windows in the top, presumably to house anti-personnel arrow shooters, as in Aigosthena.
The transition to the torsion catapults, which are not considered crossbows and came to dominate Greek and Roman artillery design, is first evident in inventories of the Athenian arsenal from between 338 and 326 BC. Torsion weapons, which rely on the energy generated from twisted animal sinew, became siege weapons and light artillery – such as the Greek ballista or the Roman scorpion.
In Roman times the crossbow became to be known as arcuballista.
Roman Empire.
Besides the "gastraphetes", the ancient world knew a variety of mechanical hand-held weapons similar to the later medieval crossbow. The exact terminology is a subject of continuing scholarly debate.
Greek and Roman authors like Vegetius (fl. 4th century) note repeatedly the use of arrow shooting weapons such as "arcuballista" and "manuballista" respectively "cheiroballistra". While most scholars agree that one or more of these terms refer to handheld mechanical weapons, there exist disagreement whether these were flexion bows or torsion powered like the recent Xanten find.
The Roman commander Arrian (c. 86 – after 146) records in his "Tactica" Roman cavalry training for shooting some mechanical handheld weapon from horseback.
Sculptural reliefs from Roman Gaul depict the use of crossbows in hunting scenes. The specimen are remarkably similar to the later medieval crossbow, including the typical nut lock (see image).
Medieval Europe.
The crossbow is portrayed as a hunting weapon on four Pictish stones from early medieval Scotland (6th to 9th centuries): St. Vigeans no. 1, Glenferness, Shandwick, and Meigle. The use of crossbows in European warfare is again evident from the Battle of Hastings until about the year 1500. They almost completely superseded hand bows in many European armies in the 12th century for a number of reasons. Although a longbow achieves comparable accuracy and faster shooting rate than an average crossbow, crossbows release more kinetic energy and can be used effectively after a week of training, while a comparable single-shot skill with a longbow takes years of strength training to overcome the draw strength of the longbow, as well as years of practice needed to use it with skill.
In the armies of Europe, mounted and unmounted crossbowmen, often mixed with slingers, javeliners and archers, occupied a central position in battle formations. Usually they engaged the enemy in offensive skirmishes before an assault of mounted knights. Crossbowmen were also valuable in counterattacks to protect their infantry. The rank of commanding officer of the crossbowmen corps was one of the highest positions in any army of this time. Along with polearm weapons made from farming equipment, the crossbow was also a weapon of choice for insurgent peasants such as the Taborites.
Mounted knights armed with lances proved ineffective against formations of pikemen combined with crossbowmen whose weapons could penetrate most knights' armor. The invention of pushlever and ratchet drawing mechanisms enabled the use of crossbows on horseback, leading to the development of new cavalry tactics. Knights and mercenaries deployed in triangular formations, with the most heavily armored knights at the front. Some of these riders would carry small, powerful all-metal crossbows of their own. Crossbows were eventually replaced in warfare by more powerful gunpowder weapons, although early guns had slower rates of fire and much worse accuracy than contemporary crossbows. Later, similar competing tactics would feature harquebusiers or musketeers in formation with pikemen (pike and shot), pitted against cavalry firing pistols or carbines.
Elsewhere.
The Saracens called the crossbow "qaws Ferengi", or "Frankish bow," as the Crusaders used the crossbow against the Arab and Turkoman horsemen with remarkable success. The adapted crossbow was used by the Islamic armies in defence of their castles. Later footstrapped version become very popular among the Muslim armies in Iberia. During the Crusades, Europeans were exposed to Saracen composite bows, made from layers of different material—often wood, horn and sinew—glued together and bound with animal tendon. These composite bows could be much more powerful than wooden bows, and were adopted for crossbow prods across Europe.
Crossbow prods could be more easily waterproofed than hand bows, which was essential in the European humid climate.
In Western Africa and Central Africa, crossbows served as a scouting weapon and for hunting, with the Spanish and the Portuguese bringing the technology to America. In the American South, the crossbow was used for hunting and warfare when firearms or gunpowder were unavailable because of economic hardships or isolation.
In Northern America, light hunting crossbows were traditionally used by the Inuit .
The native Montagnards of Vietnam's Central Highlands were also known to have used crossbows, as both a tool for hunting, and later, an effective weapon against the Viet Cong during the Vietnam War. Montagnard fighters armed with crossbows proved a highly valuable asset to the US Special Forces operating in Vietnam, and it was not uncommon for the Green Berets to integrate Montagnard crossbowmen into their strike teams.
Modern use.
Hunting, leisure and science.
Crossbows are used for shooting sports and bowhunting in modern archery and for blubber biopsy samples in scientific research.
Modern military and paramilitary use.
In modern times crossbows are no longer used for assassinations, but there are still some applications. For example, in the Americas, the Peruvian army (Ejército) equips some soldiers with crossbows and rope, to establish a zip-line in difficult terrain. In Brazil the CIGS (Jungle Warfare Training Center) also trains soldiers in the use of crossbows. In the United States, SAA International Ltd manufacture a 150 ft·lb crossbow-launched version of the U.S. Army type classified Launched Grapnel Hook (LGH), among other mine countermeasure solutions designed for the middle-eastern theatre. It has been successfully evaluated in Cambodia and Bosnia. It is used to probe for and detonate tripwire initiated mines and booby traps at up to 50 meters. The concept is similar to the LGH device originally only fired from a rifle, as a plastic retrieval line is attached. Reusable up to 20 times, the line can be reeled back in without exposing oneself. The device is of particular use in tactical situations where noise discipline is important.
In Europe, British-based Barnett International supplied crossbows to Serbian forces which according to "The Guardian" were later used "in ambushes and as a counter-sniper weapon", against the Kosovo Liberation Army during the Kosovo War in the areas of Pec and Djakovica, south west of Kosovo. Whitehall launched an investigation, though the department of trade and industry established that not being "on the military list" crossbows were not covered by such export regulations. Paul Beaver of Jane's defence publications commented that, "They are not only a silent killer, they also have a psychological effect". On 15 February 2008 Serbian Minister of Defence Dragan Sutanovac was pictured testing a Barnett crossbow during a public exercise of the Serbian army's Special Forces in Nis, 200 km south of capital Belgrade. Special forces in both Greece and Turkey also continue to employ the crossbow. Spain's Green Berets still use the crossbow as well.
In Asia, Chinese armed forces use crossbows at all unit levels from traffic police to the special force Snow Leopard Commando Unit of the People's Armed Police and the People's Liberation Army. One justification for this comes in the crossbow's ability to stop persons carrying explosives without risk of causing detonation. Furthermore, during the Xinjiang riots of July 2009, crossbows were used alongside modern military hardware to quell protestors. The Indian Navy's Marine Commando Force were equipped until the late 1980s with crossbows supplied with cyanide-tipped bolts, as an alternative to suppressed handguns.
Comparison to conventional bows.
With a crossbow, archers could release a draw force far in excess of what they could have handled with a bow. Furthermore the crossbow could hold the tension for a long time, whereas even the strongest longbowman could only hold a drawn bow for so long. The disadvantage is the greater weight and clumsiness compared to a bow, as well as the slower rate of shooting and the lower efficiency of the acceleration system, but there would be reduced elastic hysteresis, making the crossbow a more accurate weapon.
Crossbows have a much smaller draw length than bows. This means that for the same energy to be imparted to the arrow (or bolt), the crossbow has to have a much higher draw weight.
A direct comparison between a fast hand-drawn replica crossbow and a longbow show a 6:10 rate of shooting or a 4:9 rate within 30 seconds and comparable weapons.
Legal issues.
Can. 29 of the Second Lateran Council under Pope Innocent II in 1139 banned the use of crossbows, as well as slings and bows, against Christians.
Today, the crossbow often has a complicated legal status due to the possibility of lethal use and its similarities to both firearms and archery weapons. While some jurisdictions regard crossbows the same as firearms, many others do not require any sort of license to own a crossbow — even for people, such as felons, who may not legally possess a firearm. The legality of using a crossbow for hunting varies widely around the world, and even within different jurisdictions of some federal countries.

</doc>
<doc id="6949" url="http://en.wikipedia.org/wiki?curid=6949" title="Carbamazepine">
Carbamazepine

Carbamazepine (CBZ) (Tegretol, Equetro) is an anticonvulsant and mood-stabilizing drug used primarily in the treatment of epilepsy and bipolar disorder, as well as trigeminal neuralgia. Off-label uses include attention-deficit hyperactivity disorder (ADHD), schizophrenia, phantom limb syndrome, complex regional pain syndrome, borderline personality disorder, and post-traumatic stress disorder.
Studies on the use of carbamazepine in pregnant women have demonstrated exposure of the fetus to the drug and its metabolites. Intrauterine exposure to carbamazepine has been shown to be teratogenic and is associated with the development of spina bifida, neurodevelopmental problems, craniofacial defects, cardiovascular malformations, hypospadias, and developmental delays.
It is on the World Health Organization's List of Essential Medicines, a list of the most important medication needed in a basic health system.
Medical uses.
Carbamazepine is typically used for the treatment of seizure disorders and neuropathic pain. It may be used off-label as a second line treatment for bipolar disorder and as an adjunct, never alone, with an antipsychotic in some cases of schizophrenia when treatment with a conventional antipsychotic alone has failed.
In the United States, the FDA-approved indications are epilepsy (including partial seizures, generalized tonic-clonic seizures and mixed seizures), trigeminal neuralgia, and manic and mixed episodes of bipolar I disorder. Although data are still lacking, carbamazepine appears to be as effective and safe as lithium for the treatment of bipolar disorder, both in the acute and maintenance phase.
Adverse effects.
Common adverse effects may include drowsiness, dizziness, headaches and migraines, motor coordination impairment, nausea, vomiting and/or constipation. Alcohol use while taking carbamazepine may lead to enhanced depression of the central nervous system.
Less common side-effects may include cardiac arrhythmias, blurry or double vision and/or the temporary loss of blood cells or platelets and in rare cases can cause aplastic anemia or agranulocytosis. With normal use, small reductions in white cell count and serum sodium levels are common; however, in rare cases, the loss of platelets may become life-threatening. In this case a doctor may recommend frequent blood tests during the first few months of use, followed by three to four tests per year for established patients. Additionally, carbamazepine may possibly exacerbate preexisting cases of hypothyroidism, so yearly thyroid function tests are advisable for persons taking the drug.
There are also rare reports of an auditory side-effect for carbamazepine use, whereby patients perceive sounds about a semitone lower than previously. Thus, middle C would be heard as the note B3 just below it, and so on. The inverse effect (that is, notes sounding higher) has also been recorded. This unusual side-effect is usually not noticed by most people, and quickly disappears after the person stops taking carbamazepine.
Oxcarbazepine, a derivative of carbamazepine, reportedly has fewer and less serious side-effects.
Carbamazepine may cause syndrome of inappropriate antidiuretic hormone (SIADH), since it both increases the release and potentiates the action of ADH (vasopressin).
Carbamazepine may aggravate juvenile myoclonic epilepsy, so it is important to uncover any history of jerking, especially in the morning, before starting the drug. It may also aggravate other types of generalized seizure disorder, particularly absence seizures.
In addition, carbamazepine has been linked to serious adverse cognitive anomalies, including EEG slowing and apoptosis of cultured cerebellar neurons.
The FDA informed health care professionals that dangerous or even fatal skin reactions (Stevens–Johnson syndrome and toxic epidermal necrolysis), that can be caused by carbamazepine therapy, are significantly more common in patients with a particular human leukocyte antigen (HLA) allele, HLA-B*1502. This allele occurs almost exclusively in patients with ancestry across broad areas of Asia, including South Asian Indians. In Europeans a large proportion of sensitivity is associated with HLA-B58. Researchers have also identified another genetic variant, HLA-A*3101 which has been shown to be a strong predictor of both mild and severe adverse reactions to carbamazepine among Japanese and Europeans.
Associated birth defects.
If taken during pregnancy, Carbamazepine can cause birth defects that include: cardiovascular and urinary tract anomalies, craniofacial defects such as cleft palate, fingernail hypoplasia, microcephaly, developmental delays, and intrauterine growth restrictions.
Interactions.
Carbamazepine has a potential for drug interactions; caution should be used in combining other medicines with it, including other antiepileptics and mood stabilizers. Lower levels of carbamazepine are seen when administrated with phenobarbital, phenytoin (Dilantin), or primidone (Mysoline), which can result in breakthrough seizure activity. Carbamazepine, as a CYP450 inducer, may increase clearance of many drugs, decreasing their concentration in the blood to subtherapeutic levels and reducing their desired effects. Drugs that are more rapidly metabolized with carbamazepine include warfarin (Coumadin), lamotrigine (Lamictal), phenytoin (Dilantin), theophylline, and valproic acid (Depakote, Depakote ER, Depakene, Depacon). Drugs that decrease the metabolism of carbamazepine or otherwise increase its levels include erythromycin, cimetidine (Tagamet), propoxyphene (Darvon), and calcium channel blockers. Carbamazepine also increases the metabolism of the hormones in birth control pills and can reduce their effectiveness, potentially leading to unexpected pregnancies. As a drug that induces cytochrome P450 enzymes, it accelerates elimination of many benzodiazepines and decreases their action.
Valproic acid and valnoctamide both inhibit microsomal epoxide hydrolase (mEH), the enzyme responsible for the breakdown of carbamazepine-10,11 epoxide into inactive metabolites. By inhibiting mEH, valproic acid and valnoctamide cause a buildup of the active metabolite, prolonging the effects of carbamazepine and delaying its excretion.
Grapefruit juice raises the bioavailability of carbamazepine by inhibiting CYP3A4 enzymes in the gut wall and in the liver.
Environmental impact.
Carbamazepine can enter the environment through discharge of wastewater, and has also been shown to persist and accumulate in the organic components of soil and sludge. As carbamazepine is an emerging contaminant, the effects of its bioaccumulation on other living creatures and plants are not well-understood.
Pharmacokinetics.
Carbamazepine is relatively slowly but well absorbed after oral administration. Its plasma half life is about 30 hours when it is given as single dose, but it is a strong inducer of hepatic enzymes and the plasma half-life shortens to about 15 hours when it is given repeatedly. Some of its metabolites have antiepileptic properties. A slow-release preparation is used for patients who experience transient side effects coinciding with plasma concentration peaks following oral dosing.
Mechanism of action.
The mechanism of action of carbamazepine and its derivatives is relatively well-understood. Carbamazepine stabilizes the inactivated state of Voltage-gated sodium channels, making fewer of these channels available to subsequently open. This leaves the affected cells less excitable until the drug dissociates. Carbamazepine has also been shown to potentiate GABA receptors made up of alpha1, beta2, gamma2 subunits. This mechanism may contribute to its efficacy in neuropathic pain and manic-depressive illness.
History.
Carbamazepine was discovered by chemist Walter Schindler at J.R. Geigy AG (now part of Novartis) in Basel, Switzerland, in 1953. Schindler then synthesized the drug in 1960, before its anti-epileptic properties had been discovered.
Carbamazepine was first marketed as a drug to treat trigeminal neuralgia (formerly known as tic douloureux) in 1962. It has been used as an anticonvulsant and antiepileptic in the UK since 1965, and has been approved in the US since 1974.
In 1971, Drs. Takezaki and Hanaoka first used carbamazepine to control mania in patients refractory to antipsychotics (lithium was not available in Japan at that time). Dr. Okuma, working independently, did the same thing with success. As they were also epileptologists, they had some familiarity with the anti-aggression effects of this drug. Carbamazepine would be studied for bipolar disorder throughout the 1970s.
Brand names.
Carbamazepine has been sold under the names Biston (Czech), Calepsin, Carbatrol, Epitol, Equetro, Finlepsin, Sirtal, Stazepine, Telesmin, Tegretol, EPITAB XR(of Werrick Pakistan') Teril, Timonil, Trimonil, Epimaz, Carbama/Carbamaze (New Zealand), Amizepin (Poland), Carzine (Kolkata), Mazetol, Tegrital, Tegrita, Zeptol (India), Karbapin (Serbia), Hermolepsin (Sweden), Degranol (South Africa), and Tegretal (Chile, Germany).
Synthesis.
Carbamazepine, 5H-dibenzis synthesized by reacting 5H-dibenz[b,fazepine and phosgene, which forms 5-chlorcarboxy-5H-dibenz-[b,f]azepine), and its subsequent reaction with ammonia to give the desired carbamazepine. Coll. means collidine.
An alternative method of synthesis is the direct reaction of 5H-dibenz[b,f]azepine with potassium cyanate (KOCN).
Carbamazepine is a dibenzazepine.

</doc>
<doc id="6951" url="http://en.wikipedia.org/wiki?curid=6951" title="CCIR">
CCIR

CCIR is a four-letter abbreviation that may stand for:

</doc>
<doc id="6955" url="http://en.wikipedia.org/wiki?curid=6955" title="Chalcedonian Definition">
Chalcedonian Definition

The Chalcedonian Definition (also Confession or Creed of Chalcedon) was adopted in 451 at the Council of Chalcedon in Asia Minor. That council was the fourth of the first seven Ecumenical Councils, which are accepted by Chalcedonian churches (Eastern Orthodox, Catholic, and many Protestant churches). It is the first Council "not" recognised by any of the Oriental Orthodox churches, which may be classifed as non-Chalcedonian.
The Definition defines that Christ is 'acknowledged in two natures', which 'come together into one person and onehypostasis'. The formal definition of 'two natures' in Christ was understood by the critics of the council at the time, and is understood by many historians and theologians today, to side with western and Antiochene Christology and to diverge from the teaching of Cyril of Alexandria, who always stressed that Christ is 'one'. However, a modern analysis of the sources of the creed (by A. de Halleux, in Revue Theologique de Louvain 7, 1976) and a reading of the acts, or proceedings, of the council (recently translated into English) show that the bishops considered Cyril the great authority and that even the language of 'two natures' derives from him.
Oriental Orthodox dissent.
The Chalcedonian Definition was written amid controversy between the western and eastern churches over the meaning of the Incarnation (see Christology), the ecclesiastical influence of the emperor, and the supremacy of the Bishop of Rome. The western churches readily accepted the creed, but some eastern churches did not.
It became standard orthodox doctrine. However the Coptic Church of Alexandria dissented, holding to Cyril of Alexandria's preferred formula for the oneness of Christ’s nature in the incarnation of God the Word as "out of two natures". Cyril's language is not consistent and he may have countenanced the view that it is possible to contemplate in theory two natures after the incarnation, but the Church of Alexandria felt that the Definition should have stated that Christ be acknowledged "out of two natures" rather than "in two natures".
This miaphysite position, historically characterised by Chalcedonian followers as "monophysitism" though this is denied by the dissenters, formed the basis for the distinction from other churches of the Coptic Church of Egypt and Ethiopia and the "Jacobite" churches of Syria and Armenia (see Oriental Orthodoxy). Over the last 30 years, however, the miaphysite position has been accepted as a mere restatement of orthodox belief by Patriarch Bartholomew I of the Eastern Orthodox Church and by Pope John Paul II of the Roman Catholic Church.
English translation.
The key section runs:<br>
Following, then, the holy Fathers, we all unanimously teach that our Lord Jesus Christ is to us 
One and the same Son, the Self-same Perfect in Godhead, the Self-same Perfect in Manhood; truly God and truly Man; the Self-same of a rational soul and body; co-essential with the Father according to the Godhead, the Self-same co-essential with us according to the Manhood; like us in all things, sin apart; before the ages begotten of the Father as to the Godhead, but in the last days, the Self-same, for us and for our salvation (born) of Mary the Virgin Theotokos as to the Manhood; One and the Same Christ, Son, Lord, Only-begotten; acknowledged in Two Natures unconfusedly, unchangeably, indivisibly, inseparably; the difference of the Natures being in no way removed because of the Union, but rather the properties of each Nature being preserved, and (both) concurring into One Person and One Hypostasis; not as though He were parted or divided into Two Persons, but One and the Self-same Son and Only-begotten God, Word, Lord, Jesus Christ; even as from the beginning the prophets have taught concerning Him, and as the Lord Jesus Christ Himself hath taught us, and as the Symbol of the Fathers hath handed down to us.

</doc>
<doc id="6956" url="http://en.wikipedia.org/wiki?curid=6956" title="Conservation law">
Conservation law

In physics, a conservation law states that a particular measurable property of an isolated physical system does not change as the system evolves. 
One particularly important physical result concerning laws of conservation is Noether's theorem, which states that there is a one-to-one correspondence between laws of conservation and differentiable symmetries of physical systems. For example, the conservation of energy follows from the time-invariance of physical systems, and the fact that physical systems behave the same regardless of how they are oriented in space gives rise to the conservation of angular momentum.
Exact laws.
A partial listing of physical laws of conservation that are said to be exact laws, or more precisely "have never been to be violated:"
Approximate laws.
There are also approximate conservation laws. These are approximately true in particular situations, such as low speeds, short time scales, or certain interactions. 

</doc>
<doc id="6959" url="http://en.wikipedia.org/wiki?curid=6959" title="Chord">
Chord

Chord may refer to:
Chord may also refer to:
The Chords may refer to:
Chords may refer to:

</doc>
<doc id="6960" url="http://en.wikipedia.org/wiki?curid=6960" title="Car Talk">
Car Talk

Car Talk is a Peabody Award-winning radio talk show broadcast weekly on NPR stations and elsewhere. Its subjects were automobiles and automotive repair, discussed often in a humorous way. It was hosted by brothers Tom and Ray Magliozzi, known also as "Click and Clack, the Tappet Brothers".
The show was produced from 1977 to October 2012, until the Magliozzi brothers retired. Edited reruns continue to be available for airing on NPR affiliates.
Show.
"Car Talk" was presented in the form of a call-in radio show: listeners called in with questions related to motor vehicle maintenance and repair. Most of the advice sought was diagnostic, with callers describing symptoms and demonstrating sounds of an ailing vehicle while the Magliozzis make an attempt at identifying the malfunction. While the hosts peppered their call-in sessions with jokes directed at both the caller and at themselves, the Magliozzis were usually able to arrive at a diagnosis and give helpful advice.
Edited reruns are carried on Sirius XM Radio via both the Public Radio and NPR Now channels.
The "Car Talk" theme song is "Dawggy Mountain Breakdown" by bluegrass artist David Grisman.
Call-in procedure.
Throughout the program, listeners were encouraged to dial the toll-free telephone number, 1-888-CAR-TALK (1-888-227-8255), which connected to a 24-hour answering service. Although the approximately 2,000 queries received each week were screened by the "Car Talk" staff, the questions were unknown to the Magliozzis in advance as "that would entail researching the right answer, which is what? ...Work." Producers selected and contacted the callers several days ahead of the show's Wednesday taping to arrange the segment. The caller spoke briefly to a producer before being connected live with the hosts, and was given little coaching other than being told to be prepared to talk, not to use any written preparation and to "have fun". The show deliberately taped more callers than it has time to air each week in order to be able to choose the best ones for broadcast. Those segments that did make it to air were generally edited for time. For the last four years of the show, new shows included previously broadcast segments as much as 10 years old. The re-used segments, including re-used puzzlers, were not acknowledged as old material and sometimes new caller material was mixed in alongside the recycled calls.
Features.
The show originally consisted of two segments with a break in between. Then the show was changed to three segments. The hosts used to refer to content coming up in the second half of the program. Ever since the shift to the three segment format, it became a running joke to refer to the last segment as "the third half" of the program.
The show opened with a short comedy segment, typically jokes sent in by listeners, followed by eight call-in sessions. The hosts ran a contest called the "Puzzler", in which a riddle, sometimes car-related, was presented. The answer to the previous week's "Puzzler" was given at the beginning of the "second half" of the show, and a new "Puzzler" was given at the start of the "third half". The hosts gave instructions to listeners to write answers addressed to "Puzzler Tower" on some non-existent or expensive object, such as a "$26 bill" or an advanced digital SLR camera. This gag initially started as suggestions that the answers be written "on the back of a $20 bill". A running gag concerned Tom's inability to remember the previous week's "Puzzler" without heavy prompting from Ray. For each puzzler, one correct answer was chosen at random, with the winner receiving a $26 gift certificate to the "Car Talk" store, referred to as the "Shameless Commerce Division". It was originally $25, but was increased for inflation after a few years. Originally, the winner received a specific item from the store, but it soon changed to a gift certificate to allow the winner to choose the item they wanted (though Tom often made an item suggestion).
A recurring feature was "Stump the Chumps," in which the hosts revisited a caller from a previous show to determine the accuracy and the effect, if any, of their advice. A similar feature began in May 2001, "Where Are They Now, Tommy?" It began with a comical musical theme with a sputtering, backfiring car engine and a horn as a backdrop. Tom then announced who the previous caller was, followed by a short replay of the essence of the previous caller was played, preceded and followed by harp music often used in other audiovisual media to indicate recalling and returning from a dream. The hosts then greeted the previous caller, asking them if there have been any influences on the answer they're about to relate, such as arcane bribes by the NPR staff. The repair story was then discussed, followed by a fanfare and applause if the Tappet Brothers' diagnosis was correct, or a wah-wah-wah music piece mixed with a car starter operated by a weak battery (an engine which won't start) if the diagnosis was wrong. The hosts then thanked the caller for their return appearance.
The brothers also had an official Animal-Vehicle Biologist and Wildlife Guru named Kieran Lindsey. She answered questions like "How do I remove a snake from my car?" and offered advice on how those living in cities and suburbs can reconnect with wildlife.
There were numerous appearances from NPR personalities, including Bob Edwards, Susan Stamberg, Scott Simon, Ray Suarez, Will Shortz, Sylvia Poggioli, and commentator and author Daniel Pinkwater. On one occasion, the show featured Martha Stewart as an in-studio guest, whom the Magliozzis twice during the segment referred to as "Margaret".
In addition to at least one on-orbit call, the Brothers once received a call asking advice on winterizing a couple of "kit cars". After much beating around the bush and increasing evasiveness by the caller, they asked him just how much these kit cars were worth. The answer: about $800 million. It was a joke call from the Jet Propulsion Laboratory concerning the preparation of the Mars Rovers ("Spirit" and "Opportunity") for the oncoming Martian winter. Click and Clack have also been featured in editorial cartoons, including one where a befuddled NASA engineer calls them to ask how to fix the Space Shuttle.
Humor.
Humor and wisecracking pervaded the program. Tom and Ray are known for their self-deprecating humor, often joking about the supposedly poor quality of their advice and the show in general. They also commented at the end of each show: "Well, it's happened again — you've squandered another perfectly good hour listening to "Car Talk"."
At some point in almost every show, usually when giving the address for the Puzzler answers, Ray mentioned Cambridge, Massachusetts (where the show originates), at which point Tom reverently interjected with a tone of civic pride, "Our fair city." Ray invariably mocked "Cambridge, MA" the US Postal Service's two letter abbreviation for "Massachusetts" by pronouncing it as a word.
Leading into each break in the show, one of the hosts led up to the network identification with a humorous take on a disgusted reaction of some usually famous person to hearing that identification. The full line went along the pattern of, for example, "And even though Roger Clemens stabs his radio with a syringe whenever he hears "us" say it, this is NPR: National Public Radio (later just '...this is NPR')."
The ending credits of the show started with thanks to the colorfully nicknamed actual staffers: producer Doug "the subway fugitive, not a slave to fashion, bongo boy frogman" Berman; "John 'Bugsy' Lawlor, just back from the..." every week a different eating event with rhyming foodstuff names; David "Calves of Belleville" Greene; Catherine "Frau Blücher" Fenollosa, whose name caused a horse to neigh and gallop (an allusion to a running gag in the movie "Young Frankenstein"); and Carly "High Voltage" Nix, among others. Following the real staff was a lengthy list of pun-filled fictional staffers and sponsors such as statistician Marge Innovera ("margin of error"), customer care representative Haywood Jabuzoff ("Hey, would you buzz off"), meteorologist Claudio Vernight ("cloudy overnight"), optometric firm C.F. Eye Care ("see if I care"), Russian chauffeur Pikov Andropov ("pick up and drop off"), Leo Tolstoy biographer Warren Peace ("War and Peace"), hygiene officer and chief of the Tokyo office Otaka Shawa ("oh take a shower"), Swedish snow-board instructor Soren Derkeister ("sore in the keister"), and law firm Dewey, Cheetham & Howe ("Do we cheat 'em? And how!"), among many, many others.
At the end of the show, Ray warned the audience, "Don't drive like my brother," to which Tom replied, "And don't drive like "my" brother." The original tag line was "Don't drive like a knucklehead." There have been variations such as, "Don't drive like my brother..." "And don't drive like his brother," and "Don't drive like my sister..." "And don't drive like "my" sister." The tagline was heard in a cameo for the Pixar film "Cars", in which Tom and Ray voiced anthropomorphized vehicles (Rusty and Dusty Rust-Eze, respectively a 1963 Dodge Dart V1.0 and 1963 Dodge A100 van, as Lightning McQueen's racing sponsors) with personalities similar to their own on-air personae. Tom notoriously once owned a "convertible, green with large areas of rust" Dodge Dart, known jokingly on the program by the faux-elegant name "Dartre".
History.
"Car Talk" was first broadcast on WBUR in Boston in 1977 and was picked up nationally by NPR ten years later.
In 1992, "Car Talk" won a Peabody Award, saying "Each week, master mechanics Tom and Ray Magliozzi provide useful information about preserving and protecting our cars. But the real core of this program is what it tells us about human mechanics...The insight and laughter provided by Messrs. Magliozzi, in conjunction with their producer Doug Berman, provide a weekly mental tune-up for a vast and ever-growing public radio audience."
In May 2007, the program, which previously had been available only digitally as a paid subscription from Audible.com, became a free podcast distributed by NPR, after a two-month test period where only a "call of the week" was available via podcast.
As of 2012, it had 3.3 million listeners each week, on about 660 stations. On June 8, 2012, the brothers announced that they would no longer broadcast new episodes as of October. Executive producer Doug Berman said the best material from 25 years of past shows would be used to put together "repurposed" shows for NPR to broadcast. Berman estimated the archives contain enough for eight years' worth of material before anything would have to be repeated. The brothers will continue to write their syndicated newspaper column.
Hosts.
The Magliozzis are long-time car mechanics. Ray Magliozzi has a bachelor of science degree in humanities and science from MIT, while Tom has a bachelor of science degree in economics from MIT and an MBA and DBA from the Boston University Graduate School of Management.
The duo, usually led by Ray, were known for rants on the evils of the internal combustion engine, people who talk on cell phones while driving, Peugeots, women named Donna who always seem to drive Camaros, lawyers, the clever use of the English language, people who choose to live in Alaska (or similar snowy, icy climates), and practically anything else, including themselves. They had a relaxed and humorous approach to cars, car repair, cup holders, pets, lawyers, car repair mechanics, SUVs, and almost everything else. They often cast a critical, jaundiced insider's eye toward the auto industry. Tom and Ray are committed to the values of defensive driving and environmentalism.
The Magliozzis operate a garage. The show's offices were located nearby at the corner of JFK Street and Brattle Street in Harvard Square, marked as "Dewey, Cheetham & Howe", the imaginary law firm to which they refer on-air. DC&H doubled as the business name of Tappet Brothers Associates, the corporation established to manage the business end of "Car Talk". Initially a joke, the company was incorporated after the show expanded from a single station to national syndication.
The two were commencement speakers at MIT in 1999.
Executive producer Doug Berman said in 2012, "The guys are culturally right up there with Mark Twain and the Marx Brothers. They will stand the test of time. People will still be enjoying them years from now. They're that good."
Adaptations.
The show was the inspiration for the short-lived "The George Wendt Show", which briefly aired on CBS in the 1994-95 season- as a mid-season replacement.
In July 2007, PBS announced that it had greenlit an animated adaptation of "Car Talk", to air on prime-time in 2008. The show, titled "Click and Clack's As the Wrench Turns" is based on the adventures of the fictional "Click and Clack" brothers' garage at "Car Talk Plaza". The ten episodes aired in July and August 2008.
"Car Talk: The Musical!!!" was written and directed by Wesley Savick, and composed by Michael Wartofsky. The adaptation was presented by Suffolk University, and opened on March 31, 2011, at the Modern Theatre in Boston, Massachusetts. The play was not officially endorsed by the Magliozzis, but they participated in the production, lending their voices to a central puppet character named "The Wizard of Cahs".

</doc>
<doc id="6962" url="http://en.wikipedia.org/wiki?curid=6962" title="Council of Chalcedon">
Council of Chalcedon

The Council of Chalcedon ( or ) was a church council held from October 8 to November 1, AD 451, at Chalcedon (a city of Bithynia in Asia Minor), on the Asian side of the Bosporus, known in modern times as Kadıköy in Istanbul, although it was then separate from Constantinople. The council marked a significant turning point in the Christological debates that led to the separation of the church of the Western Roman Empire in the 5th century.
The Council of Chalcedon was convened by Emperor Marcian, with the reluctant approval of Pope Leo the Great, to set aside the 449 Second Council of Ephesus which would become known as the "Latrocinium" or "Robber Council". The Council of Chalcedon issued the 'Chalcedonian Definition,' which repudiated the notion of a single nature in Christ, and declared that he has two natures in one person and hypostasis; it also insisted on the completeness of his two natures: Godhead and manhood. The council also issued 27 disciplinary canons governing church administration and authority. In a further decree, later known as the canon 28, the bishops declared the See of Constantinople (New Rome) equal in honor and authority to Rome.
The Council is considered to have been the Fourth Ecumenical Council by the Eastern Orthodox Church, the Roman Catholic Church (including its Eastern Catholic Churches), the Old Catholics, and various other Western Christian groups. As such, it is recognized as infallible in its dogmatic definitions by the Roman Catholic and Eastern Orthodox Churches (then one church). Most Protestants also consider the concepts of the Trinity and Incarnation as defined at Nicaea (in 325) and Chalcedon to be orthodox doctrine to which they adhere. However, the Council is not accepted by several of the ancient Eastern Churches, including the Oriental Orthodox of Egypt, Syria, Armenia, Eritrea, Ethiopia. The Oriental Orthodox teach "The Lord Jesus Christ is God the Incarnate Word. He possesses the perfect Godhead and the perfect manhood. His fully divine nature is united with His fully human nature yet without mixing, blending or alteration" which has been misunderstood as monophysitism, a belief which the Oriental Orthodox Church strongly disagree with.
Historical background.
Relics of Nestorianism.
In 325, the first ecumenical council (First Council of Nicaea) determined that Jesus Christ was God, "consubstantial" with the Father, and rejected the Arian contention that Jesus was a created being. This was reaffirmed at the First Council of Constantinople (381) and the Council of Ephesus (431).
After the Council of Ephesus had condemned Nestorianism, there remained a conflict between Patriarchs John of Antioch and Cyril of Alexandria. Cyril claimed that John remained Nestorian in outlook, while John claimed that Cyril held to the Apollinarian heresy. The two settled their differences under the mediation of the Bishop of Beroea, Acacius, on April 12, 433. In the following year, Theodoret of Cyrrhus assented to this formula as well. He agreed to anathematize Nestorius as a heretic in 451, during the Council of Chalcedon, as the price to be paid for being restored to his see (after deposition at the Council of Ephesus of 449). This put a final end to Nestorianism within the Roman Empire
Eutychian controversy.
About two years after Cyril of Alexandria's death in 444, an aged monk from Constantinople named Eutyches began teaching a subtle variation on the traditional Christology in an attempt (as he described in a letter to Pope Leo I in 448) to stop a new outbreak of Nestorianism. He claimed to be a faithful follower of Cyril's teaching, which was declared orthodox in the Union of 433.
Cyril had taught that "There is only one "physis", since it is the Incarnation, of God the Word." Cyril had apparently understood the Greek word "physis" to mean approximately what the Latin word "persona" (person) means, while most Greek theologians would have interpreted that word to mean "natura" (nature). Thus, many understood Eutyches to be advocating Docetism, a sort of reversal of Arianism—where Arius had denied the consubstantial divinity of Jesus, Eutyches seemed to be denying his human nature. Cyril's orthodoxy was not called into question, since the Union of 433 had explicitly spoken of two "physeis" in this context. 
Leo I wrote that Eutyches' error seemed to be more from a lack of skill on the matters than from malice. Further, his side of the controversy tended not to enter into arguments with their opponents, which prevented the misunderstanding from being uncovered. Nonetheless, due to the high regard in which Eutyches was held (second only to the Patriarch of Constantinople in the East), his teaching spread rapidly throughout the East. 
In November 448, during a local synod in Constantinople, Eutyches was denounced as a heretic by the Bishop Eusebius of Dorylaeum. Eusebius demanded that Eutyches be removed from office. Patriarch Flavian of Constantinople preferred not to press the matter on account of Eutyches' great popularity. He finally relented and Eutyches was condemned as a heretic by the synod. However, the Emperor Theodosius II and the Patriarch of Alexandria, Dioscorus, rejected this decision ostensibly because Eutyches had repented and confessed his orthodoxy. Dioscorus then held his own synod which reinstated Eutyches. The competing claims between the Patriarchs of Constantinople and Alexandria led the Emperor to call a council which was held in Ephesus in 449. The emperor invited Pope Leo I to preside. He declined to attend on account of the invasion of Italy by Attila the Hun. However, he agreed to send four legates to represent him. Leo provided his legates, one of whom died en route, with a letter addressed to Flavian of Constantinople explaining Rome's position in the controversy. Leo's letter, now known as Leo's Tome, confessed that Christ had two natures, and was not of or from two natures. Although it could be reconciled with Cyril's Formula of Reunion, it was not compatible in its wording with Cyril's Twelve Anathemas. In particular, the third anathema reads: "If anyone divides in the one Christ the hypostases after the union, joining them only by a conjunction of dignity or authority or power, and not rather by a coming together in a union by nature, let him be anathema." This appeared to some to be incompatible with Leo's definition of two natures hypostatically joined. However, the Council would determine (with the exception of 13 Egyptian bishops) that this was an issue of wording and not of doctrine; a committee of bishops appointed to study the orthodoxy of the Tome using Cyril's letters (which included the twelve anathemas) as their criteria unanimously determined it to be orthodox, and the Council, with few exceptions, supported this.
"Latrocinium" of Ephesus.
On August 8, 449 the Second Council of Ephesus began its first session with Dioscorus presiding by command of the Emperor. Dioscorus began the council by banning all members of the November 447 synod which had deposed Eutyches. He then introduced Eutyches who publicly professed that while Christ had two natures before the incarnation, the two natures had merged to form a single nature after the incarnation. Of the 130 assembled bishops, 111 voted to rehabilitate Eutyches. Throughout these proceedings, Roman legate Hilary repeatedly called for the reading of Leo's Tome, but was ignored. Dioscorus then moved to depose Flavian and Eusebius of Dorylaeum on the grounds that they taught the Word had been made flesh and not just assumed flesh from the Virgin and that Christ had two natures. When Flavian and Hilary objected, Dioscorus called for a pro-monophysite mob to enter the church and assault Flavian as he clung to the altar. Flavian was mortally wounded. Dioscorus then placed Eusebius of Dorylaeum under arrest and demanded the assembled bishops approve his actions. Fearing the mob, they all did. The papal legates refused to attend the second session at which several more orthodox bishops were deposed, including Ibas of Edessa, Irenaeus of Tyre (a close personal friend of Nestorius), Domnus of Antioch, and Theodoret. Dioscorus then pressed his advantage by having Cyril of Alexandria's Twelve Anathemas posthumously declared orthodox with the intent of condemning any confession other than one nature in Christ. Roman Legate Hilary, who as pope dedicated an oratory in the Lateran Basilica in thanks for his life, managed to escape from Constantinople and brought news of the Council to Leo who immediately dubbed it a "synod of robbers"—Latrocinium—and refused to accept its pronouncements. The decisions of this council now threatened schism between the East and the West.
Convocation and session.
The situation continued to deteriorate, with Leo demanding the convocation of a new council and Emperor Theodosius II refusing to budge, all the while appointing bishops in agreement with Dioscorus. All this changed dramatically with the Emperor's death and the elevation of Marcian, an orthodox Christian, to the imperial throne. To resolve the simmering tensions, Marcian announced his intention to hold a new council. Leo had pressed for it to take place in Italy, but Emperor Marcian instead called for it to convene at Nicaea. Hunnish invasions forced it to move at the last moment to Chalcedon, where the council opened on October 8, 451. Marcian had the bishops deposed by Dioscorus returned to their dioceses and had the body of Flavian brought to the capital to be buried honorably.
The Emperor asked Leo to preside over the council, but Leo again chose to send legates in his place. This time, Bishops Paschasinus of Lilybaeum and Julian of Cos and two priests Boniface and Basil represented the western church at the council. The Council of Chalcedon condemned the work of the Robber Council and professed the doctrine of the Incarnation presented in Leo's Tome. Attendance at this council was very high, with about 370 bishops (or presbyters representing bishops) attending. Paschasinus refused to give Dioscorus (who had excommunicated Leo leading up to the council) a seat at the council. As a result, he was moved to the nave of the church. Paschasinus further ordered the reinstatement of Theodoret and that he be given a seat, but this move caused such an uproar among the council fathers, that Theodoret also sat in the nave, though he was given a vote in the proceedings, which began with a trial of Dioscorus.
Marcian wished to bring proceedings to a speedy end, and asked the council to make a pronouncement on the doctrine of the Incarnation before continuing the trial. The council fathers, however, felt that no new creed was necessary, and that the doctrine had been laid out clearly in Leo's Tome. They were also hesitant to write a new creed as the Council of Ephesus had forbidden the composition or use of any new creed. The second session of the council ended with shouts from the bishops, "It is Peter who says this through Leo. This is what we all of us believe. This is the faith of the Apostles. Leo and Cyril teach the same thing." However, during the reading of Leo's Tome, three passages were challenged as being potentially Nestorian, and their orthodoxy was defended by using the writings of Cyril. Nonetheless due to such concerns, the Council decided to adjourn and appoint a special committee to investigate the orthodoxy of Leo's Tome, judging it by the standard of Cyril's Twelve Chapters, as some of the bishops present raised concerns about their compatibility. This committee was headed by Anatolius, Patriarch of Constantinople, and was given five days to carefully study the matter; Cyril's Twelve Chapters were to be used as the orthodox standard. The committee unanimously decided in favor of the orthodoxy of Leo, determining that what he said was compatible with the teaching of Cyril. A number of other bishops also entered statements to the effect that they believed that Leo's Tome was not in contradiction with the teaching of Cyril as well.
The council continued with Dioscorus' trial, but he refused to appear before the assembly. As a result, he was condemned, but by an underwhelming amount (more than half the bishops present for the previous sessions did not attend his condemnation), and all of his decrees were declared null. Marcian responded by exiling Dioscorus. All of the bishops were then asked to sign their assent to the Tome, but a group of thirteen Egyptians refused, saying that they would assent to "the traditional faith". As a result, the Emperor's commissioners decided that a "credo" would indeed be necessary and presented a text to the fathers. No consensus was reached, and indeed the text has not survived to the present. Paschasinus threatened to return to Rome to reassemble the council in Italy. Marcian agreed, saying that if a clause were not added to the "credo" supporting Leo's doctrine , the bishops would have to relocate. The bishops relented and added a clause, saying that, according to the decision of Leo, in Christ there are two natures united, inconvertible, inseparable.
Confession of Chalcedon.
The Confession of Chalcedon provides a clear statement on the human and divine nature of Christ:
Canons.
The work of the council was completed by a series of 30 disciplinary canons the Ancient Epitomes of which are:
Canon 28 grants equal privileges ("") to Constantinople as of Rome because Constantinople is the New Rome as renewed by canon 36 of the Quinisext Council. The papal legates were not present for the vote on this canon, and protested it afterwards, and it was not ratified by Pope Leo in Rome.
According to some ancient Greek collections, canons 29 and 30 are attributed to the council: canon 29, which states that an unworthy bishop cannot be demoted but can be removed, is an extract from the minutes of the 19th session; canon 30, which grants the Egyptians time to consider their rejection of Leo's "Tome", is an extract from the minutes of the fourth session.
In all likelihood an official record of the proceedings was made either during the council itself or shortly afterwards. The assembled bishops informed the pope that a copy of all the "Acta" would be transmitted to him; in March, 453, Pope Leo commissioned Julian of Cos, then at Constantinople, to make a collection of all the Acts and translate them into Latin. Most of the documents, chiefly the minutes of the sessions, were written in Greek; others, e.g. the imperial letters, were issued in both languages; others, again, e.g. the papal letters, were written in Latin. Eventually nearly all of them were translated into both languages.
The status of the sees of Constantinople and Jerusalem.
The status of Jerusalem.
The metropolitan of Jerusalem was given independence from the metropolitan of Antioch and from any other higher-ranking bishop, given what is now known as autocephaly, in the council's seventh session whose "Decree on the Jurisdiction of Jerusalem and Antioch" contains: "the bishop of Jerusalem, or rather the most holy Church which is under him, shall have under his own power the three Palestines". This led to Jerusalem becoming a patriarchate, one of the five patriarchates known as the pentarchy, when the title of "patriarch" was created in 531 by Justinian.
The status of Constantinople.
In a canon of disputed validity, the Council of Chalcedon also elevated the See of Constantinople to a position "second in eminence and power to the Bishop of Rome".
The Council of Nicaea in 325 had noted the primacy of the See of Rome, followed by the Sees of Alexandria and Antioch. At the time, the See of Constantinople was yet of no ecclesiastical prominence but its proximity to the Imperial court, gave rise to its importance. The Council of Constantinople in 381 modified the situation somewhat by placing Constantinople second in honor, above Alexandria and Antioch, stating in Canon III, that "the bishop of Constantinople... shall have the prerogative of honor after the bishop of Rome; because Constantinople is New Rome". In the early 5th century, this status was challenged by the bishops of Alexandria, but the Council of Chalcedon confirmed in Canon XXVIII:
In making their case, the council fathers argued that tradition had accorded "honor" to the see of older Rome because it was the first imperial city. Accordingly, "moved by the same purposes" the fathers "apportioned equal prerogatives to the most holy see of new Rome" because "the city which is honored by the imperial power and senate and enjoying privileges equaling older imperial Rome should also be elevated to her level in ecclesiastical affairs and take second place after her". The framework for allocating ecclesiastical authority advocated by the council fathers mirrored the allocation of imperial authority in the later period of the Roman Empire. The Eastern position could be characterized as being political in nature, as opposed to a doctrinal view. In practice, all Christians East and West addressed the papacy as the See of Peter and Paul or the Apostolic See rather than the See of the Imperial Capital. Rome understands this to indicate that its precedence has always come from its direct lineage from the apostles Peter and Paul rather than its association with Imperial authority.
After the passage of the Canon 28, Rome filed a protest against the reduction of honor given to Antioch and Alexandria. However, fearing that withholding Rome's approval would be interpreted as a rejection of the entire council, in 453 the pope confirmed the council's canons with a protest against the 28th.
Consequences of the council.
The near-immediate result of the council was a major schism. The bishops that were uneasy with the language of Pope Leo's Tome repudiated the council, saying that the acceptance of two "physes" was tantamount to Nestorianism. Dioscorus, the Patriarch of Alexandria, advocated miaphysitism and had dominated the Council of Ephesus. Churches that rejected Chalcedon in favor of Ephesus broke off from the rest of the Church in a schism, the most significant among these being the Church of Alexandria, today known as the Coptic Orthodox Church of Alexandria.
Justinian I attempted to bring those monks who still rejected the decision of the Council of Chalcedon into communion with the greater church. The exact time of this event is unknown, but it is believed to have been between 535 and 548. St Abraham of Farshut was summoned to Constantinople and he chose to bring with him four monks. Upon arrival, Justinian summoned them and informed them that they would either accept the decision of the Council or lose their positions. Abraham refused to entertain the idea. Theodora tried to persuade Justinian to change his mind, seemingly to no avail. Abraham himself stated in a letter to his monks that he preferred to remain in exile rather than subscribe to a faith contrary to that of Athanasius. They were not alone, and the non-Chalcedon churches compose Oriental Orthodoxy, with the Church of Alexandria as their spiritual leader. Only in recent years has a degree of rapprochement between Chalcedonian Christians and the Oriental Orthodox been seen.
Liturgical Commemorations.
The Eastern Orthodox Church commemorates the "Holy Fathers of the 4th Ecumenical Council, who assembled in Chalcedon" on the Sunday on or after July 13;
For the both of the above complete propers have been composed and are found in the Menaion.
For the former "The Office of the 630 Holy and God-bearing Fathers of the 4th ... Summoned against the Monophysites Eftyches and Dioskoros ..." was composed in the middle of the 14th century by Patriarch Philotheus I of Constantinople. This contains numerous hymns exposing the council's teaching, commemorating its leaders whom it praises and whose prayers it implores, and naming its opponents pejoratively. "e.g.", "Come let us clearly reject the errors of ... but praise in divine songs the fourth council of pious fathers."
For the latter the propers are titled "We Commemorate Six Holy Ecumenical Councils". This repeatedly damns those anathematized by the councils with such rhetoric as "Christ-smashing deception enslaved Nestorius" and "mindless Arius and ... is tormented in the fires of Gehenna ..." while the fathers of the councils are praised and the dogmas of the councils are expounded in the hymns therein.
Also, in some places, there is another commemoration of the council on May 22.

</doc>
<doc id="6963" url="http://en.wikipedia.org/wiki?curid=6963" title="Canadian football">
Canadian football

Canadian football is a form of gridiron football played in Canada in which two teams of 12 players each compete for territorial control of a field of play long and wide attempting to advance a pointed prolate spheroid ball into the opposing team's scoring area (end zone). In Canada, the term football usually refers to Canadian football and American football collectively, or either sport specifically, depending on the context. The two sports have shared origins and are closely related but have significant differences. In particular, Canadian football has 12 players on the field per team rather than 11; the field is roughly 10 yards wider, and 10 yards longer between end zones that are themselves 10 yards deeper; and a team has only three downs to gain 10 yards, which results in less offensive rushing than in the American game. In the Canadian game all players on the defending team (the one which does not have possession of the ball at the start of the down) must be at least 1 yard from the line of scrimmage when the play begins. (The American game has a similar "neutral zone" but it is only the width of the football.)
Rugby football in Canada originated in the early 1860s, and over time, the unique game known as Canadian football developed. Both the Canadian Football League (CFL), the sport's top professional league, and Football Canada, the governing body for amateur play, trace their roots to 1880 and the founding of the Canadian Rugby Football Union. Currently active teams such as the Toronto Argonauts and Hamilton Tiger-Cats have similar longevity. The CFL is the most popular and only major professional Canadian football league. Its championship game, the Grey Cup, is the country's single largest sporting event, attracting a broad television audience (in 2009, about 40% of Canada's population watched part of the game). Canadian football is also played at the high school, junior, collegiate, and semi-professional levels: the Canadian Junior Football League, formed May 8, 1974, and Quebec Junior Football League are leagues for players aged 18–22, many post-secondary institutions compete in Canadian Interuniversity Sport for the Vanier Cup, and senior leagues such as the Alberta Football League have grown in popularity in recent years. Great achievements in Canadian football are enshrined in the Canadian Football Hall of Fame.
Other organizations across Canada perform senior league Canadian football during the summer.
History.
The first documented football match was a practice game played on November 9, 1861, at University College, University of Toronto (approximately 400 yards west of Queen's Park). One of the participants in the game involving University of Toronto students was (Sir) William Mulock, later Chancellor of the school. A football club was formed at the university soon afterward, although its rules of play at this stage are unclear.
The first written account of a game played was on October 15, 1862, on the Montreal Cricket Grounds. It was between the First Battalion Grenadier Guards and the Second Battalion Scots Fusilier Guards resulting in a win by the Grenadier Guards 3 goals, 2 rouges to nothing. In 1864, at Trinity College, Toronto, F. Barlow Cumberland, Frederick A. Bethune, and Christopher Gwynn, one of the founders of Milton, Massachusetts, devised rules based on rugby football. The game gradually gained a following, with the Hamilton Football Club formed on November 3, 1869, (the oldest football club in Canada). Montreal formed a team April 8, 1872, Toronto was formed on October 4, 1873, and the Ottawa FBC on September 20, 1876.
This rugby-football soon became popular at Montreal's McGill University. McGill challenged Harvard University to a game, in 1874 using a hybrid game of English rugby devised by the University of McGill.
The first attempt to establish a proper governing body and adopted the current set of Rugby rules was the Foot Ball Association of Canada, organized on March 24, 1873 followed by the Canadian Rugby Football Union (CRFU) founded June 12, 1880, which included teams from Ontario and Quebec. Later both the Ontario and Quebec Rugby Football Union (ORFU and QRFU) were formed (January 1883), and then the Interprovincial (1907) and Western Interprovincial Football Union (1936) (IRFU and WIFU). The CRFU reorganized into an umbrella organization forming the Canadian Rugby Union (CRU) in 1891. The original forerunners to the current Canadian Football League, was established in 1956 when the IRFU and WIFU formed an umbrella organization, The Canadian Football Council (CFC). And then in 1958 the CFC left The CRFU to become The CFL.
The Burnside rules closely resembling American Football that were incorporated in 1903 by The ORFU, was an effort to distinguish it from a more rugby-oriented game. The Burnside Rules had teams reduced to 12 men per side, introduced the Snap-Back system, required the offensive team to gain 10 yards on three downs, throwing out the Throw-In from the sidelines, allowed only six men on the line, stated that all Goals by Kicking were to be worth two points and the opposition was to line up 10 yards from the defenders on all Kicks. The Rules were an attempt to standardize the rules throughout the country. The CIRFU, QRFU and CRU refused to adopt the new Rules at first. In general, the evolution of Canadian Football followed its own path rather than that of American football. Forward passes were not allowed in the Canadian game until 1929, and touchdowns, which had been five points, were increased to six points in 1956.
The Grey Cup was established in 1909 after being donated by Lord Earl Grey, The Governor General of Canada as the championship of teams under the CRU for the Rugby Football Championship of Canada. Initially an amateur competition, it eventually became dominated by professional teams in the 1940s and early 1950s. The Ontario Rugby Football Union, the last amateur organization to compete for the trophy, withdrew from competition in 1954. The move ushered in the modern era of Canadian professional football.
Canadian football has mostly been contained to Canada, with the United States being the only other country to have hosted a high-level Canadian football game. The CFL's controversial "South Division" as it would come to be officially known attempted to put CFL teams in the United States playing under Canadian rules between 1992 and 1995. The move was mostly a failure, although the Baltimore Stallions would be an on-field off-field success became the only U.S.-based team to win the Grey Cup during this era, to only be pushed out by the inability to get a stadium built and the NFL awarding Baltimore a team.
As of 2013, Newfoundland and Labrador is the only province that has neither organized Canadian football at the college, professional or amateur level, nor has hosted a CFL or college game. Prince Edward Island, the smallest of the provinces, has also never hosted a CFL game.
League play.
Canadian football is played at several levels in Canada; the top league is the professional nine-team Canadian Football League (CFL). The CFL regular season begins in June, and playoffs for the Grey Cup are completed by mid-November. In cities with outdoor stadiums such as Calgary, Edmonton, Winnipeg, Montreal, Hamilton, and Regina, low temperatures and icy field conditions can seriously affect the outcome of a game.
Amateur football is governed by Football Canada. At the university level, 26 teams play in four conferences under the auspices of Canadian Interuniversity Sport; the CIS champion is awarded the Vanier Cup. Junior football is played by many after high school before joining the university ranks. There are 20 junior teams in three divisions in the Canadian Junior Football League competing for the Canadian Bowl. The Quebec Junior Football League includes teams from Ontario and Quebec who battle for the Manson Cup.
Semi-professional leagues have grown in popularity in recent years, with the Alberta Football League becoming especially popular. The Northern Football Conference formed in Ontario in 1954 has also surged in popularity as College players that do not continue to or get drafted to a professional team but still want to continue playing football. The Ontario champion plays against the Alberta champion for the "National Championship". The Canadian Major Football League is the governing body for the semi-professional game.
Women's football is starting to gain attention in Canada. The first Canadian women's league to begin operations was the Maritime Women's Football League in 2004. The largest women's league is the Western Women's Canadian Football League.
The field.
The Canadian football field is long and wide with end zones deep, and goal lines apart. At each goal line is a set of goalposts, which consist of two "uprights" joined by an crossbar which is above the goal line. The goalposts may be H-shaped (both posts fixed in the ground) although in the higher-calibre competitions the tuning-fork design (supported by a single curved post behind the goal line, so that each post starts above the ground) is preferred. The sides of the field are marked by white sidelines, the goal line is marked in white, and white lines are drawn laterally across the field every from the goal line. These lateral lines are called "yard lines" and often marked with the distance in yards from and an arrow pointed toward the nearest goal line. In previous decades, arrows were not used and every yard line was usually marked with the distance to the goal line, including the goal line itself which was marked with a "0"—in most stadiums today, only every second yard line from the nearest goal (i.e. those with distances divisible by 10) are marked with numbers, with the goal line sometimes being marked with a "G" for goal line and the centre line usually being marked with a "C" for "Centre line". "Hash marks" are painted in white, parallel to the yardage lines, at intervals, from the sidelines. On fields that have a surrounding running track, such as Commonwealth Stadium, Molson Stadium, and many universities, the end zones are often cut off in the corners to accommodate the track. This was particularly common among U.S.-based teams during the CFL's American expansion, where few American stadiums were able to accommodate the much longer CFL field.
Until 1986, the end zones were deep, giving the field an overall length of , and a correspondingly larger cutoff could be required at the corners.
Play of the game.
Teams advance across the field through the execution of quick, distinct plays, which involve the possession of a brown, prolate spheroid ball with ends tapered to a point. The ball has two one-inch-wide white stripes.
Kickoff.
Play begins with one team place-kicking the ball from its own 35-yard line. Both teams then attempt to catch the ball. The player who recovers the ball may run while holding the ball, or lateral throw the ball to a teammate.
Stoppage of play.
Play stops when the ball carrier's knee, elbow, or any other body part aside from the feet and hands, is forced to the ground (a "tackle"); when a forward pass is not caught on the fly (during a scrimmage); when a touchdown (see below) or a field goal is scored; when the ball leaves the playing area by any means (being carried, thrown, or fumbled out of bounds); or when the ball carrier is in a standing position but can no longer move forwards (called forward progress). If no score has been made, the next play starts from "scrimmage".
Scrimmage.
Before scrimmage, an official places the ball at the spot it was at the stop of clock, but no nearer than 24 yards from the sideline or 1 yard from the goal line. The line parallel to the goal line passing through the ball (line from sideline to sideline for the length of the ball) is referred to as the line of scrimmage. This line is similar to "no-man's land"; players must stay on their respective sides of this line until the play has begun again. For a scrimmage to be valid the team in possession of the football must have seven players, excluding the quarterback, within one yard of the line of scrimmage. The defending team must stay a yard or more back from the line of scrimmage.
On the field at the beginning of a play are two teams of 12 (unlike 11 in American football). The team in possession of the ball is the offence and the team defending is referred to as the defence. Play begins with a backwards pass through the legs (the snap) by a member of the offensive team, to the quarterback or punter. If the quarterback or punter receives the ball, he may then do any of the following:
Each play constitutes a "down". The offence must advance the ball at least ten yards towards the opponents' goal line within three downs or forfeit the ball to their opponents. Once ten yards have been gained the offence gains a new set of three downs (rather than the four downs given in American football). Downs do not accumulate. If the offensive team completes 10 yards on their first play, they lose the other two downs and are granted another set of three. If a team fails to gain ten yards in two downs they usually punt the ball on third down or try to kick a field goal (see below), depending on their position on the field. The team may, however use its third down in an attempt to advance the ball and gain a cumulative 10 yards.
Change in possession.
The ball changes possession in the following instances:
Rules of contact.
There are many rules to contact in this type of football. First, the only player on the field who may be legally tackled is the player currently in possession of the football (the ball carrier). Second, a receiver, that is to say, an offensive player sent down the field to receive a pass, may not be interfered with (have his motion impeded, be blocked, etc.) unless he is within one yard of the line of scrimmage (instead of in American football). Any player may block another player's passage, so long as he does not hold or trip the player he intends to block. The kicker may not be contacted after the kick but before his kicking leg returns to the ground (this rule is not enforced upon a player who has blocked a kick), and the quarterback, having already thrown the ball, may not be hit or tackled.
Infractions and penalties.
Infractions of the rules are punished with "penalties", typically a loss of yardage of 5, 10 or 15 yards against the penalized team. Minor violations such as "offside" (a player from either side encroaching into scrimmage zone before the play starts) are penalized five yards, more serious penalties (such as holding) are penalized 10 yards, and severe violations of the rules (such as face-masking) are typically penalized 15 yards. Depending on the penalty, the penalty yardage may be assessed from the original line of scrimmage, from where the violation occurred (for example, for a pass interference infraction), or from where the ball ended after the play. Penalties on the offence may, or may not, result in a loss of down; penalties on the defence may result in a first down being automatically awarded to the offence. For particularly severe conduct, the game official(s) may eject players (ejected players may be substituted for), or in exceptional cases, declare the game over and award victory to one side or the other. Penalties do not affect the yard line which the offence must reach to gain a first down (unless the penalty results in a first down being awarded); if a penalty against the defence results in the first down yardage being attained, then the offence is awarded a first down.
Penalties may occur before a play starts (such as offside), during the play (such as holding), or in a dead-ball situation (such as unsportsmanlike conduct).
Penalties never result in a score for the offence. For example, a point-of-foul infraction committed by the defence in their end zone is not ruled a touchdown, but instead advances the ball to the one-yard line with an automatic first down. For a distance penalty, if the yardage is greater than half the distance to the goal line, then the ball is advanced half the distance to the goal line, though only up to the one-yard line (unlike American football, in Canadian football no scrimmage may start inside either one-yard line). If the original penalty yardage would have resulted in a first down or moving the ball past the goal line, a first down is awarded.
In most cases, the non-penalized team will have the option of "declining" the penalty; in which case the results of the previous play stand as if the penalty had not been called. One notable exception to this rule is if the kicking team on a 3rd down punt play is penalized before the kick occurs: the receiving team may not decline the penalty and take over on downs. After the kick is made, change of possession occurs and subsequent penalties are assessed against either the spot where the ball is caught, or the runback.
Kicking.
Canadian football distinguishes four ways of kicking the ball:
On any kicking play, all onside players (the kicker, and teammates behind the kicker at the time of the kick) may recover and advance the ball. Players on the kicking team who are not onside may not approach within five yards of the ball until it has been touched by the receiving team, or by an onside teammate.
Scoring.
The methods of scoring are:
Resumption of play.
Resumption of play following a score is conducted under procedures which vary with the type of score.
Game timing.
The game consists of two 30-minute halves, each of which is divided into two 15-minute quarters. The clock counts down from 15:00 in each quarter. Timing rules change when there are three minutes remaining in a half.
A short break interval of 2 minutes occurs after the end of each quarter (a longer break of 15 minutes at halftime), and the two teams then change goals.
In the first 27 minutes of a half, the clock stops when:
The clock starts again when the referee determines the ball is ready for scrimmage, except for team time-outs (where the clock starts at the snap), after a time count foul (at the snap) and kickoffs (where the clock starts not at the kick but when the ball is first touched after the kick).
In the last three minutes of a half, the clock stops whenever the ball becomes dead. On kickoffs, the clock starts when the ball is first touched after the kick. On scrimmages, when it starts depends on what ended the previous play. The clock starts when the ball is ready for scrimmage except that it starts on the snap when on the previous play
During the last three minutes of a half, the penalty for failure to place the ball in play within the 20-second play clock, known as "time count" (this foul is known as "delay of game" in American football), is dramatically different from during the first 27 minutes. Instead of the penalty being 5 yards with the down repeated, the base penalty (except during convert attempts) becomes loss of down on first or second down, and 10 yards on third down with the down repeated. In addition, if the referee deems repeated time count violations on third down to be deliberate, he has the right to give possession to the defensive team.
The clock does not run during convert attempts in the last three minutes of a half. If the 15 minutes of a quarter expire while the ball is live, the quarter is extended until the ball becomes dead. If a quarter's time expires while the ball is dead, the quarter is extended for one more scrimmage. A quarter cannot end while a penalty is pending: after the penalty yardage is applied, the quarter is extended one scrimmage. Note that the non-penalized team has the option to "decline" any penalty it considers disadvantageous, so a losing team cannot indefinitely prolong a game by repeatedly committing infractions.
Overtime.
In the CFL, if the game is tied at the end of regulation play, then each team is given an equal number of chances to break the tie. A coin toss is held to determine which team will take possession first; the first team scrimmages the ball at the opponent's 35-yard line and advances through a series of downs until it scores or loses possession. If the team scores a touchdown, starting with the 2010 season, it is required to attempt a 2-point conversion.
The other team then scrimmages the ball at the same 35-yard line and has the same opportunity to score. After the teams have completed their possessions, if one team is ahead, then it is declared the winner; otherwise, the two teams each get another chance to score, scrimmaging from the other 35-yard line. After this second round, if there is still no winner, during the regular season the game ends as a tie. In a playoff or championship game, the teams continue to attempt to score from alternating 35-yard lines, until one team is leading after both have had an equal number of possessions.
In Canadian Interuniversity Sport football, for the Uteck Bowl, Mitchell Bowl, and Vanier Cup, the same overtime procedure is followed until there is a winner.
Players.
Offense.
The offensive positions found in Canadian football have, for the most part, evolved throughout the years, and are not officially defined in the rules. However, among offensive players, the rules recognize three different types of players:
Specific offensive positions include:
Defence.
The rules do not constrain how the defence may arrange itself (other than the requirement that they must remain one yard behind the line of scrimmage until the play starts).
Special teams.
"Special teams" generally refers to kicking plays, which typically involve a change in possession.

</doc>
<doc id="6966" url="http://en.wikipedia.org/wiki?curid=6966" title="Chinese calendar">
Chinese calendar

Chinese calendar may refer to any of the official and civil calendars used in China and some neighbouring countries in different periods of history; however, the phrase is generally synonymous with "Han calendar".
The official calendar in China today is the Gregorian calendar, which is a solar calendar. It is used for public and business affairs.
The civil calendar in much of China is the Han calendar, which is a lunisolar calendar. It is used for selecting the day of a wedding or funeral, for opening a venture, or a relocation. A similar calendar is used in Japan, Korea, and Vietnam for these purposes. Muslims living in Xinjiang, Ningxia and other parts of northern China use the Islamic calendar, which is a mean moon lunar calendar, as their civil calendar. The civil calendar for Tibet is the Tibetan calendar, which is a lunisolar calendar. The civil calendar for Miao is the Miao calendar, which is a solar calendar.
In China, some public holidays relate to the Gregorian calendar, such as Labor Day and National Day while others relate to the Chinese Calendar, such as Chinese New Year, Duanwu Festival, and the Mid-Autumn Festival. In specified provinces(Autonomous~) of China, some extra public holidays related to Islamic calendar or Tibetan calendar, such as Islamic New Year and the Major Festival in Ningxia and Xinjiang, Tibetan New Year and Summer Assembly in Tibet.
The Han calendar is a lunisolar calendar, which indicates both the moon phases and the solar terms. In Han calendar, a year usually begins on the second dark moon after the winter solstice but occasionally on the third dark moon after the winter solstice.
The year from January 31, 2014 to February 18, 2015 is a "Wǔnián" or "Mǎnián" (Year of the Horse).
Early Chinese calendars.
It is found on the oracle bones of the Shang Dynasty (late 2nd millennium BC), which seem to describe a lunisolar year of 12 months, with a possible intercalary 13th, or even 14th, added empirically to prevent calendar "drift". The Sexagenary cycle for recording days was already in use. Tradition holds that, in that era, the year began on the first new moon after the winter solstice.
Early Eastern Zhou texts, such as the "Spring and Autumn Annals", provide better understanding of the calendars used in the Zhou dynasty. One year usually had 12 months, which were alternately 29 and 30 days long (with an additional day added from time to time, to catch up with "drifts" between the calendar and the actual moon cycle), and intercalary months were added in an arbitrary fashion at the end of the year.
These arbitrary rules on day and month intercalation caused the calendars of each state to be slightly different, at times. Thus, texts like the Annals will often state whether the calendar they use (the calendar of Lu) is in phase with the "Royal calendar" (used by the Zhou kings).
Although tradition holds that in the Zhou, the year began on the new moon which preceded the winter solstice, the "Spring and Autumn Annals" seem to indicate that (in Lu at least) the Yin calendar (the calendar used in Shang dynasty, with years beginning on the first new moon after the winter solstice) was in use until the middle of the 7th century, and that the beginning of the year was shifted back one month around 650 BC.
By the beginning of the Warring States, progress in astronomy and mathematics allowed the creation of calculated calendars (where intercalary months and days are set by a rule, and not arbitrarily). The "sìfēn" 四分 (quarter remainder) calendar, which began about 484 BC, was the first calculated Chinese calendar, so named because it used a solar year of 365¼ days (the same as the 1st-century BC Julian Calendar of Rome), along with a 19-year (235-month) Rule Cycle "zhang" 章, known in the West as the Metonic cycle. The year began on the new moon preceding the winter solstice, and intercalary months were inserted at the end of the year.
In 256 BC, as the last Zhou king ceded his territory to Qin, a new calendar (the Qin calendar) began to be used. It followed the same principles as the Sifen calendar, except that the year began at Shíyuèshuò (十月朔, the closest new moon of the winter beginning). The Qin calendar was used during the Qin dynasty, and in the beginning of the Western Han dynasty. According to the "Han Shu" 21a, 973, for the moment of unification the Middle kingdoms had 6 different calendars: those of the mythological progenitors Yellow Emperor () and Zhuanxu (; ); of the dynasties Xia (; ), Yin (; ), and Zhou (; ), and of the Zhou Dynasty state of Lu (; ). Of those, the second was taken to substitute the rest. The Han imperial library is said to contain 82 volumes of descriptions of all those systems ("Han Shu" 30, 1765-6), now mostly lost.
The two oldest printed Chinese calendars are dated 877 and 882; they were found at the Buddhist pilgrimage site of Dunhuang; Patricia Ebrey writes that it is no surprise that some of the earliest printed items were calendars, since the Chinese found it necessary to calculate and mark which days were auspicious and which were not.
Ancient Han calendar.
Emperor Wu of the Western Han dynasty introduced reforms that have governed Han calendar ever since. His Tàichū (, "Grand Inception") calendar of 104 BC had a year with the winter solstice in the 11th month and was the first to use the system of 24 solar terms to determine intercalary months, in which calendar months (a month of 29 or 30 whole days) during which the sun does not pass a principal term (that is, remained within the same sign of the zodiac throughout) are designated as intercalary. The solar year of the Taichu calendar was defined as days and the lunar month as days. Because the sun's mean motion was used to calculate the solar terms until 1645, this intercalary month was equally likely to occur after any month of the year. The conjunction of the sun and moon (the astronomical new moon) was calculated using the mean motions of both the sun and moon.
It was realized in the early age of Han Calendar, that 19 solar years have 235 months. So, as 235=12*19+7, there are 7 intercalary months in 19 years.
When the 1 tropical year was calculated as formula_1 days, 1 synodic month was accordingly formula_2 days.
Also, 76 years = 365*76+76/4 = 27759 days, and likewise 940 months = 29*940+499 = 27759 days. 
In other words, 76 years = 940 months, meaning that 76 years is a cycle, or in other words the sun and moon both return to their original positions after 76 years.
The 19-year-cycle was used in the "Six Early Calendars" (古六历, Gǔlìulì). And a 600 year cycle with 221 intercalary months is used in the Yuánshǐ Calendar in the Liang(N) dynasty (401－439, established in Liangzhou). And then a 391 year cycle with 144 intercalary months was used in the Dàmíng Calendar from the Ninth year of Tianjian (天监九年, 510) in the Liang Dynasty (502-557, established in Jiankang). After the Délíng Calendar of the Tang Dynasty (618-907, established in Chang'an), the calendar was made with the true new moon, the cycle could no longer be used to determine the intercalary months.
However the Gregorian date may be estimated with a 19-year cycle. The error is a day, or about a month.
Name of ancient Han calendar.
The authorities give a name for each version of the Han calendar, such as: "Tàichū calendar"(太初历, the genesis calendar),"Dàmíng calendar"(大明历, the legend calendar), "Huángjí calendar"(皇极历, the ultimate calendar), "Shòushí calendar"(授时历, the time signal calendar), etc.
There're about 100 versions, so there're about 100 names for Han calendar. But, the civilians called it as "Huánglì"(皇历, the imperial calendar) generally.
Modern Han Calendar.
True sun and moon.
Though the fact of the irregularity of the lunar orbit was known in the 1st century BC, the starts of the months were calculated using the mean motions of both the sun and moon until 619, the second year of the Tang dynasty, when chronologists began to use true motions modeled using two offset opposing parabolas (with small linear and cubic components). Unfortunately, the parabolas did not meet smoothly at the mean motion, but met with a discontinuity or jump.
With the introduction of European astronomy into China via the Jesuits, the motions of both the sun and moon began to be calculated with sinusoids in the 1645 Chongzhen calendar (, Book of the Conformity of Time) of the Qing dynasty, made by the Jesuits Adam Schall and Giacomo Rho. The true motion of the sun was now used to calculate the jiéqì, which caused the intercalary month to often occur after the second through the ninth months, but rarely after the tenth through first months. A few autumn-winter periods have two or three calendar months in which the sun stays within one sign during the month (i.e. months that would normally be treated as intercalary months), interspersed with one or two calendar months in which the sun enters two signs of the zodiac during the month, something that was impossible using mean sun motion.
Standard time.
Before 1929, the traditional calendar was calculated by the Central Observatory (formerly the Imperial Observatory) in Beijing using Beijing local time at a longitude of 116°25'E . From 1929 to 1949 it was calculated by the Institute of Astronomy in Nanjing and since 1949 by the Purple Mountain Observatory outside of Nanjing using Chinese standard time at a longitude of 120°E (UTC+8). This shifted the midnight marking the beginning of each day in both the traditional and Gregorian calendars by plus 14 minutes 20 seconds. This shift meant that any dark moon which formerly occurred just before midnight Beijing local time now occurred just after midnight Chinese standard time, causing the first day of a lunar month to occur one day later. However, unlike the official tables, most public calendars relied on the old "Wannian Shu" (Long-term (lit. "10,000-year") Calendar; simplified Chinese: 万年书; traditional Chinese: 萬年書) last published in 1910 using Beijing time until they were forced to adopt the official traditional calendar using Chinese standard time when the two disagreed. In 1953 public calendars placed the dark moon and the first day of a lunar month on August 9, whereas the official traditional calendar placed it on August 10, which caused public calendars in most of the People's Republic of China to use the official tables and standard time after 1953. In 1978 the dates were respectively September 2 and 3, causing public calendars in the Hong Kong and Canton areas to do the same after 1978. In 1989 the dates were August 1 and 2, which caused Taiwan to do the same after 1989.
Name of modern Han Calendar.
The first version of Modern Han calendar is called as "Shíxiàn Calendar"(时宪历, the time constitution), which is issued at the second year of "Shùnzhì"(顺治二年, 1645). But, authority called it as "Hànlì"(汉历, the calendar of Han), when they issue a document for general use, such as "Imperial Hànlì collection by Kāngxī"(《康熙御制汉历大全》)
After 1912, the Han calendar became unofficial calendar. So no authority gave a name for it. People called Han calendar as "Jìulì"(旧历, the former calendar), "Lǎolì"(老历, the traditional calendar), "Yīnlì"(阴历, the lunar calendar), etc.
In the public media, the Han calendar is always called as "Nónglì" (农历, the rural calendar).
In addition, some people appeal to called it as "Xiàlì"(夏历, the calendar of Xià), for it follows the "Xià"'s year beginning.
Notes:
"Xià"'s year beginning, also called as civil year beginning, is the nearest dark moon to the vernal beginning.
"Yīn"'s year beginning, also called as earthly year beginning, is the first dark moon after the winter solstice.
"Zhōu"'s year beginning, also called as heavenly year beginning, is the last dark moon before the winter solstice.
Structure of Han calendar.
Day ("Rì", 日).
A day in the Chinese calendar runs from midnight to midnight, as in the Gregorian calendar. Currently, midnight is based on Chinese Standard Time, the mean solar time at longitude 120° east (equivalent to UTC+08).
Subdivisions of a day.
In modern Chinese, the day is divided according to the Western hour-minute-second system, but the older standards are still used in some instances.
"shí-kè" system is a sundial-clock's system. In this system, a day is divided into 12 "shí" (时/時, dual hour). The "shí" are named according to the Earthly Branches.
The halfway point of each "shí" is "zhèng" (正, mid-), for example, midday is called "zhèngwǔshí" (正午时/正午時, mid-"wǔshí"). The first hour of each "shí" is called as "chū" (初, ante mid-); and the second hour of each "shí" is called as "zhèng" (正, post mid-).
For the purposes of calculating the calendar, a day starts at midnight ("zhèngzǐshí", 正子时/正子時), but people tend to regard a day as starting at from dawn (during "yínshí").
A day is divided into 100 units as well. The boundaries of theses units are called "kè" (刻, scale). The units are called as "kè" (刻, centiday) too, although the terminology is ambiguous.
"Shí" is equivalent to 2 hours or 120 minutes. And "kè" (centiday) is equivalent to 14.4 minutes. So each "shí" can't be divided into several whole "kè" (centidays), although efforts had been made to redefine the "kè". Currently, the word "kè" is used to denote a quarter of an hour.
The "kè" is always joined to "shí", for example, in "Section 2, Calendar Records, History of the Yuán Dynasty"(元史·历志二)
A solar eclipse occurred at "Sānyuè" 1st, the 3rd year of "Chúnyòu"(1243). And the sun eclipsed at the "2 kè am of Sìshí"(09:22). According to the "Shòushí" calendar, the sun eclipsed at the "1 kè am of Sìshí"(09:07). According to the "Dàmíng" Calendar, the sun eclipsed at the "0 kè am of Sìshí"(09:00). The "Shòushí" calendar matched at the second level, and the "Dàmíng" Calendar matched at the third level.(淳祐三年癸卯，三月丁丑朔食，巳初二刻甚。《授时历》，食甚巳初一刻。《大明历》，食甚巳初初刻。右《授时》亲，《大明》次亲。)
"Gēng - diǎn" system is a bell & drum tower's system, which is a the ancient time service. 
"Gēng", was "gǔ"(鼓,drum) at first. In pre-qin, a day was divided into 10 sections, which were name with Heavenly Stems from the dusk. The time signal was release with drum.
The time service of the 5 sections in the night was practiced by the night watchman, and the signal is changed to the gong later. The name is change to ordinal name correspondingly, such as, "Yīgēng", "Èrgēng", "Sāngēng", "Sìgēng", "Wǔgēng".
"Diǎn"(点/點, point) is bell tone time signal. There're 60 "diǎns" within a day. The time between two "diǎns" is 24 minutes. The time between two "diǎns" may be called as "diǎn"点/點, one sixtieth day). A "diǎn" is divided into 100 "fēns" (分,cents).
The bell-drum time service had been handed down till the end of "Qīng" dynasty. So, the "diǎn" (point) is always joined to "gēng" (watch). There are five "diǎn" (点/點, check points) between two night watches. The "gēng - diǎn" system is used to mark the night time always, for example, in "Section 4, Military Records, History of the Yuán Dynasty" (元史·兵志四)
The curfew rule: after "yīgēng sāndiǎn"(20:24) when the bell tone stopped, walking is forbidden; after "wǔgēng sāndiǎn" (06:00) when the bell tone rang, walking is allowed. (其夜禁之法，一更三点，钟声绝，禁人行；五更三点，钟声动，听人行。”)
Week.
Days are grouped within several kinds of weeks.
The days are grouped within a 7-days week, which is called a Luminary week ("Xīngqī/Qī-yào", 星期/七曜). The name of the weekdays are Sun-day ("Rìyào", 日曜), Moon-day ("Yuèyào", 月曜), Mars-day ("Huǒyào", 火曜), Mercury-day ("Shuǐyào", 水曜), Jupiter-day ("Mùyào", 木曜), Venus-day ("Jīnyào", 金曜), and Saturn-day ("Tǔyào", 土曜).
In modern China, the names are identified by ordinal numbers, such as: "Xīngqīyī" (星期一, First-day), "Xīngqīèr" (星期二, Second-day), "Xīngqīsān" (星期三, Third-day), "Xīngqīsì" (星期四, Fourth-day), "Xīngqīwǔ" (星期五, Fifth-day), "Xīngqīlìu" (星期六, Sixth-day). The exception is Sunday, which is known as "Xīngqīrì" (星期日, Sunday).
31 January 2013 is "Xīngqīsì" (Thursday).
Each 4 weeks are grouped within a 28-days week. the week days of a 28-days week are marked with "Èrshíbāxìu" (二十八宿值日). For example, 31 January 2014 is "Níujīnníu" (牛金牛).
The days are grouped within a 10-days week, and is called Heavenly stems. The names of the weekdays are "Jiǎrì", "Yǐrì", "Bǐngrì", "Dīngrì", "Wùrì", "Jǐrì", "Gēngrì", "Xīnrì", "Rénrì", and "Guìrì".
31 January 2013 is "Dīngrì".
Some tradition holiday is established according to Heavenly Stems week. Such as the Spring/Autumn Assembly ("Chūnshè/Qīushè", 春社/秋社) is the fifth "Wùrì" after the Vernal Begins/Autumn Begins.
The days are grouped within a 12-days week, which are called Earthly Branches. The names of the weekdays are "Zǐrì", "Chǒurì", "Yínrì", "Mǎorì", "Chénrì", "Sìrì", "Wǔrì", "Wèirì", "Shēnrì", "Yǒurì", "Xūrì", and "Hàirì".
31 January 2013 is "Yǒurì".
Some traditional holidays are established according to Earthly Branches week at first. Such as the "Shàngsì" Festival (上巳节) is the first "Sìrì" in "Sānyuè", and the "Duānwǔ" Festival (端午节) is the first "Wǔrì" in "Wǔyuè" at first. These festivals are moved to the fixed calendar later. The "Shàngsì" Festival is fixed to "Sānyuè" 3rd, and the "Duānwǔ" Festival is fixed to "Wǔyuè" 5th.
The Heavenly stems and Earthly Branches run together and, when combined, make a 60-day week which is called stem-branches week.
31 January 2013 is "Dīngyǒurì".
The earliest evidence of stem-branches week was found on oracle bones dated c. 1350 BC in the Shang Dynasty. The stem-branches week continues to this day, and can still be found on Chinese calendars today.
Although the stem-branches week cannot decide the actual date alone in historical events, it can locate the accurate date along with context and other statement about time, and the difference between versions of the calendar may be neglected. For this reason, the stem-branches week is always used to mark date in the annals. Such as:
"Chronicle of Pope Rén, History of Sung Dynasty" (宋史·仁宗本纪)
In the "Bǐngyínrì" of vernal "Zhēngyuè" in the first year of "Tiānshèng", which is the first day of the month, changed the era name; ...(天聖元年春正月丙寅朔，改元；………)
In the "Wùxūrì" of "Èryuè", accepted the rule of "Gusiluo" annual tribute; in "Dīngsìrì", established the portrait of "Grand Chris" and "Grand Pope" at "Hóngqìng Palace" of the "Southern Capital" ("Suiyang"); lunched the "Monopolizing-Tea-Discount Law" at the 13 tea plantations of Huáinán (二月戊戌，許唃厮啰歲一入貢；丁巳，奉安太祖、太宗禦容於南京鴻慶宫；行淮南十三山場貼射茶法)
In the "Jiǎxūrì" of "Sānyuè", established the portrait of "Pope Zhēn" at "Yìngtiān Temple" of the "Western Capital" ("Loyang"); ...; in the "Xīnmǎorì", the "Imperial Astronomer" present the "Chóngtiān Calendar" for the approval to issue; ...(三月甲戌，奉安真宗禦容于西京應天院；……；辛卯，司天监上崇天曆； ……)
Lunar phase and lunar month ("Yuè", 月).
Lunar phase refers to the shape of the illuminated (sunlit) portion of the Moon as seen by an observer on Earth. The lunar phases corresponds to the celestial longitude difference of the moon and sun. The celestial longitude difference is cyclic variation from 0° to 360°. The principal lunar phases are new moon (0° celestial longitude difference), first quarter moon (90° celestial longitude difference), full moon (180° celestial longitude difference) and last quarter moon (270° celestial longitude difference).
In Han calendar, A lunar month is corresponds to a variation cycle (0°-360°) of the celestial longitude difference. So, the month in Han calendar starts on the day of a new moon (i.e. the astronomical new moon, not the crescent new moon) and ends the day before the next one.
The days in the month are called with two characters, such as:
In the late "Qīng" Dynasty, selected "yùnmù" (韵目, the representative character of the rhymes) are on behalf of the two date characters for telegram use. It was applied into the date in the Gregorian calendar later.
The "yùnmù" on behalf of date is used to mark the key historical events too. Such as:
"Yàndiàn" (艳电/艷電) is a telegram issued by "Chao-ming Chi-hsin Wang" ("Wang Ching-wei", VP of "Kuomintang") on December 29, 1938 and "Yàn" (艳/艷) is on behalf of 29th.
"Wénxī" Fire (文夕大火) is a conflagration on the eve of 1938-11-12 ("Evening of 1938-11-12, Chángshā was going to be occupied by the enemy, municipality burnt and fielded the city"), "Wén" (文) is on behalf of "12th" and "xī"(夕) is on behalf of "evening".
Solar year ("suìcì", 岁次/歲次) and solar month ("Xīngcì", 星次).
The solar year ("suì", 岁次/歲次) in Han calendar is the period between two winter solstices.
In the late Spring and Autumn Period (722–481 BC), the former "Sìfēn" calendar (古四分历) was established, and set the tropical year at 365.25 days, the same length as the Julian calendar which was introduced in 46 BC. The Taichu calendar (太初历) of 104 BC under Emperor Wu of Han rendered the solar year at roughly the same ( formula_3).
Many other calendars were established between then and the Yuan Dynasty (1271–1368), including those established by Li Chunfeng (602–670) and Yi Xing (683–727). In 1281, the Yuan astronomer Guo Shoujing (1233–1316) fixed the calendar at 365.2425 days, the same as the Gregorian calendar established in 1582; this calendar, the Shoushi calendar (授時曆), would be used in China for the next 363 years. Guo Shoujing established the new calendar with the aid of his own achievements in spherical trigonometry, which he derived largely from the work of Shen Kuo (1031–1095) who established trigonometry in China.
A solar year is divided into 12 solar months. The 12 solar months is decided by the 24 solar terms ("Jiéqì", 节气/節氣). 
The 24 solar terms are 24 seasonal markers, which may assist farmers to decide when to plant or harvest crops. Each successive term corresponds to a point 15° further along the ecliptic; two terms together correspond quite closely to the Western zodiac divisions.
In ancient astronomy records, the solar position is defined with 28 mansions and 12 "Xīngcì" (星次). such as: In the winter solstice, the sun stays at the 5 degree of the "Jī-mansion" (冬至日, 日在箕五度).
The 28 mansions are 28 uneven divisions of ecliptic and 12 "Xīngcì" are 12 even divisions of ecliptic.
A couple of terms are associated into a solar month. The first term called as the sectional solar term ("Jiéqì", 节气/節氣, node of climate) is the beginning of the solar term. The second term called as the primary solar term ("Zhōngqì", 中气/中氣, center of the climate) is the center of the solar month.
Usually, we use the 12 branches to mark the 12 solar months. And the period from a primary solar term to the next is associated with a Zodiac.
The 12 sectional solar terms were used by Shěn Kuò (沈括, 1031－1095) in his 12-qì calendar (12氣曆).
An astronomical year is approximately 365¼ days, a period between 12 and 13 lunar months. So, to keep the pace with the astronomical year in a long term, years with 12 lunar months and years with 13 lunar months are interleaved. Generally, in each 19 years, there're 7 years which contains 13 lunar months each and 12 years which contains 12 lunar months each.
In Han calendar, the month name are defined to keep the pace with the climatic variation generally. As the center of the climatic, the primary solar term decides the month mark(It means that the zodiac which the sun enters decides the month name). It means that the 12 lunar months fits the 12 solar months at maximum ratio.
In the other words, the month name is decided by the closest sectional primary of the first day.
For example, the table below show the information of 2014. 
From "Shíxiàn" calendar which is release at the second year of "Shùnzhì" ("Shùnzhì èrnián", 顺治二年/順治二年, 1645), the true sun position at ecliptic is used to define the solar term, and the length of the solar terms are uneven. In the winter, the length of the solar terms may be as low as 14.7 days. Thus, a month may contain two primary solar terms in winter. If there are months with 2 primary solar terms, exception occurred. There is about 0.4% of exception.
Thus, the formal month naming rules of Han calendar are:
1. The months with the Winter Solstice are the "Shíyīyuè" always.
2. The months except the intercalary month following "Shíyīyuè" are "Làyuè", "Zhēngyuè", "Èryuè", "Sānyuè", "Sìyuè", "Wǔyuè", "Lìuyuè", "Qīyuè", "Bāyuè", "Jǐuyuè", "Shíyuè".
3. If there are 11 months, there is no intercalary month.
3. If there are 12 months, the first month without a primary solar term is the intercalary month.
4. The intercalary month follows the names of the month before it.
For example, the table below shows the information of 2032-2035. The months A, M and Z are the months with winter solstice. So they are "Shíyīyuè". There are 11 months between A and M. So, there is no intercalary month in 2033. There are 12 months between M and Z, and N is the first month without primary term. So, N is the intercalary month. The other months are named accordingly.
Han calendar is worked out base on the Chinese Standard Time(UCT+8). If the calendar is checked base on the standard time of other time zone or true time of other longitude, the intercalary month may be a month with a PST. Ping-Tse Kao (高平子,"Gāo, Píngzǐ",1888-1970, one of the founders of Purple Mountain Observatory) mentioned "the calendric intercalary rule". If the calendar is worked out according to the calendric intercalary rule, the intercalary month is always a month without PST.
If the day of the primary solar term and the dark moon is the same day,
In calendric intercalary rule, if the PST preceded the dark moon, the PST belongs to the last month.
In civil intercalary rule, the PST always belongs to this month
For example: A synodic Month(month A) started at 2033/08/25 05:39, and next Synodic Month(month B) started at 2033/09/23 21:39. The time of PST is 09/23 00:51. The PST belongs to month A against B according to calendric intercalary rule.
Year ("nián", 年).
A year starts on "Zhēngyuè" 1st, and always ends on the last day of "Làyuè" (if there is an intercalary month after "Làyuè", the year will end on the last day of "Rùnyuè").
There are 12 or 13 months in a year. If there are 12 months in year, there are 353, 354 or 355 days in this year. If there are 13 months in a year, there are 383, 384 or 385 days in this year. For example, the current year starts at 2012-1-23 and ends at 2013-02-09. There are 13 months or 384 days.
The year with 13 month is a leap year. the intercalary month of the leap year between 1895 and 2101 is list as below:
In China, the age recognition for official use is base on the Gregorian calendar. But, for traditional use, it is based on Han calendar. From birthday to the end of the year, it's one year old. And, add one year old after each New Year Eve. Such as, if one's birthday is "Làyuè" 29th 2013, he is 2 years old at "Zhēngyuè" 1st 2014.
The years are named with the era name (which is a name of several years) and ordinal number generally. But, the first year of each era is called with "Yuánnián" (元年).
For the eras ante "Emperor Wǔ of Hàn Dynasty", the regnal names are regard as the era names. such as "Yǐngōng Yuánnián" (隐公元年, The first year of "Duke Yǐn of Lǔ State", 722 BC).
113 BC, "Emperor Wǔ of Hàn Dynasty" issued the first era name, "Jiànyuán" (建元), and 140 BC is marked as "Jiànyuán Yuánnián" (建元元年,140 BC).
In China, the first official era name is "Jiànyuán" (建元), the last official era name is "Xuāntǒng" (宣统/宣統).
In Japan, the first era name is "Taika" (大化), the last era name for Han calendar is "Keiō" (慶應). The first era name for the Gregorian calendar is "Meiji" (明治). Current era name is "Heisei" (平成).
After "Xuāntǒng Sānnián", the republic authority adopted the Gregorian calendar and establish the next year as the first year. The country name (Mínguǒ, 民国) is regard as the era name. The time system is used in Taiwan and some overseas Chinese societies still.
Since 1949, in mainland China, the authority abolished the era name of the ROC, and specified the Chinese of Christ Era as "Gōngyuán" (公元, Common Era). So, the "Gōngyuán" is regard as the current era name. In some Chinese society, "Xīyuán" (西元, the Western Era) takes the place of "Gōngyuán"
Continuous year numbering system.
There's not a widely recognized "epoch" for Han calendar. So, there is not a widely recognized continuous year numbering system.
Shao Yong (邵雍, 1011–1077, Courtesy name: Yáofū, Posthumous title: Kāngjié, a philosopher, cosmologist, poet and historian who greatly influenced the development of Non-Confucianism in China.) introduced a timing system in his "Huángjíjīngshì" (皇极经世, "The Ultimate which Manages the World")
In his time system, 1 "yuán" (元, round), which contains 12'9600 years, is a lifecycle of the world. Each "yuán" (round) is divided into 12 "huì" (会, assembly), which are named with Earthly Branches.
The "Hài", "Zǐ", and "Chǒu" are the "Tàigǔ" (太古, Remote Ages),which is the opening of the world (天地之分) just as the winter. The "Yín", "Mǎo", and "Chén" are the "Shànggǔ" (上古, Early Ages), which is the evolution of the world (天地之化) just as the spring. The "Sì", "Wǔ", and "Wèi" are the "Zhōnggǔ" (中古, Middle Ages), which is the climax of the world (天地之关) just as the summer. The "Shēn", "Yǒu", and "Xū" are the "Xiàgǔ" (下古, Late Ages), which is the closing of the world (天地之合) just as the autumn.
Each "huì" (assembly) is divided into 30 "yùn" (运, run), and each "yùn" (run) is divided into 12 "shì" (世, generation). So, each "shì"(generation) is equivalent to 30 years.
The "Yuán-Huì-Yùn-Shì" is corresponded with "Nián-Yuè-Rì-Shí". So the "Yuán-Huì-Yùn-Shì" is called as the "major tend" or the "numbers of the heaven", and the "Nián-Yuè-Rì-Shí" is called as the "minor tend" or the "numbers of the earth".
The "major tend" or the "numbers of the heaven" is far away from people seemingly, but the "minor tend" or the "numbers of the earth" is close to people. So the "minor tend" or the "numbers of the earth" is adapted by people for predicting destiny or fate. The numbers of "Nián-Yuè-Rì-Shí" is marked with stem-branches. So the "minor tend" of the "numbers of the earth" is show a form of "Bāzì", and the four terms are be called as Four Pillars of Destiny
For example, the eight characters of the birth of Emperor Qiánlóng is "Xīnmǎo-Dīngyǒu-Gēngwǔ-Bǐngzǐ" (辛卯、丁酉、庚午、丙子).
Shào "Huángjíjīngshì" recorded the history with stem-branches cycle from the first year of the 180th run or 2149th generation ("ARGY 6-30-1-1", 2577 BC) and marked the year with reign title from the "Jiǎchénnián" of the 2156th generation ("ARGY 6-30-8-11", 2357 BC, 1st year of "Tángyáo", 唐尧元年).
According to this timing system, 2014-1-31 is "ARG/YMD 7-12-10/1-1-1".
In the 17th century, the Jesuits tried to determine what year should be considered the epoch of Han calendar. In his "Sinicae historiae decas prima" (first published in Munich in 1658), Martino Martini (1614–1661) dated the royal ascension of Huangdi to 2697 BC, but started the Chinese calendar with the reign of Fu Xi, which he claimed started in 2952 BC. Philippe Couplet's (1623–1693) "Chronological table of Chinese monarchs" ("Tabula chronologica monarchiae sinicae"; 1686) also gave the same date for the Yellow Emperor. The Jesuits' dates provoked great interest in Europe, where they were used for comparisons with Biblical chronology. Modern Chinese chronology has generally accepted Martini's dates, except that it usually places the reign of Huangdi in 2698 BC and omits Huangdi's predecessors Fu Xi and Shennong, who are considered "too legendary to include".
Starting in 1903, radical publications started using the projected date of birth of the Yellow Emperor as the first year of Han calendar. Different newspapers and magazines proposed different dates. "Jiangsu", for example, counted 1905 as year 4396 (use an epoch of 2491 BC), whereas the "Minbao" (明报, the organ of the Tongmenghui) reckoned 1905 as 4603 (use an epoch of 2698 BC). "Liu Shipei" (劉師培; 1884–1919) claimed that the 1900 international expedition sent by eight foreign powers to suppress the Boxer Uprising entered Beijing in the 4611th year of the Yellow Emperor. Liu's calendar started with the birth of the Yellow Emperor, which was determined to be 2711 BC.
At January 2, 1912, Sun Yat-sen declared that "the Republic of China adopt the Gregorian calendar, and establish Shíyīyuè 13th 4609 of Huángdì Era as the new year's day of the first year of the Republic of China" (中華民國改用陽曆，以黄帝紀元四千六百零九年十一月十三日爲中華民國元年元旦). Sun Yat-sen's choice, which implied an epoch of 2698 BC, was adopted by many overseas Chinese communities outside Southeast Asia such as San Francisco's Chinatown. 
In the earlier 20th century, kinds of year marking system is released. Except Huángdì era, the following system are well-known,
But in any case, no reference date can be recognized as an epoch of Han calendar without the official recognition.
The frame is established at "Tàichū Yuánnián" (太初元年, 105 BC - 103 BC), and the calendars with this frame is used all the way. And, the first winter solstice of "Tàichū Yuánnián" which is a winter solstice at Jiǎzǐrì with dark moon (朔旦冬至得甲子), is a node. In the historic book, for modern Chinese, the date after then is idiomatic and the date before then is unidiomatic ("Such as: the Zhēngyuè is not always the first month in spring; the years starts at Shíyuè, etc."). So, the first winter solstice of "Tàichū Yuánnián" is a key reference date for Han calendar. It should be regarded as the epoch of Han calendar. And it's clear that it will be a neutral epoch. 
Cycle of years.
The years are grouped within a 10-year cycle which is called the 10 Celestial Stems (or called as 10 Heavenly Stems). The names of each year are: "Jiǎnián", "Yǐnián", "Bǐngnián", "Dīngnián", "Wùnián", "Jǐnián", "Gēngnián", "Xīnnián", "Rénnián" and "Guìnián".
The current year (2014-1-31~2015-2-18) is "Jiǎnián".
Each year corresponds to an element in "Wǔxíng". "Jiǎnián" and "Yǐnián" is "Mùnián" (木, Wood), "Bǐngnián" and "Dīngnián" is "Huǒnián" (火, Fire), "Wùnián" and "Jǐnián" is "Tǔnián" (土, Earth), "Gēngnián" and "Xīnnián" is "Jīnnián" (金, Metal), "Rénnián" and "Guìnián" is "Shuǐnián" (水, Water).
Therefore the current year is a "Mùnián".
The years are grouped within a 12-year cycle which is called the 12 Earthly Branches. The names of they years are: "Zǐnián", "Chǒunián", "Yínnián", "Mǎonián", "Chénnián", "Sìnián", "Wǔnián", "Wèinián", "Shēnnián", "Yǒunián", "Xūnián", and "Hàinián".
The current year is "Wǔnián".
Each cycle year is corresponds to an animal of the Chinese zodiac. "Zǐnián" to "Shǔnián" (鼠, Rat), "Chǒunián" to "Níunián" (牛, Ox), "Yínnián" to "Hǔnián" (虎, Tiger), "Mǎonián" to "Tùnián" (兔, Rabbit), "Chénnián" to "Lóngnián" (龙, Dragon), "Sìnián" to "Shénián" (蛇, Snake), "Wǔnián" to "Mǎnián" (马, Horse), "Wèinián" to "Yángnián" (羊, Goat), "Shēnnián" to "Hóunián" (猴, Monkey), "Yǒunián" to "Jīnián" (鸡, Rooster), "Xūnián" to "Gǒunián" (狗, Dog) and "Hàinián" to "Zhūnián" (猪, Pig).
The seal characters of the earthly branches show the figure of the animals. For example, "Wǔ" shows the figure of the horse face.
Therefore the current year is "Mǎnián" (Horse).
The Heavenly stems cycle and Earthly Branches cycle runs together, and become a 60-year cycle which is called the stem-branches cycle.
The current year is "Jiǎwǔnián", also called as "Mùmǎnián" (Wood Horse).
Around the Han Dynasty, the stem-branches cycle was introduced. In "Míng Dynasty" and "Qīng Dynasty", the stem-branches cycle was used along with the year mark in the Oration to "Yellow Emperor". Such as:
"Oration to Yellow Emperor at the first year of Wànlì"
"That, at the first year of Wànlì, which is Guìyǒunián, at Sìyuè started at Gēngxūrì, at 16th day which is Yǐchǒurì, the Emperor sent... Enjoy!" (万历元年，岁次癸酉，四月庚戌朔，越十六日乙丑，皇帝遣……。尚飨！)
The table right shows the stem/branch year names, correspondences to the Western (Gregorian) calendar, and other related information for the current decade. Alternatively, see this larger table of the full 60-year cycle.
Notes
1 Regard 2697 BC as 01:00.
2 Regard 2698 BC as the first year.
Holidays.
The Chinese calendar year has nine main festivals, seven determined by the lunisolar calendar, and two derived from the solar agricultural calendar. (Farmers actually used a solar calendar, and its 24 terms, to determine when to plant crops, due to the inaccuracy of the lunisolar traditional calendar. However, the traditional calendar has also come to be known as the agricultural calendar.) The two special holidays are the Qingming Festival (about 15 days after the spring equinox) and the Winter Solstice Festival, falling upon the respective solar terms, at ecliptic longitudes of 15° and 270°, respectively. As for all other calendrical calculations, the calculations use civil time in China, 
Gregorian reform.
The Gregorian calendar was adopted by the nascent Republic of China effective January 1, 1912 for official business, but the general populace continued to use the traditional calendar. The status of the Gregorian calendar was unclear between 1916 and 1921 while China was controlled by several competing warlords each supported by foreign colonial powers. From about 1921 until 1928 warlords continued to fight over northern China, but the Kuomintang or Nationalist government controlled southern China and used the Gregorian calendar. After the Kuomintang reconstituted the Republic of China on October 10, 1928, the Gregorian calendar was officially adopted, effective January 1, 1929. The People's Republic of China has continued to use the Gregorian calendar since 1949.
Relevance of the calendar today.
There have been calls for reform in recent years from experts in China, because of the increasing irrelevance of the Chinese calendar in modern life. They point to the example in Japan, where during the Meiji Restoration the nation adopted the Gregorian calendar, and simply shifted all traditional festivities onto an equivalent date. However, the Chinese calendar remains important as an element of cultural tradition, and for certain cultural activities.
Practical uses.
The original practical relevance of the lunisolar calendar for date marking has largely disappeared. First, the Gregorian calendar is much easier to compute and more in line with international standards. Its adoption for official purposes has meant that the traditional calendar is rarely used for date marking. This, in turn, means that it is more convenient to remember significant events such as birth dates by the Gregorian rather than the Chinese calendar.
Second, the 24 solar terms were important to farmers who would not be able to plan agricultural activities without foreknowledge of these terms. However, the 24 solar terms (including the solstices and equinoxes) are more predictable on the Gregorian calendar than the lunisolar calendar since they are based on the solar cycle. It is easier for the average Chinese farmer to organize their planting and harvesting with the Gregorian calendar.
However, one practical advantage of using a calendar where the months are lunar months is that the phases of the moon, and astronomical and tidal phenomena associated with them, such as spring and neap tides, fall on approximately the same day in each lunar month, and the times of high and low water and the tidal streams experienced in a certain location on a certain day of the lunar month are likely to be similar to those for the same place and lunar day in any month. For many years, therefore, mariners in East and South-East Asia have related their tidal observations to the Chinese calendar, so as to be able to provide quick, rule-of-thumb approximations of tides and tidal conditions from memory, based on the day of the Lunar month, without needing to refer to tide tables. Certain inshore passages on the China coast, for example, where there are strong tidal streams associated with spring tides, were regarded by mariners to be passable on certain days of the lunar month, and impassable on others.
Cultural issues.
The Chinese calendar remains culturally essential today. For example, most of the traditional festivals, such as Chinese New Year and the Mid-Autumn Festival, occur on new moons or full moons. The traditional Chinese calendar, as an element of traditional culture, has much cultural and nationalistic sentiment invested in it.
The calendar is still used in the more traditional Chinese households around the world to pick 'auspicious dates' for important events such as weddings, funerals, and business deals. A special calendar is used for this purpose, called "Huang Li" (), literally "Imperial Calendar", which contains auspicious activities, times, and directions for each day. The calendar follows the Gregorian dates but has the corresponding Chinese dates. Every date would have a comprehensive listing of astrological measurements and fortune elements.
Influence of Han calendar.
Other traditional East Asian calendars are very similar to if not identical to the Chinese calendar: the Korean calendar is identical; the Thai lunar calendar substitutes a big snake for the Dragon and a little snake for the Snake; the Vietnamese calendar substitutes the cat for the Rabbit in the Chinese zodiac; the Tibetan calendar differs slightly in animal names, and the traditional Japanese calendar uses a different method of calculation, resulting in disagreements between the calendars in some years.
The 12 year cycle, with the animal names translated into the vernacular, was adopted by the Göktürks (its use there is first attested 584), and spread subsequently among many if not most Turkic peoples, as well as the Mongols. A similar calendar seems to have been used by the Bulgars, as attested in the Nominalia of the Bulgarian Khans and in some other documents. The main differences between the Bulgar and the Chinese calendar are the different calculating system, the Tiger has been replaced with a wolf, and the Dragon and Monkey with an unknown animal. Also, the Bulgar calendar is a solar one.
Tibetan calendar.
A solar day is the time round the clock. In Tibetan calendar, a solar day is start at dawn, and end at the next.
A lunar month is the time between two identical moon phases (new moons or full moons). In Tibetan calendar, a lunar month is start at a full month, and end at the next.
A lunar month is divided into 30 lunar days. Each lunar day corresponds to a 12° variance of celestial longitude difference of the moon and sun.
A lunar month is divided into two half, too. The first half is called as the waning half, and the second half is called as the waxing half.
The 15 phases in the waning half is the 16th to 30th phase, and the 15 phases in the waxing half is the first to 15th phase. So, the "i" th phase corresponds to "i×12°" celestial longitude difference of the moon and sun.
The phase number decides the date. If there're two phases within a solar day, the number of the first phase number decides the date; and if there's no phase number within a solar day, the following phase number decides the date. For example,
The difference of the date rules between Tibetan and Chinese calendar is moon phase against solar day. And the difference leads the bias of date sometimes, but the bias is within 1.
A solar year is the length of time that the Sun takes to return to the same position in the cycle of seasons.
In Tibetan calendar, a solar year is divided into 12 solar months (zodiac) equally. If a lunar month entered a zodiac, the zodiac decides the month mark; if a lunar month didn't enter a zodiac, the month is an intercalary month. Such as:
The 12 solar months is corresponding to the 24 solar terms (mean solar terms) in Chinese calendar. So, the difference of the month rules between Tibetan and Chinese calendar is mean solar against true solar. And the difference leads the bias of month sequence sometimes, but the bias is within 1.
Considering the date and month rule, the bias between Tibetan and Chinese calendar is no bias, a bias of a day, a bias of a month, or a bias of a month and a day. Such as:
Miao calendar.
The Miao calendar is a solar calendar. The Miao calendar is used from ten-thousands years ago, and retired at 33rd year of "Guāngxù" (光绪三十三年, 1907). The New Year's Day in Miao calendar is the winter solstice.
A year in Miao calendar contains 12 months, which are the unfixed month (动月), the 0th month (偏月), the 1st month (正月), the 2nd month, the 3rd month, the 4th month, the 5th month, the 6th month, the 7th month, the 8th month, the 9th month, the 10th month.
The length of the 0th, 2nd, 4th, 6th, 8th, 10th month is 30 days. The length of the 1st, 3rd, 5th, 7th, 9th month is 31 days.
The length of the unfixed month is decided by the winter solstice. If the winter solstice comes after dusk, the length of the unfixed month is 31 days, otherwise the length is 30 days.
The 28 mansions and the 12 earthly branches runs together, and works out 84 mansion-branches. The 84 mansion-branches are used to count the day and year continuously, just as 60 stem-branches do.
Ancient Yi calendars.
In Yi areas, a 10-months calendar is found in the early 1980s. It's a solar calendar, which contains 10 months of 36 days, and 2/3 transition days before the winter solstice(The minor year) and summer solstice(The major year).The 36 days is named with 12 earthly branches(from tiger to ox) for 3 times.
The 10 months is named with 10 animals(Tiger, Otter, Crocodile, Boa, Pangolin, Muntjac, Bharal, Ape, Panther, and Lizard).The 10 months is divided into 5 seasons, which named with 5 elements(earth, bronze, water, wood, fire).
In Yi areas, a 18-months calendar is found in the late 1950s. It's a solar calendar, which contains 18 months of 20 days, and 2/3 transition days before the winter solstice and summer solstice.
The 18 months are named as: wind month, twitter month, sprout month, bloom month, fruit month, drought month, rainy month, freshet month, sunny month, withered month, fallen month, frost month, and celebrate month.
Chinese-Uighur calendar.
In 1258, when both North China and the Islamic world were part of the Mongol Empire, Hulagu Khan established an observatory in Maragheh for the astronomer Nasir al-Din al-Tusi at which a few Chinese astronomers were present, resulting in the Chinese-Uighur calendar that al-Tusi describes in his "Zij-i Ilkhani". The 12 year cycle, including Turkic/Mongolian translations of the animal names (known as "sanawat-e turki" سنوات ترکی,) remained in use for chronology, historiography, and bureaucratic purposes in the Persian and Turkic speaking world from Asia Minor to India and Mongolia throughout the Medieval and Early Modern periods. In Iran it remained common in agricultural records and tax assessments until a 1925 law deprecated its use.

</doc>
<doc id="6968" url="http://en.wikipedia.org/wiki?curid=6968" title="Customer relationship management">
Customer relationship management

Customer relationship management (CRM) is a system for managing a company’s interactions with current and future customers. It involves using technology to organize, automate and synchronize sales, marketing, customer service, and technical support.
Types.
Marketing and Customer Service.
Customer relationship management systems track and measure marketing campaigns over multiple networks. These systems can track customer analysis by customer clicks and sales. Places where CRM is used include call centers, social media, direct mail, data storage files, banks, and customer data queries.It helps you to find customer's profile as well.
CRM in customer contact centers.
CRM systems are customer relationship management platforms. The goal of the system is to track, record, store in databases, and then data mine the information in a way that increases customer relations (predominantly increased ARPU, and decreased churn). The CRM codifies the interactions between you and your customers so that you can maximize sales and profit using analytics and KPIs to give the users as much information on where to focus their marketing and customer service to maximize revenue and decrease idle and unproductive contact with your customers. The contact channels (now aiming to be omni-channel from multi-channel) use such operational methods as contact centers. The CRM software is installed in the contact centers, and help direct customers to the right agent or self-empowered knowledge. CRM software can also be used to identify and reward loyal customers over a period of time.
Appointments.
CRM software programs can automatically synchronize suitable appointment dates, times, and methods for customer contact. Once appointments are saved in a systems calendar, recalls the information so that it can be easily retrieved. It pulls up information on appointments and sends a represented message for action. 
CRM in B2B (Business-to-Business)market.
The modern environment requires one business to interact with another via the web. According to a Sweeney Group definition, CRM is “all the tools, technologies and procedures to manage, improve, or facilitate sales, support and related interactions with customers, prospects, and business partners throughout the enterprise”. It assumes that CRM is involved in every B2B transaction.
Despite the general notion that CRM systems were created for the customer-centric businesses, they can also be applied to B2B environments to streamline and improve customer management conditions. B2C and B2B CRM systems are not created equally and different CRM software applies to B2B and Business-to-Customer (B2C) conditions. B2B relationships usually have longer maturity times than B2C relationships. For the best level of CRM operation in a B2B environment, the software must be personalized and delivered at individual levels.
Characteristics of CRM.
Well-designed CRM includes the following characteristics:
Importance of CRM to the B2B sector.
Many of the characteristics in the B2B market suggest that CRM is a factor which influences the business. CRM has special characteristics in the B2B market.
Consider “Critical mass (software engineering)”. Due to customer relationship, a network can be established and extended. Extension causes the network not to increase benefits linearly, but in an exponential way. As new members can contact by any existing member the benefit of a network of 200 people is much more effective than one with 100. Hence, these networks can be used to increase the amount of available information for each company. This may lead to more information about a customer which can be used to make the way of handling the customer easier in the future. The history of previous sales from this customer may be a great relief. Moreover it is possible to establish technical cooperation a bigger network is more likely to provide special services. 
These services include, among others “systems integration, hosting, financial services such as payment processing, receivables management, credit analysis and logistics services”. Services of this kind encourage companies to join the B2B network by using CRM. Furthermore, B2B hubs have another advantage as they can substitute external personal if members of the network liaise. This may not only avoid extra costs for arrangement of a new contract but is also likely to accelerate the speed of this arrangement as they are in the same network and already possess information about their negotiating partner. Ultimately, special knowledge is required for B2B markets. As B2B customers are generally more rational customers than B2Cs, a person or a team with special knowledge to each customer or industry may enhance the sales in this area.
Implementing CRM to the company.
The following are general guidelines on implementing a CRM system.
CRM software.
Selecting a CRM program means finding the software that best fits the company’s needs. CRM software comes with many features and tools, and despite the fact that many CRM products offer similar feature sets, there are some unique tools in each one. Programs can be divided into categories by several criteria:
Differences between CRM for B2B (Business 2 Business) and B2C (Business 2 Customers).
B2B and B2C marketing operates differently, that is why they cannot use the same software. All the differences are focused on the approach of these two types of businesses:
B2B operations require special CRM solutions that are not the same for B2C industry:
So, all the B2B applications must be both personalized and be able to establish channels of support communication for customers
SaaS CRM Software.
These are software created “on-demand” which are available via Internet and do not require install and support. Businesses using the software do not purchase the software, and typically pay a subscription fee to the software vendor. 
Workbooks CRM.
This suite of Business Applications are specifically designed for small and mid-size organizations and are delivered via Software-as-a-Service, therefore removing the traditional requirements of having hardware to maintain and software to install and support.
Salesforce.
This software allows the company to automatically track all the web activity generated from marketing and automatically sets the Lead Source as Marketing.: Website.
BPMonline CRM.
Includes built-in features and process management tools to automate CRM activities, to improve campaign response, close deals, and satisfy customers.
AmoCRM.
AmoCRM's software assists the manager, sales team and sales management with full contact management, lead management, and sales pipeline reporting and analysis. For the B2B CRM needs, amoCRM's software is a user friendly, cost effective approach. It comes scalable to meet future growth needs without having to change platforms and retrain.
Firmao CRM.
Firmao features include VoIP switchboard integration, extensive customization possibilites, mobile applications and cloud data storage space. Users can create own templates of documents such as invoice, offer as well as custom data report. 
Small business.
For small businesses a CRM system may simply consist of a contact manager system which integrates emails, documents, jobs, faxes, and scheduling for individual accounts.
CRM systems available for specific markets (legal, finance) frequently focus on event management and relationship tracking as opposed to financial return on investment (ROI).
Social media.
CRM often makes use of social media to build up customer relationships. Some CRM systems integrate social media sites like Twitter, LinkedIn and Facebook to track and communicate with customers sharing their opinions and experiences with a company, products and services.
Enterprise Feedback Management software platforms such as Confirmit, Medallia, and Satmetrix combine internal survey data with trends identified through social media to allow businesses to make more accurate decisions on which products to supply.
Non-profit and membership-based.
Systems for non-profit and also membership-based organizations help track constituents, fund-raising, Sponsors demographics, membership levels, membership directories, volunteering and communication with individuals.
Customer-centric relationship management (CCRM).
CCRM is a style of customer relationship management that focuses on customer preferences instead of customer leverage. 
This is a nascent sub-discipline of traditional customer relationship management; to take advantage of changes in communications technology.
Customer centric organizations help customers make better decisions and it also helps drive profitability. CCRM adds value by engaging customers in individual, interactive relationships.
Customer-centricity differs from "client-centricity" in that the latter refers almost exclusively to business-to-business models rather than customer-facing firms.
Features of CCRM.
Customer-centric relationship management is used in marketing, customer service and sales, including:
Accenture and Emerald Insight are now beginning to focus on CCRM as a discipline, with studies appearing on Mendeley.
Adoption issues.
In 2003, a Gartner report estimated that more than $2 billion had been spent on software that was not being used. According to "CSO Insights", less than 40 percent of 1,275 participating companies had end-user adoption rates above 90 percent. Many corporations only use CRM systems on a partial or fragmented basis.
In a 2007 survey from the UK, four-fifths of senior executives reported that their biggest challenge is getting their staff to use the systems they had installed. 43 percent of respondents said they use less than half the functionality of their existing system.. Recently, it is found in a study that market research regarding consumers preference may increase the adoption of CRM among the developing countries' consumers.
CRM Paradox.
The CRM Paradox also referred to as the "Dark side of CRM".
Favouritism and differential treatment of customers may cause perceptions of unfairness which results in buyers opting out of relationships, 
spreading negative information, or engaging in misbehaviour that may damage the firm. 
CRM fundamentally involves treating customers differently based on the assumption that customers are different and have different needs. 
This may cause dissatisfaction, issues of distrust and unfair practices due to the perceived inequality. A customer shows trust to bond in a relationship with a firm when they know that the firm is acting fair in creating a win-win situation. However, will customers trust that firms will be fair in splitting the value creation pie in the first place? A good example: Amazon.com’s test use of dynamic pricing (different prices for different customers) was a public relations nightmare for the company.
Market leaders.
The CRM market grew by 13.7 percent in 2013, three times the average of all enterprise software categories. The following table lists the top vendors in 2006–2008 and 2013 (figures in millions of US dollars) published in Gartner studies.
Trends.
Many CRM vendors offer subscription-based web tools (cloud computing) and software as a service (SaaS). Some CRM systems are equipped with mobile capabilities, making information accessible to remote sales staff. Salesforce.com was the first company to provide enterprise applications through a web browser, and has maintained its leadership position. Traditional providers have recently moved into the cloud-based market via acquisitions of smaller providers: Oracle purchased RightNow in October 2011 and SAP acquired SuccessFactors in December 2011.
The era of the "social customer" refers to the use of social media (Twitter, Facebook, LinkedIn, Google Plus, Pinterest, Instagram, Yelp, customer reviews in Amazon, etc.) by customers. CR philosophy and strategy has shifted to encompass social networks and user communities.
Sales forces also play an important role in CRM, as maximizing sales effectiveness and increasing sales productivity is a driving force behind the adoption of CRM. Empowering sales managers was listed as one of the top 5 CRM trends in 2013.
Another related development is vendor relationship management (VRM), which provide tools and services that allow customers to manage their individual relationship with vendors. VRM development has grown out of efforts by ProjectVRM at Harvard's Berkman Center for Internet & Society and Identity Commons' Internet Identity Workshops, as well as by a growing number of startups and established companies. VRM was the subject of a cover story in the May 2010 issue of "CRM" Magazine.
In 2001, Doug Laney developed the concept and coined the term 'Extended Relationship Management' (XRM). Laney defines XRM as extending CRM disciplines to secondary allies such as the government, press and industry consortia.
CRM futurist Dennison DeGregor describes a shift from 'push CRM' toward a 'customer transparency' (CT) model, due to the increased proliferation of channels, devices, and social media.
Capterra, Inc. ranked the Top CRM Software Solutions in 2013 based on total number of customers, total number of users and social presence.

</doc>
<doc id="6970" url="http://en.wikipedia.org/wiki?curid=6970" title="Chuck-a-luck">
Chuck-a-luck

Chuck-a-luck, also known as birdcage, is a game of chance played with three dice. It is derived from grand hazard, and both can be considered a variant of sic bo, a popular casino game, although chuck-a-luck is more of a carnival game than a true casino game. The game is sometimes used as a fundraiser for charity.
Rules.
Chuck-a-luck is played with three standard dice that are kept in a device shaped somewhat like an hourglass that resembles a wire-frame bird cage and that pivots about its centre. The dealer rotates the cage end over end, with the dice landing on the bottom.
Wagers are placed based on possible combinations that can appear on the three dice. The possible wagers are usually fewer than the wagers that are possible in sic bo and, in that sense, chuck-a-luck can be considered to be a simpler game.
The wagers, and their associated odds, that are typically available are set out in the table below.
House advantage or edge.
Chuck-a-luck is a game of chance. That is, on average, even if the dice are not loaded, the players are expected to lose more than they win. The casino's advantage (house advantage or house edge) is greater than most other casino games and can be much greater.
For example, there are 216 (6 × 6 × 6) possible outcomes for a single throw of three dice. For a specific number:
At odds of 1 to 1, 2 to 1 and 10 to 1 respectively for each of these types of outcome, the expected loss as a percentage of the stake wagered is:
1 - ((75/216) × 2 + (15/216) × 3 + (1/216) × 11) = 4.6%
At worse odds of 1 to 1, 2 to 1 and 3 to 1, the expected loss as a percentage of the stake wagered is:
1 - ((75/216) × 2 + (15/216) × 3 + (1/216) × 4) = 7.9%
It should be noted that if the odds are adjusted to 1 to 1, 3 to 1 and 5 to 1 respectively, the expected loss as a percentage is:
1 - ((75/216) × 2 + (15/216) × 4 + (1/216) × 6) = 0%
However, commercially-organised gambling games always have a house advantage which acts as a fee for the privilege of being allowed to play the game, so the last scenario does not represent real practice.
Notes and references.
There is a reference to chuck-a-luck in the Abbott and Costello film "Hold That Ghost".
In Fritz Lang's 1952 film, "Rancho Notorious", chuck-a-luck is the name of the ranch run by Altar Keane (played by Marlene Dietrich) where outlaws hide from the law. Chuck-a-luck is featured in the lyrics to the theme song and in some plot points.
The game is played by Lazar in the James Bond movie "The Man with the Golden Gun".
The game is played by Freddie Rumsen in "Mad Men Season 2 Episode 9: Six-Month Leave".

</doc>
<doc id="6972" url="http://en.wikipedia.org/wiki?curid=6972" title="Chipmunk">
Chipmunk

Chipmunks are small, striped rodents of the family Sciuridae. All species of chipmunks are found in North America, with the exception of the Siberian chipmunk, which is found primarily in Asia.
Taxonomy and systematics.
Chipmunks may be classified either as a single genus, "Tamias" (), or as three genera: "Tamias", which includes the eastern chipmunk; "Eutamias", which includes the Siberian chipmunk; and "Neotamias", which includes the 23 remaining, mostly western, species. These classifications are arbitrary, and most taxonomies over the twentieth century have placed the chipmunks in a single genus. However, studies of mitochondrial DNA show that the divergence between each of the three chipmunk groups is comparable to the genetic dissimilarity between "Marmota" and "Spermophilus".
The genus name "Tamias" is Greek for "treasurer", "steward", or "housekeeper", which is a reference to the animals' role in plant dispersal through their habit of collecting and storing food for winter use.
The common name originally may have been spelled "chitmunk," from the native Odawa (Ottawa) word "jidmoonh", meaning "red squirrel" ("cf." Ojibwe, "ajidamoo"). The earliest form cited in the "Oxford English Dictionary" (from 1842) is "chipmonk," however, "chipmunk" appears in several books from the 1820s and 1830s. Other early forms include "chipmuck" and "chipminck," and in the 1830s they were also referred to as "chip squirrels;" probably in reference to the sound they make. In the mid-1800s, John James Audubon and his sons, included a lithograph of the chipmunk in their "Viviparous Quadrupeds of North America", calling it the "Chipping Squirrel Hackee." Chipmunks have also been referred to as "striped squirrels," "chippers," "munks," "timber tigers," or "ground squirrels" (although the name "ground squirrel" usually refers to other squirrels, such as those of the genus "Spermophilus").
Diet.
Chipmunks have an omnivorous diet primarily consisting of seeds, nuts and other fruits, and buds. They also commonly eat grass, shoots, and many other forms of plant matter, as well as fungi, insects and other arthropods, small frogs, worms, and bird eggs. Around humans, chipmunks can eat cultivated grains and vegetables, and other plants from farms and gardens, so they are sometimes considered pests. Chipmunks mostly forage on the ground, but they climb trees to obtain nuts such as hazelnuts and acorns. At the beginning of autumn, many species of chipmunk begin to stockpile nonperishable foods for winter. They mostly cache their foods in a larder in their burrows and remain in their nests until spring, unlike some other species, which make multiple small caches of food. Cheek pouches allow chipmunks to carry multiple food items to their burrows for either storage or consumption.
Ecology and life history.
Eastern chipmunks mate in early spring and again in early summer, producing litters of four or five young twice each year. Western chipmunks breed only once a year. The young emerge from the burrow after about six weeks and strike out on their own within the next two weeks.
These small mammals fulfill several important functions in forest ecosystems. Their activities harvesting and hoarding tree seeds play a crucial role in seedling establishment. They consume many different kinds of fungi, including those involved in symbiotic mycorrhizal associations with trees, and are an important vector for dispersal of the spores of subterranean sporocarps (truffles) which have co-evolved with these and other mycophagous mammals and thus lost the ability to disperse their spores through the air.
Chipmunks construct expansive burrows which can be more than 3.5 m in length with several well-concealed entrances. The sleeping quarters are kept extremely clean as shells and feces are stored in refuse tunnels.
The eastern chipmunk hibernates in the winter, while western chipmunks do not, relying on the stores in their burrows.
Chipmunks play an important role as prey for various predatory mammals and birds, but are also opportunistic predators themselves, particularly with regard to bird eggs and nestlings. In Oregon, mountain bluebirds ("Siala currucoides") have been observed energetically mobbing chipmunks that they see near their nest trees.
Chipmunks typically live about three years, although have been observed living to nine years in captivity.
Chipmunks in captivity are said to sleep for an average of about 15 hours a day. It is thought that mammals which can sleep in hiding, such as rodents and bats, tend to sleep longer than those that must remain on alert.
Species list.
Subgenus "Eutamias"
Subgenus "Tamias"
Subgenus "Neotamias"
Extinct:

</doc>
<doc id="6974" url="http://en.wikipedia.org/wiki?curid=6974" title="Computer music">
Computer music

Computer music is the applications of computing technology in music composition. It includes the theory and application of new and existing technologies and basic aspects of music, such as sound synthesis, digital signal processing, sound design, sonic diffusion, acoustics, and psychoacoustics. The field of computer music can trace its roots back to the origins of electronic music, and the very first experiments and innovations with electronic instruments at the turn of the 20th century.
More recently, with the advent of personal computing, and the growth of home recording, the term computer music is sometimes used to describe music that has been created using computing technology.
History.
Much of the work on computer music has drawn on the relationship between music theory and mathematics.
The world's first computer to play music was CSIRAC which was designed and built by Trevor Pearcey and Maston Beard. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the "Colonel Bogey March" of which no known recordings exist.
However, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice which is current computer-music practice.
The oldest known recordings of computer generated music were played by the Ferranti Mark 1 computer, a commercial version of the Baby Machine from the University of Manchester in the autumn of 1951. The music program was written by Christopher Strachey. During a session recorded by the BBC, the machine managed to work its way through "Baa Baa Black Sheep", "God Save the King" and part of "In the Mood".
Two further major 1950s developments were the origins of digital sound synthesis by computer, and of algorithmic composition programs beyond rote playback. Max Mathews at Bell Laboratories developed the influential MUSIC I program and its descendents, further popularising computer music through a 1963 article in "Science". Amongst other pioneers, the musical chemists Lejaren Hiller and Leonard Isaacson worked on a series of algorithmic composition experiments from 1956-9, manifested in the 1957 premiere of the "Illiac Suite" for string quartet.
In Japan, experiments in computer music date back to 1962, when Keio University professor Sekine and Toshiba engineer Hayashi experimented with the TOSBAC computer. This resulted in a piece entitled "TOSBAC Suite", influenced by the "Illiac Suite". Later Japanese computer music compositions include a piece by Kenjiro Ezaki presented during Osaka Expo '70 and "Panoramic Sonore" (1974) by music critic Akimichi Takeda. Ezaki also published an article called "Contemporary Music and Computers" in 1970. Since then, Japanese research in computer music has largely been carried out for commercial purposes in popular music, though some of the more serious Japanese musicians used large computer systems such as the "Fairlight" in the 1970s. 
Early computer-music programs typically did not run in real time. Programs would run for hours or days, on multi-million-dollar computers, to generate a few minutes of music. One way around this was to use a 'hybrid system', most notably the Roland MC-8 Microcomposer, where a microprocessor-based system controls an analog synthesizer, released in 1978. John Chowning's work on FM synthesis from the 1960s to the 1970s allowed much more efficient digital synthesis, eventually leading to the development of the affordable FM synthesis-based Yamaha DX7 digital synthesizer, released in 1983. In addition to the Yamaha DX7, the advent of inexpensive digital chips and microcomputers opened the door to real-time generation of computer music. In the 1980s, Japanese personal computers such as the NEC PC-88 came installed with FM synthesis sound chips and featured audio programming languages such as Music Macro Language (MML) and MIDI interfaces, which were most often used to produce video game music, or chiptunes. By the early 1990s, the performance of microprocessor-based computers reached the point that real-time generation of computer music using more general programs and algorithms became possible.
Interesting sounds must have a fluidity and changeability that allows them to remain fresh to the ear. In computer music this subtle ingredient is bought at a high computational cost, both in terms of the number of items requiring detail in a score and in the amount of interpretive work the instruments must produce to realize this detail in sound. 
Advances.
Advances in computing power and software for manipulation of digital media have dramatically affected the way computer music is generated and performed. Current-generation micro-computers are powerful enough to perform very sophisticated audio synthesis using a wide variety of algorithms and approaches. Computer music systems and approaches are now ubiquitous, and so firmly embedded in the process of creating music that we hardly give them a second thought: computer-based synthesizers, digital mixers, and effects units have become so commonplace that use of digital rather than analog technology to create and record music is the norm, rather than the exception.
Research.
Despite the ubiquity of computer music in contemporary culture, there is considerable activity in the field of computer music, as researchers continue to pursue new and interesting computer-based synthesis, composition, and performance approaches. Throughout the world there are many organizations and institutions dedicated to the area of computer and electronic music study and research, including the ICMA (International Computer Music Association), IRCAM, GRAME, SEAMUS (Society for Electro Acoustic Music in the United States), CEC (Canadian Electroacoustic Community), and a great number of institutions of higher learning around the world.
Computer-generated music.
Computer-generated music is music composed by, or with the extensive aid of, a computer. Although any music which uses computers in its composition or realisation is computer-generated to some extent, the use of computers is now so widespread (in the editing of pop songs, for instance) that the phrase computer-generated music is generally used to mean a kind of music which could not have been created "without" the use of computers.
We can distinguish two groups of computer-generated music: music in which a computer generated the score, which could be performed by humans, and music which is both composed and performed by computers. There is a large genre of music that is organized, synthesized, and created on computers.
Music composed and performed by computers.
Later, composers such as Gottfried Michael Koenig had computers generate the sounds of the composition as well as the score. Koenig produced algorithmic composition programs which were a generalisation of his own serial composition practice. This is not exactly similar to Xenakis' work as he used mathematical abstractions and examined how far he could explore these musically. Koenig's software translated the calculation of mathematical equations into codes which represented musical notation. This could be converted into musical notation by hand and then performed by human players. His programs Project 1 and Project 2 are examples of this kind of software. Later, he extended the same kind of principles into the realm of synthesis, enabling the computer to produce the sound directly. SSP is an example of a program which performs this kind of function. All of these programs were produced by Koenig at the Institute of Sonology in Utrecht in the 1970s.
Procedures such as those used by Koenig and Xenakis are still in use today. Since the invention of the MIDI system in the early 1980s, for example, some people have worked on programs which map MIDI notes to an algorithm and then can either output sounds or music through the computer's sound card or write an audio file for other programs to play.
Some of these simple programs are based on fractal geometry, and can map midi notes to specific fractals, or fractal equations. Although such programs are widely available and are sometimes seen as clever toys for the non-musician, some professional musicians have given them attention also. The resulting 'music' can be more like noise, or can sound quite familiar and pleasant. As with much algorithmic music, and algorithmic art in general, more depends on the way in which the parameters are mapped to aspects of these equations than on the equations themselves. Thus, for example, the same equation can be made to produce both a lyrical and melodic piece of music in the style of the mid-nineteenth century, and a fantastically dissonant cacophony more reminiscent of the avant-garde music of the 1950s and 1960s.
Other programs can map mathematical formulae and constants to produce sequences of notes. In this manner, an irrational number can give an infinite sequence of notes where each note is a digit in the decimal expression of that number. This sequence can in turn be a composition in itself, or simply the basis for further elaboration.
Operations such as these, and even more elaborate operations can also be performed in computer music programming languages such as Max/MSP, SuperCollider, Csound, Pure Data (Pd), Keykit, and ChucK. These programs now easily run on most personal computers, and are often capable of more complex functions than those which would have necessitated the most powerful mainframe computers several decades ago.
There exist programs that generate "human-sounding" melodies by using a vast database of phrases. One example is Band-in-a-Box, which is capable of creating jazz, blues and rock instrumental solos with almost no user interaction. Another is Impro-Visor, which uses a stochastic context-free grammar to generate phrases and complete solos.
Another 'cybernetic' approach to computer composition uses specialized hardware to detect external stimuli which are then mapped by the computer to realize the performance. Examples of this style of computer music can be found in the middle-80's work of David Rokeby (Very Nervous System) where audience/performer motions are 'translated' to MIDI segments. Computer controlled music is also found in the performance pieces by the Canadian composer Udo Kasemets such as the Marce(ntennia)l Circus C(ag)elebrating Duchamp (1987), a realization of the Marcel Duchamp process piece "Erratum Musical" using an electric model train to collect a hopper-car of stones to be deposited on a drum wired to an Analog:Digital converter, mapping the stone impacts to a score display (performed in Toronto by pianist Gordon Monahan during the 1987 Duchamp Centennial), or his installations and performance works (e.g. Spectrascapes) based on his Geo(sono)scope (1986) 15x4-channel computer-controlled audio mixer. In these latter works, the computer generates sound-scapes from tape-loop sound samples, live shortwave or sine-wave generators.
Computer-generated scores for performance by human players.
Many systems for generating musical scores actually existed well before the time of computers. One of these was Musikalisches Würfelspiel "(Musical dice game"; 18th century), a system which used throws of the dice to randomly select measures from a large collection of small phrases. When patched together, these phrases combined to create musical pieces which could be performed by human players. Although these works were not actually composed with a computer in the modern sense, it uses a rudimentary form of the random combinatorial techniques sometimes used in computer-generated composition.
The world's first digital computer music was generated in Australia by programmer Geoff Hill on the CSIRAC computer which was designed and built by Trevor Pearcey and Maston Beard, although it was only used to play standard tunes of the day. Subsequently, one of the first composers to write music with a computer was Iannis Xenakis. He wrote programs in the FORTRAN language that generated numeric data that he transcribed into scores to be played by traditional musical instruments. An example is "ST/48" of 1962. Although Xenakis could well have composed this music by hand, the intensity of the calculations needed to transform probabilistic mathematics into musical notation was best left to the number-crunching power of the computer.
Computers have also been used in an attempt to imitate the music of great composers of the past, such as Mozart. A present exponent of this technique is David Cope. He wrote computer programs that analyse works of other composers to produce new works in a similar style. He has used this program to great effect with composers such as Bach and Mozart (his program "Experiments in Musical Intelligence" is famous for creating "Mozart's 42nd Symphony"), and also within his own pieces, combining his own creations with that of the computer.
Melomics, a research group from the University of Málaga, Spain, developed a computer composition cluster named Iamus, which composes complex, multi-instrument pieces for editing and performance. Since its inception, Iamus has composed a full album in 2012, appropriately named Iamus, which New Scientist described as "The first major work composed by a computer and performed by a full orchestra." The group has also developed an API for developers to utilize the technology, and makes its music available on its website.
Computer-Aided Algorithmic Composition.
Computer-Aided Algorithmic Composition (CAAC, pronounced "sea-ack") is the implementation and use of algorithmic composition techniques in software. This label is derived from the combination of two labels, each too vague for continued use. The label "computer-aided composition" lacks the specificity of using generative algorithms. Music produced with notation or sequencing software could easily be considered computer-aided composition. The label "algorithmic composition" is likewise too broad, particularly in that it does not specify the use of a computer. The term computer-aided, rather than computer-assisted, is used in the same manner as Computer-Aided Design.
Machine improvisation.
Machine improvisation uses computer algorithms to create improvisation on existing music materials. This is usually done by sophisticated recombination of musical phrases extracted from existing music, either live or pre-recorded. In order to achieve credible improvisation in particular style, machine improvisation uses machine learning and pattern matching algorithms to analyze existing musical examples. The resulting patterns are then used to create new variations "in the style" of the original music, developing a notion of stylistic reinjection.
This is different from other improvisation methods with computers that use algorithmic composition to generate new music without performing analysis of existing music examples.
Statistical style modeling.
Style modeling implies building a computational representation of the musical surface that captures important stylistic features from data. Statistical approaches are used to capture the redundancies in terms of pattern dictionaries or repetitions, which are later recombined to generate new musical data. Style mixing can be realized by analysis of a database containing multiple musical examples in different styles. Machine Improvisation builds upon a long musical tradition of statistical modeling that began with Hiller and Isaacson's "Illiac Suite for String Quartet" (1957) and Xenakis' uses of Markov chains and stochastic processes. Modern methods include the use of lossless data compression for incremental parsing, prediction suffix tree and string searching by factor oracle algorithm (basically a "factor oracle" is a ﬁnite state automaton constructed in linear time and space in an incremental fashion).
Uses of machine improvisation.
Machine improvisation encourages musical creativity by providing automatic modeling and transformation structures for existing music. This creates a natural interface with the musician without need for coding musical algorithms. In live performance, the system re-injects the musician's material in several different ways, allowing a semantics-level representation of the session and a smart recombination and transformation of this material in real-time. In offline version, machine improvisation can be used to achieve style mixing, an approach inspired by Vannevar Bush's memex imaginary machine.
Implementations.
The first system implementing interactive machine improvisation by means of Markov models and style modeling techniques is the Continuator, developed by François Pachet at Sony CSL Paris in 2002 based on work on non-real time style modeling.
Matlab implementation of the Factor Oracle machine improvisation can be found as part of Computer Audition toolbox.
OMax is a software environment developed in IRCAM. OMax uses OpenMusic and Max. It is based on researches on stylistic modeling carried out by Gerard Assayag and Shlomo Dubnov and on researches on improvisation with the computer by G. Assayag, M. Chemillier and G. Bloch (aka the" OMax Brothers") in the Ircam Music Representations group.
Musicians working with machine improvisation.
Gerard Assayag (IRCAM, France),
Jeremy Baguyos (University of Nebraska at Omaha, USA)
Tim Blackwell (Goldsmiths College, Great Britain),
George Bloch (Composer, France),
Marc Chemiller (IRCAM/CNRS, France),
Nick Collins (University of Sussex, UK),
Shlomo Dubnov (Composer, Israel / USA),
Mari Kimura (Juilliard, New York City),
George Lewis (Columbia University, New York City),
Bernard Lubat (Pianist, France),
François Pachet (Sony CSL, France),
Joel Ryan (Institute of Sonology, Netherlands),
Michel Waisvisz (STEIM, Netherlands),
David Wessel (CNMAT, California),
Michael Young (Goldsmiths College, Great Britain),
Pietro Grossi (CNUCE, Institute of the National Research Council, Pisa, Italy),
Toby Gifford and Andrew Brown (Griffith University, Brisbane, Australia),
Davis Salks (jazz composer, Hamburg, PA, USA),
Doug Van Nort (electroacoustic improviser, Montreal/New York)
Live coding.
Live coding (sometimes known as 'interactive programming', 'on-the-fly programming', 'just in time programming') is the name given to the process of writing software in realtime as part of a performance. Recently it has been explored as a more rigorous alternative to laptop musicians who, live coders often feel, lack the charisma and pizzazz of musicians performing live.
Generally, this practice stages a more general approach: one of interactive programming, of writing (parts of) programs while they are interpreted. Traditionally most computer music programs have tended toward the old write/compile/run model which evolved when computers were much less powerful. This approach has locked out code-level innovation by people whose programming skills are more modest. Some programs have gradually integrated real-time controllers and gesturing (for example, MIDI-driven software synthesis and parameter control). Until recently, however, the musician/composer rarely had the capability of real-time modification of program code itself. This legacy distinction is somewhat erased by languages such as ChucK, SuperCollider, and Impromptu.
TOPLAP, an ad-hoc conglomerate of artists interested in live coding was formed in 2004, and promotes the use, proliferation and exploration of a range of software, languages and techniques to implement live coding. This is a parallel and collaborative effort e.g. with research at the Princeton Sound Lab, the University of Cologne, and the Computational Arts Research Group at Queensland University of Technology.

</doc>
<doc id="6978" url="http://en.wikipedia.org/wiki?curid=6978" title="Concept">
Concept

In metaphysics, and especially ontology, a concept is a fundamental category of existence. In contemporary philosophy, there are at least three prevailing ways to understand what a concept is: 
Mental representations.
In a physicalist theory of mind, a concept is a mental representation, which the brain uses to denote a class of things in the world. This is to say that it is literally, a symbol or group of symbols together made from the physical material of the brain. Concepts are mental representations that allow us to draw appropriate inferences about the type of entities we encounter in our everyday lives. Concepts do not encompass all mental representations, but are merely a subset of them. The use of concepts is necessary to cognitive processes such as categorization, memory, decision making, learning, and inference.
Abstract objects.
In a platonist theory of mind, concepts are construed as abstract objects. This debate concerns the ontological status of concepts - what they are really like.
There is debate as to the relationship between concepts and natural language. However, it is necessary at least to begin by understanding that the concept "dog" is philosophically distinct from the things in the world grouped by this concept - or the reference class or extension. Concepts that can be equated to a single word are called "lexical concepts". 
Study of concepts and conceptual structure falls into the disciplines of philosophy, psychology, and cognitive science.
Notable theories on the structure of concepts.
Classical theory.
The classical theory of concepts, also referred to as the empiricist theory of concepts, is the oldest theory about the structure of concepts (it can be traced back to Aristotle), and was prominently held until the 1970s. The classical theory of concepts says that concepts have a definitional structure. Adequate definitions of the kind required by this theory usually take the form of a list of features. These features must have two important qualities to provide a comprehensive definition. Features entailed by the definition of a concept must be both "necessary" and "sufficient" for membership in the class of things covered by a particular concept. A feature is considered necessary if every member of the denoted class has that feature. A feature is considered sufficient if something has all the parts required by the definition. For example, the classic example "bachelor" is said to be defined by "unmarried" and "man". An entity is a bachelor (by this definition) if and only if it is both unmarried and a man. To check whether something is a member of the class, you compare its qualities to the features in the definition. Another key part of this theory is that it obeys the "law of the excluded middle", which means that there are no partial members of a class, you are either in or out. 
The classical theory persisted for so long unquestioned because it seemed intuitively correct and has great explanatory power. It can explain how concepts would be acquired, how we use them to categorize and how we use the structure of a concept to determine its referent class. In fact, for many years it was one of the major activities in philosophy - concept analysis. Concept analysis is the act of trying to articulate the necessary and sufficient conditions for the membership in the referent class of a concept.
Arguments against the classical theory.
Given that most later theories of concepts were born out of the rejection of some or all of the classical theory, it seems appropriate to give an account of what might be wrong with this theory. In the 20th century, philosophers such as Rosch and Wittgenstein argued against the classical theory. There are six primary arguments summarized as follows:
Prototype theory.
Prototype theory came out of problems with the classical view of conceptual structure. Prototype theory says that concepts specify properties that members of a class tend to possess, rather than must possess. Wittgenstein, Rosch, Mervis, Berlin, Anglin, and Posner are a few of the key proponents and creators of this theory. Wittgenstein describes the relationship between members of a class as "family resemblances". There are not necessarily any necessary conditions for membership, a dog can still be a dog with only three legs. This view is particularly supported by psychological experimental evidence for prototypicality effects. Participants willingly and consistently rate objects in categories like 'vegetable' or 'furniture' as more or less typical of that class. It seems that our categories are fuzzy psychologically, and so this structure has explanatory power. We can judge an item's membership to the referent class of a concept by comparing it to the typical member - the most central member of the concept. If it is similar enough in the relevant ways, it will be cognitively admitted as a member of the relevant class of entities. Rosch suggests that every category is represented by a central exemplar which embodies all or the maximum possible number of features of a given category.
Theory-theory.
Theory-theory is a reaction to the previous two theories and develops them further. This theory postulates that categorization by concepts is something like scientific theorizing. Concepts are not learned in isolation, but rather are learned as a part of our experiences with the world around us. In this sense, concepts' structure relies on their relationships to other concepts as mandated by a particular mental theory about the state of the world. How this is supposed to work is a little less clear than in the previous two theories, but is still a prominent and notable theory. This is supposed to explain some of the issues of ignorance and error that come up in prototype and classical theories as concepts that are structured around each other seem to account for errors such as whale as a fish (this misconception came from an incorrect theory about what a whale is like, combining with our theory of what a fish is). When we learn that a whale is not a fish, we are recognizing that whales don't in fact fit the theory we had about what makes something a fish. In this sense, the Theory-Theory of concepts is responding to some of the issues of prototype theory and classic theory.
Issues in concept theory.
A priori concepts.
Kant declared that human minds possess pure or "a priori" concepts. Instead of being abstracted from individual perceptions, like empirical concepts, they originate in the mind itself. He called these concepts categories, in the sense of the word that means predicate, attribute, characteristic, or quality. But these pure categories are predicates of things "in general", not of a particular thing. According to Kant, there are 12 categories that constitute the understanding of phenomenal objects. Each category is that one predicate which is common to multiple empirical concepts. In order to explain how an "a priori" concept can relate to individual phenomena, in a manner analogous to an "a posteriori" concept, Kant employed the technical concept of the schema. He held that the account of the concept as an abstraction of experience is only partly correct. He called those concepts that result from abstraction "a posteriori concepts" (meaning concepts that arise out of experience). An empirical or an "a posteriori" concept is a general representation ("Vorstellung") or non-specific thought of that which is common to several specific perceived objects (Logic, I, 1., §1, Note 1)
A concept is a common feature or characteristic. Kant investigated the way that empirical "a posteriori" concepts are created.
Embodied content.
In cognitive linguistics, abstract concepts are transformations of concrete concepts derived from embodied experience. The mechanism of transformation is structural mapping, in which properties of two or more source domains are selectively mapped onto a blended space (Fauconnier & Turner, 1995; see conceptual blending). A common class of blends are metaphors. This theory contrasts with the rationalist view that concepts are perceptions (or "recollections", in Plato's term) of an independently existing world of ideas, in that it denies the existence of any such realm. It also contrasts with the empiricist view that concepts are abstract generalizations of individual experiences, because the contingent and bodily experience is preserved in a concept, and not abstracted away. While the perspective is compatible with Jamesian pragmatism, the notion of the transformation of embodied concepts through structural mapping makes a distinct contribution to the problem of concept formation.
Ontology.
Plato was the starkest proponent of the realist thesis of universal concepts. By his view, concepts (and ideas in general) are innate ideas that were instantiations of a transcendental world of pure forms that lay behind the veil of the physical world. In this way, universals were explained as transcendent objects. Needless to say this form of realism was tied deeply with Plato's ontological projects. This remark on Plato is not of merely historical interest. For example, the view that numbers are Platonic objects was revived by Kurt Gödel as a result of certain puzzles that he took to arise from the phenomenological accounts.
Gottlob Frege, founder of the analytic tradition in philosophy, famously argued for the analysis of language in terms of sense and reference. For him, the sense of an expression in language describes a certain state of affairs in the world, namely, the way that some object is presented. Since many commentators view the notion of sense as identical to the notion of concept, and Frege regards senses as the linguistic representations of states of affairs in the world, it seems to follow that we may understand concepts as the manner in which we grasp the world. Accordingly, concepts (as senses) have an ontological status (Morgolis:7)
According to Carl Benjamin Boyer, in the introduction to his "The History of the Calculus and its Conceptual Development", concepts in calculus do not refer to perceptions. As long as the concepts are useful and mutually compatible, they are accepted on their own. For example, the concepts of the derivative and the integral are not considered to refer to spatial or temporal perceptions of the external world of experience. Neither are they related in any way to mysterious limits in which quantities are on the verge of nascence or evanescence, that is, coming into or going out of existence. The abstract concepts are now considered to be totally autonomous, even though they originated from the process of abstracting or taking away qualities from perceptions until only the common, essential attributes remained.
Etymology.
The term "concept" is traced back to 1554–60 (Latin "" - "something conceived"), but what is today termed "the classical theory of concepts" is the theory of Aristotle on the definition of terms. The meaning of "concept" is explored in mainstream information science, cognitive science, metaphysics, and philosophy of mind. In computer and information science contexts, especially, the term 'concept' is often used in unclear or inconsistent ways.

</doc>
<doc id="6979" url="http://en.wikipedia.org/wiki?curid=6979" title="Cell Cycle (journal)">
Cell Cycle (journal)

Cell Cycle is a peer-reviewed scientific journal covering cell biology. The editor-in-chief is Mikhail V. Blagosklonny (Roswell Park Cancer Institute). "Cell Cycle" is abstracted and indexed in Medline/PubMed and the Science Citation Index Expanded.

</doc>
<doc id="6982" url="http://en.wikipedia.org/wiki?curid=6982" title="List of classical music competitions">
List of classical music competitions

The European Classical art music idiom has long relied on the institution of music competitions to provide a public forum that identifies the strongest young players and contributes to the establishment of their professional careers. This is a list of classical music competitions.

</doc>
<doc id="6984" url="http://en.wikipedia.org/wiki?curid=6984" title="Colin Powell">
Colin Powell

Colin Luther Powell (; born April 5, 1937) is an American statesman and a retired four-star general in the United States Army. He was the 65th United States Secretary of State, serving under U.S. President George W. Bush from 2001 to 2005, the first African American to serve in that position. During his military career, Powell also served as National Security Advisor (1987–1989), as Commander of the U.S. Army Forces Command (1989) and as Chairman of the Joint Chiefs of Staff (1989–1993), holding the latter position during the Persian Gulf War. He was the first, and so far the only, African American to serve on the Joint Chiefs of Staff, and was the first of two consecutive African American office-holders to hold the key Administration position of U.S. Secretary of State.
Early life and education.
Powell was born on April 5, 1937, in Harlem, a neighborhood in the New York City borough of Manhattan, to Jamaican immigrant parents Maud Arial (née McKoy) and Luther Theophilus Powell. He also has Scottish ancestry. Powell was raised in the South Bronx and attended Morris High School, a former public school in the Bronx, from which he graduated in 1954. While at school, he worked at a local baby furniture store where he picked up Yiddish from the shopkeepers and some of the customers. He received his BS degree in geology from the City College of New York in 1958 and was a self-admitted C average student. He was later able to earn a MBA degree from the George Washington University in 1971, after his second tour in Vietnam.
Despite his parents' pronunciation of his name as , Powell has pronounced his name since childhood, after the heroic World War II flyer Colin P. Kelly Jr. Public officials and radio and television reporters have used Powell's preferred pronunciation.
Military career.
Powell was a professional soldier for 35 years, holding a variety of command and staff positions and rising to the rank of General.
Training.
Powell described joining the Reserve Officers' Training Corps (ROTC) during college as one of the happiest experiences of his life; discovering something he loved and could do well, he felt he had "found himself." According to Powell: “It was only once I was in college, about six months into college when I found something that I liked, and that was ROTC, Reserve Officer Training Corps in the military. And I not only liked it, but I was pretty good at it. That's what you really have to look for in life, something that you like, and something that you think you're pretty good at. And if you can put those two things together, then you're on the right track, and just drive on.” Cadet Powell joined the Pershing Rifles, the ROTC fraternal organization and drill team begun by General John Pershing. Even after he had become a general, Powell kept on his desk a pen set he had won for a drill team competition.
Upon graduation, he received a commission as an Army second lieutenant. After attending basic training at Fort Benning, Powell was assigned to the 48th Infantry, in West Germany, as a platoon leader.
Vietnam War.
In his autobiography, Powell said he is haunted by the nightmare of the Vietnam War and felt that the leadership was very ineffective.
Captain Powell served a tour in Vietnam as a South Vietnamese Army (ARVN) advisor from 1962 to 1963. While on patrol in a Viet Cong-held area, he was wounded by stepping on a punji stake. The large infection made it difficult for him to walk, and caused his foot to swell for a short time, shortening his first tour.
He returned to Vietnam as a major in 1968, serving in the Americal Division (23rd Infantry Division), then as assistant chief of staff of operations for the Americal Division. During the second tour in Vietnam he was decorated for bravery after he survived a helicopter crash, single-handedly rescuing three others, including division commander Major General Charles Martin Gettys, from the burning wreckage. He was charged with investigating a detailed letter by Tom Glen (a soldier from the 11th Light Infantry Brigade), which backed up rumored allegations of the My Lai Massacre. Powell wrote: "In direct refutation of this portrayal is the fact that relations between American soldiers and the Vietnamese people are excellent." Later, Powell's assessment would be described as whitewashing the news of the massacre, and questions would continue to remain undisclosed to the public. In May 2004 Powell said to television and radio host Larry King, "I mean, I was in a unit that was responsible for My Lai. I got there after My Lai happened. So, in war, these sorts of horrible things happen every now and again, but they are still to be deplored."
After the Vietnam War.
Powell served a White House fellowship, a highly selective and prestigious position, under President Richard Nixon from 1972 to 1973.
In his autobiography, "My American Journey", Powell named several officers he served under who inspired and mentored him. As a lieutenant colonel serving in South Korea, Powell was very close to General Henry "Gunfighter" Emerson. Powell said he regarded Emerson as one of the most caring officers he ever met. Emerson insisted his troops train at night to fight a possible North Korean attack, and made them repeatedly watch the television film "Brian's Song" to promote racial harmony. Powell always professed that what set Emerson apart, was his great love of his soldiers and concern for their welfare. After a race riot occurred, where African American soldiers almost killed a Caucasian officer, Powell was charged by Emerson to crackdown on black militants; Powell's efforts led to the discharge of one soldier, and other efforts to reduce racial tensions.
A "political general".
In the early 1980s, Powell served at Fort Carson, Colorado. After he left Fort Carson, Powell became senior military assistant to Secretary of Defense Caspar Weinberger, whom he assisted during the 1983 invasion of Grenada and the 1986 airstrike on Libya.
In 1986, Powell took over the command of V Corps in Frankfurt, Germany, from Robert Lewis "Sam" Wetzel.
Following the Iran Contra scandal, Powell became, at the age of 49, Ronald Reagan's National Security Advisor, serving from 1987 to 1989 while retaining his Army commission as a lieutenant general.
In April 1989, after his tenure with the National Security Council, Powell was promoted to four-star general under President George H. W. Bush and briefly served as the Commander in Chief, Forces Command (FORSCOM), headquartered at Fort McPherson, Georgia, overseeing all Army, Army Reserve, and National Guard units in the Continental U.S., Alaska, Hawaii, and Puerto Rico. He became only the third general since World War II, joining Dwight D. Eisenhower and Alexander Haig, to reach four-star rank without ever serving as a division commander.
Later that year, President George H. W. Bush selected him as Chairman of the Joint Chiefs of Staff.
Chairman of the Joint Chiefs of Staff.
Powell's last military assignment, from October 1, 1989, to September 30, 1993, was as the 12th Chairman of the Joint Chiefs of Staff, the highest military position in the Department of Defense. At age 52, he became the youngest officer, and first Afro-Caribbean American, to serve in this position. Powell was also the first JCS Chair who received his commission through ROTC.
During this time, he oversaw 28 crises, including the invasion of Panama in 1989 to remove General Manuel Noriega from power and Operation Desert Storm in the 1991 Persian Gulf War. During these events, Powell earned his nickname, "the reluctant warrior." He rarely advocated military intervention as the first solution to an international crisis, and instead usually prescribed diplomacy and containment.
As a military strategist, Powell advocated an approach to military conflicts that maximizes the potential for success and minimizes casualties. A component of this approach is the use of overwhelming force, which he applied to Operation Desert Storm in 1991. His approach has been dubbed the "Powell Doctrine". Powell continued as chairman of the JCS into the Clinton presidency but as a dedicated "realist" he considered himself a bad fit for an administration largely made up of liberal internationalists. He clashed with then-U.S. ambassador to the United Nations Madeleine Albright over the Bosnian crisis, as he opposed any military interventions that didn't involve US interests.
During his chairmanship of the JCS, there was discussion of awarding Powell a fifth star, granting him the rank of General of the Army. But even in the wake of public and Congressional pressure to do so, Clinton-Gore presidential transition team staffers decided against it.
13 Rules of Leadership.
First printed in the August 13, 1989 issue of "Parade" magazine, these are Colin Powell's 13 Rules of Leadership.
Potential presidential candidate.
Powell's experience in military matters made him a very popular figure with both American political parties. Many Democrats admired his moderate stance on military matters, while many Republicans saw him as a great asset associated with the successes of past Republican administrations. Put forth as a potential Democratic Vice Presidential nominee in the 1992 U.S. presidential election or even potentially replacing Vice President Dan Quayle as the Republican Vice Presidential nominee, Powell eventually declared himself a Republican and began to campaign for Republican candidates in 1995. He was touted as a possible opponent of Bill Clinton in the 1996 U.S. presidential election, possibly capitalizing on a split conservative vote in Iowa and even leading New Hampshire polls for the GOP nomination, but Powell declined, citing a lack of passion for politics. Powell defeated Clinton 50-38 in a hypothetical match-up proposed to voters in the exit polls conducted on Election Day. Despite not standing in the race, Powell won the Republican New Hampshire Vice-Presidential primary on write-in votes.
In 1997 Powell founded America's Promise with the objective of helping children from all socioeconomic sectors. That same year saw the establishment of The Colin L. Powell Center for Leadership and Service. The mission of the Center is to "prepare new generations of publicly engaged leaders from populations previously underrepresented in public service and policy circles, to build a strong culture of civic engagement at City College, and to mobilize campus resources to meet pressing community needs and serve the public good." 
In the 2000 U.S. presidential election Powell campaigned for Senator John McCain and later Texas Governor George W. Bush after the latter secured the Republican nomination. Bush eventually won, and Powell was appointed Secretary of State.
Secretary of State.
As Secretary of State in the Bush administration, Powell was perceived as moderate. Powell was unanimously confirmed by the United States Senate. Over the course of his tenure he traveled less than any other U.S. Secretary of State in 30 years.
On September 11, 2001, Powell was in Lima, Peru, meeting with President Alejandro Toledo and US Ambassador John Hamilton, and attending the special session of the OAS General Assembly that subsequently adopted the Inter-American Democratic Charter. After the September 11 attacks, Powell's job became of critical importance in managing America's relationships with foreign countries in order to secure a stable coalition in the War on Terrorism.
Powell came under fire for his role in building the case for the 2003 Invasion of Iraq. In a press statement on February 24, 2001, he had said that sanctions against Iraq had prevented the development of any weapons of mass destruction by Saddam Hussein. As was the case in the days leading up to the Persian Gulf War, Powell was initially opposed to a forcible overthrow of Saddam, preferring to continue a policy of containment. However, Powell eventually agreed to go along with the Bush administration's determination to remove Saddam. He had often clashed with others in the administration, who were reportedly planning an Iraq invasion even before the September 11 attacks, an insight supported by testimony by former terrorism czar Richard Clarke in front of the 9/11 Commission. The main concession Powell wanted before he would offer his full support for the Iraq War was the involvement of the international community in the invasion, as opposed to a unilateral approach. He was also successful in persuading Bush to take the case of Iraq to the United Nations, and in moderating other initiatives. Powell was placed at the forefront of this diplomatic campaign.
Powell's chief role was to garner international support for a multi-national coalition to mount the invasion. To this end, Powell addressed a plenary session of the United Nations Security Council on February 5, 2003, to argue in favor of military action. Citing numerous anonymous Iraqi defectors, Powell asserted that "there can be no doubt that Saddam Hussein has biological weapons and the capability to rapidly produce more, many more." Powell also stated that there was "no doubt in my mind" that Saddam was working to obtain key components to produce nuclear weapons.
Most observers praised Powell's oratorical skills. However, Britain's "Channel 4 News" reported soon afterwards that a UK intelligence dossier that Powell had referred to as a "fine paper" during his presentation had been based on old material and plagiarized an essay by American graduate student Ibrahim al-Marashi.
A 2004 report by the Iraq Survey Group concluded that the evidence that Powell offered to support the allegation that the Iraqi government possessed weapons of mass destruction (WMDs) was inaccurate.
In an interview with Charlie Rose, Powell contended that prior to his UN presentation, he had merely four days to review the data concerning WMD in Iraq.
A Senate report on intelligence failures would later detail the intense debate that went on behind the scenes on what to include in Powell's speech. State Department analysts had found dozens of factual problems in drafts of the speech. Some of the claims were taken out, but others were left in, such as claims based on the yellowcake forgery. The administration came under fire for having acted on faulty intelligence, particularly what was single-sourced to the informant known as Curveball. Powell later recounted how Vice President Dick Cheney had joked with him before he gave the speech, telling him, "You've got high poll ratings; you can afford to lose a few points." Powell's longtime aide-de-camp and Chief of Staff from 1989–2003, Colonel Lawrence Wilkerson, later characterized Cheney's view of Powell's mission as to "go up there and sell it, and we'll have moved forward a peg or two. Fall on your damn sword and kill yourself, and I'll be happy, too."
In September 2005, Powell was asked about the speech during an interview with Barbara Walters and responded that it was a "blot" on his record. He went on to say, "It will always be a part of my record. It was painful. It's painful now."
Wilkerson said that he inadvertently participated in a hoax on the American people in preparing Powell's erroneous testimony before the United Nations Security Council.
Because Powell was seen as more moderate than most figures in the administration, he was spared many of the attacks that have been leveled at more controversial advocates of the invasion, such as Donald Rumsfeld and Paul Wolfowitz. At times, infighting among the Powell-led State Department, the Rumsfeld-led Defense Department, and Cheney's office had the effect of polarizing the administration on crucial issues, such as what actions to take regarding Iran and North Korea.
After Saddam Hussein had been deposed, Powell's new role was to once again establish a working international coalition, this time to assist in the rebuilding of post-war Iraq. On September 13, 2004, Powell testified before the Senate Governmental Affairs Committee, acknowledging that the sources who provided much of the information in his February 2003 UN presentation were "wrong" and that it was "unlikely" that any stockpiles of WMDs would be found. Claiming that he was unaware that some intelligence officials questioned the information prior to his presentation, Powell pushed for reform in the intelligence community, including the creation of a national intelligence director who would assure that "what one person knew, everyone else knew."
Additionally, Powell has been critical of other instances of U.S. foreign policy in the past, such as its support for the 1973 Chilean coup d'état. From two separate interviews in 2003, Powell stated in one about the 1973 event "I can't justify or explain the actions and decisions that were made at that time. It was a different time. There was a great deal of concern about communism in this part of the world. Communism was a threat to the democracies in this part of the world. It was a threat to the United States." In another interview, however, he also simply stated "With respect to your earlier comment about Chile in the 1970s and what happened with Mr. Allende, it is not a part of American history that we're proud of."
Powell announced his resignation as Secretary of State on November 15, 2004. According to "The Washington Post", he had been asked to resign by the president's chief of staff, Andrew Card. Powell announced that he would stay on until the end of Bush's first term or until his replacement's confirmation by Congress. The following day, Bush nominated National Security Advisor Condoleezza Rice as Powell's successor. News of Powell's leaving the Administration spurred mixed reactions from politicians around the world — some upset at the loss of a statesman seen as a moderating factor within the Bush administration, but others hoping for Powell's successor to wield more influence within the cabinet.
In mid-November, Powell stated that he had seen new evidence suggesting that Iran was adapting missiles for a nuclear delivery system. The accusation came at the same time as the settlement of an agreement between Iran, the IAEA, and the European Union.
On December 31, 2004, Powell rang in the New Year by pressing a button in Times Square with New York City Mayor Michael Bloomberg to initiate the ball drop and 60 second countdown, ushering in the year 2005. He appeared on the networks that were broadcasting New Year's Eve specials and talked about this honor, as well as being a native of New York City.
Life after diplomatic service.
After retiring from the role of Secretary of State, Powell returned to private life. In April 2005, he was privately telephoned by Republican senators Lincoln Chafee and Chuck Hagel, at which time Powell expressed reservations and mixed reviews about the nomination of John R. Bolton as ambassador to the United Nations, but refrained from advising the senators to oppose Bolton (Powell had clashed with Bolton during Bush's first term). The decision was viewed as potentially dealing significant damage to Bolton's chances of confirmation. Bolton was put into the position via a recess appointment because of the strong opposition in the Senate.
On April 28, 2005, an opinion piece in "The Guardian" by Sidney Blumenthal (a former top aide to President Bill Clinton) claimed that Powell was in fact "conducting a campaign" against Bolton because of the acrimonious battles they had had while working together, which among other things had resulted in Powell cutting Bolton out of talks with Iran and Libya after complaints about Bolton's involvement from the British. Blumenthal added that "The foreign relations committee has discovered that Bolton made a highly unusual request and gained access to 10 intercepts by the National Security Agency. Staff members on the committee believe that Bolton was probably spying on Powell, his senior advisors and other officials reporting to him on diplomatic initiatives that Bolton opposed."
In July 2005, Powell joined Kleiner, Perkins, Caufield & Byers, a well-known Silicon Valley venture capital firm, with the title of "strategic limited partner."
In September 2005, Powell criticized the response to Hurricane Katrina. Powell said that thousands of people were not properly protected, but because they were poor rather than because they were black.
On January 5, 2006, he participated in a meeting at the White House of former Secretaries of Defense and State to discuss United States foreign policy with Bush administration officials. In September 2006, Powell sided with more moderate Senate Republicans in supporting more rights for detainees and opposing President Bush's terrorism bill. He backed Senators John Warner, John McCain and Lindsey Graham in their statement that U.S. military and intelligence personnel in future wars will suffer for abuses committed in 2006 by the U.S. in the name of fighting terrorism. Powell stated that "The world is beginning to doubt the moral basis of [America's] fight against terrorism."
Also in 2006, Powell began appearing as a speaker at a series of motivational events called "Get Motivated", along with former New York Mayor Rudy Giuliani. In his speeches for the tour, he openly criticized the Bush Administration on a number of issues. Powell has been the recipient of mild criticism for his role with "Get Motivated" which has been called a "get-rich-quick-without-much-effort, feel-good schemology."
In 2007 he joined the Board of Directors of Steve Case's new company Revolution Health. Powell also serves on the Council on Foreign Relations Board of directors.
Powell, in honor of Martin Luther King Day, dropped the ceremonial first puck at a New York Islanders hockey game at Nassau Coliseum on January 21, 2008. On November 11, 2008, Powell again dropped the puck in recognition of Military Appreciation Day and Veterans Day.
Recently, Powell has encouraged young people to continue to use new technologies to their advantage in the future. In a speech at the Center for Strategic and International Studies to a room of young professionals, he said, "That's your generation...a generation that is hard-wired digital, a generation that understands the power of the information revolution and how it is transforming the world. A generation that you represent, and you're coming together to share; to debate; to decide; to connect with each other." At this event, he encouraged the next generation to involve themselves politically on the upcoming Next America Project, which uses online debate to provide policy recommendations for the upcoming administration.
In 2008, Powell served as a spokesperson for National Mentoring Month, a campaign held each January to recruit volunteer mentors for at-risk youth.
Soon after Barack Obama's 2008 election, Powell began being mentioned as a possible cabinet member. He was not nominated.
In September 2009, Powell advised President Obama against surging US forces in Afghanistan. The president announced the surge the following December.
On March 14, 2014, Salesforce.com announced that Powell had joined its Board of Directors.
Political views.
A liberal Republican, Powell is well known for his willingness to support liberal or centrist causes. He is pro-choice regarding abortion, and in favor of "reasonable" gun control. He stated in his autobiography that he supports affirmative action that levels the playing field, without giving a leg up to undeserving persons because of racial issues. Powell was also instrumental in the 1993 implementation of the military's don't ask, don't tell policy, though he later supported its repeal as proposed by Robert Gates and Admiral Mike Mullen in January 2010, saying "circumstances had changed".
The Vietnam War had a profound effect on Powell's views of the proper use of military force. These views are described in detail in the autobiography "My American Journey". The Powell Doctrine, as the views became known, was a central component of US policy in the Gulf War (the first U.S. war in Iraq) and U.S. invasion of Afghanistan (the overthrow of the Taliban regime in Afghanistan following the September 11 attacks). The hallmark of both operations was strong international cooperation, and the use of overwhelming military force.
Powell was the subject of controversy in 2004 when, in a conversation with British Foreign Secretary Jack Straw, he reportedly referred to neoconservatives within the Bush administration as "fucking crazies." In addition to being reported in the press (though generally, the expletive was censored in the U.S. press), the quote was used by James Naughtie in his book, "The Accidental American: Tony Blair and the Presidency", and by Chris Patten in his book, "Cousins and Strangers: America, Britain, and Europe in a New Century".
In a September 2006 letter to Sen. John McCain, General Powell expressed opposition to President Bush's push for military tribunals of those formerly and currently classified as enemy combatants. Specifically, he objected to the effort in Congress to "redefine Common Article 3 of the Geneva Convention." He also asserted: "The world is beginning to doubt the moral basis of our fight against terrorism."
Powell endorsed President Obama in 2008 and again in 2012. When asked why he is still a Republican on Meet the Press he said, “I’m still a Republican. And I think the Republican Party needs me more than the Democratic Party needs me. And you can be a Republican and still feel strongly about issues such as immigration, and improving our education system, and doing something about some of the social problems that exist in our society and our country. I don’t think there’s anything inconsistent with this.” 
Views on the Iraq War.
While Powell was wary of a military solution, he supported the decision to invade Iraq after the Bush administration concluded that diplomatic efforts had failed. After his departure from the State Department, Powell repeatedly emphasized his continued support for American involvement in the Iraq War.
At the 2007 Aspen Ideas Festival in Colorado, Powell revealed that he had spent two and a half hours explaining to President Bush "the consequences of going into an Arab country and becoming the occupiers." During this discussion, he insisted that the U.S. appeal to the United Nations first, but if diplomacy failed, he would support the invasion: "I also had to say to him that you are the President, you will have to make the ultimate judgment, and if the judgment is this isn't working and we don't think it is going to solve the problem, then if military action is undertaken I'm with you, I support you."
In a 2008 interview on CNN, Powell reiterated his support for the 2003 decision to invade Iraq in the context of his endorsement of Barack Obama, stating: "My role has been very, very straightforward. I wanted to avoid a war. The president agreed with me. We tried to do that. We couldn't get it through the U.N. and when the president made the decision, I supported that decision. And I've never blinked from that. I've never said I didn't support a decision to go to war."
Powell's position on the Iraq War troop surge of 2007 has been less clear. In December 2006, he expressed skepticism that the strategy would work and whether the U.S. military had enough troops to carry it out successfully. He stated: "I am not persuaded that another surge of troops into Baghdad for the purposes of suppressing this communitarian violence, this civil war, will work." Following his endorsement of Barack Obama in October 2008, however, Powell praised General David Petraeus and U.S. troops, as well as the Iraqi government, concluding that "it's starting to turn around." By mid-2009, he had concluded a surge of U.S. forces in Iraq should have come sooner, perhaps in late 2003. Throughout this period, Powell consistently argued that Iraqi political progress was essential, not just military force.
Role in presidential election of 2008.
Powell donated the maximum allowable amount to John McCain's campaign in the summer of 2007 and in early 2008, his name was listed as a possible running mate for Republican nominee McCain's bid during the 2008 U.S. presidential election. However, on October 19, 2008, Powell announced his endorsement of Barack Obama during a "Meet the Press" interview, citing "his ability to inspire, because of the inclusive nature of his campaign, because he is reaching out all across America, because of who he is and his rhetorical abilities," in addition to his "style and substance." He additionally referred to Obama as a "transformational figure". Powell further questioned McCain's judgment in appointing Sarah Palin as the vice presidential candidate, stating that despite the fact that she is admired, "now that we have had a chance to watch her for some seven weeks, I don't believe she's ready to be president of the United States, which is the job of the vice president." He said that Obama's choice for vice-president, Joe Biden, was ready to be president. He also added that he was "troubled" by the "false intimations that Obama was Muslim." Powell stated that "is a Christian — he's always been a Christian... But the really right answer is, what if he is? Is there something wrong with being a Muslim in this country? The answer's no, that's not America." Powell then referenced Kareem Rashad Sultan Khan, a Muslim American soldier in the U.S. Army who served and died in the Iraq War. He later stated, "Over the last seven weeks, the approach of the Republican Party has become narrower and narrower [... I look at these kind of approaches to the campaign, and they trouble me." Powell concluded his Sunday morning talk show comments, "It isn't easy for me to disappoint Sen. McCain in the way that I have this morning, and I regret that [...] I think we need a transformational figure. I think we need a president who is a generational change and that's why I'm supporting Barack Obama, not out of any lack of respect or admiration for Sen. John McCain." Later in a December 12, 2008, CNN interview with Fareed Zakaria, Powell reiterated his belief that during the last few months of the campaign, Palin pushed the Republican party further to the right and had a polarizing impact on it.
Views on the Obama administration.
In a July 2009 CNN interview with John King, Powell expressed concern over President Obama growing the size of the federal government and the size of the federal budget deficit. In September 2010, he criticized the Obama administration for not focusing "like a razor blade" on the economy and job creation. Powell reiterated that Obama was a "transformational figure." In a video that aired on CNN.com in November 2011, Colin Powell said in reference to Barack Obama, " . . . many of his decisions have been quite sound. The financial system was put back on a stable basis."
On October 25, 2012, 12 days before the presidential election, he gave his endorsement to President Obama for re-election during a broadcast of CBS This Morning. He cited success and forward progress in foreign and domestic policy arenas under the Obama Administration, and made the following statement: “I voted for him in 2008 and I plan to stick with him in 2012 and I'll be voting for he (sic) and for Vice President Joe Biden next month.”
As additional reason for his endorsement, Powell cited the changing positions and perceived lack of thoughtfulness of Mitt Romney on foreign affairs, and a concern for the validity of Romney's economic plans.
In an interview with ABC’s Diane Sawyer and George Stephanopoulos during ABC’s coverage of President Obama's second inauguration, Powell criticized members of the Republican Party who "...demonize the president”. He called on GOP leaders to publicly denounce such talk.
Views on LGBT issues.
In late May 2012 he expressed support for the legalization of same-sex marriage. He had earlier supported the repeal of Don't Ask Don't Tell.
Personal life.
Powell married Alma Johnson on August 25, 1962. Their son, Michael Powell, was the chairman of the Federal Communications Commission (FCC) from 2001 to 2005. His daughters are Linda Powell, an actress, and Annemarie Powell. As a hobby, Powell restores old Volvo and Saab cars. In 2013, he faced questions about a relationship with a Romanian diplomat, after a hacked AOL email account had been made public. He acknowledged a "very personal" email relationship but denied further involvement.
Civilian awards and honors.
Powell's civilian awards include two Presidential Medals of Freedom, the President's Citizens Medal, the Congressional Gold Medal, the Secretary of State Distinguished Service Medal, the Secretary of Energy Distinguished Service Medal, and the Ronald Reagan Freedom Award. Several schools and other institutions have been named in his honor and he holds honorary degrees from universities and colleges across the country.

</doc>
<doc id="6985" url="http://en.wikipedia.org/wiki?curid=6985" title="Chlorophyll">
Chlorophyll

Chlorophyll (also chlorophyl) is a green pigment found in cyanobacteria and the chloroplasts of algae and plants. Its name is derived from the Greek words χλωρός, "chloros" ("green") and φύλλον, "phyllon" ("leaf"). Chlorophyll is an extremely important biomolecule, critical in photosynthesis, which allows plants to absorb energy from light. Chlorophyll absorbs light most strongly in the blue portion of the electromagnetic spectrum, followed by the red portion. Conversely, it is a poor absorber of green and near-green portions of the spectrum, hence the green color of chlorophyll-containing tissues. Chlorophyll was first isolated by Joseph Bienaimé Caventou and Pierre Joseph Pelletier in 1817.
Chlorophyll and photosynthesis.
Chlorophyll is vital for photosynthesis, which allows plants to absorb energy from light.
Chlorophyll molecules are specifically arranged in and around photosystems that are embedded in the thylakoid membranes of chloroplasts. In these complexes, chlorophyll serves two primary functions. The function of the vast majority of chlorophyll (up to several hundred molecules per photosystem) is to absorb light and transfer that light energy by resonance energy transfer to a specific chlorophyll pair in the reaction center of the photosystems.
The two currently accepted photosystem units are Photosystem II and Photosystem I, which have their own distinct reaction center chlorophylls, named P680 and P700, respectively. These pigments are named after the wavelength (in nanometers) of their red-peak absorption maximum. The identity, function and spectral properties of the types of chlorophyll in each photosystem are distinct and determined by each other and the protein structure surrounding them. Once extracted from the protein into a solvent (such as acetone or methanol), these chlorophyll pigments can be separated in a simple paper chromatography experiment and, based on the number of polar groups between chlorophyll a and chlorophyll b, will chemically separate out on the paper.
The function of the reaction center chlorophyll is to use the energy absorbed by and transferred to it from the other chlorophyll pigments in the photosystems to undergo a charge separation, a specific redox reaction in which the chlorophyll donates an electron into a series of molecular intermediates called an electron transport chain. The charged reaction center chlorophyll (P680+) is then reduced back to its ground state by accepting an electron. In Photosystem II, the electron that reduces P680+ ultimately comes from the oxidation of water into O2 and H+ through several intermediates. This reaction is how photosynthetic organisms such as plants produce O2 gas, and is the source for practically all the O2 in Earth's atmosphere. Photosystem I typically works in series with Photosystem II; thus the P700+ of Photosystem I is usually reduced, via many intermediates in the thylakoid membrane, by electrons ultimately from Photosystem II. Electron transfer reactions in the thylakoid membranes are complex, however, and the source of electrons used to reduce P700+ can vary.
The electron flow produced by the reaction center chlorophyll pigments is used to shuttle H+ ions across the thylakoid membrane, setting up a chemiosmotic potential used mainly to produce ATP chemical energy; and those electrons ultimately reduce NADP+ to NADPH, a universal reductant used to reduce CO2 into sugars as well as for other biosynthetic reductions.
Reaction center chlorophyll–protein complexes are capable of directly absorbing light and performing charge separation events without other chlorophyll pigments, but the absorption cross section (the likelihood of absorbing a photon under a given light intensity) is small. Thus, the remaining chlorophylls in the photosystem and antenna pigment protein complexes associated with the photosystems all cooperatively absorb and funnel light energy to the reaction center. Besides chlorophyll "a", there are other pigments, called accessory pigments, which occur in these pigment–protein antenna complexes.
A green sea slug, "Elysia chlorotica", has been found to use the chlorophyll it has eaten to perform photosynthesis for itself. This process is known as kleptoplasty, and no other animal has been found to have this ability.
Chemical structure.
Chlorophyll is a chlorin pigment, which is structurally similar to and produced through the same metabolic pathway as other porphyrin pigments such as heme. At the center of the chlorin ring is a magnesium ion. At the time of its discovery in the early 1900s, this was the first time that this element had been detected in living tissue. For the structures depicted in this article, some of the ligands attached to the Mg2+ center are omitted for clarity. The chlorin ring can have several different side chains, usually including a long phytol chain. There are a few different forms that occur naturally, but the most widely distributed form in terrestrial plants is chlorophyll "a". After initial work done by German chemist Richard Willstätter spanning from 1905 to 1915, the general structure of chlorophyll "a" was elucidated by Hans Fischer in 1940. By 1960, when most of the stereochemistry of chlorophyll "a" was known, Robert Burns Woodward published a total synthesis of the molecule. In 1967, the last remaining stereochemical elucidation was completed by Ian Fleming, and in 1990 Woodward and co-authors published an updated synthesis. Chlorophyll f was announced to be present in cyanobacteria and other oxygenic microorganisms that form stromatolites in 2010; a molecular formula of C55H70O6N4Mg and a structure of (2-formyl)-chlorophyll "a" were deduced based on NMR, optical and mass spectra. The different structures of chlorophyll are summarized below:
When leaves degreen in the process of plant senescence, chlorophyll is converted to a group of colourless tetrapyrroles known as nonfluorescent chlorophyll catabolites (NCC's) with the general structure:
These compounds have also been identified in several ripening fruits.
Spectrophotometry.
Measurement of the absorption of light is complicated by the solvent used to extract it from plant material, which affects the values obtained,
By measuring the absorption of light in the red and far red regions it is possible to estimate the concentration of chlorophyll within a leaf. 
<br>In his scientific paper Gitelson (1999) states, "The ratio between chlorophyll fluorescence, at 735 nm and the wavelength range 700nm to 710 nm, F735/F700 was found to be linearly proportional to the chlorophyll content (with determination coefficient, r2, more than 0.95) and thus this ratio can be used as a precise indicator of chlorophyll content in plant leaves." The fluorescent ratio chlorophyll content meters use this technique.
Biosynthesis.
In plants, chlorophyll may be synthesized from succinyl-CoA and glycine, although the immediate precursor to chlorophyll "a" and "b" is protochlorophyllide. In Angiosperm plants, the last step, conversion of protochlorophyllide to chlorophyll, is light-dependent and such plants are pale (etiolated) if grown in the darkness. Non-vascular plants and green algae have an additional light-independent enzyme and grow green in the darkness instead.
Chlorophyll itself is bound to proteins and can transfer the absorbed energy in the required direction. Protochlorophyllide occurs mostly in the free form and, under light conditions, acts as a photosensitizer, forming highly toxic free radicals. Hence, plants need an efficient mechanism of regulating the amount of chlorophyll precursor. In angiosperms, this is done at the step of aminolevulinic acid (ALA), one of the intermediate compounds in the biosynthesis pathway. Plants that are fed by ALA accumulate high and toxic levels of protochlorophyllide; so do the mutants with the damaged regulatory system.
Chlorosis is a condition in which leaves produce insufficient chlorophyll, turning them yellow. Chlorosis can be caused by a nutrient deficiency of iron—called iron chlorosis—or by a shortage of magnesium or nitrogen. Soil pH sometimes plays a role in nutrient-caused chlorosis; many plants are adapted to grow in soils with specific pH levels and their ability to absorb nutrients from the soil can be dependent on this. Chlorosis can also be caused by pathogens including viruses, bacteria and fungal infections, or sap-sucking insects.
Complementary light absorbance of anthocyanins with chlorophylls.
Anthocyanins are other plant pigments. The absorbance pattern responsible for the red color of anthocyanins may be complementary to that of green chlorophyll in photosynthetically active tissues such as young "Quercus coccifera" leaves. It may protect the leaves from attacks by plant eaters that may be attracted by green color.
Culinary use.
Chlorophyll is registered as a food additive (colorant), and its E number is E140. Chefs use chlorophyll to color a variety of foods and beverages green, such as pasta and absinthe. Chlorophyll is not soluble in water, and it is first mixed with a small quantity of vegetable oil to obtain the desired solution. Extracted liquid chlorophyll was considered to be unstable and always denatured until 1997, when Frank S. & Lisa Sagliano used freeze-drying of liquid chlorophyll at the University of Florida and stabilized it as a powder, preserving it for future use.
Alternative medicine.
There are many claims that are made about the healing properties of chlorophyll but most have been disproved or are exaggerated by the companies that are marketing them. Quackwatch, a website dedicated to debunking false medical claims, has a quote from Toledo Blade (1952) which claims "Chlorophyll Held Useless As Body Deodorant", but later has John C. Kephart pointing out "No deodorant effect can possibly occur from the quantities of chlorophyll put in products such as gum, foot powder, cough drops, etc. To be effective, large doses must be given internally".

</doc>
<doc id="6986" url="http://en.wikipedia.org/wiki?curid=6986" title="Carotene">
Carotene

The term carotene (also carotin, from the Latin "carota", or carrot) is used for several related unsaturated hydrocarbon substances having the formula C40Hx, which are synthesized by plants but cannot be made by animals. Carotene is an orange photosynthetic pigment important for photosynthesis. Carotenes are all coloured to the human eye. They are responsible for the orange colour of the carrot, for which this class of chemicals is named, and for the colours of many other fruits and vegetables (for example, sweet potatoes, chanterelle and orange cantaloupe melon). Carotenes are also responsible for the orange (but not all of the yellow) colours in dry foliage. They also (in lower concentrations) impart the yellow coloration to milk-fat and butter. Omnivorous animal species which are relatively poor converters of coloured dietary carotenoids to colourless retinoids have yellowed-coloured body fat, as a result of the carotenoid retention from the vegetable portion of their diet. The typical yellow-coloured fat of humans and chickens is a result of fat storage of carotenes from their diets.
Carotenes contribute to photosynthesis by transmitting the light energy they absorb to chlorophyll. They also protect plant tissues by helping to absorb the energy from singlet oxygen, an excited form of the oxygen molecule O2 which is formed during photosynthesis.
β-Carotene is composed of two retinyl groups, and is broken down in the mucosa of the human small intestine by β-carotene 15,15'-monooxygenase to retinal, a form of vitamin A. β-Carotene can be stored in the liver and body fat and converted to retinal as needed, thus making it a form of vitamin A for humans and some other mammals. The carotenes α-carotene and γ-carotene, due to their single retinyl group (β-ionone ring), also have some vitamin A activity (though less than β-carotene), as does the xanthophyll carotenoid β-cryptoxanthin. All other carotenoids, including lycopene, have no beta-ring and thus no vitamin A activity (although they may have antioxidant activity and thus biological activity in other ways).
Animal species differ greatly in their ability to convert retinyl (beta-ionone) containing carotenoids to retinals. Carnivores in general are poor converters of dietary ionone-containing carotenoids. Pure carnivores such as ferrets lack β-carotene 15,15'-monooxygenase and cannot convert any carotenoids to retinals at all (resulting in carotenes not being a form of vitamin A for this species); while cats can convert a trace of β-carotene to retinol, although the amount is totally insufficient for meeting their daily retinol needs.
Molecular structure.
Chemically, carotenes are polyunsaturated hydrocarbons containing 40 carbon atoms per molecule, variable numbers of hydrogen atoms, and no other elements. Some carotenes are terminated by hydrocarbon rings, on one or both ends of the molecule. All are coloured to the human eye, due to extensive systems of conjugated double bonds. Structurally carotenes are tetraterpenes, meaning that they are synthesized biochemically from four 10-carbon terpene units, which in turn are formed from eight 5-carbon isoprene units.
Carotenes are found in plants in two primary forms designated by characters from the Greek alphabet: alpha-carotene (α-carotene) and beta-carotene (β-carotene). Gamma-, delta-, epsilon-, and zeta-carotene (γ, δ, ε, and ζ-carotene) also exist. Since they are hydrocarbons, and therefore contain no oxygen, carotenes are fat-soluble and insoluble in water (in contrast with other carotenoids, the xanthophylls, which contain oxygen and thus are less chemically hydrophobic).
Dietary sources.
The following foods are particularly rich in carotenes (also see Vitamin A article for amounts):
Absorption from these foods is enhanced if eaten with fats, as carotenes are fat soluble, and if the food is cooked for a few minutes until the plant cell wall splits and the colour is released into any liquid. 6 μg of dietary β-carotene supplies the equivalent of 1 μg of retinol, or 1 RE (Retinol Equivalent). This is equivalent to 3⅓ IU of vitamin A.
The multiple forms.
The two primary isomers of carotene, α-carotene and β-carotene, differ in the position of a double bond (and thus a hydrogen) in the cyclic group at one end (left in the diagram here).
β-Carotene is the more common form and can be found in yellow, orange, and green leafy fruits and vegetables. As a rule of thumb, the greater the intensity of the orange colour of the fruit or vegetable, the more β-carotene it contains.
Carotene protects plant cells against the destructive effects of ultraviolet light. β-Carotene is an antioxidant.
β-Carotene and cancer.
It has been shown in trials that the ingestion of β-carotene supplements at about 30 mg/day (10 times the Reference Daily Intake) increases the rate of lung and prostate cancer development in smokers and people with a history of asbestos exposure.
An article on the American Cancer Society says that The Cancer Research Campaign has called for warning labels on β-carotene supplements to caution smokers that such supplements may increase the risk of lung cancer.
The New England Journal of Medicine published an article in 1994 about a trial which examined the relationship between daily supplementation of β-carotene and vitamin E (α-tocopherol) and the incidence of lung cancer. The study was done using supplements and researchers were aware of the epidemiological correlation between carotenoid-rich fruits and vegetables and lower lung cancer rates. The research concluded that no reduction in lung cancer was found in the participants using these supplements, and furthermore, these supplements may, in fact, have harmful effects.
The Journal of the National Cancer Institute and The New England Journal of Medicine published articles in 1996 about a trial that was conducted to determine if vitamin A (in the form of retinyl palmitate) and β-carotene had any beneficial effects to prevent cancer. The results indicated an increased risk of lung cancer for the participants who consumed the β-carotene supplement and who had lung irritation from smoking or asbestos exposure, causing the trial to be stopped early.
A review of all randomized controlled trials in the scientific literature by the Cochrane Collaboration published in "JAMA" in 2007 found that synthetic β-carotene "increased" mortality by something between 1 and 8% (Relative Risk 1.05, 95% confidence interval 1.01–1.08). However, this meta-analysis included two large studies of smokers, so it is not clear that the results apply to the general population. The review only studied the influence of synthetic antioxidants and the results should not be translated to potential effects of fruits and vegetables.
β-Carotene and cognition.
A recent report demonstrated that 50 mg of β-carotene every other day prevented cognitive decline in a study of over 4000 physicians at a mean treatment duration of 18 years.
β-Carotene and photosensitivity.
Oral β-carotene is prescribed to people suffering from erythropoietic protoporphyria. It provides them some relief from photosensitivity.
β-Carotene and nanotechnology.
β-Carotene and lycopene molecules can be encapsulated into carbon nanotubes enhancing the optical properties of carbon nanotubes. Efficient energy transfer occurs between the encapsulated dye and nanotube — light is absorbed by the dye and without significant loss is transferred to the single wall carbon nanotube (SWCNT). Encapsulation increases chemical and thermal stability of carotene molecules; it also allows their isolation and individual characterization.
Carotenemia.
Carotenemia or hypercarotenemia is excess carotene, but unlike excess vitamin A, carotene is non-toxic. Although hypercarotenemia is not particularly dangerous, it can lead to an oranging of the skin (carotenodermia), but not the conjunctiva of eyes (thus easily distinguishing it visually from jaundice). It is most commonly associated with consumption of an abundance of carrots, but it also can be a medical sign of more dangerous conditions.
Production.
Most of the world's synthetic supply of carotene comes from a manufacturing complex located in Freeport, Texas and owned by DSM. The other major supplier BASF also uses a chemical process to produce β-carotene. Together these suppliers account for about 85% of the β-carotene on the market. In Spain Vitatene produces natural β-carotene from fungus Blakeslea trispora, as does DSM but at much lower amount when compared to its synthetic β-carotene operation. In Australia, organic β-carotene is produced by Aquacarotene Limited from dried marine algae "Dunaliella salina" grown in harvesting ponds situated in Karratha, Western Australia. BASF Australia is also producing β-carotene from microalgae grown in two sites in Australia that are the world’s largest algae farms. In Portugal, the industrial biotechnology company Biotrend is producing natural all-"trans"-β-carotene from a non genetically modified bacteria of the "Sphingomonas" genus isolated from soil.
Carotenes are also found in palm oil, corn, and in the milk of dairy cows, causing cow's milk to be light yellow, depending on the feed of the cattle, and the amount of fat in the milk (high-fat milks, such as those produced by Guernsey cows, tend to be more yellow because their fat content causes them to contain more carotene).
Carotenes are also found in some species of termites, where they apparently have been picked up from the diet of the insects.
Total synthesis.
There are currently two commonly used methods of total synthesis of β-carotene. The first was developed by the Badische Anilin- & Soda-Fabrik (BASF) and is based on the Wittig reaction with Wittig himself as patent holder:
The second is a Grignard reaction, elaborated by Hoffman-La Roche from the original synthesis of Inhoffen et al. They are both symmetrical; the BASF synthesis is C20 + C20, and the Hoffman-La Roche synthesis is C19 + C2 + C19.
Nomenclature.
Carotenes are carotenoids containing no oxygen. Carotenoids containing some oxygen are known as xanthophylls.
The two ends of the β-carotene molecule are structurally identical, and are called β-rings. Specifically, the group of nine carbon atoms at each end form a β-ring.
The α-carotene molecule has a β-ring at one end; the other end is called an ε-ring. There is no such thing as an "α-ring".
These and similar names for the ends of the carotenoid molecules form the basis of a systematic naming scheme, according to which:
ζ-Carotene is the biosynthetic precursor of neurosporene, which is the precursor of lycopene, which, in turn, is the precursor of the carotenes α through ε.
Food additive.
Carotene is also used as a substance to colour products such as juice, cakes, desserts, butter and margarine. It is approved for use as a food additive in the EU (listed as additive E160a) Australia and New Zealand (listed as 160a) and the USA.

</doc>
<doc id="6988" url="http://en.wikipedia.org/wiki?curid=6988" title="Cyclic adenosine monophosphate">
Cyclic adenosine monophosphate

Cyclic adenosine monophosphate (cAMP, cyclic AMP or 3'-5'-cyclic adenosine monophosphate) is a second messenger important in many biological processes. cAMP is derived from adenosine triphosphate (ATP) and used for intracellular signal transduction in many different organisms, conveying the cAMP-dependent pathway.
History.
Earl Sutherland of Case Western Reserve University won a Nobel Prize in Physiology or Medicine in 1971 "for his discoveries concerning the mechanisms of the action of hormones," especially epinephrine, via second messengers (such as cyclic adenosine monophosphate, cyclic AMP).
Synthesis and decomposition.
cAMP is synthesized from ATP by adenylyl cyclase located on the inner side of the plasma membrane and anchored at various locations in the interior of the cell. Adenylyl Cyclase is activated by a range of signaling molecules through the activation of adenylyl cyclase stimulatory G (Gs)-protein-coupled receptors and inhibited by agonists of adenylyl cyclase inhibitory G (Gi)-protein-coupled receptors. Liver adenylyl cyclase responds more strongly to glucagon, and muscle adenylyl cyclase responds more strongly to adrenaline.
cAMP decomposition into AMP is catalyzed by the enzyme phosphodiesterase.
Functions.
cAMP is a second messenger, used for intracellular signal transduction, such as transferring into cells the effects of hormones like glucagon and adrenaline, which cannot pass through the plasma membrane. It is involved in the activation of protein kinases and regulates the effects of adrenaline and glucagon. cAMP also binds to and regulates the function of ion channels such as the HCN channels and a few other cyclic nucleotide-binding proteins such as Epac1 and RAPGEF2.
Role of cAMP in eukaryotic cells.
cAMP and its associated kinases function in several biochemical processes, including the regulation of glycogen, sugar, and lipid metabolism.
In eukaryotes, cyclic AMP works by activating protein kinase A (PKA, or cAMP-dependent protein kinase). PKA is normally inactive as a tetrameric holoenzyme, consisting of two catalytic and two regulatory units (C2R2), with the regulatory units blocking the catalytic centers of the catalytic units. Cyclic AMP binds to specific locations on the regulatory units of the protein kinase, and causes dissociation between the regulatory and catalytic subunits, thus activating the catalytic units and enabling them to phosphorylate substrate proteins.
The active subunits catalyze the transfer of phosphate from ATP to specific serine or threonine residues of protein substrates. The phosphorylated proteins may act directly on the cell's ion channels, or may become activated or inhibited enzymes. Protein kinase A can also phosphorylate specific proteins that bind to promoter regions of DNA, causing increased expression of specific genes. Not all protein kinases respond to cAMP. Several classes of protein kinases, including protein kinase C, are not cAMP-dependent.
Further effects mainly depend on cAMP-dependent protein kinase, which vary based on the type of cell.
Still, there are some minor PKA-independent functions of cAMP, e.g., activation of calcium channels, providing a minor pathway by which growth hormone-releasing hormone causes a release of growth hormone.
However, the view that the majority of the effects of cAMP are controlled by PKA is an outdated one. In 1998 a family of cAMP-sensitive proteins with guanine nucleotide exchange factor (GEF) activity was discovered. These are termed Exchange proteins activated by cAMP (Epac) and the family comprises Epac1 and Epac2 . The mechanism of activation is similar to that of PKA: the GEF domain is usually masked by the N-terminal region containing the cAMP binding domain. When cAMP binds, the domain dissociates and exposes the now-active GEF domain, allowing Epac to activate small Ras-like GTPase proteins, such as Rap1.
Additional role of secreted cAMP in social amoebas.
In the species "Dictyostelium discoideum", cAMP acts outside the cell as a secreted signal. The chemotactic aggregation of cells is organized by periodic waves of cAMP that propagate between cells over distances as large as several centimetres. The waves are the result of a regulated production and secretion of extracellular cAMP and a spontaneous biological oscillator that initiates the waves at centers of territories.
Role of cAMP in bacteria.
In bacteria, the level of cAMP varies depending on the medium used for growth. In particular, cAMP is low when glucose is the carbon source. This occurs through inhibition of the cAMP-producing enzyme, adenylate cyclase, as a side-effect of glucose transport into the cell. The transcription factor cAMP receptor protein (CRP) also called CAP (catabolite gene activator protein) forms a complex with cAMP and thereby is activated to bind to DNA. CRP-cAMP increases expression of a large number of genes, including some encoding enzymes that can supply energy independent of glucose.
cAMP, for example, is involved in the positive regulation of the lac operon. In an environment of a low glucose concentration, cAMP accumulates and binds to the allosteric site on CRP (cAMP receptor protein), a transcription activator protein. The protein assumes its active shape and binds to a specific site upstream of the lac promoter, making it easier for RNA polymerase to bind to the adjacent promoter to start transcription of the lac operon, increasing the rate of lac operon transcription. With a high glucose concentration, the cAMP concentration decreases, and the CRP disengages from the lac operon.
Pathology.
Role of cAMP in human carcinoma.
Some research has suggested that a deregulation of cAMP pathways and an aberrant activation of cAMP-controlled genes is linked to the growth of some cancers.
Role of cAMP in prefrontal cortex disorders.
Recent research suggests that cAMP affects the function of higher-order thinking in the prefrontal cortex through its regulation of ion channels called hyperpolarization-activated cyclic nucleotide-gated channels (HCN). When cAMP stimulates the HCN, the channels open, closing the brain cell to communication and thus interfering with the function of the prefrontal cortex. This research, especially the cognitive deficits in age-related illnesses and ADHD, is of interest to researchers studying the brain.

</doc>
<doc id="6991" url="http://en.wikipedia.org/wiki?curid=6991" title="Cimabue">
Cimabue

Cimabue (; 1240 – 1302), also known as Cenni Di Pepi or in modern Italian, Benvenuto di Giuseppe, was a Florentine painter and creator of mosaics.
Cimabue is generally regarded as one of the first great Italian painters to break away from the Italo-Byzantine style, although he still relied on Byzantine models. The art of this period comprised scenes and forms that appeared relatively flat and highly stylized. Cimabue was a pioneer in the move towards naturalism, as his figures were depicted with rather more lifelike proportions and shading. Even though he was a pioneer in that move, his "Maestà" paintings show Medieval techniques and characteristics.
According to Giorgio Vasari, he was the teacher of Giotto, considered the first great artist of the Italian Renaissance.
Life.
Owing to little surviving documentation, not much is known about Cimabue's life. He was born in Florence and died in Pisa. His career was described in Giorgio Vasari's "Lives of the Most Excellent Painters, Sculptors, and Architects". Although it is one of the few early records about him, its accuracy is uncertain.
He perhaps trained in Florence under unknown masters culturally connected to Byzantine art. However, his first attributed work, the "Crucifixion" in the church of San Domenico in Arezzo (assigned to him by Italian art historian Pietro Toesca and dated to around 1270), he departed from the Byzantine style. His style was at the time more reminiscent of works such as the "Christus patiens" (c. 1250) by Giunta Pisano, although Cimabue's Christ is more bent and the clothes have the golden striations introduced by Coppo di Marcovaldo.
Around 1272 he is documented in Rome. A little later, he made another "Crucifixion" for the Florentine church of Santa Croce (incidentally: damaged by the 1966 Arno River flood). This is a larger and more evoluted work than that in Arezzo, with traces of naturalism perhaps inspired by Nicola Pisano's works. In the same period (c. 1280) he painted the "Maestà" now at the Louvre Museum, originally in the church of San Francesco at Pisa. This work established a style which was followed by numerous artists after him, including Duccio di Buoninsegna in his "Rucellai Madonna" (once wrongly attributed to Cimabue), as well as Giotto himself. Other works dating to this period, in which the influence of his pupil Giotto becomes manifest, include a "Flagellation" (Frick Collection), mosaics for the Baptistery of Florence (now largely restored), the "Maestà" at the Santa Maria dei Servi in Bologna and the "Madonna" in the Pinacoteca of Castelfiorentino. A workshop painting, perhaps assignable to a slightly later period, is the "Maestà with Saints Francis and Dominic" now at the Uffizi.
During the pontificate of Pope Nicholas IV, the first Franciscan pope, Cimabue worked at Assisi. His call was perhaps due to the fame he gained in Rome in 1272, although no works from his stay there are known. At Assisi, in the transept of the Lower Basilica of San Francesco, he frescoed a "Madonna with Child Enthroned, Four Angels and St. Francis"; the left part of the work is missing, and perhaps showed St. Antony of Padua. The authorship of the painting has been recently disputed for technical and stylistic reasons, however. Cimabue was subsequently commissioned the decoration of the apse and the transept of the Upper Basilica of Assisi, in the same period in which Roman artists were frescoing the nave. The cycle comprises scenes from the Gospels, the life of Mary and of St. Peter and St. Paul, and is today in poor condition due to the oxidation of the brighter colors.
The "Maestà of Santa Trinita", originally painted for the church of Santa Trinita in Florence dates to c. 1290–1300. It is now at the Uffizi Gallery. The softer expression of the characters suggests that it was influenced by Giotto, who was by then already active as a solo artist. Cimabue spent the period from 1301 to 1302 in Pisa, where, together with collaborators, he executed the apse mosaic for the city's cathedral. He died in 1302.
Character.
"Cimabue of Florence was a painter who lived during the author's own time, a nobler man than anyone knew but he was as a result so haughty and proud that if someone pointed out to him any mistake or defect in his work, or if he had noted any himself...he would immediately destroy the work, no matter how precious it might be." 
Legacy.
History has long regarded Cimabue as the last of an era that was overshadowed by the Italian Renaissance. As early as 1543, the historian Vasari wrote of Cimabue, "Cimabue was, in one sense, the principle cause of the renewal of painting," with the qualification that, "Giotto truly eclipsed Cimabue's fame just as a great light eclipses a much smaller one."
In Canto XI of his Purgatorio, Dante laments Cimabue's quick loss of public interest in the face of Giotto's revolution in art:
O vanity of human powers,
how briefly lasts the crowning green of glory,
unless an age of darkness follows!
In painting Cimabue thought he held the field
but now it's Giotto has the cry,
so that the other's fame is dimmed.

</doc>
<doc id="6997" url="http://en.wikipedia.org/wiki?curid=6997" title="Corporatocracy">
Corporatocracy

Corporatocracy , is a term used as an economic and political system controlled by corporations or corporate interests. It is a generally pejorative term often used by critics of the current economic situation in a particular country, especially the United States. This is different from corporatism, which is the organisation of society into groups with common interests. Corporatocracy as a term tends to be used by liberal and left-leaning critics, but also some economic libertarian critics and other political observers across the political spectrum. Economist Jeffrey Sachs described the United States as a corporatocracy in his book "The Price of Civilization". He suggested that it arose from four trends: weak national parties and strong political representation of individual districts, the large U.S. military establishment after World War II, big corporate money financing election campaigns, and globalization tilting the balance away from workers.
This collective is what author C Wright Mills called the Power Elite, wealthy individuals who hold prominent positions in corporatocracies. They control the process of determining a society's economic and political policies.
The concept has been used in explanations of bank bailouts, excessive pay for CEOs, as well as complaints such as the exploitation of national treasuries, people, and natural resources. It has been used by critics of globalization, sometimes in conjunction with criticism of the World Bank or unfair lending practices, as well as criticism of "free trade agreements".
Historical corporatocracies.
Corporations have held the right to vote in some jurisdictions. For example, Livery Companies currently appoint most of the voters for the City of London Corporation, which is the municipal government for the area centered on the financial district.

</doc>
